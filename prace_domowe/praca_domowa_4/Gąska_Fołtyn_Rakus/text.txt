

<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="applicable-device" content="pc,mobile">
    <meta name="access" content="Yes">

    
    
    
        <meta name="twitter:site" content="@SpringerLink"/>
    
        <meta name="twitter:card" content="summary_large_image"/>
    
        <meta name="twitter:image:alt" content="Content cover image"/>
    
        <meta name="twitter:title" content="Computer-aided detection of pulmonary nodules: a comparative study using the public LIDC/IDRI database"/>
    
        <meta name="twitter:description" content="European Radiology - To benchmark the performance of state-of-the-art computer-aided detection (CAD) of pulmonary nodules using the largest publicly available annotated CT database (LIDC/IDRI), and..."/>
    
        <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/330/26/7.jpg"/>
    
        <meta name="journal_id" content="330"/>
    
        <meta name="dc.title" content="Computer-aided detection of pulmonary nodules: a comparative study using the public LIDC/IDRI database"/>
    
        <meta name="dc.source" content="European Radiology 2015 26:7"/>
    
        <meta name="dc.format" content="text/html"/>
    
        <meta name="dc.publisher" content="Springer"/>
    
        <meta name="dc.date" content="2015-10-06"/>
    
        <meta name="dc.type" content="OriginalPaper"/>
    
        <meta name="dc.language" content="En"/>
    
        <meta name="dc.copyright" content="2015 The Author(s)"/>
    
        <meta name="dc.rights" content="2015 The Author(s)"/>
    
        <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    
        <meta name="dc.description" content="To benchmark the performance of state-of-the-art computer-aided detection (CAD) of pulmonary nodules using the largest publicly available annotated CT database (LIDC/IDRI), and to show that CAD finds lesions not identified by the LIDC&#8217;s four-fold double reading process. The LIDC/IDRI database contains 888 thoracic CT scans with a section thickness of 2.5&amp;nbsp;mm or lower. We report performance of two commercial and one academic CAD system. The influence of presence of contrast, section thickness, and reconstruction kernel on CAD performance was assessed. Four radiologists independently analyzed the false positive CAD marks of the best CAD system. The updated commercial CAD system showed the best performance with a sensitivity of 82&amp;nbsp;% at an average of 3.1 false positive detections per scan. Forty-five false positive CAD marks were scored as nodules by all four radiologists in our study. On the largest publicly available reference database for lung nodule detection in chest CT, the updated commercial CAD system locates the vast majority of pulmonary nodules at a low false positive rate. Potential for CAD is substantiated by the fact that it identifies pulmonary nodules that were not marked during the extensive four-fold LIDC annotation process. &#8226; CAD systems should be validated on public, heterogeneous databases. &#8226; The LIDC/IDRI database is an excellent database for benchmarking nodule CAD. &#8226; CAD can identify the majority of pulmonary nodules at a low false positive rate. &#8226; CAD can identify nodules missed by an extensive two-stage annotation process."/>
    
        <meta name="prism.issn" content="1432-1084"/>
    
        <meta name="prism.publicationName" content="European Radiology"/>
    
        <meta name="prism.publicationDate" content="2015-10-06"/>
    
        <meta name="prism.volume" content="26"/>
    
        <meta name="prism.number" content="7"/>
    
        <meta name="prism.section" content="OriginalPaper"/>
    
        <meta name="prism.startingPage" content="2139"/>
    
        <meta name="prism.endingPage" content="2147"/>
    
        <meta name="prism.copyright" content="2015 The Author(s)"/>
    
        <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    
        <meta name="prism.url" content="https://link.springer.com/article/10.1007/s00330-015-4030-7"/>
    
        <meta name="prism.doi" content="doi:10.1007/s00330-015-4030-7"/>
    
        <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s00330-015-4030-7.pdf"/>
    
        <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s00330-015-4030-7"/>
    
        <meta name="citation_journal_title" content="European Radiology"/>
    
        <meta name="citation_journal_abbrev" content="Eur Radiol"/>
    
        <meta name="citation_publisher" content="Springer Berlin Heidelberg"/>
    
        <meta name="citation_issn" content="1432-1084"/>
    
        <meta name="citation_title" content="Computer-aided detection of pulmonary nodules: a comparative study using the public LIDC/IDRI database"/>
    
        <meta name="citation_volume" content="26"/>
    
        <meta name="citation_issue" content="7"/>
    
        <meta name="citation_publication_date" content="2016/07"/>
    
        <meta name="citation_online_date" content="2015/10/06"/>
    
        <meta name="citation_firstpage" content="2139"/>
    
        <meta name="citation_lastpage" content="2147"/>
    
        <meta name="citation_article_type" content="Computer Applications"/>
    
        <meta name="citation_fulltext_world_readable" content=""/>
    
        <meta name="citation_language" content="en"/>
    
        <meta name="dc.identifier" content="doi:10.1007/s00330-015-4030-7"/>
    
        <meta name="DOI" content="10.1007/s00330-015-4030-7"/>
    
        <meta name="citation_doi" content="10.1007/s00330-015-4030-7"/>
    
        <meta name="description" content="To benchmark the performance of state-of-the-art computer-aided detection (CAD) of pulmonary nodules using the largest publicly available annotated CT data"/>
    
        <meta name="dc.creator" content="Jacobs, Colin"/>
    
        <meta name="dc.creator" content="van Rikxoort, Eva M."/>
    
        <meta name="dc.creator" content="Murphy, Keelin"/>
    
        <meta name="dc.creator" content="Prokop, Mathias"/>
    
        <meta name="dc.creator" content="Schaefer-Prokop, Cornelia M."/>
    
        <meta name="dc.creator" content="van Ginneken, Bram"/>
    
        <meta name="dc.subject" content="Imaging / Radiology"/>
    
        <meta name="dc.subject" content="Diagnostic Radiology"/>
    
        <meta name="dc.subject" content="Interventional Radiology"/>
    
        <meta name="dc.subject" content="Neuroradiology"/>
    
        <meta name="dc.subject" content="Ultrasound"/>
    
        <meta name="dc.subject" content="Internal Medicine"/>
    
        <meta name="citation_reference" content="citation_journal_title=Comput Med Imaging Graph; citation_title=Recent progress in computer-aided diagnosis of lung nodules on thin-section CT; citation_author=Q Li; citation_volume=31; citation_publication_date=2007; citation_pages=248-257; citation_doi=10.1016/j.compmedimag.2007.02.005; citation_id=CR1"/>
    
        <meta name="citation_reference" content="citation_journal_title=Mach Vis Appl; citation_title=Automated detection of lung nodules in computed tomography images: a review; citation_author=SLA Lee, AZ Kouzani, EJ Hu; citation_volume=23; citation_publication_date=2012; citation_pages=151-163; citation_doi=10.1007/s00138-010-0271-2; citation_id=CR2"/>
    
        <meta name="citation_reference" content="citation_journal_title=N Engl J Med; citation_title=Reduced lung-cancer mortality with low-dose computed tomographic screening; citation_author=DR Aberle, AM Adams, CD Berg, WC Black, JD Clapp, RM Fagerstrom; citation_volume=365; citation_publication_date=2011; citation_pages=395-409; citation_doi=10.1056/NEJMoa1102873; citation_id=CR3"/>
    
        <meta name="citation_reference" content="citation_journal_title=Ann Intern Med; citation_title=Benefits and harms of computed tomography lung cancer screening strategies: a comparative modeling study for the U.S. Preventive Services Task Force; citation_author=HJ Koning, R Meza, SK Plevritis, K Haaf, VN Munshi, J Jeon; citation_volume=160; citation_publication_date=2014; citation_pages=311-320; citation_doi=10.7326/M13-2316; citation_id=CR4"/>
    
        <meta name="citation_reference" content="citation_journal_title=N Engl J Med; citation_title=Cost-effectiveness of CT screening in the National Lung Screening Trial; citation_author=WC Black, IF Gareen, SS Soneji, JD Sicks, EB Keeler, DR Aberle; citation_volume=371; citation_publication_date=2014; citation_pages=1793-1802; citation_doi=10.1056/NEJMoa1312547; citation_id=CR5"/>
    
        <meta name="citation_reference" content="citation_journal_title=J Thorac Imaging; citation_title=Expert opinion: barriers to CT screening for lung cancer; citation_author=DR Aberle, CI Henschke, TC McLoud, PM Boiselle; citation_volume=27; citation_publication_date=2012; citation_pages=208; citation_doi=10.1097/RTI.0b013e318253d74d; citation_id=CR6"/>
    
        <meta name="citation_reference" content="citation_journal_title=Semin Respir Crit Care Med; citation_title=Lung cancer screening: the radiologist&#39;s perspective; citation_author=M Prokop; citation_volume=35; citation_publication_date=2014; citation_pages=91-98; citation_doi=10.1055/s-0033-1363455; citation_id=CR7"/>
    
        <meta name="citation_reference" content="citation_journal_title=Radiology; citation_title=Lung image database consortium: developing a resource for the medical imaging research community; citation_author=SG Armato, G McLennan, MF McNitt-Gray, CR Meyer, D Yankelevitz, DR Aberle; citation_volume=232; citation_publication_date=2004; citation_pages=739-748; citation_doi=10.1148/radiol.2323032035; citation_id=CR8"/>
    
        <meta name="citation_reference" content="citation_journal_title=Med Image Anal; citation_title=Comparing and combining algorithms for computer-aided detection of pulmonary nodules in computed tomography scans: the ANODE09 study; citation_author=B Ginneken, SG Armato, B Hoop, S Vorst, T Duindam, M Niemeijer; citation_volume=14; citation_publication_date=2010; citation_pages=707-722; citation_doi=10.1016/j.media.2010.05.005; citation_id=CR9"/>
    
        <meta name="citation_reference" content="citation_journal_title=Med Phys; citation_title=The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): a completed reference database of lung nodules on CT scans; citation_author=SG Armato, G McLennan, L Bidaut, MF McNitt-Gray, CR Meyer, AP Reeves; citation_volume=38; citation_publication_date=2011; citation_pages=915-931; citation_doi=10.1118/1.3528204; citation_id=CR10"/>
    
        <meta name="citation_reference" content="citation_journal_title=Med Image Anal; citation_title=A large scale evaluation of automatic pulmonary nodule detection in chest ct using local image features and k-nearest-neighbour classification; citation_author=K Murphy, B Ginneken, AMR Schilham, BJ Hoop, HA Gietema, M Prokop; citation_volume=13; citation_publication_date=2009; citation_pages=757-770; citation_doi=10.1016/j.media.2009.07.001; citation_id=CR11"/>
    
        <meta name="citation_reference" content="citation_journal_title=Med Phys; citation_title=Observer studies involving detection and localization: modeling, analysis, and validation; citation_author=DP Chakraborty, KS Berbaum; citation_volume=31; citation_publication_date=2004; citation_pages=2313-2330; citation_doi=10.1118/1.1769352; citation_id=CR12"/>
    
        <meta name="citation_reference" content="citation_journal_title=Ann Stat; citation_title=Bootstrap methods: another look at the jackknife; citation_author=B Efron; citation_volume=7; citation_publication_date=1979; citation_pages=1-29; citation_doi=10.1214/aos/1176344552; citation_id=CR13"/>
    
        <meta name="citation_reference" content="citation_journal_title=Radiology; citation_title=Fleischner society: glossary of terms for thoracic imaging; citation_author=DM Hansell, AA Bankier, H MacMahon, TC McLoud, NL M&#252;ller, J Remy; citation_volume=246; citation_publication_date=2008; citation_pages=697-722; citation_doi=10.1148/radiol.2462070712; citation_id=CR14"/>
    
        <meta name="citation_reference" content="citation_journal_title=Acad Radiol; citation_title=Assessment of radiologist performance in the detection of lung nodules: dependence on the definition of &#8220;truth&#8221;; citation_author=SG Armato, RY Roberts, M Kocherginsky, DR Aberle, EA Kazerooni, H Macmahon; citation_volume=16; citation_publication_date=2009; citation_pages=28-38; citation_doi=10.1016/j.acra.2008.05.022; citation_id=CR15"/>
    
        <meta name="citation_reference" content="citation_journal_title=Acad Radiol; citation_title=The Lung Image Database Consortium (LIDC): an evaluation of radiologist variability in the identification of lung nodules on CT scans; citation_author=SG Armato, MF McNitt-Gray, AP Reeves, CR Meyer, G McLennan, DR Aberle; citation_volume=14; citation_publication_date=2007; citation_pages=1409-1421; citation_doi=10.1016/j.acra.2007.07.008; citation_id=CR16"/>
    
        <meta name="citation_reference" content="citation_journal_title=Radiology; citation_title=Pulmonary nodules on multi-detector row CT scans: performance comparison of radiologists and computer-aided detection; citation_author=GD Rubin, JK Lyo, DS Paik, AJ Sherbondy, LC Chow, AN Leung; citation_volume=234; citation_publication_date=2005; citation_pages=274-283; citation_doi=10.1148/radiol.2341040589; citation_id=CR17"/>
    
        <meta name="citation_reference" content="citation_journal_title=Med Image Anal; citation_title=Automatic detection of subsolid pulmonary nodules in thoracic computed tomography images; citation_author=C Jacobs, EM Rikxoort, T Twellmann, ET Scholten, PA Jong, JM Kuhnigk; citation_volume=18; citation_publication_date=2014; citation_pages=374-384; citation_doi=10.1016/j.media.2013.12.001; citation_id=CR18"/>
    
        <meta name="citation_reference" content="citation_journal_title=N Engl J Med; citation_title=Management of lung nodules detected by volume CT scanning; citation_author=RJ Klaveren, M Oudkerk, M Prokop, ET Scholten, K Nackaerts; citation_volume=361; citation_publication_date=2009; citation_pages=2221-2222; citation_doi=10.1056/NEJMoa0906085; citation_id=CR19"/>
    
        <meta name="citation_reference" content="citation_journal_title=J Vis; citation_title=Scanners and drillers: characterizing expert visual search through volumetric images; citation_author=T Drew, ML Vo, A Olwal, F Jacobson, SE Seltzer, JM Wolfe; citation_volume=13; citation_publication_date=2013; citation_pages=1-13; citation_doi=10.1167/13.10.3; citation_id=CR20"/>
    
        <meta name="citation_reference" content="citation_journal_title=Eur Phys J Plus; citation_title=Automatic detection of lung nodules in computed tomography images: training and validation of algorithms using public research databases; citation_author=N Camarlinghi; citation_volume=128; citation_publication_date=2013; citation_pages=1-21; citation_doi=10.1140/epjp/i2013-13110-5; citation_id=CR21"/>
    
        <meta name="citation_reference" content="citation_journal_title=Artif Intell Med; citation_title=Phased searching with NEAT in a time-scaled framework: experiments on a computer-aided detection system for lung nodules; citation_author=M Tan, R Deklerck, J Cornelis, B Jansen; citation_volume=59; citation_publication_date=2013; citation_pages=157-167; citation_doi=10.1016/j.artmed.2013.07.002; citation_id=CR22"/>
    
        <meta name="citation_author" content="Jacobs, Colin"/>
    
        <meta name="citation_author_email" content="colin.jacobs@radboudumc.nl"/>
    
        <meta name="citation_author_institution" content="Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands"/>
    
        <meta name="citation_author" content="van Rikxoort, Eva M."/>
    
        <meta name="citation_author_institution" content="Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands"/>
    
        <meta name="citation_author_institution" content="Fraunhofer MEVIS, Bremen, Germany"/>
    
        <meta name="citation_author" content="Murphy, Keelin"/>
    
        <meta name="citation_author_institution" content="Irish Centre for Fetal and Neonatal Translational Research, University College Cork, Cork, Ireland"/>
    
        <meta name="citation_author" content="Prokop, Mathias"/>
    
        <meta name="citation_author_institution" content="Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands"/>
    
        <meta name="citation_author" content="Schaefer-Prokop, Cornelia M."/>
    
        <meta name="citation_author_institution" content="Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands"/>
    
        <meta name="citation_author_institution" content="Department of Radiology, Meander Medical Center, Amersfoort, The Netherlands"/>
    
        <meta name="citation_author" content="van Ginneken, Bram"/>
    
        <meta name="citation_author_institution" content="Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands"/>
    
        <meta name="citation_author_institution" content="Fraunhofer MEVIS, Bremen, Germany"/>
    
        <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s00330-015-4030-7&amp;api_key="/>
    
        <meta name="format-detection" content="telephone=no"/>
    
        <meta name="citation_cover_date" content="2016/07/01"/>
    

    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s00330-015-4030-7">
        <meta property="og:type" content="article">
        <meta property="og:site_name" content="SpringerLink">
        <meta property="og:title" content="Computer-aided detection of pulmonary nodules: a comparative study using the public LIDC/IDRI database - European Radiology">
        <meta property="og:description" content="Objectives To benchmark the performance of state-of-the-art computer-aided detection (CAD) of pulmonary nodules using the largest publicly available annotated CT database (LIDC/IDRI), and to show that CAD finds lesions not identified by the LIDC’s four-fold double reading process. Methods The LIDC/IDRI database contains 888 thoracic CT scans with a section thickness of 2.5 mm or lower. We report performance of two commercial and one academic CAD system. The influence of presence of contrast, section thickness, and reconstruction kernel on CAD performance was assessed. Four radiologists independently analyzed the false positive CAD marks of the best CAD system. Results The updated commercial CAD system showed the best performance with a sensitivity of 82 % at an average of 3.1 false positive detections per scan. Forty-five false positive CAD marks were scored as nodules by all four radiologists in our study. Conclusions On the largest publicly available reference database for lung nodule detection in chest CT, the updated commercial CAD system locates the vast majority of pulmonary nodules at a low false positive rate. Potential for CAD is substantiated by the fact that it identifies pulmonary nodules that were not marked during the extensive four-fold LIDC annotation process. Key Points • CAD systems should be validated on public, heterogeneous databases. • The LIDC/IDRI database is an excellent database for benchmarking nodule CAD. • CAD can identify the majority of pulmonary nodules at a low false positive rate. • CAD can identify nodules missed by an extensive two-stage annotation process.">
        <meta property="og:image" content="https://media.springernature.com/w200/springer-static/cover/journal/330.jpg">
    

    <title>Computer-aided detection of pulmonary nodules: a comparative study using the public LIDC/IDRI database | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    
        <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) { a{text-decoration:underline;text-decoration-skip-ink:auto}html{text-size-adjust:100%;-webkit-font-smoothing:subpixel-antialiased;box-sizing:border-box;color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:100%;height:100%;line-height:1.61803;overflow-y:scroll}body{background:#fcfcfc;font-size:1.125rem;line-height:1.5;max-width:100%;min-height:100%}article,aside,header,main,nav,section{display:block}h1{font-size:2em;margin:.67em 0}a{background-color:transparent;color:#004b83;overflow-wrap:break-word;word-break:break-word}b{font-weight:bolder}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}svg:not(:root){overflow:hidden}button,input{font-family:sans-serif;font-size:100%}input{line-height:1.15}button,input{overflow:visible}button{text-transform:none}[type=submit],button,html [type=button]{-webkit-appearance:button}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;line-height:inherit}h1,h2{font-weight:400}h1{font-family:Georgia,Palatino,serif;font-size:2rem;font-style:normal;margin-bottom:1em}h2{font-size:1.75rem}.u-h4,h2{font-family:Georgia,Palatino,serif;font-style:normal;margin-bottom:1em}.u-h4{font-size:1.25rem}.c-reading-companion__figure-title,.u-h4{font-weight:700;line-height:1.4}.c-reading-companion__figure-title{font-family:Georgia,Palatino,serif;font-size:1.25rem;font-style:normal}label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}*{box-sizing:inherit}body,button,div,form,input{margin:0;padding:0}p{padding:0}h1,h2{line-height:1.4}p{margin:0}h1,h2,ul{margin-top:0}p{margin-bottom:1.5em;overflow-wrap:break-word;word-break:break-word}p:last-child{margin-bottom:0}p:empty{display:none}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}.c-ad--728x90 iframe{height:90px;max-width:970px}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}.js .u-show-following-ad+.c-ad--728x90{display:block}}.c-ad--300x250{background-color:#f2f2f2;display:none;padding:8px}.c-ad--300x250 .c-ad__inner{min-height:calc(1.5em + 254px)}@media only screen and (min-width:320px){.js .c-ad--300x250{display:block}}.c-ad iframe{border:0;overflow:auto;vertical-align:top}.c-ad__label{color:#333;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-ad__label,.c-banner{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-banner{background-color:#f7fbfe;border-bottom:1px solid #003b84;font-size:1rem;margin:0 auto;padding:16px 12px;position:relative;text-align:center}.c-banner--marketing .c-banner__link{color:#fff}.c-banner--marketing{background-color:#004b83;border-bottom:0;color:#fff}.c-banner__link{color:#004b83;text-decoration:underline}.c-skip-link{background:#f7fbfe;bottom:auto;color:#004b83;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#004b83}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #ccc;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-pagination{align-items:center;display:flex;flex-wrap:wrap;font-size:.875rem;list-style:none;margin:0;padding:16px}@media only screen and (min-width:540px){.c-pagination{justify-content:center}}.c-pagination__item{margin-bottom:8px;margin-right:16px}.c-pagination__item:last-child{margin-right:0}.c-pagination__link{align-items:center;background-color:#f2f2f2;background-image:linear-gradient(#fff,#f2f2f2);border:1px solid #ccc;border-radius:2px;color:#004b83;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;min-width:30px;padding:8px;position:relative;text-align:center;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.c-pagination__link svg,.c-pagination__link--disabled svg{fill:currentcolor}.c-pagination__link:visited{color:#004b83}.c-pagination__link:focus,.c-pagination__link:hover{border:1px solid #666;text-decoration:none}.c-pagination__link:focus,.c-pagination__link:hover{background-color:#666;background-image:none;color:#fff}.c-pagination__link:focus svg path,.c-pagination__link:hover svg path{fill:#fff}.c-pagination__link--disabled{align-items:center;background-color:transparent;background-image:none;border-radius:2px;color:#333;cursor:default;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;opacity:.67;padding:8px;position:relative;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.c-pagination__link--disabled:visited{color:#333}.c-pagination__link--disabled,.c-pagination__link--disabled:focus,.c-pagination__link--disabled:hover{border:1px solid #ccc;text-decoration:none}.c-pagination__link--disabled:focus,.c-pagination__link--disabled:hover{background-color:transparent;background-image:none;color:#333}.c-pagination__link--disabled:focus svg path,.c-pagination__link--disabled:hover svg path{fill:#333}.c-pagination__link--active{background-color:#666;background-image:none;border-color:#666;color:#fff;cursor:default}.c-pagination__ellipsis{background:0 0;border:0;min-width:auto;padding-left:0;padding-right:0}.c-pagination__icon{fill:#999;height:12px;width:16px}.c-pagination__icon--active{fill:#004b83}.c-header{background-color:#fff;border-bottom:4px solid #00285a;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;padding:16px 0}.c-header__container,.c-header__menu{align-items:center;display:flex;flex-wrap:wrap}@supports (gap:2em){.c-header__container,.c-header__menu{gap:2em 2em}}.c-header__menu{list-style:none;margin:0;padding:0}.c-header__item{color:inherit}@supports not (gap:2em){.c-header__item{margin-left:24px}}.c-header__container{justify-content:space-between;margin:0 auto;max-width:1280px;padding:0 16px}@supports not (gap:2em){.c-header__brand{margin-right:32px}}.c-header__brand a{display:block;text-decoration:none}.c-header__link{color:inherit;text-decoration:none}.c-popup-search{background-color:#eee;box-shadow:0 3px 3px -3px rgba(0,0,0,.21);padding:16px 0;position:relative;z-index:10}@media only screen and (min-width:1024px){.js .c-popup-search{position:absolute;top:100%;width:100%}.c-popup-search__container{margin:auto;max-width:70%}}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin-bottom:16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{margin-left:0}.c-article-author-list li,.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list__item svg{margin-left:4px}.c-article-author-list__show-more{margin-right:4px}@media only screen and (max-width:539px){html.js .js-small-screen-show-inline{display:inline!important;visibility:visible!important}.js .js-smaller-author-etal{display:none;visibility:hidden}}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-button-author-list svg{margin:1px 4px 0 0}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:0 0 16px}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Georgia,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;line-height:1.3;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-reading-companion__figure-full-link svg{margin-left:4px}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;display:inline-block;font-size:.875rem;font-weight:700;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fcfcfc;border-bottom:1px solid #fcfcfc;color:#222;font-weight:700}.c-reading-companion__figures-list,.c-reading-companion__references-list,.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.3;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{display:inline-block}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-reading-companion__panel--active{display:block}.c-article-section__figure-description{font-size:1rem}.c-article-section__figure-description>*{margin-bottom:0}.page-temporary-flag .c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.page-temporary-flag .c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.page-temporary-flag .c-pdf-download{max-height:48px}}.page-temporary-flag .c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 16px}.page-temporary-flag .c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.page-temporary-flag .c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.page-temporary-flag .c-pdf-download__text{padding-right:8px}}.page-temporary-flag .c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.page-temporary-flag .c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.page-temporary-flag .c-article-extras .c-pdf-container{flex-wrap:wrap;width:100%}.page-temporary-flag .c-article-extras .c-pdf-container .c-pdf-download{width:100%}.app-search__content{display:flex}.app-search__label{color:#666;display:inline-block;font-size:.875rem;margin-bottom:8px}.app-search__input{border:1px solid #b3b3b3;border-bottom-left-radius:3px;border-top-left-radius:3px;box-shadow:inset 0 1px 3px 0 rgba(0,0,0,.21);flex:0 1 auto;font-size:.875rem;line-height:1.2;padding:.75em 1em;vertical-align:middle;width:100%}.app-search__button{align-items:center;background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.5);border-radius:0 2px 2px 0;color:#fff;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-align:center;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:50px}.app-search__button svg,.u-button svg,.u-button--primary svg{fill:currentcolor}.u-button{align-items:center;background-color:#f2f2f2;background-image:linear-gradient(#fff,#f2f2f2);border:1px solid #ccc;border-radius:2px;color:#004b83;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.5);color:#fff}.u-button--full-width{display:flex;width:100%}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-display-block{display:block}.u-display-flex{display:flex;width:100%}.u-align-items-center{align-items:center}.u-justify-content-space-between{justify-content:space-between}.u-flex-static{flex:0 0 auto}.u-display-none{display:none}.js .u-js-hide{display:none;visibility:hidden}@media print{.u-hide-print{display:none}}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-list-reset{list-style:none;margin:0;padding:0}.u-button-reset{background-color:transparent;border:0;padding:0}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-position-relative{position:relative}.u-mt-16{margin-top:16px}.u-mt-32{margin-top:32px}.u-mr-24{margin-right:24px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.u-ml-8{margin-left:8px}.u-float-left{float:left}.u-hide{display:none;visibility:hidden}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.u-text-sm{font-size:1rem}.hide{display:none;visibility:hidden}.visually-hidden{clip:rect(1px,1px,1px,1px);height:1px;position:absolute!important;width:1px}@media only screen and (max-width:30em){.js .js-smaller-author-etal{display:none;visibility:hidden}}.c-article-section__figure-description{font-family:Georgia,Palatino,serif}.c-article-section__content p{line-height:1.8}.c-pagination__input{border:1px solid #bfbfbf;border-radius:2px;box-shadow:inset 0 2px 6px 0 rgba(51,51,51,.2);box-sizing:initial;display:inline-block;height:28px;margin:0;max-width:64px;min-width:16px;padding:0 8px;text-align:center;transition:width .15s ease 0s}.c-pagination__input::-webkit-inner-spin-button,.c-pagination__input::-webkit-outer-spin-button{-webkit-appearance:none;margin:0}@media only screen and (min-width:1024px){.c-article-collection__container{display:none}}.c-reading-companion__sections-list{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-section__title,.c-article-title{font-weight:400}.c-header__cart-icon{margin-right:12px}.c-header__navigation{display:flex} }</style>


    

    
        <link rel="stylesheet" data-inline-css-source="critical-css" href="/oscar-static/app-springerlink/css/enhanced-article-36fea363a9.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
        
    

    
    <script>
        window.dataLayer = [{"GA Key":"UA-26408784-1","DOI":"10.1007/s00330-015-4030-7","Page":"article","page":{"attributes":{"environment":"live"}},"Country":"PL","doi":"10.1007-s00330-015-4030-7","Journal Title":"European Radiology","Journal Id":330,"Keywords":"Computer-assisted diagnosis, Image interpretation, computer-assisted, Lung cancer, Solitary pulmonary nodule, Lung","kwrd":["Computer-assisted_diagnosis","Image_interpretation,_computer-assisted","Lung_cancer","Solitary_pulmonary_nodule","Lung"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"Y","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"open","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"vgzm.415900-10.1007-s00330-015-4030-7","Full HTML":"Y","Subject Codes":["SCH","SCH29005","SCH29013","SCH29021","SCH2903X","SCH29064","SCH33002"],"pmc":["H","H29005","H29013","H29021","H2903X","H29064","H33002"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1432-1084","pissn":"0938-7994"},"type":"Article","category":{"pmc":{"primarySubject":"Medicine \u0026 Public Health","primarySubjectCode":"H","secondarySubjects":{"1":"Imaging / Radiology","2":"Diagnostic Radiology","3":"Interventional Radiology","4":"Neuroradiology","5":"Ultrasound","6":"Internal Medicine"},"secondarySubjectCodes":{"1":"H29005","2":"H29013","3":"H29021","4":"H2903X","5":"H29064","6":"H33002"}},"sucode":"SC11"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article"}];
    </script>

    <script>
    window.dataLayer.push({
        ga4MeasurementId: 'G-B3E4QL2TPR',
        ga360TrackingId: 'UA-26408784-1',
        twitterId: 'o47a7',
        ga4ServerUrl: 'https://collect.springer.com',
        imprint: 'springerlink'
    });
</script>


    <script>
        window.dataLayer.push({
            cmpAndNewGtmFeatureFlag: true
        });
    </script>




    <script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                
                    j.src = 'https://collect.springer.com/gtm.js?id=' + i + dl;
                
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('springer.com') > -1) {
                e.src = 'https://push-content.springernature.io/pcf_sb_5_1617714720898560639/production_live/consent-bundle-17-8.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = '/static/js/lib/cookie-consent.min.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>

    
    <script>
        (function(w, d) {
            w.config = w.config || {};
            w.config.mustardcut = false;

            
            if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
                w.config.mustardcut = true;
                d.classList.add('js');
                d.classList.remove('grade-c');
            }
        })(window, document.documentElement);
    </script>



    
<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



    
    <script class="js-entry">
        if (window.config.mustardcut) {
            (function(w, d) {
                
                
                
                    window.Component = {};
                    window.suppressShareButton = false;
                

                var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

                
                function catchNoModuleSupport() {
                    var scriptEl = d.createElement('script');
                    return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
                }

                var headScripts = [
                    {'src': '/oscar-static/js/polyfill-es5-bundle-496e53357d.js', 'async': false},
                    {'src': '/oscar-static/js/airbrake-es5-bundle-cddaa57d7d.js', 'async': false},
                ];

                var bodyScripts = [
                    {'src': '/oscar-static/js/app-es5-bundle-2d3f7161ef.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/app-es6-bundle-0991b670c0.js', 'async': false, 'module': true}
                    
                    
                        , {'src': '/oscar-static/js/global-article-es5-bundle-a068685303.js', 'async': false, 'module': false},
                        {'src': '/oscar-static/js/global-article-es6-bundle-47ef9ee60e.js', 'async': false, 'module': true}
                    
                ];

                function createScript(script) {
                    var scriptEl = d.createElement('script');
                    scriptEl.src = script.src;
                    scriptEl.async = script.async;
                    if (script.module === true) {
                        scriptEl.type = "module";
                        if (catchNoModuleSupport()) {
                            scriptEl.src = '';
                        }
                    } else if (script.module === false) {
                        scriptEl.setAttribute('nomodule', true)
                    }
                    if (script.charset) {
                        scriptEl.setAttribute('charset', script.charset);
                    }

                    return scriptEl;
                }

                for (var i = 0; i < headScripts.length; ++i) {
                    var scriptEl = createScript(headScripts[i]);
                    currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
                }

                d.addEventListener('DOMContentLoaded', function() {
                    for (var i = 0; i < bodyScripts.length; ++i) {
                        var scriptEl = createScript(bodyScripts[i]);
                        d.body.appendChild(scriptEl);
                    }
                });

                // Webfont repeat view
                var config = w.config;
                if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                    d.documentElement.className += ' webfonts-loaded';
                }
            })(window, document);
        }
    </script>



    
    
    <link rel="canonical" href="https://link.springer.com/article/10.1007/s00330-015-4030-7"/>
    

    
    <script type="application/ld+json">{"mainEntity":{"headline":"Computer-aided detection of pulmonary nodules: a comparative study using the public LIDC/IDRI database","description":"To benchmark the performance of state-of-the-art computer-aided detection (CAD) of pulmonary nodules using the largest publicly available annotated CT database (LIDC/IDRI), and to show that CAD finds lesions not identified by the LIDC’s four-fold double reading process. The LIDC/IDRI database contains 888 thoracic CT scans with a section thickness of 2.5 mm or lower. We report performance of two commercial and one academic CAD system. The influence of presence of contrast, section thickness, and reconstruction kernel on CAD performance was assessed. Four radiologists independently analyzed the false positive CAD marks of the best CAD system. The updated commercial CAD system showed the best performance with a sensitivity of 82 % at an average of 3.1 false positive detections per scan. Forty-five false positive CAD marks were scored as nodules by all four radiologists in our study. On the largest publicly available reference database for lung nodule detection in chest CT, the updated commercial CAD system locates the vast majority of pulmonary nodules at a low false positive rate. Potential for CAD is substantiated by the fact that it identifies pulmonary nodules that were not marked during the extensive four-fold LIDC annotation process. • CAD systems should be validated on public, heterogeneous databases.\n                         • The LIDC/IDRI database is an excellent database for benchmarking nodule CAD.\n                         • CAD can identify the majority of pulmonary nodules at a low false positive rate.\n                         • CAD can identify nodules missed by an extensive two-stage annotation process.\n                        ","datePublished":"2015-10-06","dateModified":"2015-10-06","pageStart":"2139","pageEnd":"2147","sameAs":"https://doi.org/10.1007/s00330-015-4030-7","keywords":"Imaging / Radiology,Diagnostic Radiology,Interventional Radiology,Neuroradiology,Ultrasound,Internal Medicine","image":"https://static-content.springer.com/image/art%3A10.1007%2Fs00330-015-4030-7/MediaObjects/330_2015_4030_Fig1_HTML.gif","isPartOf":{"name":"European Radiology","issn":["1432-1084","0938-7994"],"volumeNumber":"26","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Springer Berlin Heidelberg","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Jacobs, Colin","url":"http://orcid.org/0000-0003-1180-3805","affiliation":[{"name":"Radboud University Medical Center","address":{"name":"Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands","@type":"PostalAddress"},"@type":"Organization"}],"email":"colin.jacobs@radboudumc.nl","@type":"Person"},{"name":"van Rikxoort, Eva M.","affiliation":[{"name":"Radboud University Medical Center","address":{"name":"Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands","@type":"PostalAddress"},"@type":"Organization"},{"name":"Fraunhofer MEVIS","address":{"name":"Fraunhofer MEVIS, Bremen, Germany","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Murphy, Keelin","affiliation":[{"name":"University College Cork","address":{"name":"Irish Centre for Fetal and Neonatal Translational Research, University College Cork, Cork, Ireland","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Prokop, Mathias","affiliation":[{"name":"Radboud University Medical Center","address":{"name":"Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Schaefer-Prokop, Cornelia M.","affiliation":[{"name":"Radboud University Medical Center","address":{"name":"Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands","@type":"PostalAddress"},"@type":"Organization"},{"name":"Meander Medical Center","address":{"name":"Department of Radiology, Meander Medical Center, Amersfoort, The Netherlands","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"van Ginneken, Bram","affiliation":[{"name":"Radboud University Medical Center","address":{"name":"Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, The Netherlands","@type":"PostalAddress"},"@type":"Organization"},{"name":"Fraunhofer MEVIS","address":{"name":"Fraunhofer MEVIS, Bremen, Germany","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":true,"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>

</head>
<body class="shared-article-renderer">
    
    
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript data-test="gtm-body">
                <iframe src="https://collect.springer.com/ns.html?id=GTM-MRVXSHQ"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    


    <div class="u-vh-full">
        <a class="c-skip-link" href="#main-content">Skip to main content</a>
        
            <div class="u-hide u-show-following-ad"></div>
            <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
                <div class="c-ad__inner">
                    <p class="c-ad__label">Advertisement</p>
                    <div id="div-gpt-ad-LB1" data-pa11y-ignore data-gpt
                         data-gpt-unitpath="/270604982/springerlink/330/article" data-gpt-sizes="728x90"
                         style="min-width:728px;min-height:90px" data-gpt-targeting="pos=LB1;articleid=s00330-015-4030-7;">
                </div>
            </aside>


<div class="u-position-relative">
        <header class="c-header u-mb-24" data-test="publisher-header">
    
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-6c9a864b59.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                <span class="u-text-sm">Search</span>
                <svg class="u-icon u-flex-static u-ml-8" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>

        <div class="c-header__cart-icon">
            <div id="ecommerce-header-cart-icon-link" class="c-header__item ecommerce-cart" style="display: inline-block; margin-right: 10px;"> 
 <form action="https://order.springer.com/public/precheckout" method="post"> <button class="c-header__link" type="submit" style="
        appearance: none;
        border: none;
        background: none;
        color: inherit;
    ">
   <svg aria-hidden="true" focusable="false" height="18" viewbox="0 0 18 18" width="18" style="vertical-align: text-bottom;" xmlns="http://www.w3.org/2000/svg"> <path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z" fill="#333" /> 
   </svg><span class="u-screenreader-only visually-hidden">Go to cart</span></button> 
 </form> 
</div>
        </div>

        <nav>
            <ul class="c-header__menu">
                
        
            <li class="c-header__item">
                <a
                    data-test="login-link"
                    class="c-header__link"
                    href="https://link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs00330-015-4030-7"
                    data-track="click"
                    data-track-category="header"
                    data-track-action="login header"
                    data-track-label="link">Log in</a>
            </li>
        

        


            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="u-icon" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix page-temporary-flag" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide"
                     data-test="context-bar"
                     data-context-bar
                     aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            Computer-aided detection of pulmonary nodules: a comparative study using the public LIDC/IDRI database
                        </div>
                        
    <div class="c-pdf-container">
        <div class="c-pdf-download u-clear-both">
            <a href="https://link.springer.com/content/pdf/10.1007/s00330-015-4030-7.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" data-track-external>
                
                    <span class="c-pdf-download__text">Download PDF</span>
                    <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
                
            </a>
        </div>
    </div>


                    </div>
                </div>
            

            <div class="c-pdf-button__container u-hide-at-lg js-context-bar-sticky-point-mobile">
                
    <div class="c-pdf-container">
        <div class="c-pdf-download u-clear-both">
            <a href="https://link.springer.com/content/pdf/10.1007/s00330-015-4030-7.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" data-track-external>
                
                    <span class="c-pdf-download__text">Download PDF</span>
                    <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
                
            </a>
        </div>
    </div>

            </div>

            <div class="c-article-collection__container">
                
    

            </div>

            <article lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
        <li class="c-article-identifiers__item" data-test="article-category">Computer Applications</li>
    
    
        <li class="c-article-identifiers__item">
            <span class="c-article-identifiers__open" data-test="open-access">Open Access</span>
        </li>
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2015-10-06">06 October 2015</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="">Computer-aided detection of pulmonary nodules: a comparative study using the public LIDC/IDRI database</h1>
                        <ul class="c-article-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Colin-Jacobs" aria-label="Read more about Colin Jacobs" data-author-popup="auth-Colin-Jacobs" data-corresp-id="c1">Colin Jacobs<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0003-1180-3805"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-1180-3805</a></span><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Eva_M_-Rikxoort" aria-label="Read more about Eva M. van Rikxoort" data-author-popup="auth-Eva_M_-Rikxoort">Eva M. van Rikxoort</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Keelin-Murphy" aria-label="Read more about Keelin Murphy" data-author-popup="auth-Keelin-Murphy">Keelin Murphy</a><sup class="u-js-hide"><a href="#Aff4">4</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Mathias-Prokop" aria-label="Read more about Mathias Prokop" data-author-popup="auth-Mathias-Prokop">Mathias Prokop</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Cornelia_M_-Schaefer_Prokop" aria-label="Read more about Cornelia M. Schaefer-Prokop" data-author-popup="auth-Cornelia_M_-Schaefer_Prokop">Cornelia M. Schaefer-Prokop</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff3">3</a></sup> &amp; </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Bram-Ginneken" aria-label="Read more about Bram van Ginneken" data-author-popup="auth-Bram-Ginneken">Bram van Ginneken</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/330"><i data-test="journal-title">European Radiology</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 26</b>, <span class="u-visually-hidden">pages </span>2139–2147 (<span data-test="article-publication-year">2016</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
            
                <li class=" c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">5048 <span class="c-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">54 <span class="c-article-metrics-bar__label">Citations</span></p>
                </li>
            
            
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">3 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                    </li>
                
            
            <li class="c-article-metrics-bar__item">
                <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs00330-015-4030-7/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
            </li>
        </ul>
    </div>
</div>

                        </div>
                        
    

    

                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><h3 class="c-article__sub-heading" data-test="abstract-sub-heading">Objectives</h3><p>To benchmark the performance of state-of-the-art computer-aided detection (CAD) of pulmonary nodules using the largest publicly available annotated CT database (LIDC/IDRI), and to show that CAD finds lesions not identified by the LIDC’s four-fold double reading process.</p><h3 class="c-article__sub-heading" data-test="abstract-sub-heading">Methods</h3><p>The LIDC/IDRI database contains 888 thoracic CT scans with a section thickness of 2.5 mm or lower. We report performance of two commercial and one academic CAD system. The influence of presence of contrast, section thickness, and reconstruction kernel on CAD performance was assessed. Four radiologists independently analyzed the false positive CAD marks of the best CAD system.</p><h3 class="c-article__sub-heading" data-test="abstract-sub-heading">Results</h3><p>The updated commercial CAD system showed the best performance with a sensitivity of 82 % at an average of 3.1 false positive detections per scan. Forty-five false positive CAD marks were scored as nodules by all four radiologists in our study.</p><h3 class="c-article__sub-heading" data-test="abstract-sub-heading">Conclusions</h3><p>On the largest publicly available reference database for lung nodule detection in chest CT, the updated commercial CAD system locates the vast majority of pulmonary nodules at a low false positive rate. Potential for CAD is substantiated by the fact that it identifies pulmonary nodules that were not marked during the extensive four-fold LIDC annotation process.</p><h3 class="c-article__sub-heading" data-test="abstract-sub-heading">
                  <i>Key Points</i>
                </h3><p>• <i>CAD systems should be validated on public, heterogeneous databases.</i>
                        </p><p>• <i>The LIDC/IDRI database is an excellent database for benchmarking nodule CAD.</i>
                        </p><p>• <i>CAD can identify the majority of pulmonary nodules at a low false positive rate.</i>
                        </p><p>• <i>CAD can identify nodules missed by an extensive two-stage annotation process.</i>
                        </p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section data-title="Introduction"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>The last two decades have shown substantial research into computer-aided detection (CAD) of pulmonary nodules in thoracic computed tomography (CT) scans [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Li Q (2007) Recent progress in computer-aided diagnosis of lung nodules on thin-section CT. Comput Med Imaging Graph 31:248–257" href="/article/10.1007/s00330-015-4030-7#ref-CR1" id="ref-link-section-d31082446e547">1</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Lee SLA, Kouzani AZ, Hu EJ (2012) Automated detection of lung nodules in computed tomography images: a review. Mach Vis Appl 23:151–163" href="/article/10.1007/s00330-015-4030-7#ref-CR2" id="ref-link-section-d31082446e550">2</a>]. Although many academic and several commercial CAD algorithms have been developed, CAD for lung nodules is still not commonly used in daily clinical practice. Possible explanations for this are a lack of reimbursement, technical impediments to integration into PACS systems, but also low sensitivity and high false positive rates. The recent positive results of the NLST lung cancer screening trial [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Aberle DR, Adams AM, Berg CD, Black WC, Clapp JD, Fagerstrom RM et al (2011) Reduced lung-cancer mortality with low-dose computed tomographic screening. N Engl J Med 365:395–409" href="/article/10.1007/s00330-015-4030-7#ref-CR3" id="ref-link-section-d31082446e553">3</a>] and the subsequent developments towards implementation of lung cancer screening in the United States [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="de Koning HJ, Meza R, Plevritis SK, Ten Haaf K, Munshi VN, Jeon J et al (2014) Benefits and harms of computed tomography lung cancer screening strategies: a comparative modeling study for the U.S. Preventive Services Task Force. Ann Intern Med 160:311–320" href="/article/10.1007/s00330-015-4030-7#ref-CR4" id="ref-link-section-d31082446e556">4</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Black WC, Gareen IF, Soneji SS, Sicks JD, Keeler EB, Aberle DR et al (2014) Cost-effectiveness of CT screening in the National Lung Screening Trial. N Engl J Med 371:1793–1802" href="/article/10.1007/s00330-015-4030-7#ref-CR5" id="ref-link-section-d31082446e559">5</a>] have renewed the interest into CAD for pulmonary nodules. If lung cancer screening will be implemented on a large scale, the burden on radiologists will be substantial and CAD could play an important role in reducing reading time and thereby improving cost-effectiveness [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Aberle DR, Henschke CI, McLoud TC, Boiselle PM (2012) Expert opinion: barriers to CT screening for lung cancer. J Thorac Imaging 27:208" href="/article/10.1007/s00330-015-4030-7#ref-CR6" id="ref-link-section-d31082446e563">6</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Prokop M (2014) Lung cancer screening: the radiologist's perspective. Semin Respir Crit Care Med 35:91–98" href="/article/10.1007/s00330-015-4030-7#ref-CR7" id="ref-link-section-d31082446e566">7</a>].</p><p>Following the general demand for open and reproducible science, public databases have been established to facilitate objective measures of CAD performance, and to move CAD development to a next level [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Armato SG, McLennan G, McNitt-Gray MF, Meyer CR, Yankelevitz D, Aberle DR et al (2004) Lung image database consortium: developing a resource for the medical imaging research community. Radiology 232:739–748" href="/article/10.1007/s00330-015-4030-7#ref-CR8" id="ref-link-section-d31082446e572">8</a>–<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Armato SG, McLennan G, Bidaut L, McNitt-Gray MF, Meyer CR, Reeves AP et al (2011) The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): a completed reference database of lung nodules on CT scans. Med Phys 38:915–931" href="/article/10.1007/s00330-015-4030-7#ref-CR10" id="ref-link-section-d31082446e575">10</a>]. In 2011, the complete LIDC/IDRI (Lung Image Database Consortium / Image Database Resource Initiative) database was released [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Armato SG, McLennan G, Bidaut L, McNitt-Gray MF, Meyer CR, Reeves AP et al (2011) The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): a completed reference database of lung nodules on CT scans. Med Phys 38:915–931" href="/article/10.1007/s00330-015-4030-7#ref-CR10" id="ref-link-section-d31082446e578">10</a>]. This dataset provides by far the largest public resource to assess the performance of algorithms for the detection of pulmonary nodules in thoracic CT scans. A large effort has gone into the collection of annotations on these cases, but CAD was not used to assist the readers [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Armato SG, McLennan G, Bidaut L, McNitt-Gray MF, Meyer CR, Reeves AP et al (2011) The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): a completed reference database of lung nodules on CT scans. Med Phys 38:915–931" href="/article/10.1007/s00330-015-4030-7#ref-CR10" id="ref-link-section-d31082446e581">10</a>].</p><p>In this paper, we apply two commercial and one state-of-the-art academic nodule detection systems on the LIDC/IDRI database with the aim to set a first benchmark performance on the full database. To our knowledge, this is the first paper, which reports the performance of CAD systems on the full LIDC/IDRI database. We performed an extensive analysis of the performance of the applied CAD systems and make our evaluation publicly available so that other CAD developers can compare with this benchmark. Furthermore, we hypothesize that CAD can find lesions, which were not detected in the extensive LIDC annotation process consisting of a blinded and unblinded review by four radiologists. To investigate the latter, we evaluated the false positives of the best CAD system using a similar reading protocol as had been used in LIDC.</p></div></div></section><section data-title="Materials and methods"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Materials and methods</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Data</h3><p>This study used the LIDC/IDRI data set [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Armato SG, McLennan G, Bidaut L, McNitt-Gray MF, Meyer CR, Reeves AP et al (2011) The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): a completed reference database of lung nodules on CT scans. Med Phys 38:915–931" href="/article/10.1007/s00330-015-4030-7#ref-CR10" id="ref-link-section-d31082446e599">10</a>], consisting of 1,018 helical thoracic CT scans collected retrospectively from seven academic centres. Nine cases with inconsistent slice spacing or missing slices were excluded. In addition, 121 CT scans, which had a section thickness of 3 mm and higher, were excluded since thick section data is not optimal for CAD analysis. This resulted in 888 CT cases available for evaluation. In Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s00330-015-4030-7#Tab1">1</a>, <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s00330-015-4030-7#Tab2">2</a>, and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s00330-015-4030-7#Tab3">3</a>, the characteristics of the input data are shown.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Manufacturer and scanner model distribution of the 888 CT scans in our dataset</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s00330-015-4030-7/tables/1" aria-label="Full size table 1"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           
                    <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Section thickness distribution of the 888 CT scans in our dataset</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s00330-015-4030-7/tables/2" aria-label="Full size table 2"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Distribution of the reconstruction kernels used for the 888 CT scans in our dataset</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s00330-015-4030-7/tables/3" aria-label="Full size table 3"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading c-article__sub-heading--divider" id="Sec4">LIDC/IDRI image annotation</h3><p>The LIDC/IDRI employed a two-phase image annotation process [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Armato SG, McLennan G, Bidaut L, McNitt-Gray MF, Meyer CR, Reeves AP et al (2011) The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): a completed reference database of lung nodules on CT scans. Med Phys 38:915–931" href="/article/10.1007/s00330-015-4030-7#ref-CR10" id="ref-link-section-d31082446e1443">10</a>]. In the first phase (the blind phase), four radiologists independently reviewed all cases. In the second phase (the unblinded phase), all annotations of the other three radiologists were made available and each radiologist independently reviewed their marks along with the anonymized marks of their colleagues. Findings were annotated and categorized into <i>nodule≥3 mm</i>, <i>nodule&lt;3 mm</i>, or <i>non-nodule. Non-nodule</i> marks were used to indicate abnormalities in the scan, which were not considered a nodule. Using this two-phase process, the LIDC investigators aimed to identify as completely as possible all lung nodules, without forcing consensus among the readers. More details about the annotation process can be found in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Armato SG, McLennan G, Bidaut L, McNitt-Gray MF, Meyer CR, Reeves AP et al (2011) The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): a completed reference database of lung nodules on CT scans. Med Phys 38:915–931" href="/article/10.1007/s00330-015-4030-7#ref-CR10" id="ref-link-section-d31082446e1455">10</a>]. An XML file with the annotations is publicly available for every case.</p><h3 class="c-article__sub-heading c-article__sub-heading--divider" id="Sec5">Nodule selection and purpose</h3><p>In this study, we included all annotations available in the XML files for the 888 scans. The focus of this study was on the <i>nodule≥3 mm</i> group. As a result of the LIDC/IDRI image annotation process, each <i>nodule≥3 mm</i> had been annotated by one, two, three, or four radiologists. In total, the data set of this study included 777 locations, which were marked as <i>nodule≥3 mm</i> by all four radiologists. The 777 <i>nodule≥3 mm</i> annotations marked by all four radiologists can be categorized by size as follows: 22 nodules &lt;4 mm, 228 nodules 4–6 mm, 199 nodules 6–8 mm, and 328 nodules &gt;8 mm. The number of nodules per scan ranged between 1 and 8.</p><p>The purpose of this study was twofold. First, we aimed to assess the performance of three state-of-the-art nodule CAD systems. Secondly, we performed an observer experiment to investigate whether CAD can find additional lesions, missed during the extensive LIDC annotation process.</p><h3 class="c-article__sub-heading c-article__sub-heading--divider" id="Sec6">CAD systems</h3><p>Three CAD systems were used: a commercial CAD system <i>Visia</i> (MeVis Medical Solutions AG, Bremen, Germany), a commercial prototype CAD system <i>Herakles</i> (MeVis Medical Solutions AG, Bremen, Germany), and an academic nodule CAD system <i>ISICAD</i> (Utrecht Medical Center, Utrecht, the Netherlands) [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Murphy K, van Ginneken B, Schilham AMR, de Hoop BJ, Gietema HA, Prokop M (2009) A large scale evaluation of automatic pulmonary nodule detection in chest ct using local image features and k-nearest-neighbour classification. Med Image Anal 13:757–770" href="/article/10.1007/s00330-015-4030-7#ref-CR11" id="ref-link-section-d31082446e1498">11</a>]. <i>ISICAD</i> was the leading academic CAD system in the ANODE09 nodule detection challenge [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="van Ginneken B, Armato SG, de Hoop B, van de Vorst S, Duindam T, Niemeijer M et al (2010) Comparing and combining algorithms for computer-aided detection of pulmonary nodules in computed tomography scans: the ANODE09 study. Med Image Anal 14:707–722" href="/article/10.1007/s00330-015-4030-7#ref-CR9" id="ref-link-section-d31082446e1505">9</a>]. For all three CAD systems, a list of candidate marks per CT scan was obtained. Each CAD candidate is described by a 3D location. Additionally, <i>Herakles</i> and <i>ISICAD</i> also provide a CAD score per CAD candidate. The CAD score is the output of the internal classification scheme of the CAD system and is a measure of the likelihood that a candidate is a pulmonary nodule. An internal threshold on the CAD scores determines which candidates are active CAD marks and, hence, will be shown to the user, and which candidates are not shown. Since different thresholds can be applied on the CAD score, a CAD system can have multiple operating points. A low threshold generates more CAD marks, thereby typically increasing sensitivity at the cost of more false positive detections. A high threshold will generate less false positives but may reduce the sensitivity of a CAD system. For all three CAD systems, one fixed operating point is internally set which we will refer to as the system operating point.</p><h3 class="c-article__sub-heading c-article__sub-heading--divider" id="Sec7">Evaluation</h3><p>The performance of the CAD systems was analyzed on the set of 777 nodules annotated by 4/4 radiologists as a <i>nodule≥3 mm.</i> We employed free-response operating characteristic (FROC) analysis [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Chakraborty DP, Berbaum KS (2004) Observer studies involving detection and localization: modeling, analysis, and validation. Med Phys 31:2313–2330" href="/article/10.1007/s00330-015-4030-7#ref-CR12" id="ref-link-section-d31082446e1526">12</a>] where detection sensitivity is plotted against the average number of false positive detections per scan. Confidence intervals were estimated using bootstrapping with 5,000 iterations [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Efron B (1979) Bootstrap methods: another look at the jackknife. Ann Stat 7:1–29" href="/article/10.1007/s00330-015-4030-7#ref-CR13" id="ref-link-section-d31082446e1529">13</a>]. If a CAD system marked locations which were annotated by three or fewer radiologists as <i>nodule≥3 mm</i>, as <i>nodule&lt;3 mm</i>, and as <i>non-nodules</i>, these CAD marks were counted as false positives. For <i>Visia</i>, no CAD scores were available for the CAD candidates. Consequently, only one operating point and not a full FROC curve could be generated for <i>Visia</i>.</p><p>To gain more insight into which type of nodules were missed by CAD, we looked at the characteristics, as scored by the LIDC readers, for all <i>nodule≥3 mm</i> findings, of the false negatives. We defined subsolid nodules as nodules for which the majority of the radiologists gave a texture score smaller than 5 (1=ground-glass/non-solid, 3=part-solid, 5=solid). Subtle nodules were defined as nodules for which the majority of the radiologists gave a subtlety score smaller or equal than 3 (1=extremely subtle, 5=obvious).</p><p>To assess the robustness of the CAD algorithms, we also evaluated the CAD results on different subsets of the data. The LIDC-IDRI data set is a heterogeneous set of CT scans and CAD algorithms that could conceivably exhibit a different performance on different types of data. We analyzed the following factors: (1) presence of contrast material, i.e., non-contrast versus contrast enhanced scans, (2) section thickness, i.e., cases with section thickness &lt;2 mm versus section thickness ≥2 mm, and (3) reconstruction kernel, i.e., soft/standard versus enhancing/overenhancing kernels.</p><h3 class="c-article__sub-heading c-article__sub-heading--divider" id="Sec8">Observer study</h3><p>In order to evaluate whether CAD can find lesions missed during the extensive annotation process of the LIDC/IDRI database, we considered the CAD marks of the best CAD algorithm , which were counted as false positives at its system operating point. Two conditions were differentiated: the location of the CAD mark had in fact been marked in the LIDC annotation process, but not by all four readers as <i>nodule≥3 mm</i> as warranted for being counted as a true positive. The second condition comprised those CAD marks that had no corresponding LIDC marks at all. The CAD marks corresponding to the first condition can be subdivided according to the LIDC readings. The latter CAD marks were independently inspected by four chest radiologists, since these are potentially nodules overlooked by all four LIDC readers. Thus, we mimic the original LIDC annotation process as though CAD had been included as another independent reader in the first phase of the image annotation process. CAD marks were categorized as <i>nodule≥3 mm</i>, <i>nodule&lt;3 mm</i>, <i>non-nodules</i>, or false positive. Electronic measurement tools were available to measure size. To reduce the workload for the radiologists, a research scientist (5 years experience in nodule CAD research) first removed the marks which were obviously not a nodule. CAD marks which were marked as nodule&gt;3 mm by all four radiologists in our study were independently evaluated by an experienced radiologist that scored subtlety, location, type, and attachment to other structures. Subtlety was scored on a five-point scale (1=extremely subtle, 5=obvious).</p></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Results</h2><div class="c-article-section__content" id="Sec9-content"><h3 class="c-article__sub-heading" id="Sec10">Comparative CAD performance</h3><p>The performance of the three CAD systems is depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s00330-015-4030-7#Fig1">1</a>. From the FROC curves it is evident that <i>Herakles</i> performed best. The system performances were significantly different (p &lt; 0.001). At its system operating point, <i>Herakles</i> reached a sensitivity of 82 % at an average of 3.1 false positives per scan for nodules all four LIDC readers had agreed on.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s00330-015-4030-7/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs00330-015-4030-7/MediaObjects/330_2015_4030_Fig1_HTML.gif?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs00330-015-4030-7/MediaObjects/330_2015_4030_Fig1_HTML.gif" alt="figure 1" loading="lazy"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>FROC curves for all three CAD systems on the full database of 888 CT scans containing 777 nodules for which all four radiologists classified it as <i>nodule≥3 mm</i>. The points on the curves indicate the system operating points of the three CAD systems. For <i>Visia,</i> no continuous FROC curve but only a single operating point can be provided since the CAD scores of the CAD marks are not available. Shaded areas around the curve indicate 95 % confidence intervals</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s00330-015-4030-7/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Fig. 2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s00330-015-4030-7/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs00330-015-4030-7/MediaObjects/330_2015_4030_Fig2_HTML.gif?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs00330-015-4030-7/MediaObjects/330_2015_4030_Fig2_HTML.gif" alt="figure 2" loading="lazy"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>FROC curves for all three CAD systems on (<b>a</b>) contrast scans (<i>n</i>=242) versus non-contrast scans (<i>n</i>=646), (<b>b</b>) scans with a section thickness &lt;2 mm (<i>n</i>=445) versus scans with a section thickness ≥2 mm (<i>n</i>=443), and (<b>c</b>) scans with a soft or standard reconstruction kernel (<i>n</i>=502) versus scans with an enhancing or overenhancing reconstruction kernel (<i>n</i>=386). The reference set of nodules consists of nodules for which all four radiologists classified it as <i>nodule≥3 mm</i>. The points on the curves indicate the system operating points of the three systems. For <i>Visia,</i> no continuous FROC curve but only a single operating point can be provided since the CAD scores of the CAD marks are not available</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s00330-015-4030-7/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>We evaluated the characteristics of the 141 false negative nodules. 42 (30 %) false negatives were subsolid nodules. The size distribution of the missed nodules was as follows: five nodules &lt;4 mm, 53 nodules 4–6 mm, 31 nodules 6–8 mm, and 52 nodules &gt;8 mm. Thus, a large portion of the missed nodules were smaller than 6 mm, but still a substantial number of missed nodules, 52 (37 %), were larger than 8 mm. Finally, we found that 33 (23 %) of the missed nodules were subtle. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s00330-015-4030-7#Fig3">3</a> shows eight randomly chosen missed nodules.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Fig. 3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s00330-015-4030-7/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs00330-015-4030-7/MediaObjects/330_2015_4030_Fig3_HTML.gif?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs00330-015-4030-7/MediaObjects/330_2015_4030_Fig3_HTML.gif" alt="figure 3" loading="lazy"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Eight randomly chosen examples of false negatives of <i>Herakles</i>. Each image shows a transverse field of view of 60 x 60 mm in which the nodule is centred. Note that many missed nodules are subsolid</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s00330-015-4030-7/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The performance of the three CAD systems on the different subsets is depicted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s00330-015-4030-7#Fig2">2</a>. This figure shows that the performance of <i>ISICAD</i> and <i>Visia</i> was influenced by different data sources. <i>ISICAD</i> shows the largest performance difference between soft/standard versus enhancing/overenhancing reconstruction kernels. <i>Herakles</i> showed the most stable and robust performance for all different data sources and consistently outperformed the other two CAD systems.</p><p>We categorized the CAD marks of <i>Herakles,</i> which were counted as false positives at its system operating point. In total, there were 2,720 false positive CAD marks in the 888 cases (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s00330-015-4030-7#Tab4">4</a>). The majority of the CAD marks, 1,612 out of 2,720 (59 %), had at least one corresponding mark from the LIDC readers. These CAD marks can be further categorized into marks on annotations marked as <i>nodule≥3 mm</i> by three out of four radiologists, two out of four radiologists, one out of four radiologists; and annotations marked as <i>nodule&lt;3 mm</i> by at least one radiologist (and, hence, no <i>nodule≥3 mm</i> annotations); and finally annotations marked as <i>non-nodule</i> by at least one out of four radiologists (and, hence, no <i>nodule≥3 mm</i> or <i>nodule&lt;3 mm</i> annotations). Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s00330-015-4030-7#Tab4">4</a> shows how the CAD marks were further split out into these categories. The remaining 1,108 false positive CAD marks had no corresponding mark from the LIDC readers.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Overview of the categories in which the false positives of <i>Herakles</i> at the system operating point can be divided. In this analysis, we first check for corresponding <i>nodule≥3 mm</i> annotations<i>,</i> then we check for corresponding <i>nodule&lt;3 mm</i> annotations, and finally we check for corresponding <i>non-nodule</i> annotations. This means that in the top row where three out of four radiologists annotated the location as <i>nodule≥3 mm</i>, the fourth radiologist may have marked the location as <i>nodule&lt;3 mm, non-nodule,</i> or did not mark it at all. In the <i>nodule&lt;3 mm</i> category, all false positives whose location was marked as <i>nodule&lt;3 mm</i> by at least one radiologist were placed (and, hence, no radiologist marked it as <i>nodule≥3 mm</i>). The non-nodule category contains all false positives whose location was marked as <i>non-nodule</i> by at least one radiologist (and, hence, no radiologist marked the location as <i>nodule≥3 mm</i> or <i>nodule&lt;3 mm</i>). False positives for which no corresponding annotation was found were assigned to the last category</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s00330-015-4030-7/tables/4" aria-label="Full size table 4"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading" id="Sec11">Observer study results</h3><p>In our observer experiment, we focused on these 1,108 false positive CAD marks of <i>Herakles,</i> which had no corresponding mark from any of the LIDC readers. These are locations, which were potentially overlooked by all four LIDC readers. After CAD marks, which were obviously not a nodule had been removed by the research scientist, 269 CAD marks were left for analysis by the four radiologists. Common sources of false positive detections removed by the research scientist included fissure thickening at the chest wall, vessel bifurcations and (micro-)atelectasis. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s00330-015-4030-7#Tab5">5</a> depicts how each of the observers scored these 269 CAD marks. In total, 45 CAD marks were considered to be a <i>nodule≥3 mm</i> by all four radiologists; 177 CAD marks were considered to be a <i>nodule≥3 mm</i> by at least one of the radiologists. The size distribution of the 45 CAD marks was as follows: nine nodules &lt;4 mm, 27 nodules 4-6 mm, seven nodules 6-8 mm, and two nodules &gt;8 mm. Subtlety was scored lower or equal than 3 for 32 (71 %) nodules. Location was scored as central for 11 nodules, peripheral for 11 nodules, and in-between for 23 nodules. Nodule type was scored as follows: 32 solid, 2 ground-glass, 1 part-solid, and 10 calcified. Vascular, pleural or fissural attachment was found for 18 (40 %) nodules. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s00330-015-4030-7#Fig4">4</a> shows eight randomly chosen examples of CAD marks, which were considered a <i>nodule≥3 mm</i> by all four radiologists and were scored as solid. In addition, 169 marks were considered a <i>nodule≥ 3 mm</i> or a <i>nodule&lt;3 mm</i> by all four radiologists; 250 marks were considered a <i>nodule≥3 mm</i> or a <i>nodule&lt;3 mm</i> by at least one of the radiologists. Thus, following the reference of the 4-reader agreement and adding these 45 CAD marks to the set of nodules, the updated performance of <i>Herakles</i> at its system operating point would reach a sensitivity of 83 % at an average of 3.0 false positive detections per scan. In this FROC analysis, CAD marks on locations marked as <i>nodule≥3 mm</i> by three out of four radiologists, two out of four radiologist, one out of four radiologists, or as <i>nodule&lt;3 mm</i> by at least one radiologist were counted as false positives. Evidently, one could argue whether CAD marks on these locations should be counted as false positives or not. If CAD marks on these locations were not to be counted as false positives but ignored in the FROC analysis, a performance of 83 % sensitivity at an average of only 1.0 false positives per scan would be reached.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Results of the observer experiment. The distribution of the scores of all observers is tabulated</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s00330-015-4030-7/tables/5" aria-label="Full size table 5"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                           <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Fig. 4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s00330-015-4030-7/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs00330-015-4030-7/MediaObjects/330_2015_4030_Fig4_HTML.gif?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs00330-015-4030-7/MediaObjects/330_2015_4030_Fig4_HTML.gif" alt="figure 4" loading="lazy"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Eight randomly chosen examples of solid nodule annotations marked as <i>nodule≥3 mm</i> by all four readers in our observer experiment. These nodules were not annotated by any of the original LIDC readers. Each image shows a transverse field of view of 60 x 60 mm in which the nodule is centred</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s00330-015-4030-7/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        </div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Discussion</h2><div class="c-article-section__content" id="Sec12-content"><p>Though clear definitions are available for what represents a pulmonary nodule (Fleischner Glossary [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Hansell DM, Bankier AA, MacMahon H, McLoud TC, Müller NL, Remy J (2008) Fleischner society: glossary of terms for thoracic imaging. Radiology 246:697–722" href="/article/10.1007/s00330-015-4030-7#ref-CR14" id="ref-link-section-d31082446e2208">14</a>]), the literature lists a number of publications demonstrating the lack of observer agreement of what indeed represents a pulmonary nodule [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Armato SG, Roberts RY, Kocherginsky M, Aberle DR, Kazerooni EA, Macmahon H et al (2009) Assessment of radiologist performance in the detection of lung nodules: dependence on the definition of “truth”. Acad Radiol 16:28–38" href="/article/10.1007/s00330-015-4030-7#ref-CR15" id="ref-link-section-d31082446e2211">15</a>–<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Rubin GD, Lyo JK, Paik DS, Sherbondy AJ, Chow LC, Leung AN et al (2005) Pulmonary nodules on multi-detector row CT scans: performance comparison of radiologists and computer-aided detection. Radiology 234:274–283" href="/article/10.1007/s00330-015-4030-7#ref-CR17" id="ref-link-section-d31082446e2214">17</a>]. Not surprisingly this effect is larger for small lesions [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Armato SG, Roberts RY, Kocherginsky M, Aberle DR, Kazerooni EA, Macmahon H et al (2009) Assessment of radiologist performance in the detection of lung nodules: dependence on the definition of “truth”. Acad Radiol 16:28–38" href="/article/10.1007/s00330-015-4030-7#ref-CR15" id="ref-link-section-d31082446e2217">15</a>]. This lack of an absolute standard of truth makes benchmarking of CAD systems very difficult. Therefore, we decided to use the largest publicly available database of CT annotated pulmonary nodules. An elaborate double reading process involving four radiologists had been undertaken to define various levels of evidence for the presence of nodules to avoid the need for a consensus statement. In our study we used the extensive annotation information of the LIDC/IDRI database to benchmark the performance of state-of-the-art nodule CAD systems. To our knowledge, this is the first study that uses the full LIDC database and secondly accepts the fact that there is no absolute standard of truth for the presence of pulmonary nodules in the absence of pathological correlation.</p><p>Our study showed substantial performance differences between the three CAD systems, with the commercial prototype <i>Herakles</i> demonstrating the best performance. At its system operating point, <i>Herakles</i> detected 82 % of all <i>nodule≥3 mm</i> findings marked by all four LIDC readers at an average of 3.1 false positives per scan. If marks on the other LIDC annotations were ignored in the analysis, a sensitivity of 83 % at an average of only 1.0 false positives was reached.</p><p>The best CAD system still misses a subset of the nodules (18 % of the 777 nodules). We observed that a substantial part of the missed nodules (30 %) were subsolid nodules, which are more rare and have a markedly different internal character than solid nodules. Therefore, integrating a dedicated subsolid nodule detection scheme [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Jacobs C, van Rikxoort EM, Twellmann T, Scholten ET, de Jong PA, Kuhnigk JM et al (2014) Automatic detection of subsolid pulmonary nodules in thoracic computed tomography images. Med Image Anal 18:374–384" href="/article/10.1007/s00330-015-4030-7#ref-CR18" id="ref-link-section-d31082446e2235">18</a>] in a complete CAD solution for pulmonary nodules may prove helpful to improve overall CAD performance.</p><p>Both <i>Visia</i> and <i>ISICAD</i> showed substantial performance differences on different subsets of the data, but <i>Herakles</i> achieved a more robust performance. The performance of <i>ISICAD</i> dropped substantially on data with enhancing or overenhancing reconstruction kernels. This may be attributed to the fact that <i>ISICAD</i> was developed and trained exclusively with data from the Dutch-Belgian NELSON lung cancer screening trial, which consists of homogeneous thin-slice data reconstructed with a soft/standard reconstruction kernel [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="van Klaveren RJ, Oudkerk M, Prokop M, Scholten ET, Nackaerts K et al (2009) Management of lung nodules detected by volume CT scanning. N Engl J Med 361:2221–2222" href="/article/10.1007/s00330-015-4030-7#ref-CR19" id="ref-link-section-d31082446e2257">19</a>]. This indicates that although <i>ISICAD</i> was the leading CAD system for the data used in the ANODE challenge [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="van Ginneken B, Armato SG, de Hoop B, van de Vorst S, Duindam T, Niemeijer M et al (2010) Comparing and combining algorithms for computer-aided detection of pulmonary nodules in computed tomography scans: the ANODE09 study. Med Image Anal 14:707–722" href="/article/10.1007/s00330-015-4030-7#ref-CR9" id="ref-link-section-d31082446e2263">9</a>], which consisted only of data obtained from the NELSON trial, its performance drops when applied to data of other sources. Therefore, the heterogeneity of a reference database is an important aspect for a reliable CAD evaluation and an advantage of the LIDC/IDRI database.</p><p>Although a blinded and unblinded review of all images had been performed by the LIDC investigators, we showed that CAD can find lesions missed by the original LIDC readers. We found 45 nodules, which were accepted as a <i>nodule≥3 mm</i> by all four radiologists involved in our observer study. Previous studies have already shown that CAD can find lesions missed by multiple readers [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Jacobs C, van Rikxoort EM, Twellmann T, Scholten ET, de Jong PA, Kuhnigk JM et al (2014) Automatic detection of subsolid pulmonary nodules in thoracic computed tomography images. Med Image Anal 18:374–384" href="/article/10.1007/s00330-015-4030-7#ref-CR18" id="ref-link-section-d31082446e2273">18</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Drew T, Vo ML, Olwal A, Jacobson F, Seltzer SE, Wolfe JM (2013) Scanners and drillers: characterizing expert visual search through volumetric images. J Vis 13:1–13" href="/article/10.1007/s00330-015-4030-7#ref-CR20" id="ref-link-section-d31082446e2276">20</a>]. One possible reason why the LIDC readers missed nodules may be that the LIDC readers only inspected transverse sections [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Armato SG, McLennan G, Bidaut L, McNitt-Gray MF, Meyer CR, Reeves AP et al (2011) The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): a completed reference database of lung nodules on CT scans. Med Phys 38:915–931" href="/article/10.1007/s00330-015-4030-7#ref-CR10" id="ref-link-section-d31082446e2279">10</a>]. Characteristic features of the 45 nodules not included in the LIDC/IDRI database but seen by CAD were subtle conspicuity, small size (&lt;6 mm), and attachment to pleura or vasculature.</p><p>Since an extensive evaluation on a large reference database is essential to move CAD to the next level, we have published our results on a public website (<a href="http://luna.grand-challenge.org/">http://luna.grand-challenge.org/</a>) which allows other CAD researchers to upload results of their CAD systems for which the same FROC curves as presented in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s00330-015-4030-7#Fig1">1</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s00330-015-4030-7#Fig2">2</a> will be computed and published on the website. The annotation files of the reference standard and the extra annotations by the human readers in our observer study are available for download. By making the extra annotations available to other researchers, this study contributes to an improved reference standard for the LIDC/IDRI database, and we hope future CAD studies will use the improved reference standard.</p><p>We primarily evaluated the performance of CAD on nodules for which all four radiologists agreed that it was a <i>nodule≥3 mm</i>. Previous publications have also focused on the nodules detected by three, two, or one out of four radiologists [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Camarlinghi N (2013) Automatic detection of lung nodules in computed tomography images: training and validation of algorithms using public research databases. Eur Phys J Plus 128:1–21" href="/article/10.1007/s00330-015-4030-7#ref-CR21" id="ref-link-section-d31082446e2304">21</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Tan M, Deklerck R, Cornelis J, Jansen B (2013) Phased searching with NEAT in a time-scaled framework: experiments on a computer-aided detection system for lung nodules. Artif Intell Med 59:157–167" href="/article/10.1007/s00330-015-4030-7#ref-CR22" id="ref-link-section-d31082446e2307">22</a>]. For using CAD in a screening setting, a high sensitivity even at the expense of specificity is desirable to find all potential cancerous nodules. High false positive rates, on the other hand, increase the workload to radiologists and potentially increase unnecessary follow-up. We, therefore, report the sensitivity using the highest level of evidence (four out of four readers) and considered the lower levels of agreement for quantifying the false positive rates. For future CAD reference databases, a large database of CT images including follow-up CT and histopathological correlation would be helpful to remove subjectivity from the reference standard, and to verify whether CAD detects the clinically relevant nodules.</p><p>In conclusion, we found that, on the largest publicly available database of annotated chest CT scans for lung nodule detection, <i>Herakles</i> detects the vast majority of pulmonary nodules at a low false positive rate. The results show that the new prototype outperforms the other two CAD systems and is robust to different acquisition factors, such as presence of contrast, section thickness, and reconstruction kernel. Our observer experiment showed that <i>Herakles</i> was able show to pulmonary nodules that had been missed by the extensive LIDC annotation process. Given the growing interest and need for CAD in the context of screening, it can be expected that new CAD algorithms will be presented in the near future. Our results are publicly available and other CAD researchers may compare the performance of their CAD algorithm to the results reported here, utilizing the LIDC/IDRI database for benchmarking of available CAD systems.</p></div></div></section>
                        
                    

                    <section data-title="Abbreviations"><div class="c-article-section" id="abbreviations-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="abbreviations">Abbreviations</h2><div class="c-article-section__content" id="abbreviations-content"><dl class="c-abbreviation_list"><dt class="c-abbreviation_list__term u-text-bold u-float-left u-pr-16"><dfn>CAD:</dfn></dt><dd class="c-abbreviation_list__description u-mb-24">
                    <p>Computer-aided detection</p>
                  </dd><dt class="c-abbreviation_list__term u-text-bold u-float-left u-pr-16"><dfn>CT:</dfn></dt><dd class="c-abbreviation_list__description u-mb-24">
                    <p>Computed tomography</p>
                  </dd><dt class="c-abbreviation_list__term u-text-bold u-float-left u-pr-16"><dfn>LIDC:</dfn></dt><dd class="c-abbreviation_list__description u-mb-24">
                    <p>Lung image database consortium</p>
                  </dd><dt class="c-abbreviation_list__term u-text-bold u-float-left u-pr-16"><dfn>IDRI:</dfn></dt><dd class="c-abbreviation_list__description u-mb-24">
                    <p>Image database resource initiative</p>
                  </dd></dl></div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Li Q (2007) Recent progress in computer-aided diagnosis of lung nodules on thin-section CT. Comput Med Imaging Graph 31:248–257</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.compmedimag.2007.02.005" aria-label="Article reference 1">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17369020" aria-label="PubMed reference 1" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1948076" aria-label="PubMed Central reference 1" rel="nofollow">PubMed Central</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Recent%20progress%20in%20computer-aided%20diagnosis%20of%20lung%20nodules%20on%20thin-section%20CT&amp;journal=Comput%20Med%20Imaging%20Graph&amp;volume=31&amp;pages=248-257&amp;publication_year=2007&amp;author=Li%2CQ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Lee SLA, Kouzani AZ, Hu EJ (2012) Automated detection of lung nodules in computed tomography images: a review. Mach Vis Appl 23:151–163</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs00138-010-0271-2" aria-label="Article reference 2">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Automated%20detection%20of%20lung%20nodules%20in%20computed%20tomography%20images%3A%20a%20review&amp;journal=Mach%20Vis%20Appl&amp;volume=23&amp;pages=151-163&amp;publication_year=2012&amp;author=Lee%2CSLA&amp;author=Kouzani%2CAZ&amp;author=Hu%2CEJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">Aberle DR, Adams AM, Berg CD, Black WC, Clapp JD, Fagerstrom RM et al (2011) Reduced lung-cancer mortality with low-dose computed tomographic screening. N Engl J Med 365:395–409</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1056%2FNEJMoa1102873" aria-label="Article reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21714641" aria-label="PubMed reference 3" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Reduced%20lung-cancer%20mortality%20with%20low-dose%20computed%20tomographic%20screening&amp;journal=N%20Engl%20J%20Med&amp;volume=365&amp;pages=395-409&amp;publication_year=2011&amp;author=Aberle%2CDR&amp;author=Adams%2CAM&amp;author=Berg%2CCD&amp;author=Black%2CWC&amp;author=Clapp%2CJD&amp;author=Fagerstrom%2CRM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">de Koning HJ, Meza R, Plevritis SK, Ten Haaf K, Munshi VN, Jeon J et al (2014) Benefits and harms of computed tomography lung cancer screening strategies: a comparative modeling study for the U.S. Preventive Services Task Force. Ann Intern Med 160:311–320</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.7326%2FM13-2316" aria-label="Article reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24379002" aria-label="PubMed reference 4" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4116741" aria-label="PubMed Central reference 4" rel="nofollow">PubMed Central</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Benefits%20and%20harms%20of%20computed%20tomography%20lung%20cancer%20screening%20strategies%3A%20a%20comparative%20modeling%20study%20for%20the%20U.S.%20Preventive%20Services%20Task%20Force&amp;journal=Ann%20Intern%20Med&amp;volume=160&amp;pages=311-320&amp;publication_year=2014&amp;author=Koning%2CHJ&amp;author=Meza%2CR&amp;author=Plevritis%2CSK&amp;author=Haaf%2CK&amp;author=Munshi%2CVN&amp;author=Jeon%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Black WC, Gareen IF, Soneji SS, Sicks JD, Keeler EB, Aberle DR et al (2014) Cost-effectiveness of CT screening in the National Lung Screening Trial. N Engl J Med 371:1793–1802</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXitFOlsb7L" aria-label="CAS reference 5">CAS</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1056%2FNEJMoa1312547" aria-label="Article reference 5">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25372087" aria-label="PubMed reference 5" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4335305" aria-label="PubMed Central reference 5" rel="nofollow">PubMed Central</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Cost-effectiveness%20of%20CT%20screening%20in%20the%20National%20Lung%20Screening%20Trial&amp;journal=N%20Engl%20J%20Med&amp;volume=371&amp;pages=1793-1802&amp;publication_year=2014&amp;author=Black%2CWC&amp;author=Gareen%2CIF&amp;author=Soneji%2CSS&amp;author=Sicks%2CJD&amp;author=Keeler%2CEB&amp;author=Aberle%2CDR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Aberle DR, Henschke CI, McLoud TC, Boiselle PM (2012) Expert opinion: barriers to CT screening for lung cancer. J Thorac Imaging 27:208</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1097%2FRTI.0b013e318253d74d" aria-label="Article reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22695061" aria-label="PubMed reference 6" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=Expert%20opinion%3A%20barriers%20to%20CT%20screening%20for%20lung%20cancer&amp;journal=J%20Thorac%20Imaging&amp;volume=27&amp;publication_year=2012&amp;author=Aberle%2CDR&amp;author=Henschke%2CCI&amp;author=McLoud%2CTC&amp;author=Boiselle%2CPM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">Prokop M (2014) Lung cancer screening: the radiologist's perspective. Semin Respir Crit Care Med 35:91–98</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1055%2Fs-0033-1363455" aria-label="Article reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24481763" aria-label="PubMed reference 7" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Lung%20cancer%20screening%3A%20the%20radiologist%27s%20perspective&amp;journal=Semin%20Respir%20Crit%20Care%20Med&amp;volume=35&amp;pages=91-98&amp;publication_year=2014&amp;author=Prokop%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Armato SG, McLennan G, McNitt-Gray MF, Meyer CR, Yankelevitz D, Aberle DR et al (2004) Lung image database consortium: developing a resource for the medical imaging research community. Radiology 232:739–748</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1148%2Fradiol.2323032035" aria-label="Article reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15333795" aria-label="PubMed reference 8" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Lung%20image%20database%20consortium%3A%20developing%20a%20resource%20for%20the%20medical%20imaging%20research%20community&amp;journal=Radiology&amp;volume=232&amp;pages=739-748&amp;publication_year=2004&amp;author=Armato%2CSG&amp;author=McLennan%2CG&amp;author=McNitt-Gray%2CMF&amp;author=Meyer%2CCR&amp;author=Yankelevitz%2CD&amp;author=Aberle%2CDR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">van Ginneken B, Armato SG, de Hoop B, van de Vorst S, Duindam T, Niemeijer M et al (2010) Comparing and combining algorithms for computer-aided detection of pulmonary nodules in computed tomography scans: the ANODE09 study. Med Image Anal 14:707–722</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.media.2010.05.005" aria-label="Article reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20573538" aria-label="PubMed reference 9" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparing%20and%20combining%20algorithms%20for%20computer-aided%20detection%20of%20pulmonary%20nodules%20in%20computed%20tomography%20scans%3A%20the%20ANODE09%20study&amp;journal=Med%20Image%20Anal&amp;volume=14&amp;pages=707-722&amp;publication_year=2010&amp;author=Ginneken%2CB&amp;author=Armato%2CSG&amp;author=Hoop%2CB&amp;author=Vorst%2CS&amp;author=Duindam%2CT&amp;author=Niemeijer%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Armato SG, McLennan G, Bidaut L, McNitt-Gray MF, Meyer CR, Reeves AP et al (2011) The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): a completed reference database of lung nodules on CT scans. Med Phys 38:915–931</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1118%2F1.3528204" aria-label="Article reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21452728" aria-label="PubMed reference 10" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041807" aria-label="PubMed Central reference 10" rel="nofollow">PubMed Central</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Lung%20Image%20Database%20Consortium%20%28LIDC%29%20and%20Image%20Database%20Resource%20Initiative%20%28IDRI%29%3A%20a%20completed%20reference%20database%20of%20lung%20nodules%20on%20CT%20scans&amp;journal=Med%20Phys&amp;volume=38&amp;pages=915-931&amp;publication_year=2011&amp;author=Armato%2CSG&amp;author=McLennan%2CG&amp;author=Bidaut%2CL&amp;author=McNitt-Gray%2CMF&amp;author=Meyer%2CCR&amp;author=Reeves%2CAP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Murphy K, van Ginneken B, Schilham AMR, de Hoop BJ, Gietema HA, Prokop M (2009) A large scale evaluation of automatic pulmonary nodule detection in chest ct using local image features and k-nearest-neighbour classification. Med Image Anal 13:757–770</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="/articles/cas-redirect/1:STN:280:DC%2BD1MrntFelsw%3D%3D" aria-label="CAS reference 11">CAS</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.media.2009.07.001" aria-label="Article reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19646913" aria-label="PubMed reference 11" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20large%20scale%20evaluation%20of%20automatic%20pulmonary%20nodule%20detection%20in%20chest%20ct%20using%20local%20image%20features%20and%20k-nearest-neighbour%20classification&amp;journal=Med%20Image%20Anal&amp;volume=13&amp;pages=757-770&amp;publication_year=2009&amp;author=Murphy%2CK&amp;author=Ginneken%2CB&amp;author=Schilham%2CAMR&amp;author=Hoop%2CBJ&amp;author=Gietema%2CHA&amp;author=Prokop%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Chakraborty DP, Berbaum KS (2004) Observer studies involving detection and localization: modeling, analysis, and validation. Med Phys 31:2313–2330</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1118%2F1.1769352" aria-label="Article reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15377098" aria-label="PubMed reference 12" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Observer%20studies%20involving%20detection%20and%20localization%3A%20modeling%2C%20analysis%2C%20and%20validation&amp;journal=Med%20Phys&amp;volume=31&amp;pages=2313-2330&amp;publication_year=2004&amp;author=Chakraborty%2CDP&amp;author=Berbaum%2CKS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Efron B (1979) Bootstrap methods: another look at the jackknife. Ann Stat 7:1–29</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1214%2Faos%2F1176344552" aria-label="Article reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Bootstrap%20methods%3A%20another%20look%20at%20the%20jackknife&amp;journal=Ann%20Stat&amp;volume=7&amp;pages=1-29&amp;publication_year=1979&amp;author=Efron%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Hansell DM, Bankier AA, MacMahon H, McLoud TC, Müller NL, Remy J (2008) Fleischner society: glossary of terms for thoracic imaging. Radiology 246:697–722</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1148%2Fradiol.2462070712" aria-label="Article reference 14">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18195376" aria-label="PubMed reference 14" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Fleischner%20society%3A%20glossary%20of%20terms%20for%20thoracic%20imaging&amp;journal=Radiology&amp;volume=246&amp;pages=697-722&amp;publication_year=2008&amp;author=Hansell%2CDM&amp;author=Bankier%2CAA&amp;author=MacMahon%2CH&amp;author=McLoud%2CTC&amp;author=M%C3%BCller%2CNL&amp;author=Remy%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Armato SG, Roberts RY, Kocherginsky M, Aberle DR, Kazerooni EA, Macmahon H et al (2009) Assessment of radiologist performance in the detection of lung nodules: dependence on the definition of “truth”. Acad Radiol 16:28–38</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.acra.2008.05.022" aria-label="Article reference 15">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19064209" aria-label="PubMed reference 15" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2658894" aria-label="PubMed Central reference 15" rel="nofollow">PubMed Central</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Assessment%20of%20radiologist%20performance%20in%20the%20detection%20of%20lung%20nodules%3A%20dependence%20on%20the%20definition%20of%20%E2%80%9Ctruth%E2%80%9D&amp;journal=Acad%20Radiol&amp;volume=16&amp;pages=28-38&amp;publication_year=2009&amp;author=Armato%2CSG&amp;author=Roberts%2CRY&amp;author=Kocherginsky%2CM&amp;author=Aberle%2CDR&amp;author=Kazerooni%2CEA&amp;author=Macmahon%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Armato SG, McNitt-Gray MF, Reeves AP, Meyer CR, McLennan G, Aberle DR et al (2007) The Lung Image Database Consortium (LIDC): an evaluation of radiologist variability in the identification of lung nodules on CT scans. Acad Radiol 14:1409–1421</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.acra.2007.07.008" aria-label="Article reference 16">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17964464" aria-label="PubMed reference 16" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2290739" aria-label="PubMed Central reference 16" rel="nofollow">PubMed Central</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Lung%20Image%20Database%20Consortium%20%28LIDC%29%3A%20an%20evaluation%20of%20radiologist%20variability%20in%20the%20identification%20of%20lung%20nodules%20on%20CT%20scans&amp;journal=Acad%20Radiol&amp;volume=14&amp;pages=1409-1421&amp;publication_year=2007&amp;author=Armato%2CSG&amp;author=McNitt-Gray%2CMF&amp;author=Reeves%2CAP&amp;author=Meyer%2CCR&amp;author=McLennan%2CG&amp;author=Aberle%2CDR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">Rubin GD, Lyo JK, Paik DS, Sherbondy AJ, Chow LC, Leung AN et al (2005) Pulmonary nodules on multi-detector row CT scans: performance comparison of radiologists and computer-aided detection. Radiology 234:274–283</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1148%2Fradiol.2341040589" aria-label="Article reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15537839" aria-label="PubMed reference 17" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Pulmonary%20nodules%20on%20multi-detector%20row%20CT%20scans%3A%20performance%20comparison%20of%20radiologists%20and%20computer-aided%20detection&amp;journal=Radiology&amp;volume=234&amp;pages=274-283&amp;publication_year=2005&amp;author=Rubin%2CGD&amp;author=Lyo%2CJK&amp;author=Paik%2CDS&amp;author=Sherbondy%2CAJ&amp;author=Chow%2CLC&amp;author=Leung%2CAN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Jacobs C, van Rikxoort EM, Twellmann T, Scholten ET, de Jong PA, Kuhnigk JM et al (2014) Automatic detection of subsolid pulmonary nodules in thoracic computed tomography images. Med Image Anal 18:374–384</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.media.2013.12.001" aria-label="Article reference 18">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24434166" aria-label="PubMed reference 18" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20detection%20of%20subsolid%20pulmonary%20nodules%20in%20thoracic%20computed%20tomography%20images&amp;journal=Med%20Image%20Anal&amp;volume=18&amp;pages=374-384&amp;publication_year=2014&amp;author=Jacobs%2CC&amp;author=Rikxoort%2CEM&amp;author=Twellmann%2CT&amp;author=Scholten%2CET&amp;author=Jong%2CPA&amp;author=Kuhnigk%2CJM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">van Klaveren RJ, Oudkerk M, Prokop M, Scholten ET, Nackaerts K et al (2009) Management of lung nodules detected by volume CT scanning. N Engl J Med 361:2221–2222</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1056%2FNEJMoa0906085" aria-label="Article reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19955524" aria-label="PubMed reference 19" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Management%20of%20lung%20nodules%20detected%20by%20volume%20CT%20scanning&amp;journal=N%20Engl%20J%20Med&amp;volume=361&amp;pages=2221-2222&amp;publication_year=2009&amp;author=Klaveren%2CRJ&amp;author=Oudkerk%2CM&amp;author=Prokop%2CM&amp;author=Scholten%2CET&amp;author=Nackaerts%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Drew T, Vo ML, Olwal A, Jacobson F, Seltzer SE, Wolfe JM (2013) Scanners and drillers: characterizing expert visual search through volumetric images. J Vis 13:1–13</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1167%2F13.10.3" aria-label="Article reference 20">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Scanners%20and%20drillers%3A%20characterizing%20expert%20visual%20search%20through%20volumetric%20images&amp;journal=J%20Vis&amp;volume=13&amp;pages=1-13&amp;publication_year=2013&amp;author=Drew%2CT&amp;author=Vo%2CML&amp;author=Olwal%2CA&amp;author=Jacobson%2CF&amp;author=Seltzer%2CSE&amp;author=Wolfe%2CJM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Camarlinghi N (2013) Automatic detection of lung nodules in computed tomography images: training and validation of algorithms using public research databases. Eur Phys J Plus 128:1–21</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1140%2Fepjp%2Fi2013-13110-5" aria-label="Article reference 21">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20detection%20of%20lung%20nodules%20in%20computed%20tomography%20images%3A%20training%20and%20validation%20of%20algorithms%20using%20public%20research%20databases&amp;journal=Eur%20Phys%20J%20Plus&amp;volume=128&amp;pages=1-21&amp;publication_year=2013&amp;author=Camarlinghi%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Tan M, Deklerck R, Cornelis J, Jansen B (2013) Phased searching with NEAT in a time-scaled framework: experiments on a computer-aided detection system for lung nodules. Artif Intell Med 59:157–167</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.artmed.2013.07.002" aria-label="Article reference 22">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24028824" aria-label="PubMed reference 22" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Phased%20searching%20with%20NEAT%20in%20a%20time-scaled%20framework%3A%20experiments%20on%20a%20computer-aided%20detection%20system%20for%20lung%20nodules&amp;journal=Artif%20Intell%20Med&amp;volume=59&amp;pages=157-167&amp;publication_year=2013&amp;author=Tan%2CM&amp;author=Deklerck%2CR&amp;author=Cornelis%2CJ&amp;author=Jansen%2CB">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="https://citation-needed.springer.com/v2/references/10.1007/s00330-015-4030-7?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>The authors acknowledge the National Cancer Institute and the Foundation for the National Institutes of Health, and their critical role in the creation of the free publicly available LIDC/IDRI Database used in this study.</p><p>The scientific guarantor of this publication is Bram van Ginneken. The authors of this manuscript declare relationships with the following companies: MeVis Medical Solutions AG, Bremen, Germany</p><p>This study has received funding by a research grant from MeVis Medical Solutions AG, Bremen, Germany and by a research grant from the Netherlands Organisation for Scientific Research (NWO), project number 639.023.207. No complex statistical methods were necessary for this paper. Institutional Review Board approval was obtained. Written informed consent was waived by the Institutional Review Board.</p><p>Not applicable since no animals were involved in this study. Some study subjects or cohorts have been previously reported in previous studies involving the LIDC/IDRI database. The following publication describes the complete LIDC/IDRI database:</p><p>Armato SG, McLennan G, Bidaut L, et al. (2011) The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): a completed reference database of lung nodules on CT scans. Med Phys 38: 915–931</p><p>Methodology: retrospective, experimental, multicenter study.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Geert Grooteplein 10, 6525 GA, Nijmegen, The Netherlands</p><p class="c-article-author-affiliation__authors-list">Colin Jacobs, Eva M. van Rikxoort, Mathias Prokop, Cornelia M. Schaefer-Prokop &amp; Bram van Ginneken</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Fraunhofer MEVIS, Bremen, Germany</p><p class="c-article-author-affiliation__authors-list">Eva M. van Rikxoort &amp; Bram van Ginneken</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Department of Radiology, Meander Medical Center, Amersfoort, The Netherlands</p><p class="c-article-author-affiliation__authors-list">Cornelia M. Schaefer-Prokop</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Irish Centre for Fetal and Neonatal Translational Research, University College Cork, Cork, Ireland</p><p class="c-article-author-affiliation__authors-list">Keelin Murphy</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Colin-Jacobs"><span class="c-article-authors-search__title u-h3 js-search-name">Colin Jacobs</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=%22Colin%20Jacobs%22" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Colin%20Jacobs" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Colin%20Jacobs%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Eva_M_-Rikxoort"><span class="c-article-authors-search__title u-h3 js-search-name">Eva M. van Rikxoort</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=%22Eva%20M.%20van%20Rikxoort%22" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Eva%20M.%20van%20Rikxoort" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Eva%20M.%20van%20Rikxoort%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Keelin-Murphy"><span class="c-article-authors-search__title u-h3 js-search-name">Keelin Murphy</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=%22Keelin%20Murphy%22" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Keelin%20Murphy" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Keelin%20Murphy%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Mathias-Prokop"><span class="c-article-authors-search__title u-h3 js-search-name">Mathias Prokop</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=%22Mathias%20Prokop%22" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Mathias%20Prokop" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Mathias%20Prokop%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Cornelia_M_-Schaefer_Prokop"><span class="c-article-authors-search__title u-h3 js-search-name">Cornelia M. Schaefer-Prokop</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=%22Cornelia%20M.%20Schaefer-Prokop%22" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Cornelia%20M.%20Schaefer-Prokop" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Cornelia%20M.%20Schaefer-Prokop%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Bram-Ginneken"><span class="c-article-authors-search__title u-h3 js-search-name">Bram van Ginneken</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=%22Bram%20van%20Ginneken%22" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Bram%20van%20Ginneken" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Bram%20van%20Ginneken%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:colin.jacobs@radboudumc.nl">Colin Jacobs</a>.</p></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content">
                <p>
                           <b>Open Access</b>  This article is distributed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (http://creativecommons.org/licenses/by-nc/4.0/), which permits any noncommercial use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</p>
              <p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Computer-aided%20detection%20of%20pulmonary%20nodules%3A%20a%20comparative%20study%20using%20the%20public%20LIDC%2FIDRI%20database&amp;author=Colin%20Jacobs%20et%20al&amp;contentID=10.1007%2Fs00330-015-4030-7&amp;copyright=The%20Author%28s%29&amp;publication=0938-7994&amp;publicationDate=2015-10-06&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY-NC">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s00330-015-4030-7" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s00330-015-4030-7" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Jacobs, C., van Rikxoort, E.M., Murphy, K. <i>et al.</i> Computer-aided detection of pulmonary nodules: a comparative study using the public LIDC/IDRI database.
                    <i>Eur Radiol</i> <b>26, </b>2139–2147 (2016). https://doi.org/10.1007/s00330-015-4030-7</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" href="https://citation-needed.springer.com/v2/references/10.1007/s00330-015-4030-7?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-06-12">12 June 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Revised<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-07-20">20 July 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-09-14">14 September 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-10-06">06 October 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-07">July 2016</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1007/s00330-015-4030-7</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span>Computer-assisted diagnosis</span></li><li class="c-article-subject-list__subject"><span>Image interpretation, computer-assisted</span></li><li class="c-article-subject-list__subject"><span>Lung cancer</span></li><li class="c-article-subject-list__subject"><span>Solitary pulmonary nodule</span></li><li class="c-article-subject-list__subject"><span>Lung</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper" class="js-context-bar-sticky-point-desktop">
                    
    <div class="c-pdf-container">
        <div class="c-pdf-download u-clear-both">
            <a href="https://link.springer.com/content/pdf/10.1007/s00330-015-4030-7.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" data-track-external>
                
                    <span class="c-pdf-download__text">Download PDF</span>
                    <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
                
            </a>
        </div>
    </div>

                </div>

                <div data-test="collections">
                    
    

                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="u-mt-16" data-component-mpu>
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-pa11y-ignore data-gpt data-gpt-unitpath="/270604982/springerlink/330/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=s00330-015-4030-7;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>

    
    <script src="/.cdn-rum/performance.js" async></script>

    
        <script>
            
        </script>
    


        
    <footer class="app-footer" role="contentinfo" data-test="springerlink-footer">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" data-cc-action="preferences" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a href="https://support.springer.com/en/support/home">FAQ</a></li>
                <li><a id="contactus-footer-link" href="https://support.springer.com/en/support/solutions/articles/6000206179-contacting-us">Contact us</a></li>
                <li><a href="https://www.springer.com/gp/shop/promo/affiliate/springer-nature">Affiliate program</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 80.238.115.105</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Not affiliated
        </p>

    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-b88bf25ad4.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2022 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
    </footer>



    </div>
    
    

    
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
        <symbol id="icon-info" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-success" viewBox="0 0 18 18">
            <path d="M9 0a9 9 0 110 18A9 9 0 019 0zm3.486 4.982l-4.718 5.506L5.14 8.465a.991.991 0 00-1.423.133 1.06 1.06 0 00.13 1.463l3.407 2.733a1 1 0 001.387-.133l5.385-6.334a1.06 1.06 0 00-.116-1.464.991.991 0 00-1.424.119z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-down" viewBox="0 0 16 16">
            <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/>
        </symbol>
        <symbol id="icon-warning" viewBox="0 0 18 18">
            <path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-plus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-minus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-error" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-springer-arrow-left">
            <path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/>
        </symbol>
        <symbol id="icon-springer-arrow-right">
            <path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/>
        </symbol>
        <symbol id="icon-arrow-up" viewBox="0 0 16 16">
            <path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-tick" viewBox="0 0 24 24">
            <path d="M12,24 C5.372583,24 0,18.627417 0,12 C0,5.372583 5.372583,0 12,0 C18.627417,0 24,5.372583 24,12 C24,18.627417 18.627417,24 12,24 Z M7.657,10.79 C7.45285634,10.6137568 7.18569967,10.5283283 6.91717333,10.5534259 C6.648647,10.5785236 6.40194824,10.7119794 6.234,10.923 C5.87705269,11.3666969 5.93445559,12.0131419 6.364,12.387 L10.261,15.754 C10.6765468,16.112859 11.3037113,16.0695601 11.666,15.657 L17.759,8.713 C18.120307,8.27302248 18.0695334,7.62621189 17.644,7.248 C17.4414817,7.06995024 17.1751516,6.9821166 16.9064461,7.00476032 C16.6377406,7.02740404 16.3898655,7.15856958 16.22,7.368 L10.768,13.489 L7.657,10.79 Z"/>
        </symbol>
    </svg>

</body>
</html>

<!DOCTYPE html>
<html lang="en" xmlns:og="http://ogp.me/ns#" xmlns:fb="https://www.facebook.com/2008/fbml">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta content="mdpi" name="sso-service" />
<meta content="width=device-width, initial-scale=1.0" name="viewport" />
<title>Diagnostics  | Free Full-Text | The Performance of Deep Learning Algorithms on Automatic Pulmonary Nodule Detection and Classification Tested on Different Datasets That Are Not Derived from LIDC-IDRI: A Systematic Review | HTML</title><link rel="stylesheet" href="/assets/css/font-awesome.min.css?eb190a3a77e5e1ee">
<link rel="stylesheet" href="/assets/css/jquery.multiselect.css?f56c135cbf4d1483">
<link rel="stylesheet" href="/assets/css/chosen.min.css?d7ca5ca9441ef9e1">
<link rel="stylesheet" href="/assets/css/main2.css?55f92efea8c48975">
<link rel="mask-icon" href="/img/mask-icon-128.svg?c1c7eca266cd7013" color="#4f5671">
<link rel="apple-touch-icon" sizes="180x180" href="/icon/apple-touch-icon-180x180.png">
<link rel="apple-touch-icon" sizes="152x152" href="/icon/apple-touch-icon-152x152.png">
<link rel="apple-touch-icon" sizes="144x144" href="/icon/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon" sizes="120x120" href="/icon/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" sizes="114x114" href="/icon/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon" sizes="76x76" href="/icon/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" sizes="72x72" href="/icon/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="57x57" href="/icon/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon" href="/icon/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon-precomposed" href="/icon/apple-touch-icon-57x57.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="#ffffff">
<meta name="application-name" content="&nbsp;" />
<link rel="apple-touch-startup-image" href="/img/journals/diagnostics-logo-sq.png?cc7fe11b9251f219">
<link rel="apple-touch-icon" href="/img/journals/diagnostics-logo-sq.png?cc7fe11b9251f219">
<meta name="msapplication-TileImage" content="/img/journals/diagnostics-logo-sq.png?cc7fe11b9251f219">
<style>

h2, #abstract .related_suggestion_title {
    color: rgba(43,128,143,0.75);
}

.batch_articles a {
    color: #000;
}

    a, .batch_articles .authors a, a:focus, a:hover, a:active, .batch_articles a:focus, .batch_articles a:hover, li.side-menu-li a {
        color: rgba(43,128,143,0.75);
    }

    span.label a {
        color: #fff;
    }

    #main-content a.title-link:hover,
    #main-content a.title-link:focus,
    #main-content div.generic-item a.title-link:hover,
    #main-content div.generic-item a.title-link:focus {
        color: rgba(43,128,143,0.75);
    }

    #main-content #middle-column .generic-item.article-item a.title-link:hover,
    #main-content #middle-column .generic-item.article-item a.title-link:focus {
        color: rgba(43,128,143,0.75);
    }

    .art-authors a.toEncode {
        color: #333;
        font-weight: 700;
    }

    #main-content #middle-column ul li::before {
        color: rgba(43,128,143,0.75);
    }

    .accordion-navigation.active a.accordion__title,
    .accordion-navigation.active a.accordion__title::after {
        color: rgba(43,128,143,0.75) !important;
    }

    .accordion-navigation li:hover::before,
    .accordion-navigation li:hover a,
    .accordion-navigation li:focus a {
        color: rgba(43,128,143,0.75) !important;
    }

    .relative-size-container .relative-size-image .relative-size {
        background-color: rgba(43,128,143,0.75);
    }

    .middle-column__help__fixed a:hover i,
        color: rgba(43,128,143,0.75) !important;
    }

    input[type="checkbox"]:checked:after {
        color: rgba(43,128,143,0.75) !important;
    }

    input[type="checkbox"]:not(:disabled):hover:before {
        border-color: rgba(43,128,143,0.75) !important;
    }

    #main-content .bolded-text {
        color: rgba(43,128,143,0.75);
    }


#main-content .hypothesis-count-container {
    background-color: rgba(43,128,143,0.75) !important;
}

#main-content .hypothesis-count-container:before {
    border-bottom-color: rgba(43,128,143,0.75) !important;
}

#main-content .trendmd-widget-cookie-notification__info a {
    color: rgba(43,128,143,0.75) !important;
}

.full-size-menu ul li.menu-item .dropdown-wrapper {
    background-color: #2B808F !important;
}

.full-size-menu ul li.menu-item > a.open::after {
    border-bottom: 10px solid #2B808F;
}

#title-story .title-story-orbit .orbit-caption {
    #background: url('/img/design/000000_background.png') !important;
    background: url('/img/design/ffffff_background.png') !important;
    color: rgb(51, 51, 51) !important;
}

#main-content .content__container__orbit {
    background-color: #000 !important;
}

#main-content .content__container__journal {
    background-color: #2B808F;
    color: #fff;
}

.html-article-menu .row span {
    color: rgba(43,128,143,0.75);
}

.html-article-menu .row span.active {
    }

.side-menu-li.active::before,
.side-menu-li.active a {
    color: rgba(43,128,143,0.75) !important;
}

.side-menu-ul li.active a, .side-menu-ul li.active, .side-menu-ul li.active::before {
    color: rgba(43,128,143,0.75) !important;
}

.side-menu-ul li.active a {
    font-weight: 700 !important;
}

.result-selected, .active-result.highlighted, .active-result:hover,
.result-selected, .active-result.highlighted, .active-result:focus {
    background-color: rgba(43,128,143,0.75) !important;
    color: #fff;
}

.search-container.search-container__default-scheme {
    background-color: #2B808F;
}

nav.tab-bar .open-small-search.active:after {
    border-bottom-color: #2B808F;
}

.search-container.search-container__default-scheme .custom-accordion-for-small-screen-link::after {
    color: #fff;
}

@media only screen and (max-width: 50em) {
    #main-content .content__container.journal-info {
        color: #fff;
        background-color: rgba(43,128,143,0.75);
    }

    #main-content .content__container.journal-info a {
        color: #fff;
    }
} 

.button.button--color {
    color: rgba(43,128,143,0.75);
    border-color: rgba(43,128,143,0.75);
}

.button.button--color:hover,
.button.button--color:focus {
    color: #fff;
    border-color: rgba(43,128,143,0.75);
    background-color: rgba(43,128,143,0.75);
}

.button.button--color-inversed {
    background-color: rgba(43,128,143,0.75);
    border-color: #fff;
    color: #fff;
}

.button.button--color-inversed:hover,
.button.button--color-inversed:focus {
    background-color: rgba(43,128,143,0.75);
    border-color: #fff;
    color: #fff;
}

.button.button--color path {
    fill: rgba(43,128,143,0.75);
}

.button.button--color:hover path {
    fill: #fff;
}

#main-content #search-refinements .ui-slider-horizontal .ui-slider-range {
    background-color: rgba(43,128,143,0.75);
}

.breadcrumb__element:last-of-type a {
    color: rgba(43,128,143,0.75);
}

    
#main-header {
    background-color: rgba(43,128,143,0.75);
}

#full-size-menu .top-bar, #full-size-menu li.menu-item span.user-email {
    background-color:   rgba(43,128,143,0.75)
}

.top-bar-section li:not(.has-form) a:not(.button) {
    background-color:   rgba(43,128,143,0.75)
}

#full-size-menu li.menu-item .dropdown-wrapper li a:hover {
    color:   rgba(43,128,143,0.75)
}

#full-size-menu li.menu-item a:hover, #full-size-menu li.menu.item a:focus, nav.tab-bar a:hover {
    }
#full-size-menu li.menu.item a:active, #full-size-menu li.menu.item a.active {
    background-color: #B9E0E9;
}

#full-size-menu li.menu-item a.open-mega-menu.active, #full-size-menu li.menu-item div.mega-menu, a.open-mega-menu.active {
    background-color: #B9E0E9;
    color: #000;
}

#full-size-menu li.menu-item div.mega-menu li, #full-size-menu li.menu-item div.mega-menu a {
    background-color: #B9E0E9;
    color: #000;
    border-color: #9a9a9a;
}

div.type-section h1 {
    padding-left: 15px !important;
    background-color: rgba(43,128,143,0.75);
    color: #fff;
    font-size: 20px;
    line-height: 26px;
    font-weight: 300;
}

div.type-section h3 {
    margin-left: 15px;
    margin-bottom: 0px;
    font-weight: 300;
}

.journal-tabs .tab-title.active a {
    background-color: rgba(43,128,143,0.75);
    border-color: rgba(43,128,143,0.75);
    color: #fff;
}

</style>
<link rel="stylesheet" href="/assets/css/jquery-ui-1.10.4.custom.min.css?80647d88647bf347">
<link rel="stylesheet" href="/assets/css/magnific-popup.min.css?04d343e036f8eecd">
<link rel="stylesheet" href="/assets/css/xml2html/article-html.css?d22327de055631c3">
<meta name="title" content="The Performance of Deep Learning Algorithms on Automatic Pulmonary Nodule Detection and Classification Tested on Different Datasets That Are Not Derived from LIDC-IDRI: A Systematic Review">
<meta name="description" content="The aim of this study was to systematically review the performance of deep learning technology in detecting and classifying pulmonary nodules on computed tomography (CT) scans that were not from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) database. Furthermore, we explored the difference in performance when the deep learning technology was applied to test datasets different from the training datasets. Only peer-reviewed, original research articles utilizing deep learning technology were included in this study, and only results from testing on datasets other than the LIDC-IDRI were included. We searched a total of six databases: EMBASE, PubMed, Cochrane Library, the Institute of Electrical and Electronics Engineers, Inc. (IEEE), Scopus, and Web of Science. This resulted in 1782 studies after duplicates were removed, and a total of 26 studies were included in this systematic review. Three studies explored the performance of pulmonary nodule detection only, 16 studies explored the performance of pulmonary nodule classification only, and 7 studies had reports of both pulmonary nodule detection and classification. Three different deep learning architectures were mentioned amongst the included studies: convolutional neural network (CNN), massive training artificial neural network (MTANN), and deep stacked denoising autoencoder extreme learning machine (SDAE-ELM). The studies reached a classification accuracy between 68&amp;ndash;99.6% and a detection accuracy between 80.6&amp;ndash;94%. Performance of deep learning technology in studies using different test and training datasets was comparable to studies using same type of test and training datasets. In conclusion, deep learning was able to achieve high levels of accuracy, sensitivity, and/or specificity in detecting and/or classifying nodules when applied to pulmonary CT scans not from the LIDC-IDRI database.">
<link rel="image_src" href="/img/journals/diagnostics-logo.png?cc7fe11b9251f219">
<meta name="dc.title" content="The Performance of Deep Learning Algorithms on Automatic Pulmonary Nodule Detection and Classification Tested on Different Datasets That Are Not Derived from LIDC-IDRI: A Systematic Review">
<meta name="dc.creator" content="Dana Li">
<meta name="dc.creator" content="Bolette Mikela Vilmun">
<meta name="dc.creator" content="Jonathan Frederik Carlsen">
<meta name="dc.creator" content="Elisabeth Albrecht-Beste">
<meta name="dc.creator" content="Carsten Ammitzbøl Lauridsen">
<meta name="dc.creator" content="Michael Bachmann Nielsen">
<meta name="dc.creator" content="Kristoffer Lindskov Hansen">
<meta name="dc.type" content="Review">
<meta name="dc.source" content="Diagnostics 2019, Vol. 9, Page 207">
<meta name="dc.date" content="2019-11-29">
<meta name="dc.identifier" content="10.3390/diagnostics9040207">
<meta name="dc.publisher" content="Multidisciplinary Digital Publishing Institute">
<meta name="dc.rights" content="http://creativecommons.org/licenses/by/3.0/">
<meta name="dc.format" content="application/pdf">
<meta name="dc.language" content="en">
<meta name="dc.description" content="The aim of this study was to systematically review the performance of deep learning technology in detecting and classifying pulmonary nodules on computed tomography (CT) scans that were not from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) database. Furthermore, we explored the difference in performance when the deep learning technology was applied to test datasets different from the training datasets. Only peer-reviewed, original research articles utilizing deep learning technology were included in this study, and only results from testing on datasets other than the LIDC-IDRI were included. We searched a total of six databases: EMBASE, PubMed, Cochrane Library, the Institute of Electrical and Electronics Engineers, Inc. (IEEE), Scopus, and Web of Science. This resulted in 1782 studies after duplicates were removed, and a total of 26 studies were included in this systematic review. Three studies explored the performance of pulmonary nodule detection only, 16 studies explored the performance of pulmonary nodule classification only, and 7 studies had reports of both pulmonary nodule detection and classification. Three different deep learning architectures were mentioned amongst the included studies: convolutional neural network (CNN), massive training artificial neural network (MTANN), and deep stacked denoising autoencoder extreme learning machine (SDAE-ELM). The studies reached a classification accuracy between 68&amp;ndash;99.6% and a detection accuracy between 80.6&amp;ndash;94%. Performance of deep learning technology in studies using different test and training datasets was comparable to studies using same type of test and training datasets. In conclusion, deep learning was able to achieve high levels of accuracy, sensitivity, and/or specificity in detecting and/or classifying nodules when applied to pulmonary CT scans not from the LIDC-IDRI database.">
<meta name="dc.subject" content="deep learning">
<meta name="dc.subject" content="nodule detection">
<meta name="dc.subject" content="nodule classification">
<meta name="dc.subject" content="artificial intelligence">
<meta name="prism.issn" content="2075-4418">
<meta name="prism.publicationName" content="Diagnostics">
<meta name="prism.publicationDate" content="2019-11-29">
<meta name="prism.volume" content="9">
<meta name="prism.number" content="4">
<meta name="prism.section" content="Review">
<meta name="prism.startingPage" content="207">
<meta name="citation_issn" content="2075-4418">
<meta name="citation_journal_title" content="Diagnostics">
<meta name="citation_publisher" content="Multidisciplinary Digital Publishing Institute">
<meta name="citation_title" content="The Performance of Deep Learning Algorithms on Automatic Pulmonary Nodule Detection and Classification Tested on Different Datasets That Are Not Derived from LIDC-IDRI: A Systematic Review">
<meta name="citation_publication_date" content="2019/12">
<meta name="citation_online_date" content="2019/11/29">
<meta name="citation_volume" content="9">
<meta name="citation_issue" content="4">
<meta name="citation_firstpage" content="207">
<meta name="citation_author" content="Li, Dana">
<meta name="citation_author" content="Mikela Vilmun, Bolette">
<meta name="citation_author" content="Frederik Carlsen, Jonathan">
<meta name="citation_author" content="Albrecht-Beste, Elisabeth">
<meta name="citation_author" content="Ammitzbøl Lauridsen, Carsten">
<meta name="citation_author" content="Bachmann Nielsen, Michael">
<meta name="citation_author" content="Lindskov Hansen, Kristoffer">
<meta name="citation_doi" content="10.3390/diagnostics9040207">
<meta name="citation_id" content="mdpi-diagnostics9040207">
<meta name="citation_abstract_html_url" content="https://www.mdpi.com/2075-4418/9/4/207">
<meta name="citation_pdf_url" content="https://www.mdpi.com/2075-4418/9/4/207/pdf?version=1575860148">
<link rel="alternate" type="application/pdf" title="PDF Full-Text" href="https://www.mdpi.com/2075-4418/9/4/207/pdf?version=1575860148">
<meta name="fulltext_pdf" content="https://www.mdpi.com/2075-4418/9/4/207/pdf?version=1575860148">
<meta name="citation_fulltext_html_url" content="https://www.mdpi.com/2075-4418/9/4/207/htm">
<link rel="alternate" type="text/html" title="HTML Full-Text" href="https://www.mdpi.com/2075-4418/9/4/207/htm">
<meta name="fulltext_html" content="https://www.mdpi.com/2075-4418/9/4/207/htm">
<link rel="alternate" type="text/xml" title="XML Full-Text" href="https://www.mdpi.com/2075-4418/9/4/207/xml">
<meta name="fulltext_xml" content="https://www.mdpi.com/2075-4418/9/4/207/xml">
<meta name="citation_xml_url" content="https://www.mdpi.com/2075-4418/9/4/207/xml">
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@MDPIOpenAccess" />
<meta name="twitter:image" content="https://www.mdpi.com/img/journals/diagnostics-logo-sq.png?cc7fe11b9251f219" />
<meta property="fb:app_id" content="131189377574" />
<meta property="og:site_name" content="MDPI" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.mdpi.com/2075-4418/9/4/207" />
<meta property="og:title" content="The Performance of Deep Learning Algorithms on Automatic Pulmonary Nodule Detection and Classification Tested on Different Datasets That Are Not Derived from LIDC-IDRI: A Systematic Review" />
<meta property="og:description" content="The aim of this study was to systematically review the performance of deep learning technology in detecting and classifying pulmonary nodules on computed tomography (CT) scans that were not from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) database. Furthermore, we explored the difference in performance when the deep learning technology was applied to test datasets different from the training datasets. Only peer-reviewed, original research articles utilizing deep learning technology were included in this study, and only results from testing on datasets other than the LIDC-IDRI were included. We searched a total of six databases: EMBASE, PubMed, Cochrane Library, the Institute of Electrical and Electronics Engineers, Inc. (IEEE), Scopus, and Web of Science. This resulted in 1782 studies after duplicates were removed, and a total of 26 studies were included in this systematic review. Three studies explored the performance of pulmonary nodule detection only, 16 studies explored the performance of pulmonary nodule classification only, and 7 studies had reports of both pulmonary nodule detection and classification. Three different deep learning architectures were mentioned amongst the included studies: convolutional neural network (CNN), massive training artificial neural network (MTANN), and deep stacked denoising autoencoder extreme learning machine (SDAE-ELM). The studies reached a classification accuracy between 68&amp;ndash;99.6% and a detection accuracy between 80.6&amp;ndash;94%. Performance of deep learning technology in studies using different test and training datasets was comparable to studies using same type of test and training datasets. In conclusion, deep learning was able to achieve high levels of accuracy, sensitivity, and/or specificity in detecting and/or classifying nodules when applied to pulmonary CT scans not from the LIDC-IDRI database." />
<meta property="og:image" content="https://www.mdpi.com/diagnostics/diagnostics-09-00207/article_deploy/html/images/diagnostics-09-00207-g001-550.jpg" />
<link rel="alternate" type="application/rss+xml" title="MDPI Publishing - Latest articles" href="https://www.mdpi.com/rss">
<script type="text/x-mathjax-config">
    MathJax.Hub.processSectionDelay = 0;
      MathJax.Hub.Config({
        menuSettings: {
          CHTMLpreview: false
        },
        "CHTML-preview":{
          disabled: true
        },
        "HTML-CSS": {
          availableFonts: ["TeX"],
          preferredFonts: "TeX",
          webFont:"TeX",
          imageFont:"TeX",
          undefinedFamily:"'Arial Unicode MS',serif"
        },
        "TeX": {
          extensions: ["noErrors.js"],
          noErrors: {
            inlineDelimiters: ["",""],
            multiLine: true,
            style: {
              "font-size":   "90%",
              "text-align":  "left",
              "color":       "black",
              "padding":     "1px 3px",
              "border":      "1px solid"
            }
          }
        }
      });
    </script>
<script type="text/javascript" src="/bundles/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<meta name="google-site-verification" content="PxTlsg7z2S00aHroktQd57fxygEjMiNHydKn3txhvwY">
<meta name="facebook-domain-verification" content="mcoq8dtq6sb2hf7z29j8w515jjoof7" />
<!--[if lt IE 9]>
            <script>var browserIe8 = true;</script>
            <link rel="stylesheet" href="/assets/css/ie8foundationfix.css?8ad845af75faa4fd">
            <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
            <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.2/html5shiv.js"></script>
            <script src="//s3.amazonaws.com/nwapi/nwmatcher/nwmatcher-1.2.5-min.js"></script>
            <script src="//html5base.googlecode.com/svn-history/r38/trunk/js/selectivizr-1.0.3b.js"></script>
            <script src="//cdnjs.cloudflare.com/ajax/libs/respond.js/1.1.0/respond.min.js"></script>
            <script src="/assets/js/ie8/ie8patch.js?9e1d3c689a0471df"></script>
            <script src="/assets/js/ie8/rem.min.js?94b62787dcd6d2f2"></script>            
                                                        <![endif]-->
<script>
                (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

                ga('create', 'UA-5824718-2', 'auto');
                ga('require', 'displayfeatures');
                ga('send', 'pageview');
            </script>
<script>
                (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
                })(window,document,'script','dataLayer','GTM-WPK7SW5');
            </script>
<script type="text/javascript">
                _linkedin_partner_id = "2846186";
                window._linkedin_data_partner_ids = window._linkedin_data_partner_ids || [];
                window._linkedin_data_partner_ids.push(_linkedin_partner_id);
                </script><script type="text/javascript">
                (function(){var s = document.getElementsByTagName("script")[0];
                var b = document.createElement("script");
                b.type = "text/javascript";b.async = true;
                b.src = "https://snap.licdn.com/li.lms-analytics/insight.min.js";
                s.parentNode.insertBefore(b, s);})();
            </script>
<noscript>
                <img height="1" width="1" style="display:none;" alt="" src="https://px.ads.linkedin.com/collect/?pid=2846186&fmt=gif" />
            </noscript>
<script async src='/cdn-cgi/bm/cv/669835187/api.js'></script></head>
<body>
<noscript>
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WPK7SW5" height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
<div class="direction direction_right" id="small_right" style="border-right-width: 0px; padding:0;">
<i class="fa fa-caret-right fa-2x"></i>
</div>
<div class="big_direction direction_right" id="big_right" style="border-right-width: 0px;">
<div style="text-align: right;">
Next Article in Journal<br>
<div><a href="/2075-4418/9/4/208">Systematic Approach for Drug Repositioning of Anti-Epileptic Drugs</a></div>
Next Article in Special Issue<br>
<div><a href="/2075-4418/10/1/24">Deep and Densely Connected Networks for Classification of Diabetic Retinopathy</a></div>
</div>
</div>
<div class="direction" id="small_left" style="border-left-width: 0px">
<i class="fa fa-caret-left fa-2x"></i>
</div>
<div class="big_direction" id="big_left" style="border-left-width: 0px;">
<div>
Previous Article in Journal<br>
<div><a href="/2075-4418/9/4/206">Sarcopenic Factors May Have No Impact on Outcomes in Ovarian Cancer Patients</a></div>
Previous Article in Special Issue<br>
<div><a href="/2075-4418/9/4/192">Novel Data Mining Methodology for Healthcare Applied to a New Model to Diagnose Metabolic Syndrome without a Blood Test</a></div>
</div>
</div>
<div style="clear: both;"></div>
<div id="menuModal" class="reveal-modal reveal-modal-new reveal-modal-menu" aria-hidden="true" data-reveal role="dialog">
<div class="menu-container">
<div class="UI_NavMenu">
<a href="/about/journals">
<h2>Journals</h2>
</a>
<a href="/topics">
<h2>Topics</h2>
</a>
<div class="content__container ">
<div class="custom-accordion-for-small-screen-link ">
<h2>Information</h2>
</div>
<div class="target-item custom-accordion-for-small-screen-content show-for-medium-up">
<div class="menu-container__links">
<div style="width: 100%; max-width: 200px; float: left;">
<a href="/authors">For Authors</a>
<a href="/reviewers">For Reviewers</a>
<a href="/editors">For Editors</a>
<a href="/librarians">For Librarians</a>
<a href="/publishing_services">For Publishers</a>
<a href="/societies">For Societies</a>
<a href="/conference_organizers">For Conference Organizers</a>
</div>
<div style="width: 100%; max-width: 250px; float: left;">
<a href="/apc">Article Processing Charges</a>
<a href="/openaccess">Open Access Policy</a>
<a href="/ioap">Institutional Open Access Program</a>
<a href="/editorial_process">Editorial Process</a>
<a href="/awards">Awards</a>
<a href="/ethics">Research and Publication Ethics</a>
</div>
</div>
</div>
</div>
<a href="/authors/english">
<h2>Author Services</h2>
</a>
<div class="content__container ">
<div class="custom-accordion-for-small-screen-link ">
<h2>Initiatives</h2>
</div>
<div class="target-item custom-accordion-for-small-screen-content show-for-medium-up">
<div class="menu-container__links">
<div style="width: 100%; float: left;">
<a href="https://sciforum.net" target="_blank" rel="noopener noreferrer">Sciforum</a>
<a href="https://www.mdpi.com/books" target="_blank" rel="noopener noreferrer">MDPI Books</a>
<a href="https://www.preprints.org" target="_blank" rel="noopener noreferrer">Preprints</a>
<a href="https://www.scilit.net" target="_blank" rel="noopener noreferrer">Scilit</a>
<a href="https://sciprofiles.com" target="_blank" rel="noopener noreferrer">SciProfiles</a>
<a href="https://encyclopedia.pub" target="_blank" rel="noopener noreferrer">Encyclopedia</a>
<a href="https://jams.pub" target="_blank" rel="noopener noreferrer">JAMS</a>
<a href="/about/proceedings">Proceedings Series</a>
</div>
</div>
</div>
</div>
<a href="/about">
<h2>About</h2>
</a>
</div>
<div class="menu-container__buttons">
<a class="button UA_SignInUpButton" href="/user/login">Sign In / Sign Up</a>
</div>
</div>
</div>
<div id="captchaModal" class="reveal-modal reveal-modal-new reveal-modal-new--small" data-reveal aria-label="Captcha" aria-hidden="true" role="dialog"></div>
<div id="actionDisabledModal" class="reveal-modal" data-reveal aria-labelledby="actionDisableModalTitle" aria-hidden="true" role="dialog" style="width: 300px;">
<h2 id="actionDisableModalTitle">Notice</h2>
<form action="/email/captcha" method="post" id="emailCaptchaForm">
<div class="row">
<div id="js-action-disabled-modal-text" class="small-12 columns">
</div>
<div id="js-action-disabled-modal-submit" class="small-12 columns" style="margin-top: 10px; display: none;">
You can make submissions to other journals
<a href="https://susy.mdpi.com/user/manuscripts/upload" onclick="ga('send', 'event', 'Submit Paper', 'Send', 'Generic');">here</a>.
</div>
</div>
</form>
<a class="close-reveal-modal" aria-label="Close">
<i class="material-icons">clear</i>
</a>
</div>
<div id="rssNotificationModal" class="reveal-modal reveal-modal-new" data-reveal aria-labelledby="rssNotificationModalTitle" aria-hidden="true" role="dialog">
<div class="row">
<div class="small-12 columns">
<h2 id="rssNotificationModalTitle">Notice</h2>
<p>
You are accessing a machine-readable page. In order to be human-readable, please install an RSS reader.
</p>
</div>
</div>
<div class="row">
<div class="small-12 columns">
<a class="button button--color js-rss-notification-confirm">Continue</a>
<a class="button button--grey" onclick="$(this).closest('.reveal-modal').find('.close-reveal-modal').click(); return false;">Cancel</a>
</div>
</div>
<a class="close-reveal-modal" aria-label="Close">
<i class="material-icons">clear</i>
</a>
</div>
<div id="drop-article-label-openaccess" class="f-dropdown medium" data-dropdown-content aria-hidden="true" tabindex="-1">
<p>
All articles published by MDPI are made immediately available worldwide under an open access license. No special
permission is required to reuse all or part of the article published by MDPI, including figures and tables. For
articles published under an open access Creative Common CC BY license, any part of the article may be reused without
permission provided that the original article is clearly cited.
</p>
</div>
<div id="drop-article-label-feature" class="f-dropdown medium" data-dropdown-content aria-hidden="true" tabindex="-1">
<p>
Feature Papers represent the most advanced research with significant potential for high impact in the field. Feature
Papers are submitted upon individual invitation or recommendation by the scientific editors and undergo peer review
prior to publication.
</p>
<p>
The Feature Paper can be either an original research article, a substantial novel research study that often involves
several techniques or approaches, or a comprehensive review paper with concise and precise updates on the latest
progress in the field that systematically reviews the most exciting advances in scientific literature. This type of
paper provides an outlook on future directions of research or possible applications.
</p>
</div>
<div id="drop-article-label-choice" class="f-dropdown medium" data-dropdown-content aria-hidden="true" tabindex="-1">
<p>
Editor’s Choice articles are based on recommendations by the scientific editors of MDPI journals from around the world.
Editors select a small number of articles recently published in the journal that they believe will be particularly
interesting to authors, or important in this field. The aim is to provide a snapshot of some of the most exciting work
published in the various research areas of the journal.
</p>
</div>
<div id="container">
<noscript>
                    <div id="no-javascript">
                        You seem to have javascript disabled. Please note that many of the page functionalities won't work as expected without javascript enabled.
                    </div>
                </noscript>
<div class="fixed">
<nav class="tab-bar show-for-medium-down">
<div class="row full-width collapse">
<div class="medium-3 small-4 columns">
<a href="/">
<img class="full-size-menu__mdpi-logo" src="/img/design/mdpi-pub-logo-blue-small4.png?fff78193ca41c286" style="max-width: 65px;" title="MDPI Open Access Journals">
</a>
</div>
<div class="medium-3 small-4 columns right-aligned">
<div class="show-for-medium-down">
<a href="#" style="display: none;">
<i class="material-icons" onclick="$('#menuModal').foundation('reveal', 'close'); return false;">clear</i>
</a>
<a href="#" class="js-open-small-search open-small-search">
<i class="material-icons show-for-small only">search</i>
</a>
<a title="MDPI main page" class="js-open-menu" data-reveal-id="menuModal" href="#">
<i class="material-icons">menu</i>
</a>
</div>
</div>
</div>
</nav>
</div>
<section class="main-section">
<header>
<div class="full-size-menu show-for-large-up">
<div class="row full-width">
<div class="large-1 columns">
<a href="/">
<img class="full-size-menu__mdpi-logo" src="/img/design/mdpi-pub-logo-blue-small4.png?fff78193ca41c286" title="MDPI Open Access Journals">
</a>
</div>
<div class="large-8 columns text-right UI_NavMenu">
<ul>
<li class="menu-item">
<a href="/about/journals">Journals</a>
</li>
<li class="menu-item">
<a href="/topics">Topics</a>
</li>
 <li class="menu-item">
<a href="/authors" data-dropdown="information-dropdown" aria-controls="information-dropdown" aria-expanded="false" data-options="is_hover:true; hover_timeout:200">Information</a>
<ul id="information-dropdown" class="f-dropdown dropdown-wrapper" data-dropdown-content aria-hidden="true" tabindex="-1">
<li>
<div class="row">
<div class="small-5 columns right-border">
<ul>
<li>
<a href="/authors">For Authors</a>
</li>
<li>
<a href="/reviewers">For Reviewers</a>
</li>
<li>
<a href="/editors">For Editors</a>
</li>
<li>
<a href="/librarians">For Librarians</a>
</li>
<li>
<a href="/publishing_services">For Publishers</a>
</li>
<li>
<a href="/societies">For Societies</a>
</li>
<li>
<a href="/conference_organizers">For Conference Organizers</a>
</li>
</ul>
</div>
<div class="small-7 columns">
<ul>
<li>
<a href="/apc">Article Processing Charges</a>
</li>
<li>
<a href="/openaccess">Open Access Policy</a>
</li>
<li>
<a href="/ioap">Institutional Open Access Program</a>
</li>
<li>
<a href="/editorial_process">Editorial Process</a>
</li>
<li>
<a href="/awards">Awards</a>
</li>
<li>
<a href="/ethics">Research and Publication Ethics</a>
</li>
</ul>
</div>
</div>
</li>
</ul>
</li>
<li class="menu-item">
<a href="/authors/english">Author Services</a>
</li>
<li class="menu-item">
<a href="/about/initiatives" data-dropdown="initiatives-dropdown" aria-controls="initiatives-dropdown" aria-expanded="false" data-options="is_hover: true; hover_timeout: 200">Initiatives</a>
<ul id="initiatives-dropdown" class="f-dropdown dropdown-wrapper dropdown-wrapper__small" data-dropdown-content aria-hidden="true" tabindex="-1">
<li>
<div class="row">
<div class="small-12 columns">
<ul>
<li>
<a href="https://sciforum.net" target="_blank" rel="noopener noreferrer">
Sciforum
</a>
</li>
<li>
<a href="https://www.mdpi.com/books" target="_blank" rel="noopener noreferrer">
MDPI Books
</a>
</li>
<li>
<a href="https://www.preprints.org" target="_blank" rel="noopener noreferrer">
Preprints
</a>
</li>
<li>
<a href="https://www.scilit.net" target="_blank" rel="noopener noreferrer">
Scilit
</a>
</li>
<li>
<a href="https://sciprofiles.com" target="_blank" rel="noopener noreferrer">
SciProfiles
</a>
</li>
<li>
<a href="https://encyclopedia.pub" target="_blank" rel="noopener noreferrer">
Encyclopedia
</a>
</li>
<li>
<a href="https://jams.pub" target="_blank" rel="noopener noreferrer">
JAMS
</a>
</li>
<li>
<a href="/about/proceedings">
Proceedings Series
</a>
</li>
</ul>
</div>
</div>
</li>
</ul>
</li>
<li class="menu-item">
<a href="/about">About</a>
</li>
</ul>
</div>
<div class="large-3 columns text-right full-size-menu__buttons">
<div>
<a class="button button--default-inversed UA_SignInUpButton" href="/user/login">Sign In / Sign Up</a>
<a class="button button--default js-journal-active-only-link js-journal-active-only-submit-link UC_NavSubmitButton" href="https://susy.mdpi.com/user/manuscripts/upload?journal=diagnostics" onclick="ga('send', 'event', 'Submit Paper', 'Send', 'Diagnostics');" data-disabledmessage="new submissions are not possible.">Submit</a>
</div>
</div>
</div>
</div>
<div class="search-container hide-for-small-down row search-container__default-scheme">
<form id="basic_search" style="background-color: inherit !important;" class="large-12 medium-12 columns " action="/search" method="get">
<div class="row search-container__main-elements">
<div class="large-2 medium-2 small-12 columns text-right1 small-only-text-left">
<div class="show-for-medium-up">
<div class="search-input-label">&nbsp;</div>
</div>
<span class="search-container__title">Search<span class="hide-for-medium"> for Articles</span><span class="hide-for-small">:</span></span>
</div>
<div class="custom-accordion-for-small-screen-content">
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Title / Keyword</div>
</div>
<input type="text" placeholder="Title / Keyword" id="q" tabindex="1" name="q" value="" />
</div>
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Author / Affiliation</div>
</div>
<input type="text" id="authors" placeholder="Author / Affiliation" tabindex="2" name="authors" value="" />
</div>
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Journal</div>
</div>
<select id="journal" tabindex="3" name="journal" class="chosen-select">
<option value="">All Journals</option>
<option value="acoustics">
Acoustics
</option>
<option value="actuators">
Actuators
</option>
<option value="admsci">
Administrative Sciences
</option>
<option value="adolescents">
Adolescents
</option>
<option value="aerospace">
Aerospace
</option>
<option value="agriculture">
Agriculture
</option>
<option value="agriengineering">
AgriEngineering
</option>
<option value="agronomy">
Agronomy
</option>
<option value="ai">
AI
</option>
<option value="algorithms">
Algorithms
</option>
<option value="allergies">
Allergies
</option>
<option value="alloys">
Alloys
</option>
<option value="analytica">
Analytica
</option>
<option value="anatomia">
Anatomia
</option>
<option value="animals">
Animals
</option>
<option value="antibiotics">
Antibiotics
</option>
<option value="antibodies">
Antibodies
</option>
<option value="antioxidants">
Antioxidants
</option>
<option value="applbiosci">
Applied Biosciences
</option>
<option value="applmech">
Applied Mechanics
</option>
<option value="applmicrobiol">
Applied Microbiology
</option>
<option value="applnano">
Applied Nano
</option>
<option value="applsci">
Applied Sciences
</option>
<option value="asi">
Applied System Innovation (ASI)
</option>
<option value="appliedchem">
AppliedChem
</option>
<option value="appliedmath">
AppliedMath
</option>
<option value="aquacj">
Aquaculture Journal
</option>
<option value="architecture">
Architecture
</option>
<option value="arts">
Arts
</option>
<option value="astronomy">
Astronomy
</option>
<option value="atmosphere">
Atmosphere
</option>
<option value="atoms">
Atoms
</option>
<option value="audiolres">
Audiology Research
</option>
<option value="automation">
Automation
</option>
<option value="axioms">
Axioms
</option>
<option value="bacteria">
Bacteria
</option>
<option value="batteries">
Batteries
</option>
<option value="behavsci">
Behavioral Sciences
</option>
<option value="beverages">
Beverages
</option>
<option value="BDCC">
Big Data and Cognitive Computing (BDCC)
</option>
<option value="biochem">
BioChem
</option>
<option value="bioengineering">
Bioengineering
</option>
<option value="biologics">
Biologics
</option>
<option value="biology">
Biology
</option>
<option value="blsf">
Biology and Life Sciences Forum
</option>
<option value="biomass">
Biomass
</option>
<option value="biomechanics">
Biomechanics
</option>
<option value="biomed">
BioMed
</option>
<option value="biomedicines">
Biomedicines
</option>
<option value="biomedinformatics">
BioMedInformatics
</option>
<option value="biomimetics">
Biomimetics
</option>
<option value="biomolecules">
Biomolecules
</option>
<option value="biophysica">
Biophysica
</option>
<option value="biosensors">
Biosensors
</option>
<option value="biotech">
BioTech
</option>
<option value="birds">
Birds
</option>
<option value="brainsci">
Brain Sciences
</option>
<option value="buildings">
Buildings
</option>
<option value="businesses">
Businesses
</option>
<option value="carbon">
C
</option>
<option value="cancers">
Cancers
</option>
<option value="cardiogenetics">
Cardiogenetics
</option>
<option value="catalysts">
Catalysts
</option>
<option value="cells">
Cells
</option>
<option value="ceramics">
Ceramics
</option>
<option value="challenges">
Challenges
</option>
<option value="ChemEngineering">
ChemEngineering
</option>
<option value="chemistry">
Chemistry
</option>
<option value="chemproc">
Chemistry Proceedings
</option>
<option value="chemosensors">
Chemosensors
</option>
<option value="children">
Children
</option>
<option value="chips">
Chips
</option>
<option value="civileng">
CivilEng
</option>
<option value="cleantechnol">
Clean Technologies (Clean Technol.)
</option>
<option value="climate">
Climate
</option>
<option value="ctn">
Clinical and Translational Neuroscience (CTN)
</option>
<option value="clinpract">
Clinics and Practice
</option>
<option value="clockssleep">
Clocks &amp; Sleep
</option>
<option value="coasts">
Coasts
</option>
<option value="coatings">
Coatings
</option>
<option value="colloids">
Colloids and Interfaces
</option>
<option value="colorants">
Colorants
</option>
<option value="compounds">
Compounds
</option>
<option value="computation">
Computation
</option>
<option value="csmf">
Computer Sciences &amp; Mathematics Forum
</option>
<option value="computers">
Computers
</option>
<option value="condensedmatter">
Condensed Matter
</option>
<option value="conservation">
Conservation
</option>
<option value="constrmater">
Construction Materials
</option>
<option value="cmd">
Corrosion and Materials Degradation (CMD)
</option>
<option value="cosmetics">
Cosmetics
</option>
<option value="covid">
COVID
</option>
<option value="crops">
Crops
</option>
<option value="cryptography">
Cryptography
</option>
<option value="crystals">
Crystals
</option>

<option value="cimb">
Current Issues in Molecular Biology (CIMB)
</option>
<option value="curroncol">
Current Oncology
</option>
<option value="dairy">
Dairy
</option>
<option value="data">
Data
</option>
<option value="dentistry">
Dentistry Journal
</option>
<option value="dermato">
Dermato
</option>
<option value="dermatopathology">
Dermatopathology
</option>
<option value="designs">
Designs
</option>
<option value="diabetology">
Diabetology
</option>
<option value="diagnostics" selected='selected'>
Diagnostics
</option>
<option value="dietetics">
Dietetics
</option>
<option value="digital">
Digital
</option>
<option value="disabilities">
Disabilities
</option>
<option value="diseases">
Diseases
</option>
<option value="diversity">
Diversity
</option>
<option value="dna">
DNA
</option>
<option value="drones">
Drones
</option>
<option value="dynamics">
Dynamics
</option>
<option value="earth">
Earth
</option>
<option value="ecologies">
Ecologies
</option>
<option value="econometrics">
Econometrics
</option>
<option value="economies">
Economies
</option>
<option value="education">
Education Sciences
</option>
<option value="electricity">
Electricity
</option>
<option value="electrochem">
Electrochem
</option>
<option value="electronicmat">
Electronic Materials
</option>
<option value="electronics">
Electronics
</option>
<option value="encyclopedia">
Encyclopedia
</option>
<option value="endocrines">
Endocrines
</option>
<option value="energies">
Energies
</option>
<option value="eng">
Eng
</option>
<option value="engproc">
Engineering Proceedings
</option>
<option value="entomology">
Entomology
</option>
<option value="entropy">
Entropy
</option>
<option value="environsciproc">
Environmental Sciences Proceedings
</option>
<option value="environments">
Environments
</option>
<option value="epidemiologia">
Epidemiologia
</option>
<option value="epigenomes">
Epigenomes
</option>
<option value="ebj">
European Burn Journal (EBJ)
</option>
<option value="ejihpe">
European Journal of Investigation in Health, Psychology and Education (EJIHPE)
</option>
<option value="fermentation">
Fermentation
</option>
<option value="fibers">
Fibers
</option>
<option value="fintech">
FinTech
</option>
<option value="fire">
Fire
</option>
<option value="fishes">
Fishes
</option>
<option value="fluids">
Fluids
</option>
<option value="foods">
Foods
</option>
<option value="forecasting">
Forecasting
</option>
<option value="forensicsci">
Forensic Sciences
</option>
<option value="forests">
Forests
</option>
<option value="foundations">
Foundations
</option>
<option value="fractalfract">
Fractal and Fractional (Fractal Fract)
</option>
<option value="fuels">
Fuels
</option>
<option value="futureinternet">
Future Internet
</option>
<option value="futurepharmacol">
Future Pharmacology
</option>
<option value="futuretransp">
Future Transportation
</option>
<option value="galaxies">
Galaxies
</option>
<option value="games">
Games
</option>
<option value="gases">
Gases
</option>
<option value="gastroent">
Gastroenterology Insights
</option>
<option value="gastrointestdisord">
Gastrointestinal Disorders
</option>
<option value="gels">
Gels
</option>
<option value="genealogy">
Genealogy
</option>
<option value="genes">
Genes
</option>
<option value="geographies">
Geographies
</option>
<option value="geohazards">
GeoHazards
</option>
<option value="geomatics">
Geomatics
</option>
<option value="geosciences">
Geosciences
</option>
<option value="geotechnics">
Geotechnics
</option>
<option value="geriatrics">
 Geriatrics
</option>
<option value="healthcare">
Healthcare
</option>
<option value="hearts">
Hearts
</option>
<option value="hemato">
Hemato
</option>
<option value="hematolrep">
Hematology Reports
</option>
<option value="heritage">
Heritage
</option>
<option value="histories">
Histories
</option>
<option value="horticulturae">
Horticulturae
</option>
<option value="humanities">
Humanities
</option>
<option value="humans">
Humans
</option>
<option value="hydrobiology">
Hydrobiology
</option>
<option value="hydrogen">
Hydrogen
</option>
<option value="hydrology">
Hydrology
</option>
<option value="hygiene">
Hygiene
</option>
<option value="immuno">
Immuno
</option>
<option value="idr">
Infectious Disease Reports
</option>
<option value="informatics">
Informatics
</option>
<option value="information">
Information
</option>
<option value="infrastructures">
Infrastructures
</option>
<option value="inorganics">
Inorganics
</option>
<option value="insects">
Insects
</option>
<option value="instruments">
Instruments
</option>
<option value="ijerph">
International Journal of Environmental Research and Public Health (IJERPH)
</option>
<option value="ijfs">
International Journal of Financial Studies (IJFS)
</option>
<option value="ijms">
International Journal of Molecular Sciences (IJMS)
</option>
<option value="IJNS">
International Journal of Neonatal Screening (IJNS)
</option>
<option value="ijpb">
International Journal of Plant Biology (IJPB)
</option>
<option value="ijtm">
International Journal of Translational Medicine (IJTM)
</option>
<option value="ijtpp">
International Journal of Turbomachinery, Propulsion and Power (IJTPP)
</option>
<option value="inventions">
Inventions
</option>
<option value="IoT">
IoT
</option>
<option value="ijgi">
ISPRS International Journal of Geo-Information (IJGI)
</option>
<option value="J">
J
</option>
<option value="jal">
Journal of Ageing and Longevity (JAL)
</option>
<option value="jcdd">
Journal of Cardiovascular Development and Disease (JCDD)
</option>
<option value="jcm">
Journal of Clinical Medicine (JCM)
</option>
<option value="jcs">
Journal of Composites Science (J. Compos. Sci.)
</option>
<option value="jcp">
Journal of Cybersecurity and Privacy (JCP)
</option>
<option value="jdb">
Journal of Developmental Biology (JDB)
</option>
<option value="jfb">
Journal of Functional Biomaterials (JFB)
</option>
<option value="jfmk">
Journal of Functional Morphology and Kinesiology (JFMK)
</option>
<option value="jof">
Journal of Fungi (JoF)
</option>
<option value="jimaging">
Journal of Imaging (J. Imaging)
</option>
<option value="jintelligence">
Journal of Intelligence (J. Intell.)
</option>
<option value="jlpea">
Journal of Low Power Electronics and Applications (JLPEA)
</option>
<option value="jmmp">
Journal of Manufacturing and Materials Processing (JMMP)
</option>
<option value="jmse">
Journal of Marine Science and Engineering (JMSE)
</option>
<option value="jmp">
Journal of Molecular Pathology (JMP)
</option>
<option value="jnt">
Journal of Nanotheranostics (JNT)
</option>
<option value="jne">
Journal of Nuclear Engineering (JNE)
</option>
<option value="JOItmC">
Journal of Open Innovation: Technology, Market, and Complexity (JOItmC)
</option>
<option value="ohbm">
Journal of Otorhinolaryngology, Hearing and Balance Medicine (OHBM)
</option>
<option value="jpm">
Journal of Personalized Medicine (JPM)
</option>
<option value="jor">
Journal of Respiration (JoR)
</option>
<option value="jrfm">
Journal of Risk and Financial Management (JRFM)
</option>
<option value="jsan">
Journal of Sensor and Actuator Networks (JSAN)
</option>
<option value="jtaer">
Journal of Theoretical and Applied Electronic Commerce Research (JTAER)
</option>
<option value="jox">
Journal of Xenobiotics (JoX)
</option>
<option value="jzbg">
Journal of Zoological and Botanical Gardens (JZBG)
</option>
<option value="journalmedia">
Journalism and Media
</option>
<option value="kidneydial">
Kidney and Dialysis
</option>
<option value="knowledge">
Knowledge
</option>
 <option value="land">
Land
</option>
<option value="languages">
Languages
</option>
<option value="laws">
Laws
</option>
<option value="life">
Life
</option>
<option value="liquids">
Liquids
</option>
<option value="literature">
Literature
</option>
<option value="livers">
Livers
</option>
<option value="logics">
Logics
</option>
<option value="logistics">
Logistics
</option>
<option value="lubricants">
Lubricants
</option>
<option value="make">
Machine Learning and Knowledge Extraction (MAKE)
</option>
<option value="machines">
Machines
</option>
<option value="macromol">
Macromol
</option>
<option value="magnetism">
Magnetism
</option>
<option value="magnetochemistry">
Magnetochemistry
</option>
<option value="marinedrugs">
Marine Drugs
</option>
<option value="materials">
Materials
</option>
<option value="materproc">
Materials Proceedings
</option>
<option value="mca">
Mathematical and Computational Applications (MCA)
</option>
<option value="mathematics">
Mathematics
</option>
<option value="medsci">
Medical Sciences
</option>
<option value="msf">
Medical Sciences Forum
</option>
<option value="medicina">
Medicina
</option>
<option value="medicines">
Medicines
</option>
<option value="membranes">
Membranes
</option>
<option value="merits">
Merits
</option>
<option value="metabolites">
Metabolites
</option>
<option value="metals">
Metals
</option>
<option value="meteorology">
Meteorology
</option>
<option value="methane">
Methane
</option>
<option value="mps">
Methods and Protocols (MPs)
</option>
<option value="metrology">
Metrology
</option>
<option value="micro">
Micro
</option>
<option value="microbiolres">
Microbiology Research
</option>
<option value="micromachines">
Micromachines
</option>
<option value="microorganisms">
Microorganisms
</option>
<option value="microplastics">
Microplastics
</option>
<option value="minerals">
Minerals
</option>
<option value="mining">
Mining
</option>
<option value="modelling">
Modelling
</option>
<option value="molbank">
Molbank
</option>
<option value="molecules">
Molecules
</option>
<option value="mti">
Multimodal Technologies and Interaction (MTI)
</option>
<option value="muscles">
Muscles
</option>
<option value="nanoenergyadv">
Nanoenergy Advances
</option>
<option value="nanomanufacturing">
Nanomanufacturing
</option>
<option value="nanomaterials">
Nanomaterials
</option>
<option value="network">
Network
</option>
<option value="neuroglia">
Neuroglia
</option>
<option value="neurolint">
Neurology International
</option>
<option value="neurosci">
NeuroSci
</option>
<option value="nitrogen">
Nitrogen
</option>
<option value="ncrna">
Non-Coding RNA (ncRNA)
</option>
<option value="nursrep">
Nursing Reports
</option>
<option value="nutraceuticals">
Nutraceuticals
</option>
<option value="nutrients">
Nutrients
</option>
<option value="obesities">
Obesities
</option>
<option value="oceans">
Oceans
</option>
<option value="onco">
Onco
</option>
<option value="optics">
Optics
</option>
<option value="oral">
Oral
</option>
<option value="organics">
Organics
</option>
<option value="organoids">
Organoids
</option>
<option value="osteology">
Osteology
</option>
<option value="oxygen">
Oxygen
</option>
<option value="parasitologia">
Parasitologia
</option>
<option value="particles">
Particles
</option>
<option value="pathogens">
Pathogens
</option>
<option value="pathophysiology">
Pathophysiology
</option>
<option value="pediatrrep">
Pediatric Reports
</option>
<option value="pharmaceuticals">
 Pharmaceuticals
</option>
<option value="pharmaceutics">
Pharmaceutics
</option>
<option value="pharmacoepidemiology">
Pharmacoepidemiology
</option>
<option value="pharmacy">
Pharmacy
</option>
<option value="philosophies">
Philosophies
</option>
<option value="photochem">
Photochem
</option>
<option value="photonics">
Photonics
</option>
<option value="phycology">
Phycology
</option>
<option value="physchem">
Physchem
</option>
<option value="psf">
Physical Sciences Forum
</option>
<option value="physics">
Physics
</option>
<option value="physiologia">
Physiologia
</option>
<option value="plants">
Plants
</option>
<option value="plasma">
Plasma
</option>
<option value="pollutants">
Pollutants
</option>
<option value="polymers">
Polymers
</option>
<option value="polysaccharides">
Polysaccharides
</option>
<option value="poultry">
Poultry
</option>
<option value="powders">
Powders
</option>
<option value="proceedings">
Proceedings
</option>
<option value="processes">
Processes
</option>
<option value="prosthesis">
Prosthesis
</option>
<option value="proteomes">
Proteomes
</option>
<option value="psych">
Psych
</option>
<option value="psychiatryint">
Psychiatry International
</option>
<option value="publications">
Publications
</option>
<option value="qubs">
Quantum Beam Science (QuBS)
</option>
<option value="quantumrep">
Quantum Reports
</option>
<option value="quaternary">
Quaternary
</option>
<option value="radiation">
Radiation
</option>
<option value="reactions">
Reactions
</option>
<option value="recycling">
Recycling
</option>
<option value="religions">
Religions
</option>
<option value="remotesensing">
Remote Sensing
</option>
<option value="reports">
Reports
</option>
<option value="reprodmed">
Reproductive Medicine (Reprod. Med.)
</option>
<option value="resources">
Resources
</option>
<option value="rheumato">
Rheumato
</option>
<option value="risks">
Risks
</option>
<option value="robotics">
Robotics
</option>
<option value="ruminants">
Ruminants
</option>
<option value="safety">
Safety
</option>
<option value="sci">
Sci
</option>
<option value="scipharm">
Scientia Pharmaceutica (Sci. Pharm.)
</option>
<option value="seeds">
Seeds
</option>
<option value="sensors">
Sensors
</option>
<option value="separations">
Separations
</option>
<option value="sexes">
Sexes
</option>
<option value="signals">
Signals
</option>
<option value="sinusitis">
Sinusitis
</option>
<option value="smartcities">
Smart Cities
</option>
<option value="socsci">
Social Sciences
</option>
<option value="societies">
Societies
</option>
<option value="software">
Software
</option>
<option value="soilsystems">
Soil Systems
</option>
<option value="solar">
Solar
</option>
<option value="solids">
Solids
</option>
<option value="sports">
Sports
</option>
<option value="standards">
Standards
</option>
<option value="stats">
Stats
</option>
<option value="stresses">
Stresses
</option>
<option value="surfaces">
Surfaces
</option>
<option value="surgeries">
Surgeries
</option>
<option value="std">
Surgical Techniques Development
</option>
<option value="sustainability">
Sustainability
</option>
<option value="suschem">
Sustainable Chemistry
</option>
<option value="symmetry">
Symmetry
</option>
<option value="synbio">
SynBio
</option>
<option value="systems">
Systems
</option>
<option value="taxonomy">
Taxonomy
</option>
<option value="technologies">
Technologies
</option>
<option value="telecom">
 Telecom
</option>
<option value="textiles">
Textiles
</option>
<option value="thalassrep">
Thalassemia Reports
</option>
<option value="thermo">
Thermo
</option>
<option value="tomography">
Tomography
</option>
<option value="tourismhosp">
Tourism and Hospitality
</option>
<option value="toxics">
Toxics
</option>
<option value="toxins">
Toxins
</option>
<option value="transplantology">
Transplantology
</option>
<option value="traumacare">
Trauma Care
</option>
<option value="tropicalmed">
Tropical Medicine and Infectious Disease (TropicalMed)
</option>
<option value="universe">
Universe
</option>
<option value="urbansci">
Urban Science
</option>
<option value="uro">
Uro
</option>
<option value="vaccines">
Vaccines
</option>
<option value="vehicles">
Vehicles
</option>
<option value="venereology">
Venereology
</option>
<option value="vetsci">
Veterinary Sciences
</option>
<option value="vibration">
Vibration
</option>
<option value="viruses">
Viruses
</option>
<option value="vision">
Vision
</option>
<option value="water">
Water
</option>
<option value="wind">
Wind
</option>
<option value="women">
Women
</option>
<option value="world">
World
</option>
<option value="wevj">
World Electric Vehicle Journal (WEVJ)
</option>
<option value="youth">
Youth
</option>
<option value="zoonoticdis">
Zoonotic Diseases
</option>
</select>
</div>
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Article Type</div>
</div>
<select id="article_type" tabindex="4" name="article_type" class="chosen-select">
<option value="">All Article Types</option>
<option value="research-article">Article</option>
<option value="review-article">Review</option>
<option value="rapid-communication">Communication</option>
<option value="editorial">Editorial</option>
<option value="book-review">Book Review</option>
<option value="brief-report">Brief Report</option>
<option value="case-report">Case Report</option>
<option value="article-commentary">Comment</option>
<option value="commentary">Commentary</option>
<option value="concept-paper">Concept Paper</option>
<option value="conference-report">Conference Report</option>
<option value="correction">Correction</option>
<option value="creative">Creative</option>
<option value="data-descriptor">Data Descriptor</option>
<option value="discussion">Discussion</option>
<option value="Entry">Entry</option>
<option value="essay">Essay</option>
<option value="expression-of-concern">Expression of Concern</option>
<option value="extended-abstract">Extended Abstract</option>
<option value="guidelines">Guidelines</option>
<option value="hypothesis">Hypothesis</option>
<option value="interesting-image">Interesting Images</option>
<option value="letter">Letter</option>
<option value="books-received">New Book Received</option>
<option value="obituary">Obituary</option>
<option value="opinion">Opinion</option>
<option value="perspective">Perspective</option>
<option value="proceedings">Proceeding Paper</option>
<option value="project-report">Project Report</option>
<option value="protocol">Protocol</option>
<option value="registered-report">Registered Report</option>
<option value="reply">Reply</option>
<option value="retraction">Retraction</option>
<option value="note">Short Note</option>
<option value="study-protocol">Study Protocol</option>
<option value="systematic_review">Systematic Review</option>
<option value="technical-note">Technical Note</option>
<option value="tutorial">Tutorial</option>
<option value="viewpoint">Viewpoint</option>
</select>
</div>
<div class="large-1 medium-1 small-6 end columns small-push-6 medium-reset-order large-reset-order js-search-collapsed-button-container">
<div class="search-input-label">&nbsp;</div>
<input type="submit" id="search" value="Search" class="button button--dark button--full-width searchButton1 US_SearchButton" tabindex="12">
</div>
<div class="large-1 medium-1 small-6 end columns large-text-left small-only-text-center small-pull-6 medium-reset-order large-reset-order js-search-collapsed-link-container">
<div class="search-input-label">&nbsp;</div>
<a class="main-search-clear search-container__link" href="#" onclick="openAdvanced(''); return false;">Advanced<span class="show-for-small-only"> Search</span></a>
</div>
</div>
</div>
<div class="search-container__advanced" style="margin-top: 0; padding-top: 0px; background-color: inherit; color: inherit;">
<div class="row">
<div class="large-2 medium-2 columns show-for-medium-up">&nbsp;</div>
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Section</div>
</div>
<select id="section" tabindex="5" name="section" class="chosen-select">
<option value=""></option>
</select>
</div>
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Special Issue</div>
</div>
<select id="special_issue" tabindex="6" name="special_issue" class="chosen-select">
<option value=""></option>
</select>
</div>
<div class="large-1 medium-1 small-6 end columns ">
<div class="search-input-label">Volume</div>
<input type="text" id="volume" tabindex="7" name="volume" placeholder="..." value="9" />
</div>
<div class="large-1 medium-1 small-6 end columns ">
<div class="search-input-label">Issue</div>
<input type="text" id="issue" tabindex="8" name="issue" placeholder="..." value="4" />
</div>
<div class="large-1 medium-1 small-6 end columns ">
<div class="search-input-label">Number</div>
<input type="text" id="number" tabindex="9" name="number" placeholder="..." value="" />
</div>
<div class="large-1 medium-1 small-6 end columns ">
<div class="search-input-label">Page</div>
<input type="text" id="page" tabindex="10" name="page" placeholder="..." value="" />
</div>
<div class="large-1 medium-1 small-6 columns small-push-6 medium-reset order large-reset-order medium-reset-order js-search-expanded-button-container"></div>
<div class="large-1 medium-1 small-6 columns large-text-left small-only-text-center small-pull-6 medium-reset-order large-reset-order js-search-expanded-link-container"></div>
</div>
</div>
</form>
<form id="advanced-search" class="large-12 medium-12 columns">
<div class="search-container__advanced">
<div id="advanced-search-template" class="row advanced-search-row">
<div class="large-2 medium-2 small-12 columns show-for-medium-up">&nbsp;</div>
<div class="large-2 medium-2 small-3 columns connector-div">
<div class="search-input-label"><span class="show-for-medium-up">Logical Operator</span><span class="show-for-small">Operator</span></div>
<select class="connector">
<option value="and">AND</option>
<option value="or">OR</option>
</select>
</div>
<div class="large-3 medium-3 small-6 columns search-text-div">
<div class="search-input-label">Search Text</div>
<input type="text" class="search-text" placeholder="Search text">
</div>
<div class="large-2 medium-2 small-6 large-offset-0 medium-offset-0 small-offset-3 columns search-field-div">
<div class="search-input-label">Search Type</div>
<select class="search-field">
<option value="all">All fields</option>
<option value="title">Title</option>
<option value="abstract">Abstract</option>
<option value="keywords">Keywords</option>
<option value="authors">Authors</option>
<option value="affiliations">Affiliations</option>
<option value="doi">Doi</option>
<option value="full_text">Full Text</option>
<option value="references">References</option>
</select>
</div>
<div class="large-1 medium-1 small-3 columns">
<div class="search-input-label">&nbsp;</div>
<div class="search-action-div">
<div class="search-plus">
<i class="material-icons">add_circle_outline</i>
</div>
</div>
<div class="search-action-div">
<div class="search-minus">
<i class="material-icons">remove_circle_outline</i>
</div>
</div>
</div>
<div class="large-1 medium-1 small-6 large-offset-0 medium-offset-0 small-offset-3 end columns">
<div class="search-input-label">&nbsp;</div>
<input class="advanced-search-button button button--dark search-submit" type="submit" value="Search">
</div>
<div class="large-1 medium-1 small-6 end columns show-for-medium-up"></div>
</div>
</div>
</form>
</div>
<div class="breadcrumb row full-row">
<div class="breadcrumb__element">
<a href="/about/journals">Journals</a>
</div>
<div class="breadcrumb__element">
<a href="/journal/diagnostics">Diagnostics</a>
</div>
<div class="breadcrumb__element">
<a href="/2075-4418/9">Volume 9</a>
</div>
<div class="breadcrumb__element">
<a href="/2075-4418/9/4">Issue 4</a>
</div>
<div class="breadcrumb__element">
<a href="#">10.3390/diagnostics9040207</a>
</div>
</div>
</header>
<div id="main-content" class="">
<div class="row full-width row-fixed-left-column">
<div id="left-column" class="content__column large-3 medium-3 small-12 columns">
<div class="content__container">
<a href="/journal/diagnostics">
<img src="/img/journals/diagnostics-logo.png?cc7fe11b9251f219" alt="diagnostics-logo" title="Diagnostics" style="max-height: 60px; margin: 0 0 0 0;">
</a>
<div class="generic-item no-border">
<a class="button button--color button--full-width js-journal-active-only-link js-journal-active-only-submit-link UC_ArticleSubmitButton" href="https://susy.mdpi.com/user/manuscripts/upload?form%5Bjournal_id%5D%3D41" onclick="ga('send', 'event', 'Submit Paper', 'Send', 'Diagnostics');" data-disabledmessage="creating new submissions is not possible.">
Submit to this Journal
</a>
<a class="button button--color button--full-width js-journal-active-only-link UC_ArticleReviewButton" href="https://susy.mdpi.com/volunteer/journals/review" data-disabledmessage="volunteering as journal reviewer is not possible.">
Review for this Journal
</a>
<a class="button button--color-inversed button--full-width js-journal-active-only-link UC_ArticleEditIssueButton" href="/journalproposal/sendproposalspecialissue/diagnostics" data-path="/2075-4418/9/4/207/htm" data-disabledmessage="proposing new special issue is not possible.">
Edit a Special Issue
</a>
</div>
<div class="generic-item link-article-menu show-for-small">
<a href="#" class="link-article-menu show-for-small">
<span class="closed">&#9658;</span>
<span class="open" style="display: none;">&#9660;</span>
Article Menu
</a>
</div>
<div class="hide-small-down-initially UI_ArticleMenu">
<div class="generic-item">
<h2>Article Menu</h2>
</div>
<ul class="accordion accordion__menu" data-accordion data-options="multi_expand:false;toggleable: true">
<li class="accordion-navigation">

<a href="#overview" class="accordion__title">Article Overview</a>
<div id="overview" class="content  UI_ArticleMenu_Overview">
<ul>
<li>
<a href="/2075-4418/9/4/207#abstract">Abstract</a>
</li>
<li>
<a href="/openaccess">Open Access and Permissions</a>
</li>
<li>
<a href="/2075-4418/9/4/207#cite">Share and Cite</a>
</li>
<li>
<a href="/2075-4418/9/4/207#metrics">Article Metrics</a>
</li>
<li>
<a href="/2075-4418/9/4/207/reprints">Order Article Reprints</a>
</li>
</ul>
</div>
</li>
<li class="accordion-navigation">
<a href="#versions-div" class="accordion__title">Article Versions</a>
<div id="versions-div" class="content  UI_ArticleMenu_Versions">
<ul>
<li>
<a href="/2075-4418/9/4/207">Abstract</a>
</li>
<li>
<a href="/2075-4418/9/4/207/notes" onclick="ga('send', 'pageview', '/2075-4418/9/4/207/notes');">Article Versions Notes</a>
</li>
<li>
<a href="/2075-4418/9/4/207/htm" onclick="ga('send', 'pageview', $(this).attr('href'));" id="html_link">Full-Text HTML</a>
</li>
<li class="li-download">
<a href="/2075-4418/9/4/207/pdf?version=1575860148" onclick="ga('send', 'pageview', $(this).attr('href'));" id="pdf_link">Full-Text PDF</a>
</li>
<li class="li-download">
<a id="js-xml-access-captcha" href="#" data-target="/2075-4418/9/4/207/xml" class="accessCaptcha" onclick="ga('send', 'pageview', '/2075-4418/9/4/207/xml');">Full-Text XML</a>
</li>
<li class="li-download">
<a href="/2075-4418/9/4/207/epub" onclick="ga('send', 'pageview', '/2075-4418/9/4/207/epub');" id="epub_link">Full-Text Epub</a>
</li>
</ul>
</div>
</li>
<li class="accordion-navigation">
<a href="#related" class="accordion__title">Related Info Links</a>
<div id="related" class="content  UI_ArticleMenu_RelatedLinks">
<ul>
<li class="li-link">
<a href="https://www.ncbi.nlm.nih.gov/sites/entrez/31795409" target="_blank" rel="noopener noreferrer">PubMed/Medline</a>
</li>
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=The%20Performance%20of%20Deep%20Learning%20Algorithms%20on%20Automatic%20Pulmonary%20Nodule%20Detection%20and%20Classification%20Tested%20on%20Different%20Datasets%20That%20Are%20Not%20Derived%20from%20LIDC-IDRI%3A%20A%20Systematic%20Review" target="_blank" rel="noopener noreferrer">Google Scholar</a>
</li>
</ul>
</div>
</li>
<li class="accordion-navigation">
<a href="#authors" class="accordion__title">More by Authors Links</a>
<div id="authors" class="content  UI_ArticleMenu_AuthorsLinks">
<ul class="side-menu-ul">
<li>
<a class="expand" onclick='$(this).closest("li").next("div").toggle(); return false;'>on DOAJ</a>
</li>
<div id="AuthorDOAJExpand" style="display:none;">
<ul class="submenu">
<li class="li-link">
<a href='http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Dana%20Li%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D' target="_blank" rel="noopener noreferrer">Li, D.</a>
<li>
</li>
<li class="li-link">
<a href='http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Bolette%20Mikela%20Vilmun%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D' target="_blank" rel="noopener noreferrer">Mikela Vilmun, B.</a>
<li>
</li>
<li class="li-link">
<a href='http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Jonathan%20Frederik%20Carlsen%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D' target="_blank" rel="noopener noreferrer">Frederik Carlsen, J.</a>
<li>
</li>
<li class="li-link">
<a href='http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Elisabeth%20Albrecht-Beste%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D' target="_blank" rel="noopener noreferrer">Albrecht-Beste, E.</a>
<li>
</li>
<li class="li-link">
<a href='http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Carsten%20Ammitzb%C3%B8l%20Lauridsen%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D' target="_blank" rel="noopener noreferrer">Ammitzbøl Lauridsen, C.</a>
<li>
</li>
<li class="li-link">
<a href='http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Michael%20Bachmann%20Nielsen%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D' target="_blank" rel="noopener noreferrer">Bachmann Nielsen, M.</a>
<li>
</li>
<li class="li-link">
<a href='http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Kristoffer%20Lindskov%20Hansen%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D' target="_blank" rel="noopener noreferrer">Lindskov Hansen, K.</a>
<li>
</li>
</ul>
</div>
<li>
<a class="expand" onclick='$(this).closest("li").next("div").toggle(); return false;'>on Google Scholar</a>
</li>
<div id="AuthorGoogleExpand" style="display:none;">
<ul class="submenu">
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Dana%20Li" target="_blank" rel="noopener noreferrer">Li, D.</a>
<li>
</li>
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Bolette%20Mikela%20Vilmun" target="_blank" rel="noopener noreferrer">Mikela Vilmun, B.</a>
<li>
</li>
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Jonathan%20Frederik%20Carlsen" target="_blank" rel="noopener noreferrer">Frederik Carlsen, J.</a>
<li>
</li>
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Elisabeth%20Albrecht-Beste" target="_blank" rel="noopener noreferrer">Albrecht-Beste, E.</a>
<li>
</li>
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Carsten%20Ammitzb%C3%B8l%20Lauridsen" target="_blank" rel="noopener noreferrer">Ammitzbøl Lauridsen, C.</a>
<li>
</li>
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Michael%20Bachmann%20Nielsen" target="_blank" rel="noopener noreferrer">Bachmann Nielsen, M.</a>
<li>
</li>
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Kristoffer%20Lindskov%20Hansen" target="_blank" rel="noopener noreferrer">Lindskov Hansen, K.</a>
<li>
</li>
</ul>
</div>
<li>
<a class="expand" onclick='$(this).closest("li").next("div").toggle(); return false;'>on PubMed</a>
</li>
<div id="AuthorPubMedExpand" style="display:none;">
<ul class="submenu">
<li class="li-link">
<a href="https://www.pubmed.gov/?cmd=Search&amp;term=Dana%20Li" target="_blank" rel="noopener noreferrer">Li, D.</a>
<li>
</li>
<li class="li-link">
<a href="https://www.pubmed.gov/?cmd=Search&amp;term=Bolette%20Mikela%20Vilmun" target="_blank" rel="noopener noreferrer">Mikela Vilmun, B.</a>
<li>
</li>
<li class="li-link">
<a href="https://www.pubmed.gov/?cmd=Search&amp;term=Jonathan%20Frederik%20Carlsen" target="_blank" rel="noopener noreferrer">Frederik Carlsen, J.</a>
<li>
</li>
<li class="li-link">
<a href="https://www.pubmed.gov/?cmd=Search&amp;term=Elisabeth%20Albrecht-Beste" target="_blank" rel="noopener noreferrer">Albrecht-Beste, E.</a>
<li>
</li>
<li class="li-link">
<a href="https://www.pubmed.gov/?cmd=Search&amp;term=Carsten%20Ammitzb%C3%B8l%20Lauridsen" target="_blank" rel="noopener noreferrer">Ammitzbøl Lauridsen, C.</a>
<li>
</li>
<li class="li-link">
<a href="https://www.pubmed.gov/?cmd=Search&amp;term=Michael%20Bachmann%20Nielsen" target="_blank" rel="noopener noreferrer">Bachmann Nielsen, M.</a>
<li>
</li>
<li class="li-link">
<a href="https://www.pubmed.gov/?cmd=Search&amp;term=Kristoffer%20Lindskov%20Hansen" target="_blank" rel="noopener noreferrer">Lindskov Hansen, K.</a>
<li>
</li>
</ul>
</div>
</ul>
</div>
</li>
<li class="accordion-navigation">
<a href="#html-links" class="accordion__title">Full Article Text</a>
<div id="html-links" class="content active">
<div class="menu-caption" id="html-quick-links-title"></div>
</div>
</li>
</ul>
<div id="scifeed-modal" class="reveal-modal reveal-modal-new" data-reveal aria-labelledby="modalTitle" aria-hidden="true" role="dialog">
</div>
<span style="display:none" id="scifeed_hidden_flag"></span>
<span style="display:none" id="scifeed_subscribe_url">/ajax/scifeed/subscribe</span>
</div>
</div>

<div id="pbgrd-sky"></div>
<script src="https://cdn.pbgrd.com/core-mdpi.js"></script>
<style>.content__container {
        min-width: 300px;
    }</style>

</div>
<div id="middle-column" class="content__column large-9 medium-9 small-12 columns end middle-bordered">
<div class="middle-column__help">
<div class="middle-column__help__fixed show-for-medium-up">
<a href="#" class="UA_ShareButton" data-reveal-id="main-share-modal" title="Share">
<i class="material-icons">share</i>
</a>
<a href="#" data-reveal-id="main-help-modal" title="Help">
<i class="material-icons">announcement</i>
</a>
<a href="https://sciprofiles.com/discussion-groups/public/10.3390/diagnostics9040207" target="_blank" rel="noopener noreferrer" title="Discuss in Sciprofiles">
<i class="material-icons">question_answer</i>
</a>
<a href="#" class="" data-hypothesis-trigger-endorses-tab title="Endorse">
<i data-hypothesis-endorse-trigger class="material-icons">thumb_up</i>
<div data-hypothesis-endorsement-count data-hypothesis-trigger-endorses-tab class="hypothesis-count-container">
...
</div>
</a>
<a href="#" data-hypothesis-trigger class="js-hypothesis-open UI_ArticleAnnotationsButton" title="Comment">
<i class="material-icons">textsms</i>
<div data-hypothesis-annotation-count class="hypothesis-count-container">
...
</div>
</a>
</div>
<div id="main-help-modal" class="reveal-modal reveal-modal-new" data-reveal aria-labelledby="modalTitle" aria-hidden="true" role="dialog">
<div class="row">
<div class="small-12 columns">
<h2 style="margin: 0;">Need Help?</h2>
</div>
<div class="small-6 columns">
<h3>Support</h3>
<p>
Find support for a specific problem in the support section of our website.
</p>
<a target="_blank" href="/about/contactform" class="button button--color button--full-width">
Get Support
</a>
</div>
<div class="small-6 columns">
<h3>Feedback</h3>
<p>
Please let us know what you think of our products and services.
</p>
<a target="_blank" href="/feedback/send" class="button button--color button--full-width">
Give Feedback
</a>
</div>
<div class="small-6 columns end">
<h3>Information</h3>
<p>
Visit our dedicated information section to learn more about MDPI.
</p>
<a target="_blank" href="/authors" class="button button--color button--full-width">
Get Information
</a>
</div>
</div>
<a class="close-reveal-modal" aria-label="Close">
<i class="material-icons">clear</i>
</a>
</div>
</div>
<div class="middle-column__main ">
<div class="html-content__container content__container content__container__combined-for-large content__container__combined-for-large__first" style="overflow: auto;">
<article><div class='html-article-content'>
<div itemscope itemtype="http://schema.org/ScholarlyArticle" id="abstract" class="abstract_div">
<div class="js-check-update-container"></div>
<div>
<span itemprop="publisher" content="Multidisciplinary Digital Publishing Institute"></span><span itemprop="url" content="https://www.mdpi.com/2075-4418/9/4/207"></span>
<div class="article-icons"><span class="label openaccess" data-dropdown="drop-article-label-openaccess" aria-expanded="false">Open Access</span><span class="label articletype">Review</span></div>
<h1 class="title hypothesis_container" itemprop="name">
The Performance of Deep Learning Algorithms on Automatic Pulmonary Nodule Detection and Classification Tested on Different Datasets That Are Not Derived from LIDC-IDRI: A Systematic Review </h1>
<div class="art-authors hypothesis_container">

by
<span class="inlineblock "><div class="sciprofiles-link" style="display: inline-block"><a class="sciprofiles-link__link" href="https://sciprofiles.com/profile/880028" target="_blank" rel="noopener noreferrer"><img class="sciprofiles-link__image" src="/bundles/mdpisciprofileslink/img/unknown-user.png" style="width: auto; height: 16px; border-radius: 50%;"><span class="sciprofiles-link__name">Dana Li</span></a></div><sup> 1,2,*</sup><span style="display: inline; margin-left: 5px;"></span><a class="toEncode emailCaptcha visibility-hidden" data-author-id="2313671" href="mailto:please_login"><sup><i class="fa fa-envelope-o"></i></sup></a>, </span><span class="inlineblock "><div class="sciprofiles-link" style="display: inline-block"><a class="sciprofiles-link__link" href="https://sciprofiles.com/profile/author/K3JFWFpXZXFDR0pyTlFDWGwwVUdrSVNxdWpnenZZdkc3MmMwejhDbElNQjRvRHY4a1RwVEhHNmx1YWNMNDlCcA==" target="_blank" rel="noopener noreferrer"><img class="sciprofiles-link__image" src="/bundles/mdpisciprofileslink/img/unknown-user.png" style="width: auto; height: 16px; border-radius: 50%;"><span class="sciprofiles-link__name">Bolette Mikela Vilmun</span></a></div><sup> 1,2</sup><span style="display: inline; margin-left: 5px;"></span><a class="toEncode emailCaptcha visibility-hidden" data-author-id="2313672" href="mailto:please_login"><sup><i class="fa fa-envelope-o"></i></sup></a>, </span><span class="inlineblock "><div class="sciprofiles-link" style="display: inline-block"><a class="sciprofiles-link__link" href="https://sciprofiles.com/profile/917857" target="_blank" rel="noopener noreferrer"><img class="sciprofiles-link__image" src="/bundles/mdpisciprofileslink/img/unknown-user.png" style="width: auto; height: 16px; border-radius: 50%;"><span class="sciprofiles-link__name">Jonathan Frederik Carlsen</span></a></div><sup> 1</sup><span style="display: inline; margin-left: 5px;"></span><a class="toEncode emailCaptcha visibility-hidden" data-author-id="2313673" href="mailto:please_login"><sup><i class="fa fa-envelope-o"></i></sup></a>, </span><span class="inlineblock "><div class="sciprofiles-link" style="display: inline-block"><a class="sciprofiles-link__link" href="https://sciprofiles.com/profile/123232" target="_blank" rel="noopener noreferrer"><img class="sciprofiles-link__image" src="/bundles/mdpisciprofileslink/img/unknown-user.png" style="width: auto; height: 16px; border-radius: 50%;"><span class="sciprofiles-link__name">Elisabeth Albrecht-Beste</span></a></div><sup> 3</sup><span style="display: inline; margin-left: 5px;"></span><a class="toEncode emailCaptcha visibility-hidden" data-author-id="2313674" href="mailto:please_login"><sup><i class="fa fa-envelope-o"></i></sup></a>, </span><span class="inlineblock "><div class="sciprofiles-link" style="display: inline-block"><a class="sciprofiles-link__link" href="https://sciprofiles.com/profile/author/MkU0RTZNbEpSZXkvWERnNG9QZitpckdWdFg5aDdIODdrTWoyVFJXNktTRWxZK1NMUnIvZ1ZFK25MbnRFNTZKMw==" target="_blank" rel="noopener noreferrer"><img class="sciprofiles-link__image" src="/bundles/mdpisciprofileslink/img/unknown-user.png" style="width: auto; height: 16px; border-radius: 50%;"><span class="sciprofiles-link__name">Carsten Ammitzbøl Lauridsen</span></a></div><sup> 1,4</sup><span style="display: inline; margin-left: 5px;"></span><a class="toEncode emailCaptcha visibility-hidden" data-author-id="2313675" href="mailto:please_login"><sup><i class="fa fa-envelope-o"></i></sup></a>, </span><span class="inlineblock "><div class="sciprofiles-link" style="display: inline-block"><a class="sciprofiles-link__link" href="https://sciprofiles.com/profile/93192" target="_blank" rel="noopener noreferrer"><img class="sciprofiles-link__image" src="/bundles/mdpisciprofileslink/img/unknown-user.png" style="width: auto; height: 16px; border-radius: 50%;"><span class="sciprofiles-link__name">Michael Bachmann Nielsen</span></a></div><sup> 1,2</sup><span style="display: inline; margin-left: 5px;"></span><a class="toEncode emailCaptcha visibility-hidden" data-author-id="2313676" href="mailto:please_login"><sup><i class="fa fa-envelope-o"></i></sup></a><a href="https://orcid.org/0000-0002-9380-1688" target="_blank" rel="noopener noreferrer"><img src="/img/design/orcid.png?1b5ed457ed71c59e" title="ORCID" style="position: relative; width: 13px; margin-left: 3px; max-width: 13px !important; height: auto; top: -5px;"></a> and </span><span class="inlineblock "><div class="sciprofiles-link" style="display: inline-block"><a class="sciprofiles-link__link" href="https://sciprofiles.com/profile/917856" target="_blank" rel="noopener noreferrer"><img class="sciprofiles-link__image" src="/bundles/mdpisciprofileslink/img/unknown-user.png" style="width: auto; height: 16px; border-radius: 50%;"><span class="sciprofiles-link__name">Kristoffer Lindskov Hansen</span></a></div><sup> 1,2</sup><span style="display: inline; margin-left: 5px;"></span><a class="toEncode emailCaptcha visibility-hidden" data-author-id="2313677" href="mailto:please_login"><sup><i class="fa fa-envelope-o"></i></sup></a></span> 
</div>
<div class="nrm"></div>
<span style="display:block; height:6px;"></span>
<div></div>
<div style="margin: 5px 0 15px 0;" class="hypothesis_container">
<div class="art-affiliations">
<div class="affiliation ">
<div class="affiliation-item"><sup>1</sup></div>
<div class="affiliation-name ">Department of Diagnostic Radiology, Copenhagen University Hospital, Rigshospitalet, 2100 Copenhagen, Denmark</div>
</div>
<div class="affiliation ">
<div class="affiliation-item"><sup>2</sup></div>
<div class="affiliation-name ">Department of Clinical Medicine, University of Copenhagen, 2100 Copenhagen, Denmark</div>
</div>
<div class="affiliation ">
<div class="affiliation-item"><sup>3</sup></div>
<div class="affiliation-name ">Department of Clinical Physiology, Nuclear Medicine and PET, Copenhagen University Hospital, Rigshospitalet, 2100 Copenhagen, Denmark</div>
</div>
<div class="affiliation ">
<div class="affiliation-item"><sup>4</sup></div>
<div class="affiliation-name ">Department of Technology, Faculty of Health and Technology, University College Copenhagen, 2200 Copenhagen, Denmark</div>
</div>
<div class="affiliation">
<div class="affiliation-item"><sup>*</sup></div>
<div class="affiliation-name ">Author to whom correspondence should be addressed. </div>
</div>
</div>
</div>
<div class="bib-identity" style="margin-bottom: 10px;">
<em>Diagnostics</em> <b>2019</b>, <em>9</em>(4), 207; <a href="https://doi.org/10.3390/diagnostics9040207">https://doi.org/10.3390/diagnostics9040207</a>
</div>
<div class="pubhistory" style="font-weight: bold; padding-bottom: 10px;">
<span style="display: inline-block">Received: 5 November 2019</span>
/
<span style="display: inline-block">Revised: 25 November 2019</span>
/
<span style="display: inline-block">Accepted: 28 November 2019</span>
/
<span style="display: inline-block">Published: 29 November 2019</span>
</div>
<div class="belongsTo" style="margin-bottom: 10px;">
(This article belongs to the Special Issue <a href="        
    /journal/diagnostics/special_issues/AI_Diagnostics
">Artificial Intelligence in Diagnostics</a>)<br />
</div>
<div class="highlight-box1">
<div class="download">
<a class="button button--color-inversed margin-bottom-10 UD_ArticlePDF" href="/2075-4418/9/4/207/pdf?version=1575860148" onclick="ga('send', 'pageview', '/2075-4418/9/4/207/pdf?version=1575860148');">Download PDF</a>
<div class="js-browse-figures" style="display: inline-block;">
<a href="#" class="button button--color-inversed margin-bottom-10 openpopupgallery UI_BrowseArticleFigures" data-target='article-popup'>Browse Figure</a>
</div>
<div id="article-popup" class="popupgallery" style="display: inline; line-height: 200%">
<a href="/diagnostics/diagnostics-09-00207/article_deploy/html/images/diagnostics-09-00207-g001.png" title="
                        <strong>Figure 1</strong><br/>
                                                    &lt;p&gt;Preferred reporting items for systematic reviews and meta-analyses (PRISMA) flowchart of the literature search and study selection.&lt;/p&gt;
                                                ">
</a>
</div>
<a class="button button--color-inversed" data-dropdown="drop-supplementary-292339" aria-controls="drop-supplementary-292339" aria-expanded="false">
Citation Export
</a>
<div id="drop-supplementary-292339" class="f-dropdown label__btn__dropdown label__btn__dropdown--button" data-dropdown-content aria-hidden="true" tabindex="-1">

<form style="margin:0; padding:0; display:inline;" name="export-bibtex" method="POST" action="/export">
<input type="hidden" name="articles_ids[]" value="292339">
<input type="hidden" name="export_format_top" value="bibtex">
<input type="hidden" name="export_submit_top" value="">
</form>

<form style="margin:0; padding:0; display:inline;" name="export-endnote" method="POST" action="/export">
<input type="hidden" name="articles_ids[]" value="292339">
<input type="hidden" name="export_format_top" value="endnote_no_abstract">
<input type="hidden" name="export_submit_top" value="">
</form>

<form style="margin:0; padding:0; display:inline;" name="export-ris" method="POST" action="/export">
<input type="hidden" name="articles_ids[]" value="292339">
<input type="hidden" name="export_format_top" value="ris">
<input type="hidden" name="export_submit_top" value="">
</form>
<a href="javascript:window.document.forms['export-bibtex'].submit()">BibTeX</a>
<br />
<a href="javascript:window.document.forms['export-endnote'].submit()">EndNote</a>
<br />
<a href="javascript:window.document.forms['export-ris'].submit()">RIS</a>
<br />
<a href="/2075-4418/9/4/207#cite">Cite This Paper</a>
</div>
</div>
</div>
<div class="responsive-moving-container small hidden" data-id="article-counters" style="margin-top: 15px;"></div>
</div>
<div class='html-abstract-title'>
<a name="abstractc"></a>
<h2>Abstract</h2>
</div>
<div class="art-abstract in-tab hypothesis_container">
The aim of this study was to systematically review the performance of deep learning technology in detecting and classifying pulmonary nodules on computed tomography (CT) scans that were not from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) database. Furthermore, we explored the difference in performance when the deep learning technology was applied to test datasets different from the training datasets. Only peer-reviewed, original research articles utilizing deep learning technology were included in this study, and only results from testing on datasets other than the LIDC-IDRI were included. We searched a total of six databases: EMBASE, PubMed, Cochrane Library, the Institute of Electrical and Electronics Engineers, Inc. (IEEE), Scopus, and Web of Science. This resulted in 1782 studies after duplicates were removed, and a total of 26 studies were included in this systematic review. Three studies explored the performance of pulmonary nodule detection only, 16 studies explored the performance of pulmonary nodule classification only, and 7 studies had reports of both pulmonary nodule detection and classification. Three different deep learning architectures were mentioned amongst the included studies: convolutional neural network (CNN), massive training artificial neural network (MTANN), and deep stacked denoising autoencoder extreme learning machine (SDAE-ELM). The studies reached a classification accuracy between 68&ndash;99.6% and a detection accuracy between 80.6&ndash;94%. Performance of deep learning technology in studies using different test and training datasets was comparable to studies using same type of test and training datasets. In conclusion, deep learning was able to achieve high levels of accuracy, sensitivity, and/or specificity in detecting and/or classifying nodules when applied to pulmonary CT scans not from the LIDC-IDRI database.
</div>
<div class="art-keywords in-tab hypothesis_container"><em>Keywords: </em>
<span itemprop="keywords" style="display:none">deep learning; nodule detection; nodule classification; artificial intelligence</span>
<span> <a href="/search?q=deep%20learning">deep learning</a>; <a href="/search?q=nodule%20detection">nodule detection</a>; <a href="/search?q=nodule%20classification">nodule classification</a>; <a href="/search?q=artificial%20intelligence">artificial intelligence</a></span>
</div>
</div>
</div> <div class="hypothesis_container">
<ul class="menu html-nav" data-prev-node="#html-quick-links-title">
</ul>
<div class="html-body">
<section id='sec1-diagnostics-09-00207' type='intro'><h2 data-nested='1'> 1. Introduction</h2><div class='html-p'>Lung cancer is still the leading cause of cancer-related deaths in both the United States [<a href="#B1-diagnostics-09-00207" class="html-bibr">1</a>] and Europe, where it accounts for 20.9% of all cancer-related deaths [<a href="#B2-diagnostics-09-00207" class="html-bibr">2</a>]. Because of this, efforts have been made to reduce the incidence of lung cancer, primarily through the promotion of smoking cessation and lung cancer screening of high-risk individuals. Although much has been done with prevention, there are still around 370,000 new cases of lung cancer each year [<a href="#B2-diagnostics-09-00207" class="html-bibr">2</a>]. It is therefore crucial to diagnose lung cancer at an early stage to increase patients’ chance of survival. </div><div class='html-p'>Early efforts to detect lung cancer through imaging were widely investigated, and no significant reduction in mortality by screening with traditional chest radiography was reported [<a href="#B3-diagnostics-09-00207" class="html-bibr">3</a>,<a href="#B4-diagnostics-09-00207" class="html-bibr">4</a>]. Since then, computed tomography (CT) has emerged as an imaging method with superior sensitivity in detecting lung nodules, and screening with CT has been shown to be superior to traditional chest radiography in reducing mortality from lung cancer [<a href="#B5-diagnostics-09-00207" class="html-bibr">5</a>]. When chest radiographs are replaced by CT scans for pulmonary cancer assessment, there will inevitably be an increase in workload for the radiologists, which results in missed cases and errors in diagnostics [<a href="#B6-diagnostics-09-00207" class="html-bibr">6</a>,<a href="#B7-diagnostics-09-00207" class="html-bibr">7</a>]. </div><div class='html-p'>To aid radiologists in more accurate and time-efficient detection and diagnosis of pulmonary nodules, several computer-aided diagnosis and detection schemes have been developed [<a href="#B8-diagnostics-09-00207" class="html-bibr">8</a>,<a href="#B9-diagnostics-09-00207" class="html-bibr">9</a>,<a href="#B10-diagnostics-09-00207" class="html-bibr">10</a>]; the best known computer-aided diagnosis schemes to distinguish between benign and malignant nodules are based on volume doubling time [<a href="#B11-diagnostics-09-00207" class="html-bibr">11</a>]. Recently, deep learning has emerged as a more intelligent and accurate image classification technology [<a href="#B12-diagnostics-09-00207" class="html-bibr">12</a>] and has been adapted to classify medical images including chest CTs [<a href="#B13-diagnostics-09-00207" class="html-bibr">13</a>,<a href="#B14-diagnostics-09-00207" class="html-bibr">14</a>]. To the best of our knowledge, deep learning technology has yet to be successfully implemented in an everyday clinical workflow when diagnosing pulmonary nodules. A reason for this may be that deep learning algorithms need to be trained on data that are similar to the final task data [<a href="#B15-diagnostics-09-00207" class="html-bibr">15</a>]. Most studies have trained and tested their algorithms on the large and publicly available Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) dataset, which makes the studies homogenous [<a href="#B16-diagnostics-09-00207" class="html-bibr">16</a>]. Few studies have tested their algorithms on datasets not from LIDC-IDRI, and only a subgroup of those have trained their algorithms on datasets that were not obtained the same way as the final test data [<a href="#B17-diagnostics-09-00207" class="html-bibr">17</a>,<a href="#B18-diagnostics-09-00207" class="html-bibr">18</a>]. </div><div class='html-p'>The study aim of this systematic review was to investigate how deep learning performs for pulmonary nodule detection and/or classification of CT scans when the method is tested on datasets that are not from LIDC-IDRI. Furthermore, the study aim was to investigate whether the performance of deep learning is reduced when the algorithm is tested on a dataset that is different from the training dataset.</div></section><section id='sec2-diagnostics-09-00207' type=''><h2 data-nested='1'> 2. Materials and Methods</h2><section id='LiteratureSearchStrategy' type=''><h4 class='html-italic' data-nested='2'> Literature Search Strategy</h4><div class='html-p'>The literature search was completed on 27 May 2019 from six databases: EMBASE, PubMed, Cochrane Library, the Institute of Electrical and Electronics Engineers, Inc. (IEEE), Scopus, and Web of Science. The search was restricted to peer-reviewed publications of original research written in the English language and published in the 10 years preceding the search completion date. </div><div class='html-p'>The following specific MESH terms in PubMed were used: “lung”, “respiratory system”, “classification”, “artificial intelligence”, “tomography, emission-computed”, “tomography”, “X-ray”, and “tomography scanners, X-ray computed”. </div><div class='html-p'>The terms were then combined with following text words in the title and/or abstract: “lung”, “pulmonary”, “respiratory”, “classification”, “characterization”, “detection”, “artificial intelligence”, “machine learning”, “deep learning”, “neural network”, “computer-assisted”, “computer-aided”, “CT”, and “computed tomography”. To perform the search in EMBASE, the following combinations of EMTREE terms and text words were used: (Classification (EMTREE term) OR sensitivity and specificity (EMTREE term) OR accuracy (EMTREE term) OR diagnostic accuracy (EMTREE term) OR diagnostic test accuracy study (EMTREE term) OR diagnostic reasoning (EMTREE term) OR “detection” OR “classification” OR “diagnosis”) AND (artificial intelligence (EMTREE term) OR artificial neural network (EMTREE term) OR machine learning (EMTREE term) OR computer assisted diagnosis (EMTREE term) OR “neural network” OR “deep learning”) AND (lung (EMTREE term) OR “pulmonary”) AND (whole body CT (EMTREE term) OR computer assisted tomography (EMTREE term) OR “CT” OR “computed tomography” OR “computer tomography”).</div><div class='html-p'>After removal of duplicates, all titles and abstracts retrieved from the searches were independently screened by two authors (DL and BMV). If the two authors could not reach an agreement on a study, a third author (JFC) assessed and resolved the disagreement. Data were extracted by DL and BMV via of pre-piloted forms. To describe the performance of the proposed deep learning algorithms on detection and/or classification of pulmonary nodules, we used a combination of narrative synthesis and compared measures of sensitivity, specificity, area under the curve (AUC), and accuracy if these were available. If information from a confusion matrix was available, sensitivity and specificity were independently calculated by DL and double-checked by BMV.</div></section></section><section id='sec3-diagnostics-09-00207' type=''><h2 data-nested='1'> 3. Study Inclusion Criteria</h2><div class='html-p'>Peer-reviewed original research articles published after 2009 were reviewed for inclusion in this systematic review. Studies that examined the use of machine learning in detection and/or classification of pulmonary nodules were selected
</div><div class='html-p'><dl class='html-order'><dt id=''>1</dt><dd><div class='html-p'>If the technology was based on deep learning or had primary components of deep learning algorithms used to either detect pulmonary nodules and/or classify these nodules into different categories,</div><div class='html-p'>and</div></dd><dt id=''>2</dt><dd><div class='html-p'>if the deep learning algorithm was tested on CT scans that were not part of or derived from the LIDC-IDRI database,</div><div class='html-p'>and</div></dd><dt id=''>3</dt><dd><div class='html-p'>if any performance measures were reported, preferably in the form of, but not limited to sensitivity, specificity, accuracy, and/or AUC.</div></dd></dl></div><div class='html-p'>If more than one algorithm based on the same type of deep learning architecture was tested in the same study, the best performing algorithm was chosen for the results. Datasets were defined as different if the included CT images were obtained from different hospitals/locations/types of databases. Unless otherwise stated, the CT images used in the training dataset were not a part of the test dataset.</div></section><section id='sec4-diagnostics-09-00207' type=''><h2 data-nested='1'> 4. Literature Search Results</h2><div class='html-p'>A total of 26 studies were included in this review. Due to the heterogeneity of the results from the different studies, it was not possible to perform a meta-analysis. <a href="#diagnostics-09-00207-f001" class="html-fig">Figure 1</a> summarizes the study selection as a PRISMA flowchart. Ten studies investigated the use of deep learning for nodule detection (<a href="#diagnostics-09-00207-t001" class="html-table">Table 1</a>), i.e., nodule or non-nodule, and 23 studies examined classification performance of nodules (<a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a>). Seven studies reported results on both detection and classification performance. <a href="#diagnostics-09-00207-t003" class="html-table">Table 3</a> shows the performance of the different algorithms for nodule classification when arranged after specific types of performance measurements.</div><div class='html-p'>Three different deep learning algorithms were mentioned in the studies: convolutional neural network (CNN), massive training artificial neural network (MTANN), and deep supervised denoising autoencoder architecture based on extreme learning machine (SDAE-ELM). CNN and MTANN are both end-to-end machine-learning algorithms, meaning that inputs are complete pixelated images and are processed without known components of specific feature detection and trained using backpropagation. MTANN outputs an image with the likelihood of it being a certain class, while CNN usually outputs results in class categories instead of images [<a href="#B43-diagnostics-09-00207" class="html-bibr">43</a>]. The advantage of MTANN is fewer training cases compared to CNN without compromising classification performance [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>]. SDAE-ELM is a feature vector deep learning algorithm combined with ELM, which is a feed-forward neural network [<a href="#B37-diagnostics-09-00207" class="html-bibr">37</a>]. The advantages of stacked autoencoders include fewer training cases compared to, for example, CNN, since stacked autoencoders are able to generate new images from the image characteristic feature vectors [<a href="#B44-diagnostics-09-00207" class="html-bibr">44</a>]. </div></section><section id='sec5-diagnostics-09-00207' type=''><h2 data-nested='1'> 5. Detection Only (3 Studies)</h2><div class='html-p'>Setio et al. [<a href="#B18-diagnostics-09-00207" class="html-bibr">18</a>] and Liu et al. [<a href="#B24-diagnostics-09-00207" class="html-bibr">24</a>] both proposed CNN-based algorithms for pulmonary nodule detection. Setio et al. [<a href="#B18-diagnostics-09-00207" class="html-bibr">18</a>] tested their CNN-based program (ConvNets) on cases from the Danish Lung Cancer Screening Trial (DLCST), while Liu et al. [<a href="#B24-diagnostics-09-00207" class="html-bibr">24</a>] tested their algorithm on the Kaggle Data Science Bowl 2017 (DSB17) [<a href="#B45-diagnostics-09-00207" class="html-bibr">45</a>]. A third study by Wang et al. [<a href="#B26-diagnostics-09-00207" class="html-bibr">26</a>] tested their faster region-CNN (RCNN) based program on cases from an independent database and achieved 75.6% sensitivity on nodule detection. All studies reached a sensitivity between 75.6–85.6%. Only Setio et al. [<a href="#B18-diagnostics-09-00207" class="html-bibr">18</a>] published an accuracy rate, which was 94% (<a href="#diagnostics-09-00207-t001" class="html-table">Table 1</a>).</div><div class='html-p'>Setio et al. [<a href="#B18-diagnostics-09-00207" class="html-bibr">18</a>] trained and tested their algorithm on different types of datasets and achieved a sensitivity of 76.5%, while Liu et al. [<a href="#B24-diagnostics-09-00207" class="html-bibr">24</a>] and Wang et al. [<a href="#B26-diagnostics-09-00207" class="html-bibr">26</a>] both tested and trained their algorithm on the same type of dataset and achieved a sensitivity of 75.6% and 85.6%, respectively (<a href="#diagnostics-09-00207-t001" class="html-table">Table 1</a> and <a href="#diagnostics-09-00207-t003" class="html-table">Table 3</a>).</div></section><section id='sec6-diagnostics-09-00207' type=''><h2 data-nested='1'> 6. Classification Only (16 Studies)</h2><div class='html-p'>For studies that only reported results on classification performance, five studies [<a href="#B34-diagnostics-09-00207" class="html-bibr">34</a>,<a href="#B35-diagnostics-09-00207" class="html-bibr">35</a>,<a href="#B37-diagnostics-09-00207" class="html-bibr">37</a>,<a href="#B40-diagnostics-09-00207" class="html-bibr">40</a>,<a href="#B42-diagnostics-09-00207" class="html-bibr">42</a>] tested on local, independently obtained datasets. All studies provided reports of accuracy, which ranged between 68–92%. Four of these studies [<a href="#B34-diagnostics-09-00207" class="html-bibr">34</a>,<a href="#B35-diagnostics-09-00207" class="html-bibr">35</a>,<a href="#B40-diagnostics-09-00207" class="html-bibr">40</a>,<a href="#B42-diagnostics-09-00207" class="html-bibr">42</a>] had deep learning architectures based on CNN, while only Qiang et al. [<a href="#B37-diagnostics-09-00207" class="html-bibr">37</a>] used SDAE-ELM. For Nishio et al. [<a href="#B34-diagnostics-09-00207" class="html-bibr">34</a>], sensitivity and specificity were calculated from values given in a confusion matrix for benign, primary cancer, and metastatic cancer as 50.1% and 84.4%, 77.6% and 77.4%, and 74% and 88.2%, respectively. Onishi et al. [<a href="#B35-diagnostics-09-00207" class="html-bibr">35</a>] had an overall classification accuracy of 81.7%. The rest of the studies [<a href="#B37-diagnostics-09-00207" class="html-bibr">37</a>,<a href="#B40-diagnostics-09-00207" class="html-bibr">40</a>,<a href="#B42-diagnostics-09-00207" class="html-bibr">42</a>] categorized their nodules into malign or benign types and reached a sensitivity between 84.4–96% (<a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a>).</div><div class='html-p'>Four studies [<a href="#B31-diagnostics-09-00207" class="html-bibr">31</a>,<a href="#B32-diagnostics-09-00207" class="html-bibr">32</a>,<a href="#B33-diagnostics-09-00207" class="html-bibr">33</a>,<a href="#B41-diagnostics-09-00207" class="html-bibr">41</a>] tested their CNN-based algorithm on the Early Lung Cancer Action Program (ELCAP) public lung database [<a href="#B46-diagnostics-09-00207" class="html-bibr">46</a>]. Besides Liu et al. [<a href="#B32-diagnostics-09-00207" class="html-bibr">32</a>], who did not provide reports on accuracy, the other studies [<a href="#B31-diagnostics-09-00207" class="html-bibr">31</a>,<a href="#B33-diagnostics-09-00207" class="html-bibr">33</a>,<a href="#B41-diagnostics-09-00207" class="html-bibr">41</a>] reached classification accuracies between 90.3–94.5%. Both Liu et al. [<a href="#B33-diagnostics-09-00207" class="html-bibr">33</a>] and Yuan et al. [<a href="#B41-diagnostics-09-00207" class="html-bibr">41</a>] classified nodules into multiple categories and calculated the proportion of a specific nodule type, e.g., the proportion of classified well-circumscribed nodules actually well circumscribed, which was 95.0% for Liu et al. and 96.1% for Yuan et al. Lakshmanaprabu et al. [<a href="#B31-diagnostics-09-00207" class="html-bibr">31</a>] tested whether different CT images were categorized correctly as to whether an image was normal or contained malign or benign nodules; results are displayed in <a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a>. </div><div class='html-p'>Three studies [<a href="#B27-diagnostics-09-00207" class="html-bibr">27</a>,<a href="#B36-diagnostics-09-00207" class="html-bibr">36</a>,<a href="#B39-diagnostics-09-00207" class="html-bibr">39</a>] reported classification results tested on the DSB17 dataset [<a href="#B45-diagnostics-09-00207" class="html-bibr">45</a>]. They were all CNN-based algorithms testing whether a patient had cancer or no cancer without testing the individual nodule. They reached accuracy levels between 86.6–91.8%. Other studies that reported results on classification only tested on a variety of dataset types. All had algorithms based on CNN architecture. Ciompi et al. (2015) [<a href="#B28-diagnostics-09-00207" class="html-bibr">28</a>] tested on CT scans from the Dutch–Belgian Randomized Lung Cancer Screening Trial (Dutch acronym; NELSON [<a href="#B47-diagnostics-09-00207" class="html-bibr">47</a>] and, in a later study [<a href="#B29-diagnostics-09-00207" class="html-bibr">29</a>], they tested for solid (recall; 82.2%), non-solid (recall; 87.4%), part-solid (recall; 64.9%), calcified (recall; 82.8%), peri-fissural (recall; 60.4%), and spiculated nodules (recall; 64.3%) on patients from the DLCST.</div><div class='html-p'>Jakimovski and Davcev [<a href="#B30-diagnostics-09-00207" class="html-bibr">30</a>] used an algorithm that was both trained and tested on the Image and Data Archive of the University of South Carolina and Laboratory of Neuro Imaging (LONI database) [<a href="#B48-diagnostics-09-00207" class="html-bibr">48</a>] and achieved an accuracy of 99.6%, a sensitivity of 99.9%, and specificity of 98.6% for their best-performing algorithm. The algorithm from Jakimovski et al. [<a href="#B30-diagnostics-09-00207" class="html-bibr">30</a>] outputted a single decimal value between 0.0 and 1.0, where 0.0 was not cancer and 1.0 was cancer. They converted the value to a percentage and set a minimal threshold value at 73% before the image was categorized as cancer. The output was matched to the original database results classified by medical personnel as cancerous or not based on lung tissue biopsy [<a href="#B48-diagnostics-09-00207" class="html-bibr">48</a>]. Rangaswamy et al. [<a href="#B38-diagnostics-09-00207" class="html-bibr">38</a>] trained and tested three different classifiers on the publicly available database of interstitial lung disease (ILD) [<a href="#B49-diagnostics-09-00207" class="html-bibr">49</a>] and categorized the CT images into whether or not they contained malign or benign nodules. They found that CNN achieved the best classification result compared to the other classifiers used and achieved an accuracy of 96% (<a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a>).</div><div class='html-p'>For the above-mentioned studies, which only investigated classification performance, four studies [<a href="#B29-diagnostics-09-00207" class="html-bibr">29</a>,<a href="#B33-diagnostics-09-00207" class="html-bibr">33</a>,<a href="#B41-diagnostics-09-00207" class="html-bibr">41</a>,<a href="#B42-diagnostics-09-00207" class="html-bibr">42</a>] trained and tested on different types of datasets and achieved accuracies between 79.5–93.6%. The rest of the studies [<a href="#B27-diagnostics-09-00207" class="html-bibr">27</a>,<a href="#B28-diagnostics-09-00207" class="html-bibr">28</a>,<a href="#B30-diagnostics-09-00207" class="html-bibr">30</a>,<a href="#B31-diagnostics-09-00207" class="html-bibr">31</a>,<a href="#B32-diagnostics-09-00207" class="html-bibr">32</a>,<a href="#B34-diagnostics-09-00207" class="html-bibr">34</a>,<a href="#B35-diagnostics-09-00207" class="html-bibr">35</a>,<a href="#B36-diagnostics-09-00207" class="html-bibr">36</a>,<a href="#B37-diagnostics-09-00207" class="html-bibr">37</a>,<a href="#B38-diagnostics-09-00207" class="html-bibr">38</a>,<a href="#B39-diagnostics-09-00207" class="html-bibr">39</a>,<a href="#B40-diagnostics-09-00207" class="html-bibr">40</a>] trained and tested on the same types of datasets and achieved accuracies between 68–99.6% (<a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a> and <a href="#diagnostics-09-00207-t003" class="html-table">Table 3</a>). </div></section><section id='sec7-diagnostics-09-00207' type=''><h2 data-nested='1'> 7. Both Detection and Classification (7 Studies)</h2><div class='html-p'>Five studies [<a href="#B17-diagnostics-09-00207" class="html-bibr">17</a>,<a href="#B19-diagnostics-09-00207" class="html-bibr">19</a>,<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>,<a href="#B22-diagnostics-09-00207" class="html-bibr">22</a>,<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>] had results on both classification and detection and tested on local, independently obtained datasets. While all the studies tested a CNN architecture, Tajbakhsh and Suzuki [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>] tested both CNN- and MTANN-based algorithms. Three of the studies [<a href="#B17-diagnostics-09-00207" class="html-bibr">17</a>,<a href="#B19-diagnostics-09-00207" class="html-bibr">19</a>,<a href="#B22-diagnostics-09-00207" class="html-bibr">22</a>] measured detection performance using sensitivity and they reached levels between 86.2–97% (<a href="#diagnostics-09-00207-t001" class="html-table">Table 1</a>). Tajbakhsh and Suzuki [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>] collected information of false positives when 100% sensitivity was achieved with MTANN and CNN, which resulted in 2.7 and 22.7 false positives per patient, respectively. Detection performance was measured by Wang et al. [<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>] using the kappa consistency coefficient and reached 0.94 when compared to human experts. On classification, four of the above-mentioned studies [<a href="#B19-diagnostics-09-00207" class="html-bibr">19</a>,<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>,<a href="#B22-diagnostics-09-00207" class="html-bibr">22</a>,<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>] tested on dichotomous categories. Two of the studies [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>,<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>] reported AUC values of 77.6% and 90.6%. Chen et al. [<a href="#B22-diagnostics-09-00207" class="html-bibr">22</a>] achieved an overall classification accuracy of 87.5% when classifying adenocarcinomas and benign nodules, and Suzuki [<a href="#B19-diagnostics-09-00207" class="html-bibr">19</a>] achieved 96% sensitivity when classifying malign nodules (<a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a>). Li et al. [<a href="#B17-diagnostics-09-00207" class="html-bibr">17</a>] tested the performance of characterizing nodules into three pulmonary nodule categories: solid (sensitivity: 90.3%; specificity: 100%), part-solid (sensitivity: 55.5%; specificity: 93%), and ground glass types (sensitivity: 100%; specificity: 96.1%).</div><div class='html-p'>The rest of the studies [<a href="#B21-diagnostics-09-00207" class="html-bibr">21</a>,<a href="#B23-diagnostics-09-00207" class="html-bibr">23</a>] tested on different types of datasets. Liao et al. [<a href="#B23-diagnostics-09-00207" class="html-bibr">23</a>] tested on data from DSB17 [<a href="#B45-diagnostics-09-00207" class="html-bibr">45</a>], while Masood et al. [<a href="#B21-diagnostics-09-00207" class="html-bibr">21</a>] tested on four different types of datasets for pulmonary nodule detection and on independently obtained data for classification performance. On detection, they reached a sensitivity of 85.6% and 74.6% (<a href="#diagnostics-09-00207-t001" class="html-table">Table 1</a>). Liao et al. [<a href="#B23-diagnostics-09-00207" class="html-bibr">23</a>] classified data into dichotomous categories, while Masood et al. [<a href="#B21-diagnostics-09-00207" class="html-bibr">21</a>] classified pulmonary nodules into four nodule stages. They reached classification accuracies of 81.4% and 96.3%, respectively (<a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a>). </div><div class='html-p'>On detection, two studies [<a href="#B17-diagnostics-09-00207" class="html-bibr">17</a>,<a href="#B19-diagnostics-09-00207" class="html-bibr">19</a>] tested and trained on different types of datasets and achieved sensitivities of 86.2% and 97.0%, while the studies that trained and tested on the same types of dataset [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>,<a href="#B21-diagnostics-09-00207" class="html-bibr">21</a>,<a href="#B22-diagnostics-09-00207" class="html-bibr">22</a>,<a href="#B23-diagnostics-09-00207" class="html-bibr">23</a>,<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>] had sensitivities between 74.6–97% (<a href="#diagnostics-09-00207-t001" class="html-table">Table 1</a>). On classification, the two studies [<a href="#B17-diagnostics-09-00207" class="html-bibr">17</a>,<a href="#B19-diagnostics-09-00207" class="html-bibr">19</a>] that trained and tested on different types of dataset achieved sensitivities of 96% and 100%, and the studies that trained and tested on the same types of dataset [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>,<a href="#B21-diagnostics-09-00207" class="html-bibr">21</a>,<a href="#B22-diagnostics-09-00207" class="html-bibr">22</a>,<a href="#B23-diagnostics-09-00207" class="html-bibr">23</a>,<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>] achieved sensitivities between 76.5–83.7% and accuracies between 81.4–96.3% (<a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a> and <a href="#diagnostics-09-00207-t003" class="html-table">Table 3</a>).</div></section><section id='sec8-diagnostics-09-00207' type='discussion'><h2 data-nested='1'> 8. Discussion</h2><div class='html-p'>We found a total of 26 studies that tested deep learning algorithms on datasets that were not from the LIDC-IDRI database. Of these studies, 27% (<span class='html-italic'>n</span> = 7) tested their algorithms on datasets that were different from training datasets. We found that for testing diagnostic accuracy of pulmonary nodules on CT scans, CNN was the preferred deep learning architecture, followed by MTANN and deep SDAE-ELM.</div><div class='html-p'>Several other studies have trained and tested deep learning algorithms on the large, publicly accessible LIDC-IDRI database [<a href="#B16-diagnostics-09-00207" class="html-bibr">16</a>] and, recently, a systematic review was published overviewing the different studies that have tested on this database [<a href="#B50-diagnostics-09-00207" class="html-bibr">50</a>]. However, to review deep learning performance it is also necessary to review studies that did not use the LIDC-IDRI, as CT scans may vary from region to region. Hence, in this paper, only studies not using the LIDC-IDRI were included.</div><div class='html-p'>Algorithms with CNN architecture reached accuracies between 68–99.6% (<a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a>) on classification and 80.6–94% (<a href="#diagnostics-09-00207-t001" class="html-table">Table 1</a>) on detection. Compared to a previous study using CNN-based algorithms on CT scans from the LIDC-IDRI [<a href="#B50-diagnostics-09-00207" class="html-bibr">50</a>], there was no observed difference in classification accuracy. Sensitivity and specificity for classification found in this review were between 76.5–99.9% and 80.1–98.7% (<a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a>), respectively, which are also comparable to results of the CNN-based algorithms tested on the LIDC-IDRI [<a href="#B50-diagnostics-09-00207" class="html-bibr">50</a>]. Only Li et al. [<a href="#B17-diagnostics-09-00207" class="html-bibr">17</a>], who trained their algorithm on the LIDC-IDRI but tested on an independent dataset, had a noticeably low sensitivity result when classifying part-solid nodules (55.5%), and their algorithm was generally outperformed by double reading by radiologists on all categories (solid, part-solid, and ground glass).</div><div class='html-p'>MTANN reached a sensitivity of 97–100% on nodule detection (<a href="#diagnostics-09-00207-t001" class="html-table">Table 1</a>) and an AUC of 77.6–88.1% on classification (<a href="#diagnostics-09-00207-t002" class="html-table">Table 2</a>). This was generally higher than the sensitivity results reached by CNN for detection (74.6–97%) and classification AUC (78–90.6%). Some studies explored the difference in detection and classification performance between MTANN and CNN, and generally found MTANN to perform better than CNN [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>,<a href="#B51-diagnostics-09-00207" class="html-bibr">51</a>]. One study [<a href="#B52-diagnostics-09-00207" class="html-bibr">52</a>] found that MTANN required much fewer training data compared to CNN, which could lead to a faster implementation of deep learning technology in a clinical setting, since fewer resources have to be allocated for training. Further investigations of MTANN as a pulmonary nodule diagnosis system are required, since CNN is still the most frequently used deep learning architecture for pulmonary nodule diagnosis [<a href="#B50-diagnostics-09-00207" class="html-bibr">50</a>]. </div><div class='html-p'>We only found one study [<a href="#B37-diagnostics-09-00207" class="html-bibr">37</a>] that used an architecture other than MTANN or CNN. Qiang et al. [<a href="#B37-diagnostics-09-00207" class="html-bibr">37</a>] proposed a lung nodule classification system based on deep SDAE-ELM. The results were comparable to results obtained by CNN- and MTANN-based algorithms. To the best of our knowledge, no other study has yet investigated the deep SDAE-ELM architecture for pulmonary nodule diagnostics in CT images.</div><div class='html-p'>The two main issues with deep learning in imaging diagnostics are small training datasets and overfitting. To prevent the algorithm from overfitting, e.g., diagnosing background noise to be something of importance, more training data are required, which can be cumbersome in a clinical setting [<a href="#B53-diagnostics-09-00207" class="html-bibr">53</a>]. Studies have therefore examined transferability in deep learning, and some studies suggest that test data should be similar to training data for improved recognition results [<a href="#B15-diagnostics-09-00207" class="html-bibr">15</a>]. </div><div class='html-p'>In our study, no tendency of reduced performance was observed for the algorithms trained and tested on different datasets compared to the algorithms tested and trained on the same type of dataset. When classification performance was measured using sensitivity (<a href="#diagnostics-09-00207-t003" class="html-table">Table 3</a>a), studies that used same type of dataset for test and training ranged between 76.5–99.9%, while the two studies [<a href="#B19-diagnostics-09-00207" class="html-bibr">19</a>,<a href="#B42-diagnostics-09-00207" class="html-bibr">42</a>] that tested and trained on different types of datasets had a sensitivity of 96%. We found no studies that trained and tested on different types of datasets measuring performance in AUC (<a href="#diagnostics-09-00207-t003" class="html-table">Table 3</a>b). Accuracy results for studies that tested and trained on same type of dataset were between 68–96.3%, while accuracy results from studies that tested and trained on different types of datasets were between 79.5–93.9% (<a href="#diagnostics-09-00207-t003" class="html-table">Table 3</a>c). All studies reported sensitivity of detection. Sensitivity ranged from 74.697% for studies tested and trained on same type of dataset, and from 76.6–97% for studies tested and trained on different types of dataset (<a href="#diagnostics-09-00207-t001" class="html-table">Table 1</a>). Our findings were in accordance with previous studies and suggests that comparable results can be reached despite datasets being of different patient composition and scan parameters, as long as they are similar in the underlying category and source type, e.g., lung nodule detection and CT [<a href="#B54-diagnostics-09-00207" class="html-bibr">54</a>]. Because of this tendency, studies have had success with training their algorithms through pre-training [<a href="#B55-diagnostics-09-00207" class="html-bibr">55</a>], transfer learning [<a href="#B56-diagnostics-09-00207" class="html-bibr">56</a>], and/or fine-tuning [<a href="#B57-diagnostics-09-00207" class="html-bibr">57</a>] to bypass the problem of a small training dataset, in addition to developing variations of algorithms that are based on other deep learning technologies besides the popular CNN, e.g., MTANN and deep SDAE-ELM. </div><div class='html-p'>The heterogeneity of the included studies was a limitation of this review, since this prevented us from performing a meta-analysis to statistically compare the performance of deep learning algorithms. Thus, our study could not conclude whether there was a statistically significant difference in the performance of detection and/or classification by deep learning when trained and tested on the same or on different types of datasets. There may also be a risk of publication bias in these types of studies, since it may not seem relevant for the authors to submit research for publication with low or negative results of their algorithm. However, our study strengths include many studies from a variety of literature search engines and a systematic literature search ensuring that no relevant studies were missed. </div><div class='html-p'>Several large companies have invested in researching deep learning in general image recognition of day-to-day objects [<a href="#B58-diagnostics-09-00207" class="html-bibr">58</a>,<a href="#B59-diagnostics-09-00207" class="html-bibr">59</a>] and, recently, some vendors have moved towards automatic recognition in clinical radiology [<a href="#B60-diagnostics-09-00207" class="html-bibr">60</a>]. With the increasing popularity of artificial intelligence emerging in healthcare and the increasing workload for radiologists, it would be wise to implement deep learning in clinical practice, but, to the best of our knowledge, there has not been any consistent, standardized incorporation of deep learning into the workflow of clinical radiology for pulmonary nodules. The next step should be to move forward with research on the clinical applications and use of deep learning in medical imaging and day-to-day workflow. </div></section><section id='sec9-diagnostics-09-00207' type='conclusions'><h2 data-nested='1'> 9. Conclusions</h2><div class='html-p'>Studies on deep learning found high levels of accuracy, sensitivity, and/or specificity in detecting and/or classifying pulmonary nodules on CT scans that were not from the LIDC-IDRI database. A tendency of comparable performance levels was observed regardless of whether the deep learning algorithms were trained and tested on the same type of dataset or on different types of dataset. To aid radiologists in their diagnostic work, artificial intelligence will become a valuable tool in the future, providing more accurate and time-efficient detection and diagnosis of pulmonary nodules; however, more studies and development are warranted.</div></section>
</div>
<div class="html-back">
<section class='html-notes'><h2>Author Contributions</h2><div class='html-p'>Conceptualization, D.L., C.A.L., J.F.C., M.B.N. and K.L.H.; Methodology, D.L., B.M.V., J.F.C., E.A.-B., M.B.N. and K.L.H.; Investigation, D.L., B.M.V., J.F.C. and K.L.H.; Data acquisition, D.L.; Writing—Original Draft Preparation, D.L.; Writing—Review &amp; Editing, D.L., B.M.V., J.F.C., E.A.-B., C.A.L., M.B.N. and K.L.H.; Supervision, J.F.C., M.B.N. and K.L.H.; Project Administration, D.L.; Funding Acquisition, M.B.N.</div></section><section class='html-notes'><h2>Conflicts of Interest</h2><div class='html-p'>The authors declare no conflict of interest.</div></section><section id='html-references_list'><h2>References</h2><ol class='html-xx'><li id='B1-diagnostics-09-00207' class='html-x' data-content='1.'>Siegel, R.L.; Miller, K.D.; Jemal, A. Cancer statistics, 2019. <span class='html-italic'>CA Cancer J. Clin.</span> <b>2019</b>, <span class='html-italic'>69</span>, 7–34. [<a href="https://scholar.google.com/scholar_lookup?title=Cancer+statistics,+2019&author=Siegel,+R.L.&author=Miller,+K.D.&author=Jemal,+A.&publication_year=2019&journal=CA+Cancer+J.+Clin.&volume=69&pages=7%E2%80%9334&doi=10.3322/caac.21551&pmid=30620402" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.3322/caac.21551" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/30620402" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B2-diagnostics-09-00207' class='html-x' data-content='2.'>Data Explorer ECIS. Available online: <a href='https://ecis.jrc.ec.europa.eu/explorer.php?$0-0$1-AE28E$2-All$4-1,2$3-All$6-0,14$5-2008,2008$7-8$CEstByCancer$X0_8-3$CEstRelativeCanc$X1_8-3$X1_9-AE28' target='_blank' rel="noopener noreferrer">https://ecis.jrc.ec.europa.eu/explorer.php?<span>$</span>0-0<span>$</span>1-AE28E<span>$</span>2-All<span>$</span>4-1,2<span>$</span>3-All<span>$</span>6-0,14<span>$</span>5-2008,2008<span>$</span>7-8<span>$</span>CEstByCancer<span>$</span>X0_8-3<span>$</span>CEstRelativeCanc<span>$</span>X1_8-3<span>$</span>X1_9-AE28</a> (accessed on 5 August 2008).</li><li id='B3-diagnostics-09-00207' class='html-x' data-content='3.'>Fontana, R.S. The Mayo Lung Project: A perspective. <span class='html-italic'>Cancer</span> <b>2000</b>, <span class='html-italic'>89</span>, 2352–2355. [<a href="https://scholar.google.com/scholar_lookup?title=The+Mayo+Lung+Project:+A+perspective&author=Fontana,+R.S.&publication_year=2000&journal=Cancer&volume=89&pages=2352%E2%80%932355&doi=10.1002/1097-0142(20001201)89:11+%3C2352::AID-CNCR7%3E3.0.CO;2-5" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1002/1097-0142(20001201)89:11+&lt;2352::AID-CNCR7&gt;3.0.CO;2-5" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B4-diagnostics-09-00207' class='html-x' data-content='4.'>Oken, M.M.; Hocking, W.G.; Kvale, P.A.; Andriole, G.L.; Buys, S.S.; Church, T.R.; Crawford, E.D.; Fouad, M.N.; Isaacs, C.; Reding, D.J.; et al. Screening by chest radiograph and lung cancer mortality: The Prostate, Lung, Colorectal, and Ovarian (PLCO) randomized trial. <span class='html-italic'>JAMA</span> <b>2011</b>, <span class='html-italic'>306</span>, 1865–1873. [<a href="https://scholar.google.com/scholar_lookup?title=Screening+by+chest+radiograph+and+lung+cancer+mortality:+The+Prostate,+Lung,+Colorectal,+and+Ovarian+(PLCO)+randomized+trial&author=Oken,+M.M.&author=Hocking,+W.G.&author=Kvale,+P.A.&author=Andriole,+G.L.&author=Buys,+S.S.&author=Church,+T.R.&author=Crawford,+E.D.&author=Fouad,+M.N.&author=Isaacs,+C.&author=Reding,+D.J.&publication_year=2011&journal=JAMA&volume=306&pages=1865%E2%80%931873&doi=10.1001/jama.2011.1591" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1001/jama.2011.1591" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B5-diagnostics-09-00207' class='html-x' data-content='5.'>Gillaspie, E.A.; Allen, M.S. Computed tomographic screening for lung cancer: The Mayo Clinic experience. <span class='html-italic'>Thorac. Surg. Clin.</span> <b>2015</b>, <span class='html-italic'>25</span>, 121–127. [<a href="https://scholar.google.com/scholar_lookup?title=Computed+tomographic+screening+for+lung+cancer:+The+Mayo+Clinic+experience&author=Gillaspie,+E.A.&author=Allen,+M.S.&publication_year=2015&journal=Thorac.+Surg.+Clin.&volume=25&pages=121%E2%80%93127&doi=10.1016/j.thorsurg.2014.11.001&pmid=25901556" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.thorsurg.2014.11.001" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/25901556" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B6-diagnostics-09-00207' class='html-x' data-content='6.'>Krupinski, E.A.; Berbaum, K.S.; Caldwell, R.T.; Schartz, K.M.; Madsen, M.T.; Kramer, D.J. Do Long Radiology Workdays Impact Nodule Detection in Dynamic CT Interpretation? <span class='html-italic'>J. Am. Coll. Radiol.</span> <b>2012</b>, <span class='html-italic'>9</span>, 191–198. [<a href="https://scholar.google.com/scholar_lookup?title=Do+Long+Radiology+Workdays+Impact+Nodule+Detection+in+Dynamic+CT+Interpretation?&author=Krupinski,+E.A.&author=Berbaum,+K.S.&author=Caldwell,+R.T.&author=Schartz,+K.M.&author=Madsen,+M.T.&author=Kramer,+D.J.&publication_year=2012&journal=J.+Am.+Coll.+Radiol.&volume=9&pages=191%E2%80%93198&doi=10.1016/j.jacr.2011.11.013" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.jacr.2011.11.013" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B7-diagnostics-09-00207' class='html-x' data-content='7.'>Sokolovskaya, E.; Shinde, T.; Ruchman, R.B.; Kwak, A.J.; Lu, S.; Shariff, Y.K.; Wiggins, E.F.; Talangbayan, L. The Effect of Faster Reporting Speed for Imaging Studies on the Number of Misses and Interpretation Errors: A Pilot Study. <span class='html-italic'>J. Am. Coll. Radiol.</span> <b>2015</b>, <span class='html-italic'>12</span>, 683–688. [<a href="https://scholar.google.com/scholar_lookup?title=The+Effect+of+Faster+Reporting+Speed+for+Imaging+Studies+on+the+Number+of+Misses+and+Interpretation+Errors:+A+Pilot+Study&author=Sokolovskaya,+E.&author=Shinde,+T.&author=Ruchman,+R.B.&author=Kwak,+A.J.&author=Lu,+S.&author=Shariff,+Y.K.&author=Wiggins,+E.F.&author=Talangbayan,+L.&publication_year=2015&journal=J.+Am.+Coll.+Radiol.&volume=12&pages=683%E2%80%93688&doi=10.1016/j.jacr.2015.03.040" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.jacr.2015.03.040" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B8-diagnostics-09-00207' class='html-x' data-content='8.'>Ozekes, S.; Osman, O. Computerized lung nodule detection using 3D feature extraction and learning based algorithms. <span class='html-italic'>J. Med. Syst.</span> <b>2010</b>, <span class='html-italic'>34</span>, 185–194. [<a href="https://scholar.google.com/scholar_lookup?title=Computerized+lung+nodule+detection+using+3D+feature+extraction+and+learning+based+algorithms&author=Ozekes,+S.&author=Osman,+O.&publication_year=2010&journal=J.+Med.+Syst.&volume=34&pages=185%E2%80%93194&doi=10.1007/s10916-008-9230-0" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s10916-008-9230-0" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B9-diagnostics-09-00207' class='html-x' data-content='9.'>Armato, S.G., 3rd; Li, F.; Giger, M.L.; MacMahon, H.; Sone, S.; Doi, K. Lung cancer: Performance of automated lung nodule detection applied to cancers missed in a CT screening program. <span class='html-italic'>Radiology</span> <b>2002</b>, <span class='html-italic'>225</span>, 685–692. [<a href="https://scholar.google.com/scholar_lookup?title=Lung+cancer:+Performance+of+automated+lung+nodule+detection+applied+to+cancers+missed+in+a+CT+screening+program&author=Armato,+S.G.,+3rd&author=Li,+F.&author=Giger,+M.L.&author=MacMahon,+H.&author=Sone,+S.&author=Doi,+K.&publication_year=2002&journal=Radiology&volume=225&pages=685%E2%80%93692&doi=10.1148/radiol.2253011376" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1148/radiol.2253011376" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B10-diagnostics-09-00207' class='html-xx' data-content='10.'>Huang, P.; Park, S.; Yan, R.; Lee, J.; Chu, L.C.; Lin, C.T.; Hussien, A.; Rathmell, J.; Thomas, B.; Chen, C.; et al. Added Value of Computer-aided CT Image Features for Early Lung Cancer Diagnosis with Small Pulmonary Nodules: A Matched Case-Control Study. <span class='html-italic'>Radiology</span> <b>2018</b>, <span class='html-italic'>286</span>, 286–295. [<a href="https://scholar.google.com/scholar_lookup?title=Added+Value+of+Computer-aided+CT+Image+Features+for+Early+Lung+Cancer+Diagnosis+with+Small+Pulmonary+Nodules:+A+Matched+Case-Control+Study&author=Huang,+P.&author=Park,+S.&author=Yan,+R.&author=Lee,+J.&author=Chu,+L.C.&author=Lin,+C.T.&author=Hussien,+A.&author=Rathmell,+J.&author=Thomas,+B.&author=Chen,+C.&publication_year=2018&journal=Radiology&volume=286&pages=286%E2%80%93295&doi=10.1148/radiol.2017162725" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1148/radiol.2017162725" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B11-diagnostics-09-00207' class='html-xx' data-content='11.'>Revel, M.P.; Merlin, A.; Peyrard, S.; Triki, R.; Couchon, S.; Chatellier, G.; Frija, G. Software volumetric evaluation of doubling times for differentiating benign versus malignant pulmonary nodules. <span class='html-italic'>AJR Am. J. Roentgenol.</span> <b>2006</b>, <span class='html-italic'>187</span>, 135–142. [<a href="https://scholar.google.com/scholar_lookup?title=Software+volumetric+evaluation+of+doubling+times+for+differentiating+benign+versus+malignant+pulmonary+nodules&author=Revel,+M.P.&author=Merlin,+A.&author=Peyrard,+S.&author=Triki,+R.&author=Couchon,+S.&author=Chatellier,+G.&author=Frija,+G.&publication_year=2006&journal=AJR+Am.+J.+Roentgenol.&volume=187&pages=135%E2%80%93142&doi=10.2214/AJR.05.1228" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.2214/AJR.05.1228" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B12-diagnostics-09-00207' class='html-xx' data-content='12.'>Krizhevsky, A.; Sutskever, I.; Hinton, G.E. ImageNet Classification with Deep Convolutional Neural Networks. In Proceedings of the Neural Information Processing Systems 25 (NIPS), Lake Tahoe, CA, USA, 3–6 December 2012. [<a href="https://scholar.google.com/scholar_lookup?title=ImageNet+Classification+with+Deep+Convolutional+Neural+Networks&conference=Proceedings+of+the+Neural+Information+Processing+Systems+25+(NIPS)&author=Krizhevsky,+A.&author=Sutskever,+I.&author=Hinton,+G.E.&publication_year=2012" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>]</li><li id='B13-diagnostics-09-00207' class='html-xx' data-content='13.'>Chen, G.-L.; Zhang, J.-J.; Zhuo, D.-Y.; Pan, Y.-N.; Pang, C.-Y. Identification of pulmonary nodules via CT images with hierarchical fully convolutional networks. <span class='html-italic'>Med Biol. Eng. Comput.</span> <b>2019</b>, <span class='html-italic'>57</span>, 1567–1580. [<a href="https://scholar.google.com/scholar_lookup?title=Identification+of+pulmonary+nodules+via+CT+images+with+hierarchical+fully+convolutional+networks&author=Chen,+G.-L.&author=Zhang,+J.-J.&author=Zhuo,+D.-Y.&author=Pan,+Y.-N.&author=Pang,+C.-Y.&publication_year=2019&journal=Med+Biol.+Eng.+Comput.&volume=57&pages=1567%E2%80%931580&doi=10.1007/s11517-019-01976-1&pmid=31025248" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s11517-019-01976-1" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/31025248" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B14-diagnostics-09-00207' class='html-xx' data-content='14.'>Savaş, S.; Topaloğlu, N.; Kazcı, Ö.; Koşar, P.N. Classification of Carotid Artery Intima Media Thickness Ultrasound Images with Deep Learning. <span class='html-italic'>J. Med. Syst.</span> <b>2019</b>, <span class='html-italic'>43</span>, 273. [<a href="https://scholar.google.com/scholar_lookup?title=Classification+of+Carotid+Artery+Intima+Media+Thickness+Ultrasound+Images+with+Deep+Learning&author=Sava%C5%9F,+S.&author=Topalo%C4%9Flu,+N.&author=Kazc%C4%B1,+%C3%96.&author=Ko%C5%9Far,+P.N.&publication_year=2019&journal=J.+Med.+Syst.&volume=43&pages=273&doi=10.1007/s10916-019-1406-2&pmid=31278481" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s10916-019-1406-2" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/31278481" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B15-diagnostics-09-00207' class='html-xx' data-content='15.'>Azizpour, H.; Razavian, A.S.; Sullivan, J.; Maki, A.; Carlsson, S. <span class='html-italic'>From Generic to Specific Deep Representations for Visual Recognition</span>, 2014. [<a href="https://dx.doi.org/10.1109/CVPRW.2015.7301270" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B16-diagnostics-09-00207' class='html-xx' data-content='16.'>Armato, S.G.; McLennan, G.; Bidaut, L.; McNitt-Gray, M.F.; Meyer, C.R.; Reeves, A.P.; Zhao, B.; Aberle, D.R.; Henschke, C.I.; Hoffman, E.A.; et al. The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): A completed reference database of lung nodules on CT scans. <span class='html-italic'>Med. Phys.</span> <b>2011</b>, <span class='html-italic'>38</span>, 915–931. [<a href="https://scholar.google.com/scholar_lookup?title=The+Lung+Image+Database+Consortium+(LIDC)+and+Image+Database+Resource+Initiative+(IDRI):+A+completed+reference+database+of+lung+nodules+on+CT+scans&author=Armato,+S.G.&author=McLennan,+G.&author=Bidaut,+L.&author=McNitt-Gray,+M.F.&author=Meyer,+C.R.&author=Reeves,+A.P.&author=Zhao,+B.&author=Aberle,+D.R.&author=Henschke,+C.I.&author=Hoffman,+E.A.&publication_year=2011&journal=Med.+Phys.&volume=38&pages=915%E2%80%93931&doi=10.1118/1.3528204&pmid=21452728" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1118/1.3528204" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/21452728" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B17-diagnostics-09-00207' class='html-xx' data-content='17.'>Li, L.; Liu, Z.; Huang, H.; Lin, M.; Luo, D.-H. Evaluating the performance of a deep learning-based computer-aided diagnosis (DL-CAD) system for detecting and characterizing lung nodules: Comparison with the performance of double reading by radiologists. <span class='html-italic'>Thorac. Cancer</span> <b>2019</b>, <span class='html-italic'>10</span>, 183–192. [<a href="https://scholar.google.com/scholar_lookup?title=Evaluating+the+performance+of+a+deep+learning-based+computer-aided+diagnosis+(DL-CAD)+system+for+detecting+and+characterizing+lung+nodules:+Comparison+with+the+performance+of+double+reading+by+radiologists&author=Li,+L.&author=Liu,+Z.&author=Huang,+H.&author=Lin,+M.&author=Luo,+D.-H.&publication_year=2019&journal=Thorac.+Cancer&volume=10&pages=183%E2%80%93192&doi=10.1111/1759-7714.12931&pmid=30536611" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1111/1759-7714.12931" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/30536611" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B18-diagnostics-09-00207' class='html-xx' data-content='18.'>Setio, A.A.A.; Ciompi, F.; Litjens, G.; Gerke, P.; Jacobs, C.; Van Riel, S.J.; Wille, M.M.W.; Naqibullah, M.; Sanchez, C.I.; Van Ginneken, B. Pulmonary Nodule Detection in CT Images: False Positive Reduction Using Multi-View Convolutional Networks. <span class='html-italic'>IEEE Trans. Med Imaging</span> <b>2016</b>, <span class='html-italic'>35</span>, 1160–1169. [<a href="https://scholar.google.com/scholar_lookup?title=Pulmonary+Nodule+Detection+in+CT+Images:+False+Positive+Reduction+Using+Multi-View+Convolutional+Networks&author=Setio,+A.A.A.&author=Ciompi,+F.&author=Litjens,+G.&author=Gerke,+P.&author=Jacobs,+C.&author=Van+Riel,+S.J.&author=Wille,+M.M.W.&author=Naqibullah,+M.&author=Sanchez,+C.I.&author=Van+Ginneken,+B.&publication_year=2016&journal=IEEE+Trans.+Med+Imaging&volume=35&pages=1160%E2%80%931169&doi=10.1109/TMI.2016.2536809&pmid=26955024" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/TMI.2016.2536809" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/26955024" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B19-diagnostics-09-00207' class='html-xx' data-content='19.'>Suzuki, K. A supervised ‘lesion-enhancement’ filter by use of a massive-training artificial neural network (MTANN) in computer-aided diagnosis (CAD). <span class='html-italic'>Phys. Med. Biol.</span> <b>2009</b>, <span class='html-italic'>54</span>. [<a href="https://scholar.google.com/scholar_lookup?title=A+supervised+%E2%80%98lesion-enhancement%E2%80%99+filter+by+use+of+a+massive-training+artificial+neural+network+(MTANN)+in+computer-aided+diagnosis+(CAD)&author=Suzuki,+K.&publication_year=2009&journal=Phys.+Med.+Biol.&volume=54&doi=10.1088/0031-9155/54/18/S03" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1088/0031-9155/54/18/S03" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B20-diagnostics-09-00207' class='html-xx' data-content='20.'>Tajbakhsh, N.; Suzuki, K. Comparing two classes of end-to-end machine-learning models in lung nodule detection and classification: MTANNs vs. CNNs. <span class='html-italic'>Pattern Recognit.</span> <b>2017</b>, <span class='html-italic'>63</span>, 476–486. [<a href="https://scholar.google.com/scholar_lookup?title=Comparing+two+classes+of+end-to-end+machine-learning+models+in+lung+nodule+detection+and+classification:+MTANNs+vs.+CNNs&author=Tajbakhsh,+N.&author=Suzuki,+K.&publication_year=2017&journal=Pattern+Recognit.&volume=63&pages=476%E2%80%93486&doi=10.1016/j.patcog.2016.09.029" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.patcog.2016.09.029" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B21-diagnostics-09-00207' class='html-xx' data-content='21.'>Masood, A.; Sheng, B.; Li, P.; Hou, X.-H.; Wei, X.-E.; Qin, J.; Feng, D.-G. Computer-Assisted Decision Support System in Pulmonary Cancer detection and stage classification on CT images. <span class='html-italic'>J. Biomed. Inform.</span> <b>2018</b>, <span class='html-italic'>79</span>, 117–128. [<a href="https://scholar.google.com/scholar_lookup?title=Computer-Assisted+Decision+Support+System+in+Pulmonary+Cancer+detection+and+stage+classification+on+CT+images&author=Masood,+A.&author=Sheng,+B.&author=Li,+P.&author=Hou,+X.-H.&author=Wei,+X.-E.&author=Qin,+J.&author=Feng,+D.-G.&publication_year=2018&journal=J.+Biomed.+Inform.&volume=79&pages=117%E2%80%93128&doi=10.1016/j.jbi.2018.01.005" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.jbi.2018.01.005" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B22-diagnostics-09-00207' class='html-xx' data-content='22.'>Chen, S.-H.; Guo, J.-X.; Wang, C.-D.; Xu, X.-X.; Yi, Z.; Li, W.-M. DeepLNAnno: A Web-Based Lung Nodules Annotating System for CT Images. <span class='html-italic'>J. Med. Syst.</span> <b>2019</b>, <span class='html-italic'>43</span>. [<a href="https://scholar.google.com/scholar_lookup?title=DeepLNAnno:+A+Web-Based+Lung+Nodules+Annotating+System+for+CT+Images&author=Chen,+S.-H.&author=Guo,+J.-X.&author=Wang,+C.-D.&author=Xu,+X.-X.&author=Yi,+Z.&author=Li,+W.-M.&publication_year=2019&journal=J.+Med.+Syst.&volume=43&doi=10.1007/s10916-019-1258-9" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s10916-019-1258-9" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B23-diagnostics-09-00207' class='html-xx' data-content='23.'>Liao, F.-Z.; Liang, M.; Li, Z.; Hu, X.-L.; Song, S. Evaluate the Malignancy of Pulmonary Nodules Using the 3-D Deep Leaky Noisy-or Network. <span class='html-italic'>IEEE Trans. Neural Netw. Learn. Syst.</span> <b>2019</b>, <span class='html-italic'>30</span>, 3484–3494. [<a href="https://scholar.google.com/scholar_lookup?title=Evaluate+the+Malignancy+of+Pulmonary+Nodules+Using+the+3-D+Deep+Leaky+Noisy-or+Network&author=Liao,+F.-Z.&author=Liang,+M.&author=Li,+Z.&author=Hu,+X.-L.&author=Song,+S.&publication_year=2019&journal=IEEE+Trans.+Neural+Netw.+Learn.+Syst.&volume=30&pages=3484%E2%80%933494&doi=10.1109/TNNLS.2019.2892409" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/TNNLS.2019.2892409" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B24-diagnostics-09-00207' class='html-xx' data-content='24.'>Liu, M.-Z.; Jiang, X.; Liu, Y.-H.; Zhao, F.-X.; Zhou, H.-L. A semi-supervised convolutional transfer neural network for 3D pulmonary nodules detection. <span class='html-italic'>Neurocomputing</span> <b>2019</b>, in press. [<a href="https://scholar.google.com/scholar_lookup?title=A+semi-supervised+convolutional+transfer+neural+network+for+3D+pulmonary+nodules+detection&author=Liu,+M.-Z.&author=Jiang,+X.&author=Liu,+Y.-H.&author=Zhao,+F.-X.&author=Zhou,+H.-L.&publication_year=2019&journal=Neurocomputing&doi=10.1016/j.neucom.2018.12.081" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.neucom.2018.12.081" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B25-diagnostics-09-00207' class='html-xx' data-content='25.'>Wang, Y.; Yan, F.-R.; Lu, X.-F.; Zheng, G.-M.; Zhang, X.; Wang, C.; Zhou, K.-F.; Zhang, Y.-W.; Li, H.; Zhao, Q.; et al. IILS: Intelligent imaging layout system for automatic imaging report standardization and intra-interdisciplinary clinical workflow optimization. <span class='html-italic'>EBioMedicine</span> <b>2019</b>, <span class='html-italic'>44</span>, 162–181. [<a href="https://scholar.google.com/scholar_lookup?title=IILS:+Intelligent+imaging+layout+system+for+automatic+imaging+report+standardization+and+intra-interdisciplinary+clinical+workflow+optimization&author=Wang,+Y.&author=Yan,+F.-R.&author=Lu,+X.-F.&author=Zheng,+G.-M.&author=Zhang,+X.&author=Wang,+C.&author=Zhou,+K.-F.&author=Zhang,+Y.-W.&author=Li,+H.&author=Zhao,+Q.&publication_year=2019&journal=EBioMedicine&volume=44&pages=162%E2%80%93181&doi=10.1016/j.ebiom.2019.05.040&pmid=31129095" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.ebiom.2019.05.040" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/31129095" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B26-diagnostics-09-00207' class='html-xx' data-content='26.'>Wang, J.; Wang, J.-W.; Wen, Y.-F.; Lu, H.-B.; Niu, T.-Y.; Pan, J.-F.; Qian, D.-H. Pulmonary Nodule Detection in Volumetric Chest CT Scans Using CNNs-Based Nodule-Size-Adaptive Detection and Classification. <span class='html-italic'>IEEE Access</span> <b>2019</b>, <span class='html-italic'>7</span>, 46033–46044. [<a href="https://scholar.google.com/scholar_lookup?title=Pulmonary+Nodule+Detection+in+Volumetric+Chest+CT+Scans+Using+CNNs-Based+Nodule-Size-Adaptive+Detection+and+Classification&author=Wang,+J.&author=Wang,+J.-W.&author=Wen,+Y.-F.&author=Lu,+H.-B.&author=Niu,+T.-Y.&author=Pan,+J.-F.&author=Qian,+D.-H.&publication_year=2019&journal=IEEE+Access&volume=7&pages=46033%E2%80%9346044&doi=10.1109/ACCESS.2019.2908195" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/ACCESS.2019.2908195" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B27-diagnostics-09-00207' class='html-xx' data-content='27.'>Alakwaa, W.; Nassef, M.; Badr, A. Lung Cancer Detection and Classification with 3D Convolutional Neural Network (3D-CNN). <span class='html-italic'>Int. J. Adv. Comput. Sci. Appl.</span> <b>2017</b>, <span class='html-italic'>8</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Lung+Cancer+Detection+and+Classification+with+3D+Convolutional+Neural+Network+(3D-CNN)&author=Alakwaa,+W.&author=Nassef,+M.&author=Badr,+A.&publication_year=2017&journal=Int.+J.+Adv.+Comput.+Sci.+Appl.&volume=8&doi=10.14569/IJACSA.2017.080853" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.14569/IJACSA.2017.080853" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B28-diagnostics-09-00207' class='html-xx' data-content='28.'>Ciompi, F.; de Hoop, B.; van Riel, S.J.; Chung, K.; Scholten, E.T.; Oudkerk, M.; de Jong, P.A.; Prokop, M.; van Ginneken, B. Automatic classification of pulmonary peri-fissural nodules in computed tomography using an ensemble of 2D views and a convolutional neural network out-of-the-box. <span class='html-italic'>Med. Image Anal.</span> <b>2015</b>, <span class='html-italic'>26</span>, 195–202. [<a href="https://scholar.google.com/scholar_lookup?title=Automatic+classification+of+pulmonary+peri-fissural+nodules+in+computed+tomography+using+an+ensemble+of+2D+views+and+a+convolutional+neural+network+out-of-the-box&author=Ciompi,+F.&author=de+Hoop,+B.&author=van+Riel,+S.J.&author=Chung,+K.&author=Scholten,+E.T.&author=Oudkerk,+M.&author=de+Jong,+P.A.&author=Prokop,+M.&author=van+Ginneken,+B.&publication_year=2015&journal=Med.+Image+Anal.&volume=26&pages=195%E2%80%93202&doi=10.1016/j.media.2015.08.001&pmid=26458112" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.media.2015.08.001" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/26458112" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B29-diagnostics-09-00207' class='html-xx' data-content='29.'>Ciompi, F.; Chung, K.; Van Riel, S.J.; Setio, A.A.A.; Gerke, P.K.; Jacobs, C.; Th Scholten, E.; Schaefer-Prokop, C.; Wille, M.M.W.; Marchianò, A.; et al. Towards automatic pulmonary nodule management in lung cancer screening with deep learning. <span class='html-italic'>Sci. Rep.</span> <b>2017</b>, <span class='html-italic'>7</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Towards+automatic+pulmonary+nodule+management+in+lung+cancer+screening+with+deep+learning&author=Ciompi,+F.&author=Chung,+K.&author=Van+Riel,+S.J.&author=Setio,+A.A.A.&author=Gerke,+P.K.&author=Jacobs,+C.&author=Th+Scholten,+E.&author=Schaefer-Prokop,+C.&author=Wille,+M.M.W.&author=Marchian%C3%B2,+A.&publication_year=2017&journal=Sci.+Rep.&volume=7&doi=10.1038/srep46479" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1038/srep46479" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B30-diagnostics-09-00207' class='html-xx' data-content='30.'>Jakimovski, G.; Davcev, D. Using Double Convolution Neural Network for Lung Cancer Stage Detection. <span class='html-italic'>Appl. Sci.</span> <b>2019</b>, <span class='html-italic'>9</span>, 427. [<a href="https://scholar.google.com/scholar_lookup?title=Using+Double+Convolution+Neural+Network+for+Lung+Cancer+Stage+Detection&author=Jakimovski,+G.&author=Davcev,+D.&publication_year=2019&journal=Appl.+Sci.&volume=9&pages=427&doi=10.3390/app9030427" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.3390/app9030427" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B31-diagnostics-09-00207' class='html-xx' data-content='31.'>Lakshmanaprabu, S.K.; Mohanty, S.N.; Shankar, K.; Arunkumar, N.; Ramirez, G. Optimal deep learning model for classification of lung cancer on CT images. <span class='html-italic'>Future Gener. Comput. Syst.</span> <b>2019</b>, <span class='html-italic'>92</span>, 374–382. [<a href="https://scholar.google.com/scholar_lookup?title=Optimal+deep+learning+model+for+classification+of+lung+cancer+on+CT+images&author=Lakshmanaprabu,+S.K.&author=Mohanty,+S.N.&author=Shankar,+K.&author=Arunkumar,+N.&author=Ramirez,+G.&publication_year=2019&journal=Future+Gener.+Comput.+Syst.&volume=92&pages=374%E2%80%93382&doi=10.1016/j.future.2018.10.009" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.future.2018.10.009" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B32-diagnostics-09-00207' class='html-xx' data-content='32.'>Liu, S.; Xie, Y.-T.; Jirapatnakul, A.; Reeves, A.P. Pulmonary nodule classification in lung cancer screening with three-dimensional convolutional neural networks. <span class='html-italic'>J. Med. Imaging</span> <b>2017</b>, <span class='html-italic'>4</span>, 1. [<a href="https://scholar.google.com/scholar_lookup?title=Pulmonary+nodule+classification+in+lung+cancer+screening+with+three-dimensional+convolutional+neural+networks&author=Liu,+S.&author=Xie,+Y.-T.&author=Jirapatnakul,+A.&author=Reeves,+A.P.&publication_year=2017&journal=J.+Med.+Imaging&volume=4&pages=1&doi=10.1117/1.JMI.4.4.041308" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1117/1.JMI.4.4.041308" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B33-diagnostics-09-00207' class='html-xx' data-content='33.'>Liu, X.-L.; Hou, F.; Qin, H.; Hao, A. Multi-view multi-scale CNNs for lung nodule type classification from CT images. <span class='html-italic'>Pattern Recognit.</span> <b>2018</b>, <span class='html-italic'>77</span>, 262–275. [<a href="https://scholar.google.com/scholar_lookup?title=Multi-view+multi-scale+CNNs+for+lung+nodule+type+classification+from+CT+images&author=Liu,+X.-L.&author=Hou,+F.&author=Qin,+H.&author=Hao,+A.&publication_year=2018&journal=Pattern+Recognit.&volume=77&pages=262%E2%80%93275&doi=10.1016/j.patcog.2017.12.022" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.patcog.2017.12.022" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B34-diagnostics-09-00207' class='html-xx' data-content='34.'>Nishio, M.; Sugiyama, O.; Yakami, M.; Ueno, S.; Kubo, T.; Kuroda, T.; Togashi, K. Computer-aided diagnosis of lung nodule classification between benign nodule, primary lung cancer, and metastatic lung cancer at different image size using deep convolutional neural network with transfer learning. <span class='html-italic'>PLoS ONE</span> <b>2018</b>, <span class='html-italic'>13</span>, e0200721. [<a href="https://scholar.google.com/scholar_lookup?title=Computer-aided+diagnosis+of+lung+nodule+classification+between+benign+nodule,+primary+lung+cancer,+and+metastatic+lung+cancer+at+different+image+size+using+deep+convolutional+neural+network+with+transfer+learning&author=Nishio,+M.&author=Sugiyama,+O.&author=Yakami,+M.&author=Ueno,+S.&author=Kubo,+T.&author=Kuroda,+T.&author=Togashi,+K.&publication_year=2018&journal=PLoS+ONE&volume=13&pages=e0200721&doi=10.1371/journal.pone.0200721&pmid=30052644" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1371/journal.pone.0200721" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/30052644" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B35-diagnostics-09-00207' class='html-xx' data-content='35.'>Onishi, Y.; Teramoto, A.; Tsujimoto, M.; Tsukamoto, T.; Saito, K.; Toyama, H.; Imaizumi, K.; Fujita, H. Automated Pulmonary Nodule Classification in Computed Tomography Images Using a Deep Convolutional Neural Network Trained by Generative Adversarial Networks. <span class='html-italic'>BioMed Res. Int.</span> <b>2019</b>, <span class='html-italic'>2019</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Automated+Pulmonary+Nodule+Classification+in+Computed+Tomography+Images+Using+a+Deep+Convolutional+Neural+Network+Trained+by+Generative+Adversarial+Networks&author=Onishi,+Y.&author=Teramoto,+A.&author=Tsujimoto,+M.&author=Tsukamoto,+T.&author=Saito,+K.&author=Toyama,+H.&author=Imaizumi,+K.&author=Fujita,+H.&publication_year=2019&journal=BioMed+Res.+Int.&volume=2019&doi=10.1155/2019/6051939&pmid=30719445" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1155/2019/6051939" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/30719445" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B36-diagnostics-09-00207' class='html-xx' data-content='36.'>Polat, H.; Mehr, H.D. Classification of pulmonary CT images by using hybrid 3D-deep convolutional neural network architecture. <span class='html-italic'>Appl. Sci. (Switz.)</span> <b>2019</b>, <span class='html-italic'>9</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Classification+of+pulmonary+CT+images+by+using+hybrid+3D-deep+convolutional+neural+network+architecture&author=Polat,+H.&author=Mehr,+H.D.&publication_year=2019&journal=Appl.+Sci.+(Switz.)&volume=9&doi=10.3390/app9050940" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.3390/app9050940" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B37-diagnostics-09-00207' class='html-xx' data-content='37.'>Qiang, Y.; Ge, L.; Zhao, X.; Zhang, X.-L.; Tang, X.-X. Pulmonary nodule diagnosis using dual-modal supervised autoencoder based on extreme learning machine. <span class='html-italic'>Expert Syst.</span> <b>2017</b>, <span class='html-italic'>34</span>, e12224. [<a href="https://scholar.google.com/scholar_lookup?title=Pulmonary+nodule+diagnosis+using+dual-modal+supervised+autoencoder+based+on+extreme+learning+machine&author=Qiang,+Y.&author=Ge,+L.&author=Zhao,+X.&author=Zhang,+X.-L.&author=Tang,+X.-X.&publication_year=2017&journal=Expert+Syst.&volume=34&pages=e12224&doi=10.1111/exsy.12224" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1111/exsy.12224" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B38-diagnostics-09-00207' class='html-xx' data-content='38.'>Rangaswamy, C.; Raju, G.T.; Seshikala, G. SVM, RBFNN and CNN classifiers for detection and classification of lung cancer from CT scans image. <span class='html-italic'>J. Int. Pharm. Res.</span> <b>2019</b>, <span class='html-italic'>46</span>, 230–236. [<a href="https://scholar.google.com/scholar_lookup?title=SVM,+RBFNN+and+CNN+classifiers+for+detection+and+classification+of+lung+cancer+from+CT+scans+image&author=Rangaswamy,+C.&author=Raju,+G.T.&author=Seshikala,+G.&publication_year=2019&journal=J.+Int.+Pharm.+Res.&volume=46&pages=230%E2%80%93236" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>]</li><li id='B39-diagnostics-09-00207' class='html-xx' data-content='39.'>Sori, W.J.; Feng, J.; Liu, S. Multi-path convolutional neural network for lung cancer detection. <span class='html-italic'>Multidimens. Syst. Signal Process.</span> <b>2018</b>, 30. [<a href="https://scholar.google.com/scholar_lookup?title=Multi-path+convolutional+neural+network+for+lung+cancer+detection&author=Sori,+W.J.&author=Feng,+J.&author=Liu,+S.&publication_year=2018&journal=Multidimens.+Syst.+Signal+Process.&pages=30&doi=10.1007/s11045-018-0626-9" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s11045-018-0626-9" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B40-diagnostics-09-00207' class='html-xx' data-content='40.'>Wang, S.; Wang, R.; Zhang, S.; Li, R.; Fu, Y.; Sun, X.; Li, Y.; Sun, X.; Jiang, X.; Guo, X.; et al. 3D convolutional neural network for differentiating pre-invasive lesions from invasive adenocarcinomas appearing as ground-glass nodules with diameters ≤3 cm using HRCT. <span class='html-italic'>Quant. Imaging Med. Surg.</span> <b>2018</b>, <span class='html-italic'>8</span>, 491–499. [<a href="https://scholar.google.com/scholar_lookup?title=3D+convolutional+neural+network+for+differentiating+pre-invasive+lesions+from+invasive+adenocarcinomas+appearing+as+ground-glass+nodules+with+diameters+%E2%89%A43+cm+using+HRCT&author=Wang,+S.&author=Wang,+R.&author=Zhang,+S.&author=Li,+R.&author=Fu,+Y.&author=Sun,+X.&author=Li,+Y.&author=Sun,+X.&author=Jiang,+X.&author=Guo,+X.&publication_year=2018&journal=Quant.+Imaging+Med.+Surg.&volume=8&pages=491%E2%80%93499&doi=10.21037/qims.2018.06.03" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.21037/qims.2018.06.03" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B41-diagnostics-09-00207' class='html-xx' data-content='41.'>Yuan, J.-J.; Liu, X.-L.; Hou, F.; Qin, H.; Hao, A. Hybrid-feature-guided lung nodule type classification on CT images. <span class='html-italic'>Comput. Graph. (Pergamon)</span> <b>2018</b>, <span class='html-italic'>70</span>, 288–299. [<a href="https://scholar.google.com/scholar_lookup?title=Hybrid-feature-guided+lung+nodule+type+classification+on+CT+images&author=Yuan,+J.-J.&author=Liu,+X.-L.&author=Hou,+F.&author=Qin,+H.&author=Hao,+A.&publication_year=2018&journal=Comput.+Graph.+(Pergamon)&volume=70&pages=288%E2%80%93299&doi=10.1016/j.cag.2017.07.020" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.cag.2017.07.020" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B42-diagnostics-09-00207' class='html-xx' data-content='42.'>Zhang, C.; Sun, X.; Dang, K.; Li, K.; Guo, X.-W.; Chang, J.; Yu, Z.-Q.; Huang, F.-Y.; Wu, Y.-S.; Liang, Z.; et al. Toward an Expert Level of Lung Cancer Detection and Classification Using a Deep Convolutional Neural Network. <span class='html-italic'>Oncologist</span> <b>2019</b>, <span class='html-italic'>24</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Toward+an+Expert+Level+of+Lung+Cancer+Detection+and+Classification+Using+a+Deep+Convolutional+Neural+Network&author=Zhang,+C.&author=Sun,+X.&author=Dang,+K.&author=Li,+K.&author=Guo,+X.-W.&author=Chang,+J.&author=Yu,+Z.-Q.&author=Huang,+F.-Y.&author=Wu,+Y.-S.&author=Liang,+Z.&publication_year=2019&journal=Oncologist&volume=24&doi=10.1634/theoncologist.2018-0908" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1634/theoncologist.2018-0908" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B43-diagnostics-09-00207' class='html-xx' data-content='43.'>Suzuki, K. Overview of deep learning in medical imaging. <span class='html-italic'>Radiol. Phys. Technol.</span> <b>2017</b>, <span class='html-italic'>10</span>, 257–273. [<a href="https://scholar.google.com/scholar_lookup?title=Overview+of+deep+learning+in+medical+imaging&author=Suzuki,+K.&publication_year=2017&journal=Radiol.+Phys.+Technol.&volume=10&pages=257%E2%80%93273&doi=10.1007/s12194-017-0406-5" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s12194-017-0406-5" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B44-diagnostics-09-00207' class='html-xx' data-content='44.'>Liu, G.-F.; Bao, H.-Q.; Han, B.-K. A Stacked Autoencoder-Based Deep Neural Network for Achieving Gearbox Fault Diagnosis. <span class='html-italic'>Math. Probl. Eng.</span> <b>2018</b>, <span class='html-italic'>2018</span>, 1–10. [<a href="https://scholar.google.com/scholar_lookup?title=A+Stacked+Autoencoder-Based+Deep+Neural+Network+for+Achieving+Gearbox+Fault+Diagnosis&author=Liu,+G.-F.&author=Bao,+H.-Q.&author=Han,+B.-K.&publication_year=2018&journal=Math.+Probl.+Eng.&volume=2018&pages=1%E2%80%9310&doi=10.1155/2018/5105709" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1155/2018/5105709" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B45-diagnostics-09-00207' class='html-xx' data-content='45.'>Kaggle Data Science Bowl 2017. Available online: <a href='https://www.kaggle.com/c/data-science-bowl-2017/data' target='_blank' rel="noopener noreferrer">https://www.kaggle.com/c/data-science-bowl-2017/data</a> (accessed on 15 November 2019).</li><li id='B46-diagnostics-09-00207' class='html-xx' data-content='46.'>ELCAP Public Lung Image Database. Available online: <a href='http://www.via.cornell.edu/databases/lungdb.html' target='_blank' rel="noopener noreferrer">http://www.via.cornell.edu/databases/lungdb.html</a> (accessed on 28 October 2019).</li><li id='B47-diagnostics-09-00207' class='html-xx' data-content='47.'>Ru Zhao, Y.; Xie, X.; de Koning, H.J.; Mali, W.P.; Vliegenthart, R.; Oudkerk, M. NELSON lung cancer screening study. <span class='html-italic'>Cancer Imaging</span> <b>2011</b>, <span class='html-italic'>11</span>, S79–S84. [<a href="https://scholar.google.com/scholar_lookup?title=NELSON+lung+cancer+screening+study&author=Ru+Zhao,+Y.&author=Xie,+X.&author=de+Koning,+H.J.&author=Mali,+W.P.&author=Vliegenthart,+R.&author=Oudkerk,+M.&publication_year=2011&journal=Cancer+Imaging&volume=11&pages=S79%E2%80%93S84&doi=10.1102/1470-7330.2011.9020&pmid=22185865" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1102/1470-7330.2011.9020" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/22185865" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B48-diagnostics-09-00207' class='html-xx' data-content='48.'>The Image and Data Archive of the University of South Carolina and Laboratory of Neuro Imaging. Available online: <a href='https://ida.loni.usc.edu/login.jsp' target='_blank' rel="noopener noreferrer">https://ida.loni.usc.edu/login.jsp</a> (accessed on 28 October 2019).</li><li id='B49-diagnostics-09-00207' class='html-xx' data-content='49.'>Multimedia database of Interstitial Lung Diseases. Available online: <a href='http://medgift.hevs.ch/wordpress/databases/ild-database/' target='_blank' rel="noopener noreferrer">http://medgift.hevs.ch/wordpress/databases/ild-database/</a> (accessed on 15 November 2017).</li><li id='B50-diagnostics-09-00207' class='html-xx' data-content='50.'>Pehrson, L.M.; Nielsen, M.B.; Ammitzbol Lauridsen, C. Automatic Pulmonary Nodule Detection Applying Deep Learning or Machine Learning Algorithms to the LIDC-IDRI Database: A Systematic Review. <span class='html-italic'>Diagnostics (Basel)</span> <b>2019</b>, <span class='html-italic'>9</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Automatic+Pulmonary+Nodule+Detection+Applying+Deep+Learning+or+Machine+Learning+Algorithms+to+the+LIDC-IDRI+Database:+A+Systematic+Review&author=Pehrson,+L.M.&author=Nielsen,+M.B.&author=Ammitzbol+Lauridsen,+C.&publication_year=2019&journal=Diagnostics+(Basel)&volume=9&doi=10.3390/diagnostics9010029&pmid=30866425" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.3390/diagnostics9010029" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/30866425" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B51-diagnostics-09-00207' class='html-xx' data-content='51.'>Tajbakhsh, N.; Suzuki, K. A Comparative Study of Modern Machine Learning Approaches for Focal Lesion Detection and Classification in Medical Images: BoVW, CNN and MTANN. In <span class='html-italic'>Artificial Intelligence in Decision Support Systems for Diagnosis in Medical Imaging</span>; Springer: Cham, Switzerland, 2018; pp. 31–58. [<a href="https://scholar.google.com/scholar_lookup?title=A+Comparative+Study+of+Modern+Machine+Learning+Approaches+for+Focal+Lesion+Detection+and+Classification+in+Medical+Images:+BoVW,+CNN+and+MTANN&author=Tajbakhsh,+N.&author=Suzuki,+K.&publication_year=2018&pages=31%E2%80%9358" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/978-3-319-68843-5_2" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B52-diagnostics-09-00207' class='html-xx' data-content='52.'>Suzuki, K.; Armato, S.G.; Li, F.; Sone, S.; Doi, K. Massive training artificial neural network (MTANN) for reduction of false positives in computerized detection of lung nodules in low-dose computed tomography. <span class='html-italic'>Med. Phys.</span> <b>2003</b>, <span class='html-italic'>30</span>, 1602–1617. [<a href="https://scholar.google.com/scholar_lookup?title=Massive+training+artificial+neural+network+(MTANN)+for+reduction+of+false+positives+in+computerized+detection+of+lung+nodules+in+low-dose+computed+tomography&author=Suzuki,+K.&author=Armato,+S.G.&author=Li,+F.&author=Sone,+S.&author=Doi,+K.&publication_year=2003&journal=Med.+Phys.&volume=30&pages=1602%E2%80%931617&doi=10.1118/1.1580485&pmid=12906178" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1118/1.1580485" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/12906178" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B53-diagnostics-09-00207' class='html-xx' data-content='53.'>Cho, J.; Lee, K.; Shin, E.; Choy, G.; Do, S. How much data is needed to train a medical image deep learning system to achieve necessary high accuracy? <span class='html-italic'>arXiv</span> <b>2015</b>, arXiv:1511.06348. [<a href="https://scholar.google.com/scholar_lookup?title=How+much+data+is+needed+to+train+a+medical+image+deep+learning+system+to+achieve+necessary+high+accuracy?&author=Cho,+J.&author=Lee,+K.&author=Shin,+E.&author=Choy,+G.&author=Do,+S.&publication_year=2015&journal=arXiv" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>]</li><li id='B54-diagnostics-09-00207' class='html-xx' data-content='54.'>Yosinski, J.; Clune, J.; Bengio, Y.; Lipson, H. How transferable are features in deep neural networks? In Proceedings of the Neural Information Processing Systems 27 (NIPS 2014), Montreal, QC, Canada, 8–11 December 2014. [<a href="https://scholar.google.com/scholar_lookup?title=How+transferable+are+features+in+deep+neural+networks?&conference=Proceedings+of+the+Neural+Information+Processing+Systems+27+(NIPS+2014)&author=Yosinski,+J.&author=Clune,+J.&author=Bengio,+Y.&author=Lipson,+H.&publication_year=2014" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>]</li><li id='B55-diagnostics-09-00207' class='html-xx' data-content='55.'>Schlegl, T.; Ofner, J.; Langs, G. <span class='html-italic'>Unsupervised Pre-training Across Image Domains Improves Lung Tissue Classification</span>; Springer: Cham, Switzerland, 2014; pp. 82–93. [<a href="https://scholar.google.com/scholar_lookup?title=Unsupervised+Pre-training+Across+Image+Domains+Improves+Lung+Tissue+Classification&author=Schlegl,+T.&author=Ofner,+J.&author=Langs,+G.&publication_year=2014" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/978-3-319-13972-2_8pp" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B56-diagnostics-09-00207' class='html-xx' data-content='56.'>Oquab, M.; Bottou, L.; Laptev, I.; Sivic, J. Learning and Transferring Mid-Level Image Representations using Convolutional Neural Networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Columbus, OH, USA, 24–27 June 2014. [<a href="https://scholar.google.com/scholar_lookup?title=Learning+and+Transferring+Mid-Level+Image+Representations+using+Convolutional+Neural+Networks&conference=Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition+(CVPR)&author=Oquab,+M.&author=Bottou,+L.&author=Laptev,+I.&author=Sivic,+J.&publication_year=2014" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>]</li><li id='B57-diagnostics-09-00207' class='html-xx' data-content='57.'>Tajbakhsh, N.; Shin, J.Y.; Gurudu, S.R.; Hurst, R.T.; Kendall, C.B.; Gotway, M.B.; Liang, J. Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning? <span class='html-italic'>IEEE Trans. Med. Imaging</span> <b>2016</b>, <span class='html-italic'>35</span>, 1299–1312. [<a href="https://scholar.google.com/scholar_lookup?title=Convolutional+Neural+Networks+for+Medical+Image+Analysis:+Full+Training+or+Fine+Tuning?&author=Tajbakhsh,+N.&author=Shin,+J.Y.&author=Gurudu,+S.R.&author=Hurst,+R.T.&author=Kendall,+C.B.&author=Gotway,+M.B.&author=Liang,+J.&publication_year=2016&journal=IEEE+Trans.+Med.+Imaging&volume=35&pages=1299%E2%80%931312&doi=10.1109/TMI.2016.2535302" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/TMI.2016.2535302" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B58-diagnostics-09-00207' class='html-xx' data-content='58.'>Szegedy, C.; Liu, W.; Jia, Y.; Sermanet, P.; Reed, S.; Anguelov, D.; Erhan, D.; Vanhoucke, V.; Rabinovich, A. Going Deeper with Convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Boston, MA, USA, 7–12 June 2015. [<a href="https://scholar.google.com/scholar_lookup?title=Going+Deeper+with+Convolutions&conference=Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition&author=Szegedy,+C.&author=Liu,+W.&author=Jia,+Y.&author=Sermanet,+P.&author=Reed,+S.&author=Anguelov,+D.&author=Erhan,+D.&author=Vanhoucke,+V.&author=Rabinovich,+A.&publication_year=2015" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>]</li><li id='B59-diagnostics-09-00207' class='html-xx' data-content='59.'>Taigman, Y.; Marc, M.Y.; Ranzato, A.; Wolf, L. DeepFace: Closing the Gap to Human-Level Performance in Face Verification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Columbus, OH, USA, 24–27 June 2014. [<a href="https://scholar.google.com/scholar_lookup?title=DeepFace:+Closing+the+Gap+to+Human-Level+Performance+in+Face+Verification&conference=Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition+(CVPR)&author=Taigman,+Y.&author=Marc,+M.Y.&author=Ranzato,+A.&author=Wolf,+L.&publication_year=2014" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>]</li><li id='B60-diagnostics-09-00207' class='html-xx' data-content='60.'>Nuance + NVIDIA Advance AI for Radiology Nuance. Available online: <a href='https://www.nuance.com/about-us/newsroom/press-releases/nuance-nvidia-advance-ai-radiology.html' target='_blank' rel="noopener noreferrer">https://www.nuance.com/about-us/newsroom/press-releases/nuance-nvidia-advance-ai-radiology.html</a> (accessed on 15 November 2019).</li></ol></section><section id='FigureandTables' type='display-objects'><div class="html-fig-wrap" id="diagnostics-09-00207-f001">
<div class='html-fig_img'>
<div class="html-figpopup html-figpopup-link" href="#fig_body_display_diagnostics-09-00207-f001">
<img alt="Diagnostics 09 00207 g001 550" data-large="/diagnostics/diagnostics-09-00207/article_deploy/html/images/diagnostics-09-00207-g001.png" data-original="/diagnostics/diagnostics-09-00207/article_deploy/html/images/diagnostics-09-00207-g001.png" onerror="/diagnostics/diagnostics-09-00207/article_deploy/html/images/diagnostics-09-00207-g001.png" src="/diagnostics/diagnostics-09-00207/article_deploy/html/images/diagnostics-09-00207-g001-550.jpg" />
<a class="html-expand html-figpopup" href="#fig_body_display_diagnostics-09-00207-f001"></a>
</div>
</div>
<div class="html-fig_description">
<b>Figure 1.</b>
Preferred reporting items for systematic reviews and meta-analyses (PRISMA) flowchart of the literature search and study selection.

</div>
</div>
<div class="html-fig_show  mfp-hide" id="fig_body_display_diagnostics-09-00207-f001">
<div class="html-caption"> <b>Figure 1.</b>
Preferred reporting items for systematic reviews and meta-analyses (PRISMA) flowchart of the literature search and study selection.</div>
<div class="html-img"><img alt="Diagnostics 09 00207 g001" data-large="/diagnostics/diagnostics-09-00207/article_deploy/html/images/diagnostics-09-00207-g001.png" data-original="/diagnostics/diagnostics-09-00207/article_deploy/html/images/diagnostics-09-00207-g001.png" onerror="/diagnostics/diagnostics-09-00207/article_deploy/html/images/diagnostics-09-00207-g001.png" src="/diagnostics/diagnostics-09-00207/article_deploy/html/images/diagnostics-09-00207-g001.png" /></div>
</div><div class="html-table-wrap" id="diagnostics-09-00207-t001">
<div class="html-table_wrap_td">
<div class="html-tablepopup html-tablepopup-link" href='#table_body_display_diagnostics-09-00207-t001'>
<img alt="Table" src="https://www.mdpi.com/img/table.png" />
<a class="html-expand html-tablepopup" href="#table_body_display_diagnostics-09-00207-t001"></a>
</div>
</div>
<div class="html-table_wrap_discription">
<b>Table 1.</b>
Performance of the studies exploring detection of pulmonary nodules.
</div>
</div>
<div class="html-table_show  mfp-hide " id="table_body_display_diagnostics-09-00207-t001">
<div class="html-caption"><b>Table 1.</b>
Performance of the studies exploring detection of pulmonary nodules.</div>
<table>
<thead><tr><th colspan='9' align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Detection</th></tr><tr><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Author</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Year</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Deep Learning Architecture</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Dataset for Training</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Dataset for Testing</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Sensitivity</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Specificity</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>AUC</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Accuracy</th></tr></thead><tbody><tr><td align='center' valign='middle' class='html-align-center'>Suzuki, Kenji * [<a href="#B19-diagnostics-09-00207" class="html-bibr">19</a>]</td><td align='center' valign='middle' class='html-align-center'>2009</td><td align='center' valign='middle' class='html-align-center'>MTANN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset A</td><td align='center' valign='middle' class='html-align-center'>Independent dataset B</td><td align='center' valign='middle' class='html-align-center'>97</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Tajbakhsh, Nima et al. [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>100</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'>MTANN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>100</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Masood, Anum et al. [<a href="#B21-diagnostics-09-00207" class="html-bibr">21</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>FCNN</td><td align='center' valign='middle' class='html-align-center'>LIDC-IDRI, RIDER, LungCT-diagnosis, LUNA16, LISS, SPIE challenge dataset and independent dataset</td><td align='center' valign='middle' class='html-align-center'>RIDER</td><td align='center' valign='middle' class='html-align-center'>74.6</td><td align='center' valign='middle' class='html-align-center'>86.5</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>80.6</td></tr><tr><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'>SPIE challenge dataset</td><td align='center' valign='middle' class='html-align-center'>81.2</td><td align='center' valign='middle' class='html-align-center'>83</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>84.9</td></tr><tr><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'>LungCT-diagnosis</td><td align='center' valign='middle' class='html-align-center'>82.5</td><td align='center' valign='middle' class='html-align-center'>93.6</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>89.5</td></tr><tr><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>83.7</td><td align='center' valign='middle' class='html-align-center'>96.2</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>86.3</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Chen, Sihang et al. [<a href="#B22-diagnostics-09-00207" class="html-bibr">22</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>97</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Liao, Fangzhou et al. [<a href="#B23-diagnostics-09-00207" class="html-bibr">23</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>LUNA16 and DSB17</td><td align='center' valign='middle' class='html-align-center'>DSB17</td><td align='center' valign='middle' class='html-align-center'>85.6</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Liu, Mingzhe et al. [<a href="#B24-diagnostics-09-00207" class="html-bibr">24</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>LUNA16 and DSB17</td><td align='center' valign='middle' class='html-align-center'>DSB17</td><td align='center' valign='middle' class='html-align-center'>85.6</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Li, Li et al. * [<a href="#B17-diagnostics-09-00207" class="html-bibr">17</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>LIDC-IDRI and NLST</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>86.2</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Wang, Yang et al. [<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>RCNN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Setio, A.A.A et al. * [<a href="#B18-diagnostics-09-00207" class="html-bibr">18</a>]</td><td align='center' valign='middle' class='html-align-center'>2016</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>LIDC-IDRI and ANODE09</td><td align='center' valign='middle' class='html-align-center'>DLCST</td><td align='center' valign='middle' class='html-align-center'>76.5</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>94</td></tr><tr><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'>ANODE09</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Wang, Jun et al. [<a href="#B26-diagnostics-09-00207" class="html-bibr">26</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2019</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Tianchi AI challenge dataset and independent dataset</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>75.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>N/A</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>N/A</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>N/A</td></tr></tbody>
</table>
<div class='html-table_foot html-p'><div class='html-p' style='text-indent:0em;'><span class='html-fn-content'>Studies marked with * are studies where test dataset was different from training dataset. AUC: area under the curve. Abbreviations: massive training artificial neural network (MTANN), convolutional neural network (CNN), lung image database consortium and image database resource initiative (LIDC-IDRI), reference image database to evaluate therapy response (RIDER), Society of Photo-Optical Instrumentation Engineers (SPIE), lung nodule analysis 2016 (LUNA16), lung CT imaging signs (LISS), Kaggle data science bowl 2017 (DSB17), Danish lung cancer screening trial (DLCST), automatic nodule detection 2009 (ANODE09).</span></div><div style='clear:both;'></div></div>
</div><div class="html-table-wrap" id="diagnostics-09-00207-t002">
<div class="html-table_wrap_td">
<div class="html-tablepopup html-tablepopup-link" href='#table_body_display_diagnostics-09-00207-t002'>
<img alt="Table" src="https://www.mdpi.com/img/table.png" />
<a class="html-expand html-tablepopup" href="#table_body_display_diagnostics-09-00207-t002"></a>
</div>
</div>
<div class="html-table_wrap_discription">
<b>Table 2.</b>
Performance of studies exploring classification of pulmonary nodules.
</div>
</div>
<div class="html-table_show  mfp-hide " id="table_body_display_diagnostics-09-00207-t002">
<div class="html-caption"><b>Table 2.</b>
Performance of studies exploring classification of pulmonary nodules.</div>
<table>
<thead><tr><th colspan='10' align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Classification</th></tr><tr><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Author</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Year</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Deep Learning Architecture</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Dataset for Training</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Dataset for Testing</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Categories for Testing</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Sensitivity</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Specificity</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>AUC</th><th align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Accuracy</th></tr></thead><tbody><tr><td align='center' valign='middle' class='html-align-center'>Alakwaa, Wafaa et al. [<a href="#B27-diagnostics-09-00207" class="html-bibr">27</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>LUNA16 and DSB17</td><td align='center' valign='middle' class='html-align-center'>DSB17</td><td align='center' valign='middle' class='html-align-center'>Cancer vs. no cancer</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>86.6</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Chen, Sihang et al. [<a href="#B22-diagnostics-09-00207" class="html-bibr">22</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Adenocarcinoma vs. benign</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>87.5</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Ciompi, Francesco et al. [<a href="#B28-diagnostics-09-00207" class="html-bibr">28</a>]</td><td align='center' valign='middle' class='html-align-center'>2015</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>ImageNet and NELSON</td><td align='center' valign='middle' class='html-align-center'>NELSON</td><td align='center' valign='middle' class='html-align-center'>Peri-fissural nodules (PFN) vs. non-PFN</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>84.7</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Ciompi, Francesco et al. *[<a href="#B29-diagnostics-09-00207" class="html-bibr">29</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>MILD</td><td align='center' valign='middle' class='html-align-center'>DLCST</td><td align='center' valign='middle' class='html-align-center'>Multiple categories (overall)</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>79.5</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Jakimovski, Goran et al. [<a href="#B30-diagnostics-09-00207" class="html-bibr">30</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>CDNN</td><td align='center' valign='middle' class='html-align-center'>LONI database</td><td align='center' valign='middle' class='html-align-center'>LONI database</td><td align='center' valign='middle' class='html-align-center'>Cancer vs. no cancer</td><td align='center' valign='middle' class='html-align-center'>99.9</td><td align='center' valign='middle' class='html-align-center'>98.7</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>99.6</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Lakshmanaprabu, S.K. et al. [<a href="#B31-diagnostics-09-00207" class="html-bibr">31</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>ODNN</td><td align='center' valign='middle' class='html-align-center'>ELCAP</td><td align='center' valign='middle' class='html-align-center'>ELCAP</td><td align='center' valign='middle' class='html-align-center'>Abnormal vs. normal</td><td align='center' valign='middle' class='html-align-center'>96.2</td><td align='center' valign='middle' class='html-align-center'>94.2</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>94.5</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Li, Li et al. * [<a href="#B17-diagnostics-09-00207" class="html-bibr">17</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>LIDC-IDRI and NLST</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Multiple categories (overall)</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Liao, Fangzhou et al. [<a href="#B23-diagnostics-09-00207" class="html-bibr">23</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>LUNA16 and DSB17</td><td align='center' valign='middle' class='html-align-center'>DSB17</td><td align='center' valign='middle' class='html-align-center'>Cancer vs. no-cancer (scale)</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>87</td><td align='center' valign='middle' class='html-align-center'>81.4</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Liu, Shuang et al. [<a href="#B32-diagnostics-09-00207" class="html-bibr">32</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>NLST and ELCAP</td><td align='center' valign='middle' class='html-align-center'>NLST and ELCAP</td><td align='center' valign='middle' class='html-align-center'>Malign vs. benign</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>78</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Liu, Xinglong et al. * [<a href="#B33-diagnostics-09-00207" class="html-bibr">33</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>LIDC-IDRI</td><td align='center' valign='middle' class='html-align-center'>ELCAP</td><td align='center' valign='middle' class='html-align-center'>Multiple categories (overall)</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>90.3</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Masood, Anum et al. [<a href="#B21-diagnostics-09-00207" class="html-bibr">21</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>FCNN</td><td align='center' valign='middle' class='html-align-center'>LIDC-IDRI, RIDER, LungCT-Diagnosis, LUNA16, LISS, SPIE challenge dataset and Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Four stage categories (overall)</td><td align='center' valign='middle' class='html-align-center'>83.7</td><td align='center' valign='middle' class='html-align-center'>96.2</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>96.3</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Nishio, Mizuho et al. [<a href="#B34-diagnostics-09-00207" class="html-bibr">34</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Benign, primary and metastic cancer (overall)</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>68</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Onishi, Yuya et al. [<a href="#B35-diagnostics-09-00207" class="html-bibr">35</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>DCNN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Malign vs. benign</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>84.1</td><td align='center' valign='middle' class='html-align-center'>81.7</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Polat, Huseyin et al. [<a href="#B36-diagnostics-09-00207" class="html-bibr">36</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>DSB17</td><td align='center' valign='middle' class='html-align-center'>DSB17</td><td align='center' valign='middle' class='html-align-center'>Cancer vs. no cancer</td><td align='center' valign='middle' class='html-align-center'>88.5</td><td align='center' valign='middle' class='html-align-center'>94.2</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>91.8</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Qiang, Yan et al. [<a href="#B37-diagnostics-09-00207" class="html-bibr">37</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>Deep SDAE-ELM</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Malign vs. benign</td><td align='center' valign='middle' class='html-align-center'>84.4</td><td align='center' valign='middle' class='html-align-center'>81.3</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>82.8</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Rangaswamy et al. [<a href="#B38-diagnostics-09-00207" class="html-bibr">38</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>ILD</td><td align='center' valign='middle' class='html-align-center'>ILD</td><td align='center' valign='middle' class='html-align-center'>Malign vs. benign</td><td align='center' valign='middle' class='html-align-center'>98</td><td align='center' valign='middle' class='html-align-center'>94</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>96</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Sori, Worku Jifara et al. [<a href="#B39-diagnostics-09-00207" class="html-bibr">39</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>LUNA16 and DSB17</td><td align='center' valign='middle' class='html-align-center'>DSB17</td><td align='center' valign='middle' class='html-align-center'>Cancer vs. no cancer</td><td align='center' valign='middle' class='html-align-center'>87.4</td><td align='center' valign='middle' class='html-align-center'>89.1</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>87.8</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Suzuki, Kenji * [<a href="#B19-diagnostics-09-00207" class="html-bibr">19</a>]</td><td align='center' valign='middle' class='html-align-center'>2009</td><td align='center' valign='middle' class='html-align-center'>MTANN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset A</td><td align='center' valign='middle' class='html-align-center'>Independent dataset B</td><td align='center' valign='middle' class='html-align-center'>Malign vs. benign</td><td align='center' valign='middle' class='html-align-center'>96</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Tajbakhsh, Nima et al. [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Malign vs. benign</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>77.6</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'>MTANN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Malign vs. benign</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>88.1</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Wang, Shengping et al. [<a href="#B40-diagnostics-09-00207" class="html-bibr">40</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>PIL vs. IAC</td><td align='center' valign='middle' class='html-align-center'>88.5</td><td align='center' valign='middle' class='html-align-center'>80.1</td><td align='center' valign='middle' class='html-align-center'>89.2</td><td align='center' valign='middle' class='html-align-center'>84</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Wang, Yang et al. [<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>RCNN</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Independent dataset</td><td align='center' valign='middle' class='html-align-center'>Malign vs. benign</td><td align='center' valign='middle' class='html-align-center'>76.5</td><td align='center' valign='middle' class='html-align-center'>89.1</td><td align='center' valign='middle' class='html-align-center'>90.6</td><td align='center' valign='middle' class='html-align-center'>87.3</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Yuan, Jingjing et al. * [<a href="#B41-diagnostics-09-00207" class="html-bibr">41</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>CNN</td><td align='center' valign='middle' class='html-align-center'>LIDC-IDRI</td><td align='center' valign='middle' class='html-align-center'>ELCAP</td><td align='center' valign='middle' class='html-align-center'>Multiple categories (overall)</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>N/A</td><td align='center' valign='middle' class='html-align-center'>93.9</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Zhang, Chao et al. * [<a href="#B42-diagnostics-09-00207" class="html-bibr">42</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2019</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>LUNA16, DSB17 and Independent dataset(A)</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Independent dataset(B)</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Malign vs. benign</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>96</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>88</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>N/A</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>92</td></tr></tbody>
</table>
<div class='html-table_foot html-p'><div class='html-p' style='text-indent:0em;'><span class='html-fn-content'>Studies marked with * are studies where test dataset was different from training dataset. Abbreviations: massive training artificial neural network (MTANN), convolutional neural network (CNN), deep neural network (DNN), lung image database consortium and image database resource initiative (LIDC-IDRI), the Dutch–Belgian randomized lung cancer screening trial (Dutch acronym; NELSON), multicentric Italian lung detection (MILD), laboratory of neuro imaging (LONI), early lung cancer action program (ELCAP), reference image database to evaluate therapy response (RIDER), Society of Photo-Optical Instrumentation Engineers (SPIE), lung nodule analysis 2016 (LUNA16), lung CT imaging signs (LISS), Kaggle data science bowl 2017 (DSB17), interstitial lung disease (ILD), Danish lung cancer screening trial (DLCST), automatic nodule detection 2009 (ANODE09), pre-invasive lesions (PIL), invasive adenocarcinomas (IAC).</span></div><div style='clear:both;'></div></div>
</div><div class='html-table-group' id='diagnostics-09-00207-t003'><div class='html-caption'>
<b>Table 3.</b>
Studies that provided classification performance results in (<b>a</b>) sensitivity and specificity, (<b>b</b>) AUC, and (<b>c</b>) accuracy.</div><div class="html-table-wrap" id="diagnostics-09-00207-t003a">
<div class="html-table_wrap_td">
<div class="html-tablepopup html-tablepopup-link" href='#table_body_display_diagnostics-09-00207-t003a'>
<img alt="Table" src="https://www.mdpi.com/img/table.png" />
<a class="html-expand html-tablepopup" href="#table_body_display_diagnostics-09-00207-t003a"></a>
</div>
</div>
<div class="html-table_wrap_discription">
<b></b>
(<b>a</b>)
</div>
</div>
<div class="html-table_show  mfp-hide " id="table_body_display_diagnostics-09-00207-t003a">
<div class="html-caption"><b></b>
(<b>a</b>)</div>
<table>
<thead><tr><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Author</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Year</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Sensitivity</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Specificity</th></tr></thead><tbody><tr><td align='center' valign='middle' class='html-align-center'>Jakimovski, Goran et al. [<a href="#B30-diagnostics-09-00207" class="html-bibr">30</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>99.9</td><td align='center' valign='middle' class='html-align-center'>98.7</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Lakshmanaprabu, S.K. et al. [<a href="#B31-diagnostics-09-00207" class="html-bibr">31</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>96.2</td><td align='center' valign='middle' class='html-align-center'>94.2</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Masood, Anum et al. [<a href="#B21-diagnostics-09-00207" class="html-bibr">21</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>83.7</td><td align='center' valign='middle' class='html-align-center'>96.2</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Polat, Huseyin et al. [<a href="#B36-diagnostics-09-00207" class="html-bibr">36</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>88.5</td><td align='center' valign='middle' class='html-align-center'>94.2</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Qiang, Yan et al. [<a href="#B37-diagnostics-09-00207" class="html-bibr">37</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>84.4</td><td align='center' valign='middle' class='html-align-center'>81.3</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Rangaswamy et al. [<a href="#B38-diagnostics-09-00207" class="html-bibr">38</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>98</td><td align='center' valign='middle' class='html-align-center'>94</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Sori, Worku Jifara et al. [<a href="#B39-diagnostics-09-00207" class="html-bibr">39</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>87.4</td><td align='center' valign='middle' class='html-align-center'>89.1</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Suzuki, Kenji et al. [<a href="#B19-diagnostics-09-00207" class="html-bibr">19</a>]</td><td align='center' valign='middle' class='html-align-center'>2009</td><td align='center' valign='middle' class='html-align-center'>96 *</td><td align='center' valign='middle' class='html-align-center'>N/A</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Wang, Shengping et al. [<a href="#B40-diagnostics-09-00207" class="html-bibr">40</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>88.5</td><td align='center' valign='middle' class='html-align-center'>80.1</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Wang, Yang et al. [<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>76.5</td><td align='center' valign='middle' class='html-align-center'>89.1</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Zhang, Chao et al. [<a href="#B42-diagnostics-09-00207" class="html-bibr">42</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2019</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>96 *</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>88 *</td></tr></tbody>
</table>
</div><div class="html-table-wrap" id="diagnostics-09-00207-t003b">
<div class="html-table_wrap_td">
<div class="html-tablepopup html-tablepopup-link" href='#table_body_display_diagnostics-09-00207-t003b'>
<img alt="Table" src="https://www.mdpi.com/img/table.png" />
<a class="html-expand html-tablepopup" href="#table_body_display_diagnostics-09-00207-t003b"></a>
</div>
</div>
<div class="html-table_wrap_discription">
<b></b>
(<b>b</b>)
</div>
</div>
<div class="html-table_show  mfp-hide " id="table_body_display_diagnostics-09-00207-t003b">
<div class="html-caption"><b></b>
(<b>b</b>)</div>
<table>
<thead><tr><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Author</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Year</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>AUC</th></tr></thead><tbody><tr><td align='center' valign='middle' class='html-align-center'>Ciompi, Francesco et al. [<a href="#B28-diagnostics-09-00207" class="html-bibr">28</a>]</td><td align='center' valign='middle' class='html-align-center'>2015</td><td align='center' valign='middle' class='html-align-center'>84.7</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Liao, Fangzhou et al. [<a href="#B23-diagnostics-09-00207" class="html-bibr">23</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>87</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Liu, Shuang et al. [<a href="#B32-diagnostics-09-00207" class="html-bibr">32</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>78</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Onishi, Yuya et al. [<a href="#B35-diagnostics-09-00207" class="html-bibr">35</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>84.1</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Tajbakhsh, Nima et al.(CNN) [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>77.6</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Tajbakhsh, Nima et al.(MTANN) [<a href="#B20-diagnostics-09-00207" class="html-bibr">20</a>]</td><td align='center' valign='middle' class='html-align-center'> </td><td align='center' valign='middle' class='html-align-center'>88.1</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Wang, Shengping et al. [<a href="#B40-diagnostics-09-00207" class="html-bibr">40</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>89.2</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Wang, Yang et al. [<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2019</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>90.6</td></tr></tbody>
</table>
</div><div class="html-table-wrap" id="diagnostics-09-00207-t003c">
<div class="html-table_wrap_td">
<div class="html-tablepopup html-tablepopup-link" href='#table_body_display_diagnostics-09-00207-t003c'>
<img alt="Table" src="https://www.mdpi.com/img/table.png" />
<a class="html-expand html-tablepopup" href="#table_body_display_diagnostics-09-00207-t003c"></a>
</div>
</div>
<div class="html-table_wrap_discription">
<b></b>
(<b>c</b>)
</div>
</div>
<div class="html-table_show  mfp-hide " id="table_body_display_diagnostics-09-00207-t003c">
<div class="html-caption"><b></b>
(<b>c</b>)</div>
<table>
<thead><tr><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Author</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Year</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Accuracy</th></tr></thead><tbody><tr><td align='center' valign='middle' class='html-align-center'>Alakwaa, Wafaa et al. [<a href="#B27-diagnostics-09-00207" class="html-bibr">27</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>86.6</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Chen, Sihang et al. [<a href="#B22-diagnostics-09-00207" class="html-bibr">22</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>87.5</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Ciompi, Francesco et al. [<a href="#B29-diagnostics-09-00207" class="html-bibr">29</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>79.5 *</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Jakimovski, Goran et al. [<a href="#B30-diagnostics-09-00207" class="html-bibr">30</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>99.6</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Lakshmanaprabu, S.K. et al. [<a href="#B31-diagnostics-09-00207" class="html-bibr">31</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>94.5</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Liao, Fangzhou et al. [<a href="#B23-diagnostics-09-00207" class="html-bibr">23</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>81.4</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Liu, Xinglong et al. [<a href="#B33-diagnostics-09-00207" class="html-bibr">33</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>90.3 *</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Masood, Anum et al. [<a href="#B21-diagnostics-09-00207" class="html-bibr">21</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>96.3</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Nishio, Mizuho et al. [<a href="#B34-diagnostics-09-00207" class="html-bibr">34</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>68</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Onishi, Yuya et al. [<a href="#B35-diagnostics-09-00207" class="html-bibr">35</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>81.7</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Polat, Huseyin et al. [<a href="#B36-diagnostics-09-00207" class="html-bibr">36</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>91.8</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Qiang, Yan et al. [<a href="#B37-diagnostics-09-00207" class="html-bibr">37</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>82.8</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Rangaswamy et al. [<a href="#B38-diagnostics-09-00207" class="html-bibr">38</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>96</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Sori, Worku Jifara et al. [<a href="#B39-diagnostics-09-00207" class="html-bibr">39</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>87.8</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Wang, Shengping et al. [<a href="#B40-diagnostics-09-00207" class="html-bibr">40</a>]</td><td align='center' valign='middle' class='html-align-center'>2018</td><td align='center' valign='middle' class='html-align-center'>84</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Wang, Yang et al. [<a href="#B25-diagnostics-09-00207" class="html-bibr">25</a>]</td><td align='center' valign='middle' class='html-align-center'>2019</td><td align='center' valign='middle' class='html-align-center'>87.3</td></tr><tr><td align='center' valign='middle' class='html-align-center'>Yuan, Jingjing et al. [<a href="#B41-diagnostics-09-00207" class="html-bibr">41</a>]</td><td align='center' valign='middle' class='html-align-center'>2017</td><td align='center' valign='middle' class='html-align-center'>93.9 *</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Zhang, Chao et al. [<a href="#B42-diagnostics-09-00207" class="html-bibr">42</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2019</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>92 *</td></tr></tbody>
</table>
<div class='html-table_foot html-p'><div class='html-p' style='text-indent:0em;'><span class='html-fn-content'>Results marked with * are from studies where test dataset was different from training dataset.</span></div><div style='clear:both;'></div></div>
</div></div></section>
<section id="html-copyright"><br>© 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<a href="https://creativecommons.org/licenses/by/4.0/" target='_blank' rel="noopener noreferrer">http://creativecommons.org/licenses/by/4.0/</a>).</section>
</div>
</div>
</article>
</div>
</div>
</div>
</div>
</div>
</section>
<div id="footer">
<div class="journal-info">
<span>
<em><a class="Var_JournalInfo" href="/journal/diagnostics">Diagnostics</a></em>,
EISSN 2075-4418,
Published by MDPI
</span>
<span>
<a data-dropdown="drop-view-disclaimer-journal" aria-controls="drop-view-disclaimer-journal" aria-expanded="false" data-options="align:top; is_hover:true; hover_timeout:2000;">
Disclaimer
</a>
<div id="drop-view-disclaimer-journal" class="f-dropdown label__btn__dropdown label__btn__dropdown--wide text-left" data-dropdown-content aria-hidden="true" tabindex="-1">
The statements, opinions and data contained in the journal <em>Diagnostics</em> are solely
those of the individual authors and contributors and not of the publisher and the editor(s).
MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.
</div>
</span>
<div class="large-right">
<span>
<a href="/rss/journal/diagnostics" class="rss-link">RSS</a>
</span>
<span>
<a href="/journal/diagnostics/toc-alert">Content Alert</a>
</span>
</div>
</div>
<div class="row full-width footer-links" data-equalizer="footer" data-equalizer-mq="small">
<div class="large-2 large-push-4 medium-3 small-6 columns" data-equalizer-watch="footer">
<h3>
Further Information
</h3>
<a href="/apc">
Article Processing Charges
</a>
<a href="/about/payment">
Pay an Invoice
</a>
<a href="/openaccess">
Open Access Policy
</a>
<a href="/about/contact">
Contact MDPI
</a>
<a href="https://careers.mdpi.com" target="_blank" rel="noopener noreferrer">
Jobs at MDPI
</a>
</div>
<div class="large-2 large-push-4 medium-3 small-6 columns" data-equalizer-watch="footer">
<h3>
Guidelines
</h3>
<a href="/authors">
For Authors
</a>
<a href="/reviewers">
For Reviewers
</a>
<a href="/editors">
For Editors
</a>
<a href="/librarians">
For Librarians
</a>
<a href="/publishing_services">
For Publishers
</a>
<a href="/societies">
For Societies
</a>
<a href="/conference_organizers">
For Conference Organizers
</a>
</div>
<div class="large-2 large-push-4 medium-3 small-6 columns">
<h3>
MDPI Initiatives
</h3>
<a href="https://sciforum.net" target="_blank" rel="noopener noreferrer">
Sciforum
</a>
<a href="https://www.mdpi.com/books" target="_blank" rel="noopener noreferrer">
MDPI Books
</a>
<a href="https://www.preprints.org" target="_blank" rel="noopener noreferrer">
Preprints
</a>
<a href="https://www.scilit.net" target="_blank" rel="noopener noreferrer">
Scilit
</a>
<a href="https://sciprofiles.com" target="_blank" rel="noopener noreferrer">
SciProfiles
</a>
<a href="https://encyclopedia.pub" target="_blank" rel="noopener noreferrer">
Encyclopedia
</a>
<a href="https://jams.pub" target="_blank" rel="noopener noreferrer">
JAMS
</a>
<a href="/about/proceedings">
Proceedings Series
</a>
</div>
<div class="large-2 large-push-4 medium-3 small-6 right-border-large-without columns UA_FooterFollowMDPI">
<h3>
Follow MDPI
</h3>
<a href="https://www.linkedin.com/company/mdpi" target="_blank" rel="noopener noreferrer">
LinkedIn
</a>
<a href="https://www.facebook.com/MDPIOpenAccessPublishing" target="_blank" rel="noopener noreferrer">
Facebook
</a>
<a href="https://twitter.com/MDPIOpenAccess" target="_blank" rel="noopener noreferrer">
Twitter
</a>
</div>
<div id="footer-subscribe" class="large-4 large-pull-8 medium-12 small-12 left-border-large columns">
<div class="footer-subscribe__container">
<img class="show-for-large-up" src="/img/design/mdpi-pub-logo-white-small.png?71d18e5f805839ab" alt="MDPI" title="MDPI Open Access Journals" style="height: 50px; margin-bottom: 10px;">
<form id="newsletter" method="POST" action="/subscribe">
<p>
Subscribe to receive issue release notifications and newsletters from MDPI journals
</p>
<select multiple id="newsletter-journal" class="foundation-select" name="journals[]">
<option value="acoustics">Acoustics</option>
<option value="actuators">Actuators</option>
<option value="admsci">Administrative Sciences</option>
<option value="adolescents">Adolescents</option>
<option value="aerospace">Aerospace</option>
<option value="agriculture">Agriculture</option>
<option value="agriengineering">AgriEngineering</option>
<option value="agronomy">Agronomy</option>
 <option value="ai">AI</option>
<option value="algorithms">Algorithms</option>
<option value="allergies">Allergies</option>
<option value="alloys">Alloys</option>
<option value="analytica">Analytica</option>
<option value="anatomia">Anatomia</option>
<option value="animals">Animals</option>
<option value="antibiotics">Antibiotics</option>
<option value="antibodies">Antibodies</option>
<option value="antioxidants">Antioxidants</option>
<option value="applbiosci">Applied Biosciences</option>
<option value="applmech">Applied Mechanics</option>
<option value="applmicrobiol">Applied Microbiology</option>
<option value="applnano">Applied Nano</option>
<option value="applsci">Applied Sciences</option>
<option value="asi">Applied System Innovation</option>
<option value="appliedchem">AppliedChem</option>
<option value="appliedmath">AppliedMath</option>
<option value="aquacj">Aquaculture Journal</option>
<option value="architecture">Architecture</option>
<option value="arts">Arts</option>
<option value="astronomy">Astronomy</option>
<option value="atmosphere">Atmosphere</option>
<option value="atoms">Atoms</option>
<option value="audiolres">Audiology Research</option>
<option value="automation">Automation</option>
<option value="axioms">Axioms</option>
<option value="bacteria">Bacteria</option>
<option value="batteries">Batteries</option>
<option value="behavsci">Behavioral Sciences</option>
<option value="beverages">Beverages</option>
<option value="BDCC">Big Data and Cognitive Computing</option>
<option value="biochem">BioChem</option>
<option value="bioengineering">Bioengineering</option>
<option value="biologics">Biologics</option>
<option value="biology">Biology</option>
<option value="blsf">Biology and Life Sciences Forum</option>
<option value="biomass">Biomass</option>
<option value="biomechanics">Biomechanics</option>
<option value="biomed">BioMed</option>
<option value="biomedicines">Biomedicines</option>
<option value="biomedinformatics">BioMedInformatics</option>
<option value="biomimetics">Biomimetics</option>
<option value="biomolecules">Biomolecules</option>
<option value="biophysica">Biophysica</option>
<option value="biosensors">Biosensors</option>
<option value="biotech">BioTech</option>
<option value="birds">Birds</option>
<option value="brainsci">Brain Sciences</option>
<option value="buildings">Buildings</option>
<option value="businesses">Businesses</option>
<option value="carbon">C</option>
<option value="cancers">Cancers</option>
<option value="cardiogenetics">Cardiogenetics</option>
<option value="catalysts">Catalysts</option>
<option value="cells">Cells</option>
<option value="ceramics">Ceramics</option>
<option value="challenges">Challenges</option>
<option value="ChemEngineering">ChemEngineering</option>
 <option value="chemistry">Chemistry</option>
<option value="chemproc">Chemistry Proceedings</option>
<option value="chemosensors">Chemosensors</option>
<option value="children">Children</option>
<option value="chips">Chips</option>
<option value="civileng">CivilEng</option>
<option value="cleantechnol">Clean Technologies</option>
<option value="climate">Climate</option>
<option value="ctn">Clinical and Translational Neuroscience</option>
<option value="clinpract">Clinics and Practice</option>
<option value="clockssleep">Clocks &amp; Sleep</option>
<option value="coasts">Coasts</option>
<option value="coatings">Coatings</option>
<option value="colloids">Colloids and Interfaces</option>
<option value="colorants">Colorants</option>
<option value="compounds">Compounds</option>
<option value="computation">Computation</option>
<option value="csmf">Computer Sciences &amp; Mathematics Forum</option>
<option value="computers">Computers</option>
<option value="condensedmatter">Condensed Matter</option>
<option value="conservation">Conservation</option>
<option value="constrmater">Construction Materials</option>
<option value="cmd">Corrosion and Materials Degradation</option>
<option value="cosmetics">Cosmetics</option>
<option value="covid">COVID</option>
<option value="crops">Crops</option>
<option value="cryptography">Cryptography</option>
<option value="crystals">Crystals</option>
<option value="cimb">Current Issues in Molecular Biology</option>
<option value="curroncol">Current Oncology</option>
<option value="dairy">Dairy</option>
<option value="data">Data</option>
<option value="dentistry">Dentistry Journal</option>
<option value="dermato">Dermato</option>
<option value="dermatopathology">Dermatopathology</option>
<option value="designs">Designs</option>
<option value="diabetology">Diabetology</option>
<option value="diagnostics">Diagnostics</option>
<option value="dietetics">Dietetics</option>
<option value="digital">Digital</option>
<option value="disabilities">Disabilities</option>
<option value="diseases">Diseases</option>
<option value="diversity">Diversity</option>
<option value="dna">DNA</option>
<option value="drones">Drones</option>
<option value="dynamics">Dynamics</option>
<option value="earth">Earth</option>
<option value="ecologies">Ecologies</option>
<option value="econometrics">Econometrics</option>
<option value="economies">Economies</option>
<option value="education">Education Sciences</option>
<option value="electricity">Electricity</option>
<option value="electrochem">Electrochem</option>
<option value="electronicmat">Electronic Materials</option>
<option value="electronics">Electronics</option>
<option value="encyclopedia">Encyclopedia</option>
<option value="endocrines">Endocrines</option>
<option value="energies">Energies</option>
 <option value="eng">Eng</option>
<option value="engproc">Engineering Proceedings</option>
<option value="entomology">Entomology</option>
<option value="entropy">Entropy</option>
<option value="environsciproc">Environmental Sciences Proceedings</option>
<option value="environments">Environments</option>
<option value="epidemiologia">Epidemiologia</option>
<option value="epigenomes">Epigenomes</option>
<option value="ebj">European Burn Journal</option>
<option value="ejihpe">European Journal of Investigation in Health, Psychology and Education</option>
<option value="fermentation">Fermentation</option>
<option value="fibers">Fibers</option>
<option value="fintech">FinTech</option>
<option value="fire">Fire</option>
<option value="fishes">Fishes</option>
<option value="fluids">Fluids</option>
<option value="foods">Foods</option>
<option value="forecasting">Forecasting</option>
<option value="forensicsci">Forensic Sciences</option>
<option value="forests">Forests</option>
<option value="foundations">Foundations</option>
<option value="fractalfract">Fractal and Fractional</option>
<option value="fuels">Fuels</option>
<option value="futureinternet">Future Internet</option>
<option value="futurepharmacol">Future Pharmacology</option>
<option value="futuretransp">Future Transportation</option>
<option value="galaxies">Galaxies</option>
<option value="games">Games</option>
<option value="gases">Gases</option>
<option value="gastroent">Gastroenterology Insights</option>
<option value="gastrointestdisord">Gastrointestinal Disorders</option>
<option value="gels">Gels</option>
<option value="genealogy">Genealogy</option>
<option value="genes">Genes</option>
<option value="geographies">Geographies</option>
<option value="geohazards">GeoHazards</option>
<option value="geomatics">Geomatics</option>
<option value="geosciences">Geosciences</option>
<option value="geotechnics">Geotechnics</option>
<option value="geriatrics">Geriatrics</option>
<option value="healthcare">Healthcare</option>
<option value="hearts">Hearts</option>
<option value="hemato">Hemato</option>
<option value="hematolrep">Hematology Reports</option>
<option value="heritage">Heritage</option>
<option value="histories">Histories</option>
<option value="horticulturae">Horticulturae</option>
<option value="humanities">Humanities</option>
<option value="humans">Humans</option>
<option value="hydrobiology">Hydrobiology</option>
<option value="hydrogen">Hydrogen</option>
<option value="hydrology">Hydrology</option>
<option value="hygiene">Hygiene</option>
<option value="immuno">Immuno</option>
<option value="idr">Infectious Disease Reports</option>
<option value="informatics">Informatics</option>
<option value="information">Information</option>
<option value="infrastructures">Infrastructures</option>
<option value="inorganics">Inorganics</option>
<option value="insects">Insects</option>
<option value="instruments">Instruments</option>
<option value="ijerph">International Journal of Environmental Research and Public Health</option>
<option value="ijfs">International Journal of Financial Studies</option>
<option value="ijms">International Journal of Molecular Sciences</option>
<option value="IJNS">International Journal of Neonatal Screening</option>
<option value="ijpb">International Journal of Plant Biology</option>
<option value="ijtm">International Journal of Translational Medicine</option>
<option value="ijtpp">International Journal of Turbomachinery, Propulsion and Power</option>
<option value="inventions">Inventions</option>
<option value="IoT">IoT</option>
<option value="ijgi">ISPRS International Journal of Geo-Information</option>
<option value="J">J</option>
<option value="jal">Journal of Ageing and Longevity</option>
<option value="jcdd">Journal of Cardiovascular Development and Disease</option>
<option value="jcm">Journal of Clinical Medicine</option>
<option value="jcs">Journal of Composites Science</option>
<option value="jcp">Journal of Cybersecurity and Privacy</option>
<option value="jdb">Journal of Developmental Biology</option>
<option value="jfb">Journal of Functional Biomaterials</option>
<option value="jfmk">Journal of Functional Morphology and Kinesiology</option>
<option value="jof">Journal of Fungi</option>
<option value="jimaging">Journal of Imaging</option>
<option value="jintelligence">Journal of Intelligence</option>
<option value="jlpea">Journal of Low Power Electronics and Applications</option>
<option value="jmmp">Journal of Manufacturing and Materials Processing</option>
<option value="jmse">Journal of Marine Science and Engineering</option>
<option value="jmp">Journal of Molecular Pathology</option>
<option value="jnt">Journal of Nanotheranostics</option>
<option value="jne">Journal of Nuclear Engineering</option>
<option value="JOItmC">Journal of Open Innovation: Technology, Market, and Complexity</option>
<option value="ohbm">Journal of Otorhinolaryngology, Hearing and Balance Medicine</option>
<option value="jpm">Journal of Personalized Medicine</option>
<option value="jor">Journal of Respiration</option>
<option value="jrfm">Journal of Risk and Financial Management</option>
<option value="jsan">Journal of Sensor and Actuator Networks</option>
<option value="jtaer">Journal of Theoretical and Applied Electronic Commerce Research</option>
<option value="jox">Journal of Xenobiotics</option>
<option value="jzbg">Journal of Zoological and Botanical Gardens</option>
<option value="journalmedia">Journalism and Media</option>
<option value="kidneydial">Kidney and Dialysis</option>
<option value="knowledge">Knowledge</option>
<option value="land">Land</option>
<option value="languages">Languages</option>
<option value="laws">Laws</option>
<option value="life">Life</option>
<option value="liquids">Liquids</option>
<option value="literature">Literature</option>
<option value="livers">Livers</option>
<option value="logics">Logics</option>
<option value="logistics">Logistics</option>
<option value="lubricants">Lubricants</option>
<option value="make">Machine Learning and Knowledge Extraction</option>
<option value="machines">Machines</option>
<option value="macromol">Macromol</option>
<option value="magnetism">Magnetism</option>
<option value="magnetochemistry">Magnetochemistry</option>
<option value="marinedrugs">Marine Drugs</option>
<option value="materials">Materials</option>
<option value="materproc">Materials Proceedings</option>
<option value="mca">Mathematical and Computational Applications</option>
<option value="mathematics">Mathematics</option>
<option value="medsci">Medical Sciences</option>
<option value="msf">Medical Sciences Forum</option>
<option value="medicina">Medicina</option>
<option value="medicines">Medicines</option>
<option value="membranes">Membranes</option>
<option value="merits">Merits</option>
<option value="metabolites">Metabolites</option>
<option value="metals">Metals</option>
<option value="meteorology">Meteorology</option>
<option value="methane">Methane</option>
<option value="mps">Methods and Protocols</option>
<option value="metrology">Metrology</option>
<option value="micro">Micro</option>
<option value="microbiolres">Microbiology Research</option>
<option value="micromachines">Micromachines</option>
<option value="microorganisms">Microorganisms</option>
<option value="microplastics">Microplastics</option>
<option value="minerals">Minerals</option>
<option value="mining">Mining</option>
<option value="modelling">Modelling</option>
<option value="molbank">Molbank</option>
<option value="molecules">Molecules</option>
<option value="mti">Multimodal Technologies and Interaction</option>
<option value="muscles">Muscles</option>
<option value="nanoenergyadv">Nanoenergy Advances</option>
<option value="nanomanufacturing">Nanomanufacturing</option>
<option value="nanomaterials">Nanomaterials</option>
<option value="network">Network</option>
<option value="neuroglia">Neuroglia</option>
<option value="neurolint">Neurology International</option>
<option value="neurosci">NeuroSci</option>
<option value="nitrogen">Nitrogen</option>
<option value="ncrna">Non-Coding RNA</option>
<option value="nursrep">Nursing Reports</option>
<option value="nutraceuticals">Nutraceuticals</option>
<option value="nutrients">Nutrients</option>
<option value="obesities">Obesities</option>
<option value="oceans">Oceans</option>
<option value="onco">Onco</option>
<option value="optics">Optics</option>
<option value="oral">Oral</option>
<option value="organics">Organics</option>
<option value="organoids">Organoids</option>
<option value="osteology">Osteology</option>
<option value="oxygen">Oxygen</option>
<option value="parasitologia">Parasitologia</option>
<option value="particles">Particles</option>
<option value="pathogens">Pathogens</option>
<option value="pathophysiology">Pathophysiology</option>
<option value="pediatrrep">Pediatric Reports</option>
<option value="pharmaceuticals">Pharmaceuticals</option>
<option value="pharmaceutics">Pharmaceutics</option>
<option value="pharmacoepidemiology">Pharmacoepidemiology</option>
<option value="pharmacy">Pharmacy</option>
<option value="philosophies">Philosophies</option>
<option value="photochem">Photochem</option>
<option value="photonics">Photonics</option>
<option value="phycology">Phycology</option>
<option value="physchem">Physchem</option>
<option value="psf">Physical Sciences Forum</option>
<option value="physics">Physics</option>
<option value="physiologia">Physiologia</option>
<option value="plants">Plants</option>
<option value="plasma">Plasma</option>
<option value="pollutants">Pollutants</option>
<option value="polymers">Polymers</option>
<option value="polysaccharides">Polysaccharides</option>
<option value="poultry">Poultry</option>
<option value="powders">Powders</option>
<option value="proceedings">Proceedings</option>
<option value="processes">Processes</option>
<option value="prosthesis">Prosthesis</option>
<option value="proteomes">Proteomes</option>
<option value="psych">Psych</option>
<option value="psychiatryint">Psychiatry International</option>
<option value="publications">Publications</option>
 <option value="qubs">Quantum Beam Science</option>
<option value="quantumrep">Quantum Reports</option>
<option value="quaternary">Quaternary</option>
<option value="radiation">Radiation</option>
<option value="reactions">Reactions</option>
<option value="recycling">Recycling</option>
<option value="religions">Religions</option>
<option value="remotesensing">Remote Sensing</option>
<option value="reports">Reports</option>
<option value="reprodmed">Reproductive Medicine</option>
<option value="resources">Resources</option>
<option value="rheumato">Rheumato</option>
<option value="risks">Risks</option>
<option value="robotics">Robotics</option>
<option value="ruminants">Ruminants</option>
<option value="safety">Safety</option>
<option value="sci">Sci</option>
<option value="scipharm">Scientia Pharmaceutica</option>
<option value="seeds">Seeds</option>
<option value="sensors">Sensors</option>
<option value="separations">Separations</option>
<option value="sexes">Sexes</option>
<option value="signals">Signals</option>
<option value="sinusitis">Sinusitis</option>
<option value="smartcities">Smart Cities</option>
<option value="socsci">Social Sciences</option>
<option value="societies">Societies</option>
<option value="software">Software</option>
<option value="soilsystems">Soil Systems</option>
<option value="solar">Solar</option>
<option value="solids">Solids</option>
<option value="sports">Sports</option>
<option value="standards">Standards</option>
<option value="stats">Stats</option>
<option value="stresses">Stresses</option>
<option value="surfaces">Surfaces</option>
<option value="surgeries">Surgeries</option>
<option value="std">Surgical Techniques Development</option>
<option value="sustainability">Sustainability</option>
<option value="suschem">Sustainable Chemistry</option>
<option value="symmetry">Symmetry</option>
<option value="synbio">SynBio</option>
<option value="systems">Systems</option>
<option value="taxonomy">Taxonomy</option>
<option value="technologies">Technologies</option>
<option value="telecom">Telecom</option>
<option value="textiles">Textiles</option>
<option value="thalassrep">Thalassemia Reports</option>
<option value="thermo">Thermo</option>
<option value="tomography">Tomography</option>
<option value="tourismhosp">Tourism and Hospitality</option>
<option value="toxics">Toxics</option>
<option value="toxins">Toxins</option>
<option value="transplantology">Transplantology</option>
<option value="traumacare">Trauma Care</option>
<option value="tropicalmed">Tropical Medicine and Infectious Disease</option>
<option value="universe">Universe</option>
<option value="urbansci">Urban Science</option>
<option value="uro">Uro</option>
<option value="vaccines">Vaccines</option>
<option value="vehicles">Vehicles</option>
<option value="venereology">Venereology</option>
<option value="vetsci">Veterinary Sciences</option>
<option value="vibration">Vibration</option>
<option value="viruses">Viruses</option>
<option value="vision">Vision</option>
<option value="water">Water</option>
<option value="wind">Wind</option>
<option value="women">Women</option>
<option value="world">World</option>
<option value="wevj">World Electric Vehicle Journal</option>
<option value="youth">Youth</option>
<option value="zoonoticdis">Zoonotic Diseases</option>
</select>
<input name="email" type="email" placeholder="Enter your email address..." required="required" />
<button class="genericCaptcha button button--dark UA_FooterNewsletterSubscribeButton" type="submit">Subscribe</button>
</form>
</div>
</div>
</div>
<div id="footer-copyright">
<div class="row">
<div class="columns large-6 medium-6 small-12 text-left">
© 1996-2022 MDPI (Basel, Switzerland) unless otherwise stated
</div>
<div class="columns large-6 medium-6 small-12 small-text-left medium-text-right large-text-right">
<a data-dropdown="drop-view-disclaimer" aria-controls="drop-view-disclaimer" aria-expanded="false" data-options="align:top; is_hover:true; hover_timeout:2000;">
Disclaimer
</a>
<div id="drop-view-disclaimer" class="f-dropdown label__btn__dropdown label__btn__dropdown--wide text-left" data-dropdown-content aria-hidden="true" tabindex="-1">
The statements, opinions and data contained in the journals are solely
those of the individual authors and contributors and not of the publisher and the editor(s).
MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.
</div>
<a href="/about/terms-and-conditions">
Terms and Conditions
</a>
<a href="/about/privacy">
Privacy Policy
</a>
</div>
</div>
</div>
</div>
<div id="cookie-notification" class="js-allow-cookies" style="display: none;">
<div class="columns large-10 medium-10 small-12">
We use cookies on our website to ensure you get the best experience.<br class="show-for-medium-up" />
Read more about our cookies <a href="/about/privacy">here</a>.
</div>
<div class="columns large-2 medium-2 small-12 small-only-text-left text-right">
<a class="button button--default" href="/accept_cookies">Accept</a>
</div>
</div>
<div id="cookie-notification" class="js-survey" style="display: none;">
<div class="columns large-10 medium-10 small-12">
<strong>We have just recently launched a new version of our website.</strong><br class="show-for-meidum-up" />
<span style="font-weight: 400;">
Help us to further improve by taking part in this short 5 minute survey <span style="inline-block">
<span class="show-for-medium-up js-survey-link"><a href="https://www.surveymonkey.com/r/VWJZ6VW" target="_blank" rel="noopener noreferrer">here</a>.</span>
<span class="show-for-small-only js-survey-link"><a href="https://www.surveymonkey.com/r/VWMDSNQ" target="_blank" rel="noopener noreferrer">here</a>.</span>
</span>
</span>
</div>
<div class="columns large-2 medium-2 small-12 small-only-text-left text-right">
<a class="button button--default js-disable-survey-link" href="/disable_survey">Never show this again</a>
</div>
</div>
</div>
<div id="main-share-modal" class="reveal-modal reveal-modal-new reveal-modal-new--small" data-reveal aria-labelledby="modalTitle" aria-hidden="true" role="dialog">
<div class="row">
<div class="small-12 columns">
<h2 style="margin: 0;">Share Link</h2>
</div>
<div class="small-12 columns">
<div class="social-media-links UA_ShareModalLinks" style="text-align: left;">
<a href="/cdn-cgi/l/email-protection#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" title="Email">
<i class="fa fa-envelope-square" style="font-size: 30px;"></i>
</a>
<a href="https://twitter.com/intent/tweet?text=The+Performance+of+Deep+Learning+Algorithms+on+Automatic+Pulmonary+Nodule+Detection+and+Classification+Tested+on+Different+Datasets+That+Are+Not+Derived+from+LIDC-IDRI%3A+A+Systematic+Review&amp;hashtags=mdpidiagnostics&amp;url=https%3A%2F%2Fwww.mdpi.com%2F584678&amp;via=diagnostic_mdpi" onclick="windowOpen(this.href,600,800); return false" title="Twitter" target="_blank" rel="noopener noreferrer">
<i class="fa fa-twitter-square" style="font-size: 30px;"></i>
</a>
<a href="	                    http://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fwww.mdpi.com%2F584678&amp;title=The%20Performance%20of%20Deep%20Learning%20Algorithms%20on%20Automatic%20Pulmonary%20Nodule%20Detection%20and%20Classification%20Tested%20on%20Different%20Datasets%20That%20Are%20Not%20Derived%20from%20LIDC-IDRI%3A%20A%20Systematic%20Review%26source%3Dhttps%3A%2F%2Fwww.mdpi.com%26summary%3DThe%20aim%20of%20this%20study%20was%20to%20systematically%20review%20the%20performance%20of%20deep%20learning%20technology%20in%20detecting%20and%20classifying%20pulmonary%20nodules%20on%20computed%20tomography%20%28CT%29%20scans%20that%20were%20not%20from%20the%20Lung%20Image%20Database%20Consortium%20and%20Image%20Database%20%5B...%5D" onclick="windowOpen(this.href,600,800); return false" title="LinkedIn" target="_blank" rel="noopener noreferrer">
<i class="fa fa-linkedin-square" style="font-size: 30px;"></i>
</a>
<a href="https://www.facebook.com/sharer.php?u=https://www.mdpi.com/584678" title="facebook" target="_blank" rel="noopener noreferrer">
<i class="fa fa-facebook-square" style="font-size: 30px;"></i>
</a>
<a href="javascript:void(0);" title="Wechat" data-reveal-id="weixin-share-modal">
<i class="fa fa-weixin-square" style="font-size: 26px;"></i>
</a>
<a href="https://www.reddit.com/submit?url=https://www.mdpi.com/584678" title="Reddit" target="_blank" rel="noopener noreferrer">
<i class="fa fa-reddit-square" style="font-size: 30px;"></i>
</a>
<a href="https://www.mendeley.com/import/?url=https://www.mdpi.com/584678" title="Mendeley" target="_blank" rel="noopener noreferrer">
<i class="fa fa-mendeley-square" style="font-size: 30px;"></i>
</a>
<a href="http://www.citeulike.org/posturl?url=https://www.mdpi.com/584678" title="CiteULike" target="_blank" rel="noopener noreferrer">
<i class="fa fa-citeulike-square" style="font-size: 30px;"></i>
</a>
</div>
</div>
<div class="small-9 columns">
<input id="js-clipboard-text" type="text" readonly value="https://www.mdpi.com/584678" />
</div>
<div class="small-3 columns text-left">
<a class="button button--color js-clipboard-copy" data-clipboard-target="#js-clipboard-text">Copy</a>
</div>
</div>
<a class="close-reveal-modal" aria-label="Close">
<i class="material-icons">clear</i>
</a>
</div>
<div id="weixin-share-modal" class="reveal-modal reveal-modal-new" data-reveal aria-labelledby="weixin-share-modal-title" aria-hidden="true" role="dialog">
<div class="row">
<div class="small-12 columns">
<h2 id="weixin-share-modal-title" style="margin: 0;">Share</h2>
</div>
<div class="small-12 columns">
<div class="weixin-qr-code-section">

<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg width="300" height="300" version="1.1" xmlns="http://www.w3.org/2000/svg">
<desc>https://www.mdpi.com/584678</desc>
<g id="elements" fill="black" stroke="none">
<rect x="0" y="0" width="12" height="12" />
<rect x="12" y="0" width="12" height="12" />
<rect x="24" y="0" width="12" height="12" />
<rect x="36" y="0" width="12" height="12" />
<rect x="48" y="0" width="12" height="12" />
<rect x="60" y="0" width="12" height="12" />
<rect x="72" y="0" width="12" height="12" />
<rect x="132" y="0" width="12" height="12" />
<rect x="144" y="0" width="12" height="12" />
<rect x="156" y="0" width="12" height="12" />
<rect x="168" y="0" width="12" height="12" />
<rect x="216" y="0" width="12" height="12" />
<rect x="228" y="0" width="12" height="12" />
<rect x="240" y="0" width="12" height="12" />
<rect x="252" y="0" width="12" height="12" />
<rect x="264" y="0" width="12" height="12" />
<rect x="276" y="0" width="12" height="12" />
<rect x="288" y="0" width="12" height="12" />
<rect x="0" y="12" width="12" height="12" />
<rect x="72" y="12" width="12" height="12" />
<rect x="108" y="12" width="12" height="12" />
<rect x="120" y="12" width="12" height="12" />
<rect x="156" y="12" width="12" height="12" />
<rect x="216" y="12" width="12" height="12" />
<rect x="288" y="12" width="12" height="12" />
<rect x="0" y="24" width="12" height="12" />
<rect x="24" y="24" width="12" height="12" />
<rect x="36" y="24" width="12" height="12" />
<rect x="48" y="24" width="12" height="12" />
<rect x="72" y="24" width="12" height="12" />
<rect x="144" y="24" width="12" height="12" />
<rect x="168" y="24" width="12" height="12" />
<rect x="192" y="24" width="12" height="12" />
<rect x="216" y="24" width="12" height="12" />
<rect x="240" y="24" width="12" height="12" />
<rect x="252" y="24" width="12" height="12" />
<rect x="264" y="24" width="12" height="12" />
<rect x="288" y="24" width="12" height="12" />
<rect x="0" y="36" width="12" height="12" />
<rect x="24" y="36" width="12" height="12" />
<rect x="36" y="36" width="12" height="12" />
<rect x="48" y="36" width="12" height="12" />
<rect x="72" y="36" width="12" height="12" />
<rect x="96" y="36" width="12" height="12" />
<rect x="144" y="36" width="12" height="12" />
<rect x="156" y="36" width="12" height="12" />
<rect x="180" y="36" width="12" height="12" />
<rect x="192" y="36" width="12" height="12" />
<rect x="216" y="36" width="12" height="12" />
<rect x="240" y="36" width="12" height="12" />
<rect x="252" y="36" width="12" height="12" />
<rect x="264" y="36" width="12" height="12" />
<rect x="288" y="36" width="12" height="12" />
<rect x="0" y="48" width="12" height="12" />
<rect x="24" y="48" width="12" height="12" />
<rect x="36" y="48" width="12" height="12" />
<rect x="48" y="48" width="12" height="12" />
<rect x="72" y="48" width="12" height="12" />
<rect x="96" y="48" width="12" height="12" />
<rect x="108" y="48" width="12" height="12" />
<rect x="156" y="48" width="12" height="12" />
<rect x="216" y="48" width="12" height="12" />
<rect x="240" y="48" width="12" height="12" />
<rect x="252" y="48" width="12" height="12" />
<rect x="264" y="48" width="12" height="12" />
<rect x="288" y="48" width="12" height="12" />
<rect x="0" y="60" width="12" height="12" />
<rect x="72" y="60" width="12" height="12" />
<rect x="132" y="60" width="12" height="12" />
<rect x="144" y="60" width="12" height="12" />
<rect x="156" y="60" width="12" height="12" />
<rect x="168" y="60" width="12" height="12" />
<rect x="192" y="60" width="12" height="12" />
<rect x="216" y="60" width="12" height="12" />
<rect x="288" y="60" width="12" height="12" />
<rect x="0" y="72" width="12" height="12" />
<rect x="12" y="72" width="12" height="12" />
<rect x="24" y="72" width="12" height="12" />
<rect x="36" y="72" width="12" height="12" />
<rect x="48" y="72" width="12" height="12" />
<rect x="60" y="72" width="12" height="12" />
<rect x="72" y="72" width="12" height="12" />
<rect x="96" y="72" width="12" height="12" />
<rect x="120" y="72" width="12" height="12" />
<rect x="144" y="72" width="12" height="12" />
<rect x="168" y="72" width="12" height="12" />
<rect x="192" y="72" width="12" height="12" />
<rect x="216" y="72" width="12" height="12" />
<rect x="228" y="72" width="12" height="12" />
<rect x="240" y="72" width="12" height="12" />
<rect x="252" y="72" width="12" height="12" />
<rect x="264" y="72" width="12" height="12" />
<rect x="276" y="72" width="12" height="12" />
<rect x="288" y="72" width="12" height="12" />
<rect x="120" y="84" width="12" height="12" />
<rect x="132" y="84" width="12" height="12" />
<rect x="168" y="84" width="12" height="12" />
<rect x="0" y="96" width="12" height="12" />
<rect x="12" y="96" width="12" height="12" />
<rect x="60" y="96" width="12" height="12" />
<rect x="72" y="96" width="12" height="12" />
<rect x="84" y="96" width="12" height="12" />
<rect x="108" y="96" width="12" height="12" />
<rect x="132" y="96" width="12" height="12" />
<rect x="144" y="96" width="12" height="12" />
<rect x="156" y="96" width="12" height="12" />
<rect x="168" y="96" width="12" height="12" />
<rect x="240" y="96" width="12" height="12" />
<rect x="252" y="96" width="12" height="12" />
<rect x="0" y="108" width="12" height="12" />
<rect x="12" y="108" width="12" height="12" />
<rect x="84" y="108" width="12" height="12" />
<rect x="108" y="108" width="12" height="12" />
<rect x="144" y="108" width="12" height="12" />
<rect x="156" y="108" width="12" height="12" />
<rect x="168" y="108" width="12" height="12" />
<rect x="180" y="108" width="12" height="12" />
<rect x="204" y="108" width="12" height="12" />
<rect x="228" y="108" width="12" height="12" />
<rect x="240" y="108" width="12" height="12" />
<rect x="252" y="108" width="12" height="12" />
<rect x="264" y="108" width="12" height="12" />
<rect x="276" y="108" width="12" height="12" />
<rect x="24" y="120" width="12" height="12" />
<rect x="48" y="120" width="12" height="12" />
<rect x="60" y="120" width="12" height="12" />
<rect x="72" y="120" width="12" height="12" />
<rect x="120" y="120" width="12" height="12" />
<rect x="144" y="120" width="12" height="12" />
<rect x="168" y="120" width="12" height="12" />
<rect x="180" y="120" width="12" height="12" />
<rect x="204" y="120" width="12" height="12" />
<rect x="216" y="120" width="12" height="12" />
<rect x="228" y="120" width="12" height="12" />
<rect x="240" y="120" width="12" height="12" />
<rect x="252" y="120" width="12" height="12" />
<rect x="276" y="120" width="12" height="12" />
<rect x="288" y="120" width="12" height="12" />
<rect x="24" y="132" width="12" height="12" />
<rect x="36" y="132" width="12" height="12" />
<rect x="48" y="132" width="12" height="12" />
<rect x="108" y="132" width="12" height="12" />
<rect x="144" y="132" width="12" height="12" />
<rect x="168" y="132" width="12" height="12" />
<rect x="204" y="132" width="12" height="12" />
<rect x="228" y="132" width="12" height="12" />
<rect x="252" y="132" width="12" height="12" />
<rect x="288" y="132" width="12" height="12" />
<rect x="36" y="144" width="12" height="12" />
<rect x="48" y="144" width="12" height="12" />
<rect x="72" y="144" width="12" height="12" />
<rect x="96" y="144" width="12" height="12" />
<rect x="108" y="144" width="12" height="12" />
<rect x="168" y="144" width="12" height="12" />
<rect x="180" y="144" width="12" height="12" />
<rect x="216" y="144" width="12" height="12" />
<rect x="288" y="144" width="12" height="12" />
<rect x="0" y="156" width="12" height="12" />
<rect x="24" y="156" width="12" height="12" />
<rect x="48" y="156" width="12" height="12" />
<rect x="60" y="156" width="12" height="12" />
<rect x="132" y="156" width="12" height="12" />
<rect x="144" y="156" width="12" height="12" />
<rect x="156" y="156" width="12" height="12" />
<rect x="180" y="156" width="12" height="12" />
<rect x="192" y="156" width="12" height="12" />
<rect x="204" y="156" width="12" height="12" />
<rect x="228" y="156" width="12" height="12" />
<rect x="276" y="156" width="12" height="12" />
<rect x="0" y="168" width="12" height="12" />
<rect x="36" y="168" width="12" height="12" />
<rect x="48" y="168" width="12" height="12" />
<rect x="60" y="168" width="12" height="12" />
<rect x="72" y="168" width="12" height="12" />
<rect x="96" y="168" width="12" height="12" />
<rect x="108" y="168" width="12" height="12" />
<rect x="120" y="168" width="12" height="12" />
<rect x="156" y="168" width="12" height="12" />
<rect x="168" y="168" width="12" height="12" />
<rect x="180" y="168" width="12" height="12" />
<rect x="204" y="168" width="12" height="12" />
<rect x="216" y="168" width="12" height="12" />
<rect x="228" y="168" width="12" height="12" />
<rect x="240" y="168" width="12" height="12" />
<rect x="252" y="168" width="12" height="12" />
<rect x="276" y="168" width="12" height="12" />
<rect x="288" y="168" width="12" height="12" />
<rect x="0" y="180" width="12" height="12" />
<rect x="84" y="180" width="12" height="12" />
<rect x="108" y="180" width="12" height="12" />
<rect x="132" y="180" width="12" height="12" />
<rect x="204" y="180" width="12" height="12" />
<rect x="228" y="180" width="12" height="12" />
<rect x="252" y="180" width="12" height="12" />
<rect x="264" y="180" width="12" height="12" />
<rect x="288" y="180" width="12" height="12" />
<rect x="0" y="192" width="12" height="12" />
<rect x="36" y="192" width="12" height="12" />
<rect x="72" y="192" width="12" height="12" />
<rect x="96" y="192" width="12" height="12" />
<rect x="108" y="192" width="12" height="12" />
<rect x="120" y="192" width="12" height="12" />
<rect x="156" y="192" width="12" height="12" />
<rect x="180" y="192" width="12" height="12" />
<rect x="192" y="192" width="12" height="12" />
<rect x="204" y="192" width="12" height="12" />
<rect x="216" y="192" width="12" height="12" />
<rect x="228" y="192" width="12" height="12" />
<rect x="240" y="192" width="12" height="12" />
<rect x="264" y="192" width="12" height="12" />
<rect x="96" y="204" width="12" height="12" />
<rect x="132" y="204" width="12" height="12" />
<rect x="144" y="204" width="12" height="12" />
<rect x="168" y="204" width="12" height="12" />
<rect x="192" y="204" width="12" height="12" />
<rect x="240" y="204" width="12" height="12" />
<rect x="0" y="216" width="12" height="12" />
<rect x="12" y="216" width="12" height="12" />
<rect x="24" y="216" width="12" height="12" />
<rect x="36" y="216" width="12" height="12" />
<rect x="48" y="216" width="12" height="12" />
<rect x="60" y="216" width="12" height="12" />
<rect x="72" y="216" width="12" height="12" />
<rect x="96" y="216" width="12" height="12" />
<rect x="132" y="216" width="12" height="12" />
<rect x="144" y="216" width="12" height="12" />
<rect x="156" y="216" width="12" height="12" />
<rect x="192" y="216" width="12" height="12" />
<rect x="216" y="216" width="12" height="12" />
<rect x="240" y="216" width="12" height="12" />
<rect x="288" y="216" width="12" height="12" />
<rect x="0" y="228" width="12" height="12" />
<rect x="72" y="228" width="12" height="12" />
<rect x="96" y="228" width="12" height="12" />
<rect x="108" y="228" width="12" height="12" />
<rect x="120" y="228" width="12" height="12" />
<rect x="132" y="228" width="12" height="12" />
<rect x="168" y="228" width="12" height="12" />
<rect x="180" y="228" width="12" height="12" />
<rect x="192" y="228" width="12" height="12" />
<rect x="240" y="228" width="12" height="12" />
<rect x="276" y="228" width="12" height="12" />
<rect x="0" y="240" width="12" height="12" />
<rect x="24" y="240" width="12" height="12" />
<rect x="36" y="240" width="12" height="12" />
<rect x="48" y="240" width="12" height="12" />
<rect x="72" y="240" width="12" height="12" />
<rect x="156" y="240" width="12" height="12" />
<rect x="180" y="240" width="12" height="12" />
<rect x="192" y="240" width="12" height="12" />
<rect x="204" y="240" width="12" height="12" />
<rect x="216" y="240" width="12" height="12" />
<rect x="228" y="240" width="12" height="12" />
<rect x="240" y="240" width="12" height="12" />
<rect x="264" y="240" width="12" height="12" />
<rect x="0" y="252" width="12" height="12" />
<rect x="24" y="252" width="12" height="12" />
<rect x="36" y="252" width="12" height="12" />
<rect x="48" y="252" width="12" height="12" />
<rect x="72" y="252" width="12" height="12" />
<rect x="108" y="252" width="12" height="12" />
<rect x="132" y="252" width="12" height="12" />
<rect x="144" y="252" width="12" height="12" />
<rect x="156" y="252" width="12" height="12" />
<rect x="180" y="252" width="12" height="12" />
<rect x="192" y="252" width="12" height="12" />
<rect x="216" y="252" width="12" height="12" />
<rect x="276" y="252" width="12" height="12" />
<rect x="288" y="252" width="12" height="12" />
<rect x="0" y="264" width="12" height="12" />
<rect x="24" y="264" width="12" height="12" />
<rect x="36" y="264" width="12" height="12" />
<rect x="48" y="264" width="12" height="12" />
<rect x="72" y="264" width="12" height="12" />
<rect x="144" y="264" width="12" height="12" />
<rect x="192" y="264" width="12" height="12" />
<rect x="252" y="264" width="12" height="12" />
<rect x="264" y="264" width="12" height="12" />
<rect x="288" y="264" width="12" height="12" />
<rect x="0" y="276" width="12" height="12" />
<rect x="72" y="276" width="12" height="12" />
<rect x="96" y="276" width="12" height="12" />
<rect x="108" y="276" width="12" height="12" />
<rect x="120" y="276" width="12" height="12" />
<rect x="192" y="276" width="12" height="12" />
<rect x="204" y="276" width="12" height="12" />
<rect x="228" y="276" width="12" height="12" />
<rect x="240" y="276" width="12" height="12" />
<rect x="288" y="276" width="12" height="12" />
<rect x="0" y="288" width="12" height="12" />
<rect x="12" y="288" width="12" height="12" />
<rect x="24" y="288" width="12" height="12" />
<rect x="36" y="288" width="12" height="12" />
<rect x="48" y="288" width="12" height="12" />
<rect x="60" y="288" width="12" height="12" />
<rect x="72" y="288" width="12" height="12" />
<rect x="96" y="288" width="12" height="12" />
<rect x="108" y="288" width="12" height="12" />
<rect x="120" y="288" width="12" height="12" />
<rect x="132" y="288" width="12" height="12" />
<rect x="168" y="288" width="12" height="12" />
<rect x="192" y="288" width="12" height="12" />
<rect x="204" y="288" width="12" height="12" />
<rect x="252" y="288" width="12" height="12" />
<rect x="288" y="288" width="12" height="12" />
</g>
</svg>
</div>
</div>
</div>
<a class="close-reveal-modal" aria-label="Close">
<i class="material-icons">clear</i>
</a>
</div>
<a href="#" class="back-to-top"><span class="show-for-medium-up">Back to Top</span><span class="show-for-small">Top</span></a>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script src="/assets/js/modernizr-2.8.3.min.js?5227e0738f7f421d"></script>
<script src="/assets/js/jquery-1.12.4.min.js?4f252523d4af0b47"></script>
<script src="/assets/js/foundation-5.5.3.min.js?6b2ec41c18b29054"></script>
<script src="/assets/js/foundation-5.5.3.equalizer.min.js?0f6c549b75ec554c"></script>
<script src="/assets/js/jquery.multiselect.js?0edd3998731d1091"></script>
<script src="/assets/js/jquery.cycle2.min.js?63413052928f97ee"></script>
<script>
            $('select.foundation-select').multiselect({
                search: true,
                minHeight: 130,
                maxHeight: 130,
            });

            $(document).foundation({
                orbit: {
                    timer_speed: 4000,
                },
                reveal: {
                    animation: 'fadeAndPop',
                    animation_speed: 100,
                }
            });

            // old browser fix - this way the console log rows won't throw (silent) errors in browsers not supporting console log
            if (!window.console) window.console = {};
            if (!window.console.log) window.console.log = function () { };

    var currentJournalNameSystem = "diagnostics";

            $(document).ready(function()
            {
                $(".chosen-select").each(function(element) {
                    var maxSelected = (undefined !== $(this).data('maxselectedoptions') ? $(this).data('maxselectedoptions') : 100);

                    $(this).on('chosen:ready', function(event, data) {
                        var select = $(data.chosen.form_field);
                        if (select.attr('id') === 'journal-browser-volume') {
                            $(data.chosen.dropdown).addClass('UI_JournalBrowser_Volume_Options');
                        }
                        if (select.attr('id') === 'journal-browser-issue') {
                            $(data.chosen.dropdown).addClass('UI_JournalBrowser_Issue_Options');
                        }
                    }).chosen({ disable_search_threshold: 7, max_selected_options: maxSelected, width: "100%" });
                });

                $(".toEncode").each(function(e) {
                    var oldHref = $(this).attr("href");
                    var newHref = oldHref.replace('.botdefense.please.enable.javascript.','@');
                    $(this).attr("href", newHref);

                    if (!$(this).hasClass("emailCaptcha"))
                    {
                        $(this).html(newHref.replace('mailto:', ''));
                    }
                    
                    
                    $(this).removeClass("visibility-hidden");
                });

                $(document).on('opened.fndtn.reveal', '[data-reveal]', function()
                {
                    $(document).foundation('equalizer', 'reflow');
                });

                // fix the images that have tag height / width defined
                // otherwise the default foundation styles overwrite the tag definitions
                $("img").each(function()
                {
                   if ($(this).attr('width') != undefined || $(this).attr('height') != undefined)
                   {
                       $(this).addClass("img-fixed");
                   }
                });

                $("#basic_search, #advanced_search").submit(function(e) {
                    var searchArguments = false;

                    $(this).find("input,select").not("#search,.search-button").each(function() {
                        if (undefined === $(this).val() || "" === $(this).val()) {
                            $(this).attr('name', null);
                        } else {
                            $(this).attr('name');
                            searchArguments = true;
                        }
                    });

                    if (!searchArguments) {
                        window.location = $(this).attr('action');
                        return false;
                    }
                });

                $(".hide-show-desktop-option").click(function(e) 
                {
                    e.preventDefault();
                    var parentDiv = $(this).closest("div");

                    $.ajax({
                        url: $(this).attr('href'),
                        success: function(msg)
                        {
                            parentDiv.removeClass().hide();
                        }
                    });
                });

                $(".generic-toggleable-header").click(function(e) {
                    $(this).toggleClass("active");
                    $(this).next(".generic-toggleable-content").toggleClass("active");
                });

                /*
                * handle whole row as a link if the row contains only one visible link
                */
                $("table.new tr").hover(function()
                {
                   if ($(this).find("td:visible a").length == 1)
                   {
                       $(this).addClass("single-link");
                   }
                },
                function()
                {
                   $(this).removeClass("single-link");
                });

                $("table.new:not(.table-of-tables)").on("click", "tr.single-link", function(e)
                {
                    var target = $(e.target);
                    if (!e.ctrlKey && !target.is("a")) {
                        $(this).find("td:visible a")[0].click();
                    }
                });

                $(document).on("click", ".custom-accordion-for-small-screen-link", function(e) {
                    if ($(this).closest("#basic_search").length > 0) {
                        if ($(".search-container__advanced").first().is(":visible")) {
                            openAdvanced()
                        }
                    }

                    if (Foundation.utils.is_small_only()) {
                        if ($(this).hasClass("active")) {
                            $(this).removeClass("active");
                            $(this).next(".custom-accordion-for-small-screen-content").addClass("show-for-medium-up");
                        }
                        else {
                            $(this).addClass("active");
                            $(this).next(".custom-accordion-for-small-screen-content").removeClass("show-for-medium-up");
                            $(document).foundation('orbit', 'reflow');
                        }
                    }

                    if (undefined !== $(this).data("callback")) {
                        var customCallback = $(this).data("callback");
                        func = window[customCallback];
                        func();
                    }
                });

                $(document).on("click", ".js-open-small-search", function(e) {
                    e.preventDefault();  
                    $(this).toggleClass("active").closest(".tab-bar").toggleClass("active");
                    $(".search-container").toggleClass("hide-for-small-down");
                });

                $(document).on("click", ".js-survey-link", function(e) {
                    localStorage.setItem("mdpi_disable_survey", true);
                    window.location.href = "/disable_survey";
                });

                $(document).on("click", ".js-disable-survey-link", function(e) {
                    localStorage.setItem("mdpi_disable_survey", true);
                });

                $(document).on("click", ".js-open-menu", function(e) {
                    $(".search-container").addClass("hide-for-small-down");

                });

                $(window).on('resize', function() {
                    recalculate_main_browser_position();
                    recalculate_responsive_moving_containers();
                });

                checkCookiesAllowed();
                updateSearchLabelVisibilities();
                recalculate_main_browser_position();
                recalculate_responsive_moving_containers();
                
                
                if (window.document.documentMode == 11) {
                    $("<link/>", { rel: "stylesheet", type: "text/css", href: "https://fonts.googleapis.com/icon?family=Material+Icons"}).appendTo("head");
                }
            });

            function recalculate_main_browser_position() {
                if (Foundation.utils.is_small_only()) {
                    if ($("#js-main-top-container").parent("#js-large-main-top-container").length > 0) {
                        $("#js-main-top-container").appendTo($("#js-small-main-top-container"));
                    }
                }
                else {
                    if ($("#js-main-top-container").parent("#js-small-main-top-container").length > 0) {
                        $("#js-main-top-container").appendTo($("#js-large-main-top-container"));
                    }
                }
            }

            function recalculate_responsive_moving_containers() {
                $(".responsive-moving-container.large").each(function() {
                    var previousParent = $(".responsive-moving-container.active[data-id='"+$(this).data("id")+"']");
                    var movingContent  = previousParent.html();

                    if (Foundation.utils.is_small_only()) {
                        var currentParent = $(".responsive-moving-container.small[data-id='"+$(this).data("id")+"']");
                    }
                    else if (Foundation.utils.is_medium_only()) {
                        var currentParent = $(".responsive-moving-container.medium[data-id='"+$(this).data("id")+"']");
                    }
                    else {
                        var currentParent = $(".responsive-moving-container.large[data-id='"+$(this).data("id")+"']");
                    }

                    if (previousParent.attr("class") !== currentParent.attr("class")) {
                        currentParent.html(movingContent);
                        previousParent.html();
                        currentParent.addClass("active");
                        previousParent.removeClass("active");
                    }
                });
            }

            // cookies allowed is checked from a) local storage and b) from server separately so that the footer bar doesn't
            // get included in the custom page caches
            function checkCookiesAllowed() {
                var cookiesEnabled = localStorage.getItem("mdpi_cookies_enabled"); 

                if (null === cookiesEnabled) {
                    $.ajax({
                        url: "/ajax_cookie_value/mdpi_cookies_accepted",
                        success: function(data)
                        {
                            if (data.value) {
                                localStorage.setItem("mdpi_cookies_enabled", true);
                                checkDisplaySurvey();
                            }
                            else {
                                $(".js-allow-cookies").show();
                            }
                        }
                    });
                }
                else {
                    checkDisplaySurvey();
                }
            }

            // cookies allowed is checked from a) local storage and b) from server separately so that the footer bar doesn't
            // get included in the custom page caches
            //
            // NOTE! survey has been closed. Not used anymore (this code can be moved to somewhere for storage in case we need similar logic with other iterations)
            // 
            function checkDisplaySurvey() {
                
                var surveyDisabled = localStorage.getItem("mdpi_disable_survey"); 
                var viewCount      = localStorage.getItem("mdpi_new_layout_views"); 
                var viewLimit      = localStorage.getItem("mdpi_new_layout_limit");

                if (null !== surveyDisabled) {
                    return;
                }

                
                return;
                // todo: the below part can be removed later on...

                if (null === viewLimit) {
                    localStorage.setItem("mdpi_new_layout_limit", Math.floor(Math.random() * 50));
                    localStorage.setItem("mdpi_new_layout_views", 0);
                }
                else {
                    viewCount++;
                    localStorage.setItem("mdpi_new_layout_views", viewCount);

                    if (viewCount >= viewLimit) {
                        $.ajax({
                            url: "/ajax_cookie_value/mdpi_disable_survey",
                            success: function(data)
                            {
                                if (data.value) {
                                    localStorage.setItem("mdpi_disable_survey", true);
                                }
                                else {
                                    $(".js-survey").show();
                                }
                            }
                        });
                    }
                }
            }
            
        </script>
<script src="/assets/js/lib.js?f6e377fcd57aadd4"></script>
<script src="/assets/js/mdpi.js?5eb1824a20c5547f"></script>
<script>var banners_url = 'https://serve.mdpi.com';</script>
<script type='text/javascript' src='/assets/js/ifvisible.min.js?c621d19ecb761212'></script>
<script src="/assets/js/xmltohtml/affix.js?ac4ea55275297c15"></script>
<script src="/assets/js/clipboard.min.js?3f3688138a1b9fc4"></script>
<script type="text/javascript">
        $(document).ready(function()
        {
            var helpFunctions = $(".middle-column__help__fixed");
            var middleColumn  = $("#middle-column");

            helpFunctions.affix({
                offset: {
                    top: function() {
                        return middleColumn.offset().top - 8 - (Foundation.utils.is_medium_only() ? 30 : 0);
                    },
                    bottom: function() {
                        return $("#footer").innerHeight() + 56 + (Foundation.utils.is_medium_only() ? 0 : 0);
                    }
                }
            });

            new ClipboardJS('.js-clipboard-copy');
        });
    </script>
<script src="/assets/js/jquery-ui-1.12.0.min.js?4c2c52cc11e5a28d"></script>
<script>
        $(document).ready(function()
        {
            
            $(".link-article-menu").click(function(e) {
                e.preventDefault();

                $(this).find('span').toggle();
                $(this).next("div").toggleClass("active");
            });

                    });
    </script>
<script src="/assets/js/xmltohtml/affix.js?ac4ea55275297c15"></script>
<script src="/assets/js/xmltohtml/storage.js?e9b262d3a3476d25"></script>
<script src="/assets/js/xmltohtml/jquery-scrollspy.js?09cbaec0dbb35a67"></script>
<script src="/assets/js/xmltohtml/magnific-popup.js?4a09c18460afb26c"></script>
<script src="/assets/js/xmltohtml/underscore.js?f893e294cde60c24"></script>
<script type="text/javascript">
    $('document').ready(function(){
    //   if(1 == 0){
    //     var doi = $('.html-art-header').find('a');
    //     var text = doi.text();
    //     doi.remove();
    //     $('.html-art-header p').append(text);
    //     $('.html-art-header').html($('.html-art-header')[0].innerHTML.replace(/doi:\s+/,'doi:&nbsp;'))
    //   }

      $("#left-column").addClass("show-for-large-up");
      $("#middle-column").removeClass("medium-9").removeClass("left-bordered").addClass("medium-12");
    });
	$(document).on('DOMNodeInserted', function(e) {

        var element = $(e.target);

        if (element.hasClass('menu') && element.hasClass('html-nav') )
        {
            element.addClass("side-menu-ul");
                                            }
    });
  </script>
<script src="/assets/js/jquery-ui-1.10.4.custom.min.js?9fb4d59ff745b497"></script>
<script src="/assets/js/xmltohtml/articles.js?a87788b81891bfc0"></script>
<script>
        repositionOpenSideBar = function() {
            $('#left-column').addClass("show-for-large-up show-for-medium-up").show();
            $('#middle-column').removeClass('large-12').removeClass('medium-12');
            $('#middle-column').addClass('large-9');
        }

        repositionCloseSideBar = function() {
            $('#left-column').removeClass("show-for-large-up show-for-medium-up").hide();
            $('#middle-column').removeClass('large-9');
            $('#middle-column').addClass('large-12').addClass('medium-12');
        }
    </script>
<script>
        $(document).ready(function() {

            $(document).on('keyup', function (e) {
                if (e.keyCode == 27) {

                    var hElem = $(this).find(".annotator-adder");

                    if (hElem.length){
                        hElem.css({'visibility':'hidden'});
                    } else {
                        document.querySelector("hypothesis-adder").shadowRoot.querySelector(".annotator-adder").style.visibility = "hidden";
                    }

                }
            });
        });
    </script>
<script>
            window.hypothesisConfig = function () {
                return {
                    sidebarAppUrl: 'https://commenting.mdpi.com/app.html',
                    showHighlights:   'whenSidebarOpen'  ,
                    openSidebar:  false  ,
                    assetRoot: 'https://commentingres.mdpi.com/hypothesis',
                    services: [{
                        apiUrl: 'https://commenting.mdpi.com/api/',
                        authority: 'mdpi',
                        grantToken: '',
                        doi: '10.3390/diagnostics9040207'
                    }],
                };
            };
            MathJax . Hub . Startup . signal . Interest ( function ( message ) {
                if ( message == 'End' ){
                var hypoLink = document . getElementById ( "hypothesis_frame" )
                hypoLink . setAttribute ( "src" , "https://commenting.mdpi.com/embed.js" )
                }
});
        </script>
<script async id="hypothesis_frame"></script>
<!--[if lt IE 9]>
                        <script src="/assets/js/ie8/ie8.js?6eef8fcbc831f5bd"></script>
            <script src="/assets/js/ie8/jquery.xdomainrequest.min.js?a945caca315782b0"></script>
        <![endif]-->

<script>
            !function(e,t,n,s,u,a){e.twq||(s=e.twq=function(){s.exe?s.exe.apply(s,arguments):s.queue.push(arguments);
            },s.version='1.1',s.queue=[],u=t.createElement(n),u.async=!0,u.src='//static.ads-twitter.com/uwt.js',
            a=t.getElementsByTagName(n)[0],a.parentNode.insertBefore(u,a))}(window,document,'script');
            // Insert Twitter Pixel ID and Standard Event data below
            twq('init','o2pip');
            twq('track','PageView');
        </script>

<script type="text/javascript">(function(){window['__CF$cv$params']={r:'7020f0755c72d46b',m:'NwQcD2R16c99OLltQDYk94uVxIZ4S.nQAGUXZn3k3jI-1650993104-0-AVrIajcC/DGmdnvWggphY/dJ3295/lo2J/L2cC+8ZmlzS6T4z/oaNpVCrMpFDSmPrpF4+z4cCVXhfYMDEKLkx2y2Q3e+7gRhThbpgnh1655d3n664FfsOfEqdTrMhjDbuCCsLnxd9JCtuAW06ZISpHg=',s:[0x2c0141a690,0x358dc952c1],}})();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194" integrity="sha512-Gi7xpJR8tSkrpF7aordPZQlW2DLtzUlZcumS8dMQjwDHEnw9I7ZLyiOj/6tZStRBGtGgN6ceN6cMH8z7etPGlw==" data-cf-beacon='{"rayId":"7020f0755c72d46b","token":"28b078b091674c0f80b4eb2521a2d256","version":"2021.12.0","si":100}' crossorigin="anonymous"></script>
</body>
</html>

<!DOCTYPE html>
<html lang="en" xmlns:og="http://ogp.me/ns#" xmlns:fb="https://www.facebook.com/2008/fbml">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta content="mdpi" name="sso-service" />
<meta content="width=device-width, initial-scale=1.0" name="viewport" />
<title>Diagnostics  | Free Full-Text | Automatic Pulmonary Nodule Detection Applying Deep Learning or Machine Learning Algorithms to the LIDC-IDRI Database: A Systematic Review | HTML</title><link rel="stylesheet" href="/assets/css/font-awesome.min.css?eb190a3a77e5e1ee">
<link rel="stylesheet" href="/assets/css/jquery.multiselect.css?f56c135cbf4d1483">
<link rel="stylesheet" href="/assets/css/chosen.min.css?d7ca5ca9441ef9e1">
<link rel="stylesheet" href="/assets/css/main2.css?55f92efea8c48975">
<link rel="mask-icon" href="/img/mask-icon-128.svg?c1c7eca266cd7013" color="#4f5671">
<link rel="apple-touch-icon" sizes="180x180" href="/icon/apple-touch-icon-180x180.png">
<link rel="apple-touch-icon" sizes="152x152" href="/icon/apple-touch-icon-152x152.png">
<link rel="apple-touch-icon" sizes="144x144" href="/icon/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon" sizes="120x120" href="/icon/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" sizes="114x114" href="/icon/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon" sizes="76x76" href="/icon/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" sizes="72x72" href="/icon/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="57x57" href="/icon/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon" href="/icon/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon-precomposed" href="/icon/apple-touch-icon-57x57.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="#ffffff">
<meta name="application-name" content="&nbsp;" />
<link rel="apple-touch-startup-image" href="/img/journals/diagnostics-logo-sq.png?cc7fe11b9251f219">
<link rel="apple-touch-icon" href="/img/journals/diagnostics-logo-sq.png?cc7fe11b9251f219">
<meta name="msapplication-TileImage" content="/img/journals/diagnostics-logo-sq.png?cc7fe11b9251f219">
<style>

h2, #abstract .related_suggestion_title {
    color: rgba(43,128,143,0.75);
}

.batch_articles a {
    color: #000;
}

    a, .batch_articles .authors a, a:focus, a:hover, a:active, .batch_articles a:focus, .batch_articles a:hover, li.side-menu-li a {
        color: rgba(43,128,143,0.75);
    }

    span.label a {
        color: #fff;
    }

    #main-content a.title-link:hover,
    #main-content a.title-link:focus,
    #main-content div.generic-item a.title-link:hover,
    #main-content div.generic-item a.title-link:focus {
        color: rgba(43,128,143,0.75);
    }

    #main-content #middle-column .generic-item.article-item a.title-link:hover,
    #main-content #middle-column .generic-item.article-item a.title-link:focus {
        color: rgba(43,128,143,0.75);
    }

    .art-authors a.toEncode {
        color: #333;
        font-weight: 700;
    }

    #main-content #middle-column ul li::before {
        color: rgba(43,128,143,0.75);
    }

    .accordion-navigation.active a.accordion__title,
    .accordion-navigation.active a.accordion__title::after {
        color: rgba(43,128,143,0.75) !important;
    }

    .accordion-navigation li:hover::before,
    .accordion-navigation li:hover a,
    .accordion-navigation li:focus a {
        color: rgba(43,128,143,0.75) !important;
    }

    .relative-size-container .relative-size-image .relative-size {
        background-color: rgba(43,128,143,0.75);
    }

    .middle-column__help__fixed a:hover i,
        color: rgba(43,128,143,0.75) !important;
    }

    input[type="checkbox"]:checked:after {
        color: rgba(43,128,143,0.75) !important;
    }

    input[type="checkbox"]:not(:disabled):hover:before {
        border-color: rgba(43,128,143,0.75) !important;
    }

    #main-content .bolded-text {
        color: rgba(43,128,143,0.75);
    }


#main-content .hypothesis-count-container {
    background-color: rgba(43,128,143,0.75) !important;
}

#main-content .hypothesis-count-container:before {
    border-bottom-color: rgba(43,128,143,0.75) !important;
}

#main-content .trendmd-widget-cookie-notification__info a {
    color: rgba(43,128,143,0.75) !important;
}

.full-size-menu ul li.menu-item .dropdown-wrapper {
    background-color: #2B808F !important;
}

.full-size-menu ul li.menu-item > a.open::after {
    border-bottom: 10px solid #2B808F;
}

#title-story .title-story-orbit .orbit-caption {
    #background: url('/img/design/000000_background.png') !important;
    background: url('/img/design/ffffff_background.png') !important;
    color: rgb(51, 51, 51) !important;
}

#main-content .content__container__orbit {
    background-color: #000 !important;
}

#main-content .content__container__journal {
    background-color: #2B808F;
    color: #fff;
}

.html-article-menu .row span {
    color: rgba(43,128,143,0.75);
}

.html-article-menu .row span.active {
    }

.side-menu-li.active::before,
.side-menu-li.active a {
    color: rgba(43,128,143,0.75) !important;
}

.side-menu-ul li.active a, .side-menu-ul li.active, .side-menu-ul li.active::before {
    color: rgba(43,128,143,0.75) !important;
}

.side-menu-ul li.active a {
    font-weight: 700 !important;
}

.result-selected, .active-result.highlighted, .active-result:hover,
.result-selected, .active-result.highlighted, .active-result:focus {
    background-color: rgba(43,128,143,0.75) !important;
    color: #fff;
}

.search-container.search-container__default-scheme {
    background-color: #2B808F;
}

nav.tab-bar .open-small-search.active:after {
    border-bottom-color: #2B808F;
}

.search-container.search-container__default-scheme .custom-accordion-for-small-screen-link::after {
    color: #fff;
}

@media only screen and (max-width: 50em) {
    #main-content .content__container.journal-info {
        color: #fff;
        background-color: rgba(43,128,143,0.75);
    }

    #main-content .content__container.journal-info a {
        color: #fff;
    }
} 

.button.button--color {
    color: rgba(43,128,143,0.75);
    border-color: rgba(43,128,143,0.75);
}

.button.button--color:hover,
.button.button--color:focus {
    color: #fff;
    border-color: rgba(43,128,143,0.75);
    background-color: rgba(43,128,143,0.75);
}

.button.button--color-inversed {
    background-color: rgba(43,128,143,0.75);
    border-color: #fff;
    color: #fff;
}

.button.button--color-inversed:hover,
.button.button--color-inversed:focus {
    background-color: rgba(43,128,143,0.75);
    border-color: #fff;
    color: #fff;
}

.button.button--color path {
    fill: rgba(43,128,143,0.75);
}

.button.button--color:hover path {
    fill: #fff;
}

#main-content #search-refinements .ui-slider-horizontal .ui-slider-range {
    background-color: rgba(43,128,143,0.75);
}

.breadcrumb__element:last-of-type a {
    color: rgba(43,128,143,0.75);
}

    
#main-header {
    background-color: rgba(43,128,143,0.75);
}

#full-size-menu .top-bar, #full-size-menu li.menu-item span.user-email {
    background-color:   rgba(43,128,143,0.75)
}

.top-bar-section li:not(.has-form) a:not(.button) {
    background-color:   rgba(43,128,143,0.75)
}

#full-size-menu li.menu-item .dropdown-wrapper li a:hover {
    color:   rgba(43,128,143,0.75)
}

#full-size-menu li.menu-item a:hover, #full-size-menu li.menu.item a:focus, nav.tab-bar a:hover {
    }
#full-size-menu li.menu.item a:active, #full-size-menu li.menu.item a.active {
    background-color: #B9E0E9;
}

#full-size-menu li.menu-item a.open-mega-menu.active, #full-size-menu li.menu-item div.mega-menu, a.open-mega-menu.active {
    background-color: #B9E0E9;
    color: #000;
}

#full-size-menu li.menu-item div.mega-menu li, #full-size-menu li.menu-item div.mega-menu a {
    background-color: #B9E0E9;
    color: #000;
    border-color: #9a9a9a;
}

div.type-section h1 {
    padding-left: 15px !important;
    background-color: rgba(43,128,143,0.75);
    color: #fff;
    font-size: 20px;
    line-height: 26px;
    font-weight: 300;
}

div.type-section h3 {
    margin-left: 15px;
    margin-bottom: 0px;
    font-weight: 300;
}

.journal-tabs .tab-title.active a {
    background-color: rgba(43,128,143,0.75);
    border-color: rgba(43,128,143,0.75);
    color: #fff;
}

</style>
<link rel="stylesheet" href="/assets/css/jquery-ui-1.10.4.custom.min.css?80647d88647bf347">
<link rel="stylesheet" href="/assets/css/magnific-popup.min.css?04d343e036f8eecd">
<link rel="stylesheet" href="/assets/css/xml2html/article-html.css?d22327de055631c3">
<meta name="title" content="Automatic Pulmonary Nodule Detection Applying Deep Learning or Machine Learning Algorithms to the LIDC-IDRI Database: A Systematic Review">
<meta name="description" content="The aim of this study was to provide an overview of the literature available on machine learning (ML) algorithms applied to the Lung Image Database Consortium Image Collection (LIDC-IDRI) database as a tool for the optimization of detecting lung nodules in thoracic CT scans. This systematic review was compiled according to Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Only original research articles concerning algorithms applied to the LIDC-IDRI database were included. The initial search yielded 1972 publications after removing duplicates, and 41 of these articles were included in this study. The articles were divided into two subcategories describing their overall architecture. The majority of feature-based algorithms achieved an accuracy &amp;gt;90% compared to the deep learning (DL) algorithms that achieved an accuracy in the range of 82.2%&amp;ndash;97.6%. In conclusion, ML and DL algorithms are able to detect lung nodules with a high level of accuracy, sensitivity, and specificity using ML, when applied to an annotated archive of CT scans of the lung. However, there is no consensus on the method applied to determine the efficiency of ML algorithms.">
<link rel="image_src" href="/img/journals/diagnostics-logo.png?cc7fe11b9251f219">
<meta name="dc.title" content="Automatic Pulmonary Nodule Detection Applying Deep Learning or Machine Learning Algorithms to the LIDC-IDRI Database: A Systematic Review">
<meta name="dc.creator" content="Lea Marie Pehrson">
<meta name="dc.creator" content="Michael Bachmann Nielsen">
<meta name="dc.creator" content="Carsten Ammitzbøl Lauridsen">
<meta name="dc.type" content="Review">
<meta name="dc.source" content="Diagnostics 2019, Vol. 9, Page 29">
<meta name="dc.date" content="2019-03-07">
<meta name="dc.identifier" content="10.3390/diagnostics9010029">
<meta name="dc.publisher" content="Multidisciplinary Digital Publishing Institute">
<meta name="dc.rights" content="http://creativecommons.org/licenses/by/3.0/">
<meta name="dc.format" content="application/pdf">
<meta name="dc.language" content="en">
<meta name="dc.description" content="The aim of this study was to provide an overview of the literature available on machine learning (ML) algorithms applied to the Lung Image Database Consortium Image Collection (LIDC-IDRI) database as a tool for the optimization of detecting lung nodules in thoracic CT scans. This systematic review was compiled according to Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Only original research articles concerning algorithms applied to the LIDC-IDRI database were included. The initial search yielded 1972 publications after removing duplicates, and 41 of these articles were included in this study. The articles were divided into two subcategories describing their overall architecture. The majority of feature-based algorithms achieved an accuracy &amp;gt;90% compared to the deep learning (DL) algorithms that achieved an accuracy in the range of 82.2%&amp;ndash;97.6%. In conclusion, ML and DL algorithms are able to detect lung nodules with a high level of accuracy, sensitivity, and specificity using ML, when applied to an annotated archive of CT scans of the lung. However, there is no consensus on the method applied to determine the efficiency of ML algorithms.">
<meta name="dc.subject" content="deep learning">
<meta name="dc.subject" content="machine learning">
<meta name="dc.subject" content="nodule detection">
<meta name="prism.issn" content="2075-4418">
<meta name="prism.publicationName" content="Diagnostics">
<meta name="prism.publicationDate" content="2019-03-07">
<meta name="prism.volume" content="9">
<meta name="prism.number" content="1">
<meta name="prism.section" content="Review">
<meta name="prism.startingPage" content="29">
<meta name="citation_issn" content="2075-4418">
<meta name="citation_journal_title" content="Diagnostics">
<meta name="citation_publisher" content="Multidisciplinary Digital Publishing Institute">
<meta name="citation_title" content="Automatic Pulmonary Nodule Detection Applying Deep Learning or Machine Learning Algorithms to the LIDC-IDRI Database: A Systematic Review">
<meta name="citation_publication_date" content="2019/3">
<meta name="citation_online_date" content="2019/03/07">
<meta name="citation_volume" content="9">
<meta name="citation_issue" content="1">
<meta name="citation_firstpage" content="29">
<meta name="citation_author" content="Pehrson, Lea Marie">
<meta name="citation_author" content="Nielsen, Michael Bachmann">
<meta name="citation_author" content="Ammitzbøl Lauridsen, Carsten">
<meta name="citation_doi" content="10.3390/diagnostics9010029">
<meta name="citation_id" content="mdpi-diagnostics9010029">
<meta name="citation_abstract_html_url" content="https://www.mdpi.com/2075-4418/9/1/29">
<meta name="citation_pdf_url" content="https://www.mdpi.com/2075-4418/9/1/29/pdf?version=1551940425">
<link rel="alternate" type="application/pdf" title="PDF Full-Text" href="https://www.mdpi.com/2075-4418/9/1/29/pdf?version=1551940425">
<meta name="fulltext_pdf" content="https://www.mdpi.com/2075-4418/9/1/29/pdf?version=1551940425">
<meta name="citation_fulltext_html_url" content="https://www.mdpi.com/2075-4418/9/1/29/htm">
<link rel="alternate" type="text/html" title="HTML Full-Text" href="https://www.mdpi.com/2075-4418/9/1/29/htm">
<meta name="fulltext_html" content="https://www.mdpi.com/2075-4418/9/1/29/htm">
<link rel="alternate" type="text/xml" title="XML Full-Text" href="https://www.mdpi.com/2075-4418/9/1/29/xml">
<meta name="fulltext_xml" content="https://www.mdpi.com/2075-4418/9/1/29/xml">
<meta name="citation_xml_url" content="https://www.mdpi.com/2075-4418/9/1/29/xml">
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@MDPIOpenAccess" />
<meta name="twitter:image" content="https://www.mdpi.com/img/journals/diagnostics-logo-sq.png?cc7fe11b9251f219" />
<meta property="fb:app_id" content="131189377574" />
<meta property="og:site_name" content="MDPI" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.mdpi.com/2075-4418/9/1/29" />
<meta property="og:title" content="Automatic Pulmonary Nodule Detection Applying Deep Learning or Machine Learning Algorithms to the LIDC-IDRI Database: A Systematic Review" />
<meta property="og:description" content="The aim of this study was to provide an overview of the literature available on machine learning (ML) algorithms applied to the Lung Image Database Consortium Image Collection (LIDC-IDRI) database as a tool for the optimization of detecting lung nodules in thoracic CT scans. This systematic review was compiled according to Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Only original research articles concerning algorithms applied to the LIDC-IDRI database were included. The initial search yielded 1972 publications after removing duplicates, and 41 of these articles were included in this study. The articles were divided into two subcategories describing their overall architecture. The majority of feature-based algorithms achieved an accuracy &amp;gt;90% compared to the deep learning (DL) algorithms that achieved an accuracy in the range of 82.2%&amp;ndash;97.6%. In conclusion, ML and DL algorithms are able to detect lung nodules with a high level of accuracy, sensitivity, and specificity using ML, when applied to an annotated archive of CT scans of the lung. However, there is no consensus on the method applied to determine the efficiency of ML algorithms." />
<meta property="og:image" content="https://www.mdpi.com/diagnostics/diagnostics-09-00029/article_deploy/html/images/diagnostics-09-00029-g001-550.jpg" />
<link rel="alternate" type="application/rss+xml" title="MDPI Publishing - Latest articles" href="https://www.mdpi.com/rss">
<script type="text/x-mathjax-config">
    MathJax.Hub.processSectionDelay = 0;
      MathJax.Hub.Config({
        menuSettings: {
          CHTMLpreview: false
        },
        "CHTML-preview":{
          disabled: true
        },
        "HTML-CSS": {
          availableFonts: ["TeX"],
          preferredFonts: "TeX",
          webFont:"TeX",
          imageFont:"TeX",
          undefinedFamily:"'Arial Unicode MS',serif"
        },
        "TeX": {
          extensions: ["noErrors.js"],
          noErrors: {
            inlineDelimiters: ["",""],
            multiLine: true,
            style: {
              "font-size":   "90%",
              "text-align":  "left",
              "color":       "black",
              "padding":     "1px 3px",
              "border":      "1px solid"
            }
          }
        }
      });
    </script>
<script type="text/javascript" src="/bundles/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<meta name="google-site-verification" content="PxTlsg7z2S00aHroktQd57fxygEjMiNHydKn3txhvwY">
<meta name="facebook-domain-verification" content="mcoq8dtq6sb2hf7z29j8w515jjoof7" />
<!--[if lt IE 9]>
            <script>var browserIe8 = true;</script>
            <link rel="stylesheet" href="/assets/css/ie8foundationfix.css?8ad845af75faa4fd">
            <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
            <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.2/html5shiv.js"></script>
            <script src="//s3.amazonaws.com/nwapi/nwmatcher/nwmatcher-1.2.5-min.js"></script>
            <script src="//html5base.googlecode.com/svn-history/r38/trunk/js/selectivizr-1.0.3b.js"></script>
            <script src="//cdnjs.cloudflare.com/ajax/libs/respond.js/1.1.0/respond.min.js"></script>
            <script src="/assets/js/ie8/ie8patch.js?9e1d3c689a0471df"></script>
            <script src="/assets/js/ie8/rem.min.js?94b62787dcd6d2f2"></script>            
                                                        <![endif]-->
<script>
                (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

                ga('create', 'UA-5824718-2', 'auto');
                ga('require', 'displayfeatures');
                ga('send', 'pageview');
            </script>
<script>
                (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
                j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
                'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
                })(window,document,'script','dataLayer','GTM-WPK7SW5');
            </script>
<script type="text/javascript">
                _linkedin_partner_id = "2846186";
                window._linkedin_data_partner_ids = window._linkedin_data_partner_ids || [];
                window._linkedin_data_partner_ids.push(_linkedin_partner_id);
                </script><script type="text/javascript">
                (function(){var s = document.getElementsByTagName("script")[0];
                var b = document.createElement("script");
                b.type = "text/javascript";b.async = true;
                b.src = "https://snap.licdn.com/li.lms-analytics/insight.min.js";
                s.parentNode.insertBefore(b, s);})();
            </script>
<noscript>
                <img height="1" width="1" style="display:none;" alt="" src="https://px.ads.linkedin.com/collect/?pid=2846186&fmt=gif" />
            </noscript>
<script async src='/cdn-cgi/bm/cv/669835187/api.js'></script></head>
<body>
<noscript>
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WPK7SW5" height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
<div class="direction direction_right" id="small_right" style="border-right-width: 0px; padding:0;">
<i class="fa fa-caret-right fa-2x"></i>
</div>
<div class="big_direction direction_right" id="big_right" style="border-right-width: 0px;">
<div style="text-align: right;">
Next Article in Journal<br>
<div><a href="/2075-4418/9/1/30">Roles of ERCP in the Early Diagnosis of Pancreatic Cancer</a></div>
</div>
</div>
<div class="direction" id="small_left" style="border-left-width: 0px">
<i class="fa fa-caret-left fa-2x"></i>
</div>
<div class="big_direction" id="big_left" style="border-left-width: 0px;">
<div>
Previous Article in Journal<br>
<div><a href="/2075-4418/9/1/28">4-Pyridoxic Acid/Pyridoxine Ratio in Patients with Type 2 Diabetes is Related to Global Cardiovascular Risk Scores</a></div>
</div>
</div>
<div style="clear: both;"></div>
<div id="menuModal" class="reveal-modal reveal-modal-new reveal-modal-menu" aria-hidden="true" data-reveal role="dialog">
<div class="menu-container">
<div class="UI_NavMenu">
<a href="/about/journals">
<h2>Journals</h2>
</a>
<a href="/topics">
<h2>Topics</h2>
</a>
<div class="content__container ">
<div class="custom-accordion-for-small-screen-link ">
<h2>Information</h2>
</div>
<div class="target-item custom-accordion-for-small-screen-content show-for-medium-up">
<div class="menu-container__links">
<div style="width: 100%; max-width: 200px; float: left;">
<a href="/authors">For Authors</a>
<a href="/reviewers">For Reviewers</a>
<a href="/editors">For Editors</a>
<a href="/librarians">For Librarians</a>
<a href="/publishing_services">For Publishers</a>
<a href="/societies">For Societies</a>
<a href="/conference_organizers">For Conference Organizers</a>
</div>
<div style="width: 100%; max-width: 250px; float: left;">
<a href="/apc">Article Processing Charges</a>
<a href="/openaccess">Open Access Policy</a>
<a href="/ioap">Institutional Open Access Program</a>
<a href="/editorial_process">Editorial Process</a>
<a href="/awards">Awards</a>
<a href="/ethics">Research and Publication Ethics</a>
</div>
</div>
</div>
</div>
<a href="/authors/english">
<h2>Author Services</h2>
</a>
<div class="content__container ">
<div class="custom-accordion-for-small-screen-link ">
<h2>Initiatives</h2>
</div>
<div class="target-item custom-accordion-for-small-screen-content show-for-medium-up">
<div class="menu-container__links">
<div style="width: 100%; float: left;">
<a href="https://sciforum.net" target="_blank" rel="noopener noreferrer">Sciforum</a>
<a href="https://www.mdpi.com/books" target="_blank" rel="noopener noreferrer">MDPI Books</a>
<a href="https://www.preprints.org" target="_blank" rel="noopener noreferrer">Preprints</a>
<a href="https://www.scilit.net" target="_blank" rel="noopener noreferrer">Scilit</a>
<a href="https://sciprofiles.com" target="_blank" rel="noopener noreferrer">SciProfiles</a>
<a href="https://encyclopedia.pub" target="_blank" rel="noopener noreferrer">Encyclopedia</a>
<a href="https://jams.pub" target="_blank" rel="noopener noreferrer">JAMS</a>
<a href="/about/proceedings">Proceedings Series</a>
</div>
</div>
</div>
</div>
<a href="/about">
<h2>About</h2>
</a>
</div>
<div class="menu-container__buttons">
<a class="button UA_SignInUpButton" href="/user/login">Sign In / Sign Up</a>
</div>
</div>
</div>
<div id="captchaModal" class="reveal-modal reveal-modal-new reveal-modal-new--small" data-reveal aria-label="Captcha" aria-hidden="true" role="dialog"></div>
<div id="actionDisabledModal" class="reveal-modal" data-reveal aria-labelledby="actionDisableModalTitle" aria-hidden="true" role="dialog" style="width: 300px;">
<h2 id="actionDisableModalTitle">Notice</h2>
<form action="/email/captcha" method="post" id="emailCaptchaForm">
<div class="row">
<div id="js-action-disabled-modal-text" class="small-12 columns">
</div>
<div id="js-action-disabled-modal-submit" class="small-12 columns" style="margin-top: 10px; display: none;">
You can make submissions to other journals
<a href="https://susy.mdpi.com/user/manuscripts/upload" onclick="ga('send', 'event', 'Submit Paper', 'Send', 'Generic');">here</a>.
</div>
</div>
</form>
<a class="close-reveal-modal" aria-label="Close">
<i class="material-icons">clear</i>
</a>
</div>
<div id="rssNotificationModal" class="reveal-modal reveal-modal-new" data-reveal aria-labelledby="rssNotificationModalTitle" aria-hidden="true" role="dialog">
<div class="row">
<div class="small-12 columns">
<h2 id="rssNotificationModalTitle">Notice</h2>
<p>
You are accessing a machine-readable page. In order to be human-readable, please install an RSS reader.
</p>
</div>
</div>
<div class="row">
<div class="small-12 columns">
<a class="button button--color js-rss-notification-confirm">Continue</a>
<a class="button button--grey" onclick="$(this).closest('.reveal-modal').find('.close-reveal-modal').click(); return false;">Cancel</a>
</div>
</div>
<a class="close-reveal-modal" aria-label="Close">
<i class="material-icons">clear</i>
</a>
</div>
<div id="drop-article-label-openaccess" class="f-dropdown medium" data-dropdown-content aria-hidden="true" tabindex="-1">
<p>
All articles published by MDPI are made immediately available worldwide under an open access license. No special
permission is required to reuse all or part of the article published by MDPI, including figures and tables. For
articles published under an open access Creative Common CC BY license, any part of the article may be reused without
permission provided that the original article is clearly cited.
</p>
</div>
<div id="drop-article-label-feature" class="f-dropdown medium" data-dropdown-content aria-hidden="true" tabindex="-1">
<p>
Feature Papers represent the most advanced research with significant potential for high impact in the field. Feature
Papers are submitted upon individual invitation or recommendation by the scientific editors and undergo peer review
prior to publication.
</p>
<p>
The Feature Paper can be either an original research article, a substantial novel research study that often involves
several techniques or approaches, or a comprehensive review paper with concise and precise updates on the latest
progress in the field that systematically reviews the most exciting advances in scientific literature. This type of
paper provides an outlook on future directions of research or possible applications.
</p>
</div>
<div id="drop-article-label-choice" class="f-dropdown medium" data-dropdown-content aria-hidden="true" tabindex="-1">
<p>
Editor’s Choice articles are based on recommendations by the scientific editors of MDPI journals from around the world.
Editors select a small number of articles recently published in the journal that they believe will be particularly
interesting to authors, or important in this field. The aim is to provide a snapshot of some of the most exciting work
published in the various research areas of the journal.
</p>
</div>
<div id="container">
<noscript>
                    <div id="no-javascript">
                        You seem to have javascript disabled. Please note that many of the page functionalities won't work as expected without javascript enabled.
                    </div>
                </noscript>
<div class="fixed">
<nav class="tab-bar show-for-medium-down">
<div class="row full-width collapse">
<div class="medium-3 small-4 columns">
<a href="/">
<img class="full-size-menu__mdpi-logo" src="/img/design/mdpi-pub-logo-blue-small4.png?fff78193ca41c286" style="max-width: 65px;" title="MDPI Open Access Journals">
</a>
</div>
<div class="medium-3 small-4 columns right-aligned">
<div class="show-for-medium-down">
<a href="#" style="display: none;">
<i class="material-icons" onclick="$('#menuModal').foundation('reveal', 'close'); return false;">clear</i>
</a>
<a href="#" class="js-open-small-search open-small-search">
<i class="material-icons show-for-small only">search</i>
</a>
<a title="MDPI main page" class="js-open-menu" data-reveal-id="menuModal" href="#">
<i class="material-icons">menu</i>
</a>
</div>
</div>
</div>
</nav>
</div>
<section class="main-section">
<header>
<div class="full-size-menu show-for-large-up">
<div class="row full-width">
<div class="large-1 columns">
<a href="/">
<img class="full-size-menu__mdpi-logo" src="/img/design/mdpi-pub-logo-blue-small4.png?fff78193ca41c286" title="MDPI Open Access Journals">
</a>
</div>
<div class="large-8 columns text-right UI_NavMenu">
<ul>
<li class="menu-item">
<a href="/about/journals">Journals</a>
</li>
<li class="menu-item">
<a href="/topics">Topics</a>
</li>
<li class="menu-item">
<a href="/authors" data-dropdown="information-dropdown" aria-controls="information-dropdown" aria-expanded="false" data-options="is_hover:true; hover_timeout:200">Information</a>
<ul id="information-dropdown" class="f-dropdown dropdown-wrapper" data-dropdown-content aria-hidden="true" tabindex="-1">
<li>
<div class="row">
<div class="small-5 columns right-border">
<ul>
<li>
<a href="/authors">For Authors</a>
</li>
<li>
<a href="/reviewers">For Reviewers</a>
</li>
<li>
<a href="/editors">For Editors</a>
</li>
<li>
<a href="/librarians">For Librarians</a>
</li>
<li>
<a href="/publishing_services">For Publishers</a>
</li>
<li>
<a href="/societies">For Societies</a>
</li>
<li>
<a href="/conference_organizers">For Conference Organizers</a>
</li>
</ul>
</div>
<div class="small-7 columns">
<ul>
<li>
<a href="/apc">Article Processing Charges</a>
</li>
<li>
<a href="/openaccess">Open Access Policy</a>
 </li>
<li>
<a href="/ioap">Institutional Open Access Program</a>
</li>
<li>
<a href="/editorial_process">Editorial Process</a>
</li>
<li>
<a href="/awards">Awards</a>
</li>
<li>
<a href="/ethics">Research and Publication Ethics</a>
</li>
</ul>
</div>
</div>
</li>
</ul>
</li>
<li class="menu-item">
<a href="/authors/english">Author Services</a>
</li>
<li class="menu-item">
<a href="/about/initiatives" data-dropdown="initiatives-dropdown" aria-controls="initiatives-dropdown" aria-expanded="false" data-options="is_hover: true; hover_timeout: 200">Initiatives</a>
<ul id="initiatives-dropdown" class="f-dropdown dropdown-wrapper dropdown-wrapper__small" data-dropdown-content aria-hidden="true" tabindex="-1">
<li>
<div class="row">
<div class="small-12 columns">
<ul>
<li>
<a href="https://sciforum.net" target="_blank" rel="noopener noreferrer">
Sciforum
</a>
</li>
<li>
<a href="https://www.mdpi.com/books" target="_blank" rel="noopener noreferrer">
MDPI Books
</a>
</li>
<li>
<a href="https://www.preprints.org" target="_blank" rel="noopener noreferrer">
Preprints
</a>
</li>
<li>
<a href="https://www.scilit.net" target="_blank" rel="noopener noreferrer">
Scilit
</a>
</li>
<li>
<a href="https://sciprofiles.com" target="_blank" rel="noopener noreferrer">
SciProfiles
</a>
</li>
<li>
<a href="https://encyclopedia.pub" target="_blank" rel="noopener noreferrer">
Encyclopedia
</a>
</li>
<li>
<a href="https://jams.pub" target="_blank" rel="noopener noreferrer">
JAMS
</a>
</li>
<li>
<a href="/about/proceedings">
Proceedings Series
</a>
</li>
</ul>
</div>
</div>
</li>
</ul>
</li>
<li class="menu-item">
<a href="/about">About</a>
</li>
</ul>
</div>
<div class="large-3 columns text-right full-size-menu__buttons">
<div>
<a class="button button--default-inversed UA_SignInUpButton" href="/user/login">Sign In / Sign Up</a>
<a class="button button--default js-journal-active-only-link js-journal-active-only-submit-link UC_NavSubmitButton" href="https://susy.mdpi.com/user/manuscripts/upload?journal=diagnostics" onclick="ga('send', 'event', 'Submit Paper', 'Send', 'Diagnostics');" data-disabledmessage="new submissions are not possible.">Submit</a>
</div>
</div>
</div>
</div>
 <div class="search-container hide-for-small-down row search-container__default-scheme">
<form id="basic_search" style="background-color: inherit !important;" class="large-12 medium-12 columns " action="/search" method="get">
<div class="row search-container__main-elements">
<div class="large-2 medium-2 small-12 columns text-right1 small-only-text-left">
<div class="show-for-medium-up">
<div class="search-input-label">&nbsp;</div>
</div>
<span class="search-container__title">Search<span class="hide-for-medium"> for Articles</span><span class="hide-for-small">:</span></span>
</div>
<div class="custom-accordion-for-small-screen-content">
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Title / Keyword</div>
</div>
<input type="text" placeholder="Title / Keyword" id="q" tabindex="1" name="q" value="" />
</div>
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Author / Affiliation</div>
</div>
<input type="text" id="authors" placeholder="Author / Affiliation" tabindex="2" name="authors" value="" />
</div>
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Journal</div>
</div>
<select id="journal" tabindex="3" name="journal" class="chosen-select">
<option value="">All Journals</option>
<option value="acoustics">
Acoustics
</option>
<option value="actuators">
Actuators
</option>
<option value="admsci">
Administrative Sciences
</option>
<option value="adolescents">
Adolescents
</option>
<option value="aerospace">
Aerospace
</option>
<option value="agriculture">
Agriculture
</option>
<option value="agriengineering">
AgriEngineering
</option>
<option value="agronomy">
Agronomy
</option>
<option value="ai">
AI
</option>
<option value="algorithms">
Algorithms
</option>
<option value="allergies">
Allergies
</option>
<option value="alloys">
Alloys
</option>
<option value="analytica">
Analytica
</option>
<option value="anatomia">
Anatomia
</option>
<option value="animals">
Animals
</option>
<option value="antibiotics">
Antibiotics
</option>
<option value="antibodies">
Antibodies
</option>
<option value="antioxidants">
Antioxidants
</option>
<option value="applbiosci">
Applied Biosciences
</option>
<option value="applmech">
Applied Mechanics
</option>
<option value="applmicrobiol">
Applied Microbiology
</option>
<option value="applnano">
Applied Nano
</option>
<option value="applsci">
Applied Sciences
</option>
<option value="asi">
Applied System Innovation (ASI)
</option>
<option value="appliedchem">
AppliedChem
</option>
<option value="appliedmath">
AppliedMath
</option>
<option value="aquacj">
Aquaculture Journal
</option>
<option value="architecture">
Architecture
</option>
<option value="arts">
Arts
</option>
<option value="astronomy">
Astronomy
</option>
<option value="atmosphere">
Atmosphere
</option>
<option value="atoms">
Atoms
</option>
<option value="audiolres">
Audiology Research
</option>
<option value="automation">
Automation
</option>
<option value="axioms">
Axioms
</option>
<option value="bacteria">
Bacteria
</option>
<option value="batteries">
Batteries
</option>
<option value="behavsci">
Behavioral Sciences
</option>
<option value="beverages">
Beverages
</option>
<option value="BDCC">
Big Data and Cognitive Computing (BDCC)
</option>
<option value="biochem">
BioChem
</option>
<option value="bioengineering">
Bioengineering
</option>
<option value="biologics">
Biologics
</option>
<option value="biology">
Biology
</option>
<option value="blsf">
Biology and Life Sciences Forum
</option>
<option value="biomass">
Biomass
</option>
<option value="biomechanics">
Biomechanics
</option>
<option value="biomed">
BioMed
</option>
<option value="biomedicines">
Biomedicines
</option>
<option value="biomedinformatics">
BioMedInformatics
</option>
<option value="biomimetics">
Biomimetics
</option>
<option value="biomolecules">
Biomolecules
</option>
<option value="biophysica">
Biophysica
</option>
<option value="biosensors">
Biosensors
</option>
 <option value="biotech">
BioTech
</option>
<option value="birds">
Birds
</option>
<option value="brainsci">
Brain Sciences
</option>
<option value="buildings">
Buildings
</option>
<option value="businesses">
Businesses
</option>
<option value="carbon">
C
</option>
<option value="cancers">
Cancers
</option>
<option value="cardiogenetics">
Cardiogenetics
</option>
<option value="catalysts">
Catalysts
</option>
<option value="cells">
Cells
</option>
<option value="ceramics">
Ceramics
</option>
<option value="challenges">
Challenges
</option>
<option value="ChemEngineering">
ChemEngineering
</option>
<option value="chemistry">
Chemistry
</option>
<option value="chemproc">
Chemistry Proceedings
</option>
<option value="chemosensors">
Chemosensors
</option>
<option value="children">
Children
</option>
<option value="chips">
Chips
</option>
<option value="civileng">
CivilEng
</option>
<option value="cleantechnol">
Clean Technologies (Clean Technol.)
</option>
<option value="climate">
Climate
</option>
<option value="ctn">
Clinical and Translational Neuroscience (CTN)
</option>
<option value="clinpract">
Clinics and Practice
</option>
<option value="clockssleep">
Clocks &amp; Sleep
</option>
<option value="coasts">
Coasts
</option>
<option value="coatings">
Coatings
</option>
<option value="colloids">
Colloids and Interfaces
</option>
<option value="colorants">
Colorants
</option>
<option value="compounds">
Compounds
</option>
<option value="computation">
Computation
</option>
<option value="csmf">
Computer Sciences &amp; Mathematics Forum
</option>
<option value="computers">
Computers
</option>
<option value="condensedmatter">
Condensed Matter
</option>
<option value="conservation">
Conservation
</option>
<option value="constrmater">
Construction Materials
</option>
<option value="cmd">
Corrosion and Materials Degradation (CMD)
</option>
<option value="cosmetics">
Cosmetics
</option>
<option value="covid">
COVID
</option>
<option value="crops">
Crops
</option>
<option value="cryptography">
Cryptography
</option>
<option value="crystals">
Crystals
</option>
<option value="cimb">
Current Issues in Molecular Biology (CIMB)
</option>
<option value="curroncol">
Current Oncology
</option>
<option value="dairy">
Dairy
</option>
<option value="data">
Data
</option>
<option value="dentistry">
Dentistry Journal
</option>
<option value="dermato">
Dermato
</option>
<option value="dermatopathology">
Dermatopathology
</option>
<option value="designs">
Designs
</option>
<option value="diabetology">
Diabetology
</option>
<option value="diagnostics" selected='selected'>
Diagnostics
</option>
<option value="dietetics">
Dietetics
</option>
<option value="digital">
Digital
</option>
<option value="disabilities">
Disabilities
</option>
<option value="diseases">
Diseases
</option>
<option value="diversity">
Diversity
</option>
<option value="dna">
DNA
</option>
<option value="drones">
Drones
</option>
<option value="dynamics">
Dynamics
</option>
<option value="earth">
Earth
</option>
<option value="ecologies">
Ecologies
</option>
<option value="econometrics">
Econometrics
</option>
<option value="economies">
Economies
</option>
<option value="education">
Education Sciences
</option>
<option value="electricity">
Electricity
</option>
<option value="electrochem">
Electrochem
</option>
<option value="electronicmat">
Electronic Materials
</option>
<option value="electronics">
Electronics
</option>
<option value="encyclopedia">
Encyclopedia
</option>
<option value="endocrines">
Endocrines
</option>
<option value="energies">
Energies
</option>
<option value="eng">
Eng
</option>
<option value="engproc">
Engineering Proceedings
</option>
<option value="entomology">
Entomology
</option>
<option value="entropy">
Entropy
</option>
<option value="environsciproc">
Environmental Sciences Proceedings
</option>
<option value="environments">
Environments
</option>
<option value="epidemiologia">
Epidemiologia
</option>
<option value="epigenomes">
Epigenomes
</option>
<option value="ebj">
European Burn Journal (EBJ)
</option>
<option value="ejihpe">
European Journal of Investigation in Health, Psychology and Education (EJIHPE)
</option>
<option value="fermentation">
Fermentation
</option>
<option value="fibers">
Fibers
</option>
<option value="fintech">
FinTech
</option>
<option value="fire">
Fire
</option>
<option value="fishes">
Fishes
</option>
<option value="fluids">
Fluids
</option>
<option value="foods">
Foods
</option>
<option value="forecasting">
Forecasting
</option>
<option value="forensicsci">
Forensic Sciences
</option>
<option value="forests">
Forests
</option>
<option value="foundations">
Foundations
</option>
<option value="fractalfract">
Fractal and Fractional (Fractal Fract)
</option>
<option value="fuels">
Fuels
</option>
<option value="futureinternet">
Future Internet
</option>
<option value="futurepharmacol">
Future Pharmacology
</option>
<option value="futuretransp">
Future Transportation
</option>
<option value="galaxies">
Galaxies
</option>
<option value="games">
Games
</option>
<option value="gases">
Gases
</option>
<option value="gastroent">
Gastroenterology Insights
</option>
<option value="gastrointestdisord">
Gastrointestinal Disorders
</option>
<option value="gels">
Gels
</option>
<option value="genealogy">
Genealogy
</option>
<option value="genes">
Genes
</option>
<option value="geographies">
Geographies
</option>
<option value="geohazards">
GeoHazards
</option>
<option value="geomatics">
Geomatics
</option>
<option value="geosciences">
Geosciences
</option>
<option value="geotechnics">
Geotechnics
</option>
<option value="geriatrics">
Geriatrics
</option>
<option value="healthcare">
Healthcare
</option>
<option value="hearts">
Hearts
</option>
<option value="hemato">
Hemato
</option>
<option value="hematolrep">
Hematology Reports
</option>
<option value="heritage">
Heritage
</option>
<option value="histories">
Histories
</option>
<option value="horticulturae">
Horticulturae
</option>
<option value="humanities">
Humanities
</option>
<option value="humans">
Humans
</option>
<option value="hydrobiology">
Hydrobiology
</option>
<option value="hydrogen">
Hydrogen
</option>
<option value="hydrology">
Hydrology
</option>
<option value="hygiene">
Hygiene
</option>
<option value="immuno">
Immuno
</option>
<option value="idr">
Infectious Disease Reports
</option>
<option value="informatics">
Informatics
</option>
<option value="information">
Information
</option>
<option value="infrastructures">
Infrastructures
</option>
<option value="inorganics">
Inorganics
</option>
<option value="insects">
Insects
</option>
<option value="instruments">
Instruments
</option>
<option value="ijerph">
International Journal of Environmental Research and Public Health (IJERPH)
</option>
<option value="ijfs">
International Journal of Financial Studies (IJFS)
</option>
<option value="ijms">
International Journal of Molecular Sciences (IJMS)
</option>
<option value="IJNS">
International Journal of Neonatal Screening (IJNS)
</option>
<option value="ijpb">
International Journal of Plant Biology (IJPB)
</option>
<option value="ijtm">
International Journal of Translational Medicine (IJTM)
</option>
<option value="ijtpp">
International Journal of Turbomachinery, Propulsion and Power (IJTPP)
</option>
<option value="inventions">
Inventions
</option>
<option value="IoT">
IoT
</option>
<option value="ijgi">
ISPRS International Journal of Geo-Information (IJGI)
</option>
<option value="J">
J
</option>
<option value="jal">
Journal of Ageing and Longevity (JAL)
</option>
<option value="jcdd">
Journal of Cardiovascular Development and Disease (JCDD)
</option>
<option value="jcm">
Journal of Clinical Medicine (JCM)
</option>
<option value="jcs">
Journal of Composites Science (J. Compos. Sci.)
</option>
<option value="jcp">
Journal of Cybersecurity and Privacy (JCP)
</option>
<option value="jdb">
Journal of Developmental Biology (JDB)
</option>
<option value="jfb">
Journal of Functional Biomaterials (JFB)
</option>
<option value="jfmk">
Journal of Functional Morphology and Kinesiology (JFMK)
</option>
<option value="jof">
Journal of Fungi (JoF)
</option>
<option value="jimaging">
Journal of Imaging (J. Imaging)
</option>
<option value="jintelligence">
Journal of Intelligence (J. Intell.)
</option>
<option value="jlpea">
Journal of Low Power Electronics and Applications (JLPEA)
</option>
<option value="jmmp">
Journal of Manufacturing and Materials Processing (JMMP)
</option>
<option value="jmse">
Journal of Marine Science and Engineering (JMSE)
</option>
<option value="jmp">
Journal of Molecular Pathology (JMP)
</option>
<option value="jnt">
Journal of Nanotheranostics (JNT)
</option>
<option value="jne">
Journal of Nuclear Engineering (JNE)
</option>
<option value="JOItmC">
Journal of Open Innovation: Technology, Market, and Complexity (JOItmC)
</option>
<option value="ohbm">
Journal of Otorhinolaryngology, Hearing and Balance Medicine (OHBM)
</option>
<option value="jpm">
Journal of Personalized Medicine (JPM)
</option>
<option value="jor">
Journal of Respiration (JoR)
</option>
<option value="jrfm">
Journal of Risk and Financial Management (JRFM)
</option>
<option value="jsan">
Journal of Sensor and Actuator Networks (JSAN)
</option>
<option value="jtaer">
Journal of Theoretical and Applied Electronic Commerce Research (JTAER)
</option>
<option value="jox">
Journal of Xenobiotics (JoX)
</option>
<option value="jzbg">
Journal of Zoological and Botanical Gardens (JZBG)
</option>
<option value="journalmedia">
Journalism and Media
</option>
<option value="kidneydial">
Kidney and Dialysis
</option>
<option value="knowledge">
Knowledge
</option>
<option value="land">
Land
</option>
<option value="languages">
Languages
</option>
<option value="laws">
Laws
</option>
<option value="life">
Life
</option>
<option value="liquids">
Liquids
</option>
<option value="literature">
Literature
</option>
<option value="livers">
Livers
</option>
<option value="logics">
Logics
</option>
<option value="logistics">
Logistics
</option>
<option value="lubricants">
Lubricants
</option>
<option value="make">
Machine Learning and Knowledge Extraction (MAKE)
</option>
<option value="machines">
Machines
</option>
<option value="macromol">
Macromol
</option>
<option value="magnetism">
Magnetism
</option>
<option value="magnetochemistry">
Magnetochemistry
</option>
<option value="marinedrugs">
Marine Drugs
</option>
<option value="materials">
Materials
</option>
<option value="materproc">
Materials Proceedings
</option>
<option value="mca">
Mathematical and Computational Applications (MCA)
</option>
<option value="mathematics">
Mathematics
</option>
<option value="medsci">
Medical Sciences
</option>
<option value="msf">
Medical Sciences Forum
</option>
<option value="medicina">
Medicina
</option>
<option value="medicines">
Medicines
</option>
<option value="membranes">
Membranes
</option>
<option value="merits">
Merits
</option>
<option value="metabolites">
Metabolites
</option>
<option value="metals">
Metals
</option>
<option value="meteorology">
Meteorology
</option>
 <option value="methane">
Methane
</option>
<option value="mps">
Methods and Protocols (MPs)
</option>
<option value="metrology">
Metrology
</option>
<option value="micro">
Micro
</option>
<option value="microbiolres">
Microbiology Research
</option>
<option value="micromachines">
Micromachines
</option>
<option value="microorganisms">
Microorganisms
</option>
<option value="microplastics">
Microplastics
</option>
<option value="minerals">
Minerals
</option>
<option value="mining">
Mining
</option>
<option value="modelling">
Modelling
</option>
<option value="molbank">
Molbank
</option>
<option value="molecules">
Molecules
</option>
<option value="mti">
Multimodal Technologies and Interaction (MTI)
</option>
<option value="muscles">
Muscles
</option>
<option value="nanoenergyadv">
Nanoenergy Advances
</option>
<option value="nanomanufacturing">
Nanomanufacturing
</option>
<option value="nanomaterials">
Nanomaterials
</option>
<option value="network">
Network
</option>
<option value="neuroglia">
Neuroglia
</option>
<option value="neurolint">
Neurology International
</option>
<option value="neurosci">
NeuroSci
</option>
<option value="nitrogen">
Nitrogen
</option>
<option value="ncrna">
Non-Coding RNA (ncRNA)
</option>
<option value="nursrep">
Nursing Reports
</option>
<option value="nutraceuticals">
Nutraceuticals
</option>
<option value="nutrients">
Nutrients
</option>
<option value="obesities">
Obesities
</option>
<option value="oceans">
Oceans
</option>
<option value="onco">
Onco
</option>
<option value="optics">
Optics
</option>
<option value="oral">
Oral
</option>
<option value="organics">
Organics
</option>
<option value="organoids">
Organoids
</option>
<option value="osteology">
Osteology
</option>
<option value="oxygen">
Oxygen
</option>
<option value="parasitologia">
Parasitologia
</option>
<option value="particles">
Particles
</option>
<option value="pathogens">
Pathogens
</option>
<option value="pathophysiology">
Pathophysiology
</option>
<option value="pediatrrep">
Pediatric Reports
</option>
<option value="pharmaceuticals">
Pharmaceuticals
</option>
<option value="pharmaceutics">
Pharmaceutics
</option>
<option value="pharmacoepidemiology">
Pharmacoepidemiology
</option>
<option value="pharmacy">
Pharmacy
</option>
<option value="philosophies">
Philosophies
</option>
<option value="photochem">
Photochem
</option>
<option value="photonics">
Photonics
</option>
<option value="phycology">
Phycology
</option>
<option value="physchem">
Physchem
</option>
<option value="psf">
Physical Sciences Forum
</option>
<option value="physics">
Physics
</option>
<option value="physiologia">
Physiologia
</option>
<option value="plants">
Plants
</option>
<option value="plasma">
Plasma
</option>
<option value="pollutants">
Pollutants
</option>
<option value="polymers">
Polymers
</option>
<option value="polysaccharides">
Polysaccharides
</option>
<option value="poultry">
Poultry
</option>
<option value="powders">
Powders
</option>
<option value="proceedings">
Proceedings
</option>
<option value="processes">
Processes
</option>
<option value="prosthesis">
Prosthesis
</option>
<option value="proteomes">
Proteomes
</option>
<option value="psych">
Psych
</option>
<option value="psychiatryint">
Psychiatry International
</option>
<option value="publications">
Publications
</option>
<option value="qubs">
Quantum Beam Science (QuBS)
</option>
<option value="quantumrep">
Quantum Reports
</option>
<option value="quaternary">
Quaternary
</option>
<option value="radiation">
Radiation
</option>
<option value="reactions">
Reactions
</option>
<option value="recycling">
Recycling
</option>
<option value="religions">
Religions
</option>
<option value="remotesensing">
Remote Sensing
</option>
<option value="reports">
Reports
</option>
<option value="reprodmed">
Reproductive Medicine (Reprod. Med.)
</option>
<option value="resources">
Resources
</option>
<option value="rheumato">
Rheumato
</option>
<option value="risks">
Risks
</option>
<option value="robotics">
Robotics
</option>
<option value="ruminants">
Ruminants
</option>
<option value="safety">
Safety
</option>
<option value="sci">
Sci
</option>
<option value="scipharm">
Scientia Pharmaceutica (Sci. Pharm.)
</option>
<option value="seeds">
Seeds
</option>
<option value="sensors">
Sensors
</option>
<option value="separations">
Separations
</option>
<option value="sexes">
Sexes
</option>
<option value="signals">
Signals
</option>
<option value="sinusitis">
Sinusitis
</option>
<option value="smartcities">
Smart Cities
</option>
<option value="socsci">
Social Sciences
</option>
<option value="societies">
Societies
</option>
<option value="software">
Software
</option>
<option value="soilsystems">
Soil Systems
</option>
<option value="solar">
Solar
</option>
<option value="solids">
Solids
</option>
<option value="sports">
Sports
</option>
<option value="standards">
Standards
</option>
<option value="stats">
Stats
</option>
<option value="stresses">
Stresses
</option>
<option value="surfaces">
Surfaces
</option>
<option value="surgeries">
Surgeries
</option>
<option value="std">
Surgical Techniques Development
</option>
<option value="sustainability">
Sustainability
</option>
<option value="suschem">
Sustainable Chemistry
</option>
<option value="symmetry">
Symmetry
</option>
<option value="synbio">
SynBio
</option>
<option value="systems">
Systems
</option>
<option value="taxonomy">
Taxonomy
</option>
<option value="technologies">
Technologies
</option>
<option value="telecom">
Telecom
</option>
<option value="textiles">
Textiles
</option>
<option value="thalassrep">
Thalassemia Reports
</option>
<option value="thermo">
Thermo
</option>
<option value="tomography">
Tomography
</option>
<option value="tourismhosp">
Tourism and Hospitality
</option>
<option value="toxics">
Toxics
</option>
<option value="toxins">
Toxins
</option>
<option value="transplantology">
Transplantology
</option>
<option value="traumacare">
Trauma Care
</option>
<option value="tropicalmed">
Tropical Medicine and Infectious Disease (TropicalMed)
</option>
<option value="universe">
Universe
</option>
<option value="urbansci">
Urban Science
</option>
<option value="uro">
Uro
</option>
<option value="vaccines">
Vaccines
</option>
<option value="vehicles">
Vehicles
</option>
<option value="venereology">
Venereology
</option>
<option value="vetsci">
Veterinary Sciences
</option>
<option value="vibration">
Vibration
</option>
<option value="viruses">
Viruses
</option>
<option value="vision">
Vision
</option>
<option value="water">
Water
</option>
<option value="wind">
Wind
</option>
<option value="women">
Women
</option>
<option value="world">
World
</option>
<option value="wevj">
World Electric Vehicle Journal (WEVJ)
</option>
<option value="youth">
Youth
</option>
<option value="zoonoticdis">
Zoonotic Diseases
</option>
</select>
</div>
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Article Type</div>
</div>
<select id="article_type" tabindex="4" name="article_type" class="chosen-select">
<option value="">All Article Types</option>
<option value="research-article">Article</option>
<option value="review-article">Review</option>
<option value="rapid-communication">Communication</option>
<option value="editorial">Editorial</option>
<option value="book-review">Book Review</option>
<option value="brief-report">Brief Report</option>
<option value="case-report">Case Report</option>
<option value="article-commentary">Comment</option>
<option value="commentary">Commentary</option>
<option value="concept-paper">Concept Paper</option>
<option value="conference-report">Conference Report</option>
<option value="correction">Correction</option>
<option value="creative">Creative</option>
<option value="data-descriptor">Data Descriptor</option>
<option value="discussion">Discussion</option>
<option value="Entry">Entry</option>
<option value="essay">Essay</option>
<option value="expression-of-concern">Expression of Concern</option>
<option value="extended-abstract">Extended Abstract</option>
<option value="guidelines">Guidelines</option>
<option value="hypothesis">Hypothesis</option>
<option value="interesting-image">Interesting Images</option>
<option value="letter">Letter</option>
<option value="books-received">New Book Received</option>
<option value="obituary">Obituary</option>
<option value="opinion">Opinion</option>
<option value="perspective">Perspective</option>
<option value="proceedings">Proceeding Paper</option>
<option value="project-report">Project Report</option>
<option value="protocol">Protocol</option>
<option value="registered-report">Registered Report</option>
<option value="reply">Reply</option>
<option value="retraction">Retraction</option>
<option value="note">Short Note</option>
<option value="study-protocol">Study Protocol</option>
<option value="systematic_review">Systematic Review</option>
<option value="technical-note">Technical Note</option>
<option value="tutorial">Tutorial</option>
<option value="viewpoint">Viewpoint</option>
</select>
</div>
<div class="large-1 medium-1 small-6 end columns small-push-6 medium-reset-order large-reset-order js-search-collapsed-button-container">
<div class="search-input-label">&nbsp;</div>
<input type="submit" id="search" value="Search" class="button button--dark button--full-width searchButton1 US_SearchButton" tabindex="12">
</div>
<div class="large-1 medium-1 small-6 end columns large-text-left small-only-text-center small-pull-6 medium-reset-order large-reset-order js-search-collapsed-link-container">
<div class="search-input-label">&nbsp;</div>
<a class="main-search-clear search-container__link" href="#" onclick="openAdvanced(''); return false;">Advanced<span class="show-for-small-only"> Search</span></a>
</div>
</div>
</div>
<div class="search-container__advanced" style="margin-top: 0; padding-top: 0px; background-color: inherit; color: inherit;">
<div class="row">
<div class="large-2 medium-2 columns show-for-medium-up">&nbsp;</div>
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Section</div>
</div>
<select id="section" tabindex="5" name="section" class="chosen-select">
<option value=""></option>
</select>
</div>
<div class="large-2 medium-2 small-6 columns ">
<div class="">
<div class="search-input-label">Special Issue</div>
</div>
<select id="special_issue" tabindex="6" name="special_issue" class="chosen-select">
<option value=""></option>
</select>
</div>
<div class="large-1 medium-1 small-6 end columns ">
<div class="search-input-label">Volume</div>
<input type="text" id="volume" tabindex="7" name="volume" placeholder="..." value="9" />
</div>
<div class="large-1 medium-1 small-6 end columns ">
<div class="search-input-label">Issue</div>
<input type="text" id="issue" tabindex="8" name="issue" placeholder="..." value="1" />
</div>
<div class="large-1 medium-1 small-6 end columns ">
<div class="search-input-label">Number</div>
<input type="text" id="number" tabindex="9" name="number" placeholder="..." value="" />
</div>
<div class="large-1 medium-1 small-6 end columns ">
<div class="search-input-label">Page</div>
<input type="text" id="page" tabindex="10" name="page" placeholder="..." value="" />
</div>
<div class="large-1 medium-1 small-6 columns small-push-6 medium-reset order large-reset-order medium-reset-order js-search-expanded-button-container"></div>
<div class="large-1 medium-1 small-6 columns large-text-left small-only-text-center small-pull-6 medium-reset-order large-reset-order js-search-expanded-link-container"></div>
</div>
</div>
</form>
<form id="advanced-search" class="large-12 medium-12 columns">
<div class="search-container__advanced">
<div id="advanced-search-template" class="row advanced-search-row">
<div class="large-2 medium-2 small-12 columns show-for-medium-up">&nbsp;</div>
<div class="large-2 medium-2 small-3 columns connector-div">
<div class="search-input-label"><span class="show-for-medium-up">Logical Operator</span><span class="show-for-small">Operator</span></div>
<select class="connector">
<option value="and">AND</option>
<option value="or">OR</option>
</select>
</div>
<div class="large-3 medium-3 small-6 columns search-text-div">
<div class="search-input-label">Search Text</div>
<input type="text" class="search-text" placeholder="Search text">
</div>
<div class="large-2 medium-2 small-6 large-offset-0 medium-offset-0 small-offset-3 columns search-field-div">
<div class="search-input-label">Search Type</div>
<select class="search-field">
<option value="all">All fields</option>
<option value="title">Title</option>
<option value="abstract">Abstract</option>
<option value="keywords">Keywords</option>
<option value="authors">Authors</option>
 <option value="affiliations">Affiliations</option>
<option value="doi">Doi</option>
<option value="full_text">Full Text</option>
<option value="references">References</option>
</select>
</div>
<div class="large-1 medium-1 small-3 columns">
<div class="search-input-label">&nbsp;</div>
<div class="search-action-div">
<div class="search-plus">
<i class="material-icons">add_circle_outline</i>
</div>
</div>
<div class="search-action-div">
<div class="search-minus">
<i class="material-icons">remove_circle_outline</i>
</div>
</div>
</div>
<div class="large-1 medium-1 small-6 large-offset-0 medium-offset-0 small-offset-3 end columns">
<div class="search-input-label">&nbsp;</div>
<input class="advanced-search-button button button--dark search-submit" type="submit" value="Search">
</div>
<div class="large-1 medium-1 small-6 end columns show-for-medium-up"></div>
</div>
</div>
</form>
</div>
<div class="breadcrumb row full-row">
<div class="breadcrumb__element">
<a href="/about/journals">Journals</a>
</div>
<div class="breadcrumb__element">
<a href="/journal/diagnostics">Diagnostics</a>
</div>
<div class="breadcrumb__element">
<a href="/2075-4418/9">Volume 9</a>
</div>
<div class="breadcrumb__element">
<a href="/2075-4418/9/1">Issue 1</a>
</div>
<div class="breadcrumb__element">
<a href="#">10.3390/diagnostics9010029</a>
</div>
</div>
</header>
<div id="main-content" class="">
<div class="row full-width row-fixed-left-column">
<div id="left-column" class="content__column large-3 medium-3 small-12 columns">
<div class="content__container">
<a href="/journal/diagnostics">
<img src="/img/journals/diagnostics-logo.png?cc7fe11b9251f219" alt="diagnostics-logo" title="Diagnostics" style="max-height: 60px; margin: 0 0 0 0;">
</a>
<div class="generic-item no-border">
<a class="button button--color button--full-width js-journal-active-only-link js-journal-active-only-submit-link UC_ArticleSubmitButton" href="https://susy.mdpi.com/user/manuscripts/upload?form%5Bjournal_id%5D%3D41" onclick="ga('send', 'event', 'Submit Paper', 'Send', 'Diagnostics');" data-disabledmessage="creating new submissions is not possible.">
Submit to this Journal
</a>
<a class="button button--color button--full-width js-journal-active-only-link UC_ArticleReviewButton" href="https://susy.mdpi.com/volunteer/journals/review" data-disabledmessage="volunteering as journal reviewer is not possible.">
Review for this Journal
</a>
<a class="button button--color-inversed button--full-width js-journal-active-only-link UC_ArticleEditIssueButton" href="/journalproposal/sendproposalspecialissue/diagnostics" data-path="/2075-4418/9/1/29/htm" data-disabledmessage="proposing new special issue is not possible.">
Edit a Special Issue
</a>
</div>
<div class="generic-item link-article-menu show-for-small">
<a href="#" class="link-article-menu show-for-small">
<span class="closed">&#9658;</span>
<span class="open" style="display: none;">&#9660;</span>
Article Menu
</a>
</div>
<div class="hide-small-down-initially UI_ArticleMenu">
<div class="generic-item">
<h2>Article Menu</h2>
</div>
<ul class="accordion accordion__menu" data-accordion data-options="multi_expand:false;toggleable: true">
<li class="accordion-navigation">
<a href="#overview" class="accordion__title">Article Overview</a>
<div id="overview" class="content  UI_ArticleMenu_Overview">
<ul>
<li>
<a href="/2075-4418/9/1/29#abstract">Abstract</a>
</li>
<li>
<a href="/openaccess">Open Access and Permissions</a>
</li>
<li>
<a href="/2075-4418/9/1/29#cite">Share and Cite</a>
</li>
<li>
<a href="/2075-4418/9/1/29#metrics">Article Metrics</a>
</li>
<li>
<a href="/2075-4418/9/1/29/reprints">Order Article Reprints</a>
</li>
</ul>
</div>
</li>
<li class="accordion-navigation">
<a href="#versions-div" class="accordion__title">Article Versions</a>
<div id="versions-div" class="content  UI_ArticleMenu_Versions">
<ul>
<li>
<a href="/2075-4418/9/1/29">Abstract</a>
</li>
<li>
<a href="/2075-4418/9/1/29/notes" onclick="ga('send', 'pageview', '/2075-4418/9/1/29/notes');">Article Versions Notes</a>
</li>
<li>
<a href="/2075-4418/9/1/29/htm" onclick="ga('send', 'pageview', $(this).attr('href'));" id="html_link">Full-Text HTML</a>
</li>
<li class="li-download">
<a href="/2075-4418/9/1/29/pdf?version=1551940425" onclick="ga('send', 'pageview', $(this).attr('href'));" id="pdf_link">Full-Text PDF</a>
</li>
<li class="li-download">
<a id="js-xml-access-captcha" href="#" data-target="/2075-4418/9/1/29/xml" class="accessCaptcha" onclick="ga('send', 'pageview', '/2075-4418/9/1/29/xml');">Full-Text XML</a>
</li>
<li class="li-download">
<a href="/2075-4418/9/1/29/epub" onclick="ga('send', 'pageview', '/2075-4418/9/1/29/epub');" id="epub_link">Full-Text Epub</a>
</li>
</ul>
</div>
</li>
<li class="accordion-navigation">
<a href="#related" class="accordion__title">Related Info Links</a>
<div id="related" class="content  UI_ArticleMenu_RelatedLinks">
<ul>
<li class="li-link">
<a href="https://www.ncbi.nlm.nih.gov/sites/entrez/30866425" target="_blank" rel="noopener noreferrer">PubMed/Medline</a>
</li>
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Automatic%20Pulmonary%20Nodule%20Detection%20Applying%20Deep%20Learning%20or%20Machine%20Learning%20Algorithms%20to%20the%20LIDC-IDRI%20Database%3A%20A%20Systematic%20Review" target="_blank" rel="noopener noreferrer">Google Scholar</a>
</li>
</ul>
</div>
</li>
<li class="accordion-navigation">
<a href="#authors" class="accordion__title">More by Authors Links</a>
<div id="authors" class="content  UI_ArticleMenu_AuthorsLinks">
<ul class="side-menu-ul">
<li>
<a class="expand" onclick='$(this).closest("li").next("div").toggle(); return false;'>on DOAJ</a>
</li>
<div id="AuthorDOAJExpand" style="display:none;">
<ul class="submenu">
<li class="li-link">
<a href='http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Lea%20Marie%20Pehrson%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D' target="_blank" rel="noopener noreferrer">Pehrson, L. Marie</a>
<li>
</li>
<li class="li-link">
<a href='http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Michael%20Bachmann%20Nielsen%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D' target="_blank" rel="noopener noreferrer">Nielsen, M. Bachmann</a>
<li>
</li>
<li class="li-link">
<a href='http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Carsten%20Ammitzb%C3%B8l%20Lauridsen%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D' target="_blank" rel="noopener noreferrer">Ammitzbøl Lauridsen, C.</a>
<li>
</li>
</ul>
</div>
<li>
<a class="expand" onclick='$(this).closest("li").next("div").toggle(); return false;'>on Google Scholar</a>
</li>
<div id="AuthorGoogleExpand" style="display:none;">
<ul class="submenu">
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Lea%20Marie%20Pehrson" target="_blank" rel="noopener noreferrer">Pehrson, L. Marie</a>
<li>
</li>
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Michael%20Bachmann%20Nielsen" target="_blank" rel="noopener noreferrer">Nielsen, M. Bachmann</a>
<li>
</li>
<li class="li-link">
<a href="https://scholar.google.com/scholar?q=Carsten%20Ammitzb%C3%B8l%20Lauridsen" target="_blank" rel="noopener noreferrer">Ammitzbøl Lauridsen, C.</a>
<li>
</li>
</ul>
</div>
<li>
<a class="expand" onclick='$(this).closest("li").next("div").toggle(); return false;'>on PubMed</a>
</li>
<div id="AuthorPubMedExpand" style="display:none;">
<ul class="submenu">
<li class="li-link">
<a href="https://www.pubmed.gov/?cmd=Search&amp;term=Lea%20Marie%20Pehrson" target="_blank" rel="noopener noreferrer">Pehrson, L. Marie</a>
<li>
</li>
<li class="li-link">
<a href="https://www.pubmed.gov/?cmd=Search&amp;term=Michael%20Bachmann%20Nielsen" target="_blank" rel="noopener noreferrer">Nielsen, M. Bachmann</a>
<li>
</li>
<li class="li-link">
<a href="https://www.pubmed.gov/?cmd=Search&amp;term=Carsten%20Ammitzb%C3%B8l%20Lauridsen" target="_blank" rel="noopener noreferrer">Ammitzbøl Lauridsen, C.</a>
<li>
</li>
</ul>
</div>
</ul>
</div>
</li>
<li class="accordion-navigation">
<a href="#html-links" class="accordion__title">Full Article Text</a>
<div id="html-links" class="content active">
<div class="menu-caption" id="html-quick-links-title"></div>
</div>
</li>
</ul>
<div id="scifeed-modal" class="reveal-modal reveal-modal-new" data-reveal aria-labelledby="modalTitle" aria-hidden="true" role="dialog">
</div>
<span style="display:none" id="scifeed_hidden_flag"></span>
<span style="display:none" id="scifeed_subscribe_url">/ajax/scifeed/subscribe</span>
</div>
</div>

<div id="pbgrd-sky"></div>
<script src="https://cdn.pbgrd.com/core-mdpi.js"></script>
<style>.content__container {
        min-width: 300px;
    }</style>

</div>
<div id="middle-column" class="content__column large-9 medium-9 small-12 columns end middle-bordered">
<div class="middle-column__help">
<div class="middle-column__help__fixed show-for-medium-up">
<a href="#" class="UA_ShareButton" data-reveal-id="main-share-modal" title="Share">
<i class="material-icons">share</i>
</a>
<a href="#" data-reveal-id="main-help-modal" title="Help">
<i class="material-icons">announcement</i>
</a>
<a href="https://sciprofiles.com/discussion-groups/public/10.3390/diagnostics9010029" target="_blank" rel="noopener noreferrer" title="Discuss in Sciprofiles">
<i class="material-icons">question_answer</i>
</a>
<a href="#" class="" data-hypothesis-trigger-endorses-tab title="Endorse">
<i data-hypothesis-endorse-trigger class="material-icons">thumb_up</i>
<div data-hypothesis-endorsement-count data-hypothesis-trigger-endorses-tab class="hypothesis-count-container">
...
</div>
</a>
<a href="#" data-hypothesis-trigger class="js-hypothesis-open UI_ArticleAnnotationsButton" title="Comment">
<i class="material-icons">textsms</i>
<div data-hypothesis-annotation-count class="hypothesis-count-container">
...
</div>
</a>
</div>
<div id="main-help-modal" class="reveal-modal reveal-modal-new" data-reveal aria-labelledby="modalTitle" aria-hidden="true" role="dialog">
<div class="row">
<div class="small-12 columns">
<h2 style="margin: 0;">Need Help?</h2>
</div>
<div class="small-6 columns">
<h3>Support</h3>
<p>
Find support for a specific problem in the support section of our website.
</p>
<a target="_blank" href="/about/contactform" class="button button--color button--full-width">
Get Support
</a>
</div>
<div class="small-6 columns">
<h3>Feedback</h3>
<p>
Please let us know what you think of our products and services.
</p>
<a target="_blank" href="/feedback/send" class="button button--color button--full-width">
Give Feedback
</a>
</div>
<div class="small-6 columns end">
<h3>Information</h3>
<p>
Visit our dedicated information section to learn more about MDPI.
</p>
<a target="_blank" href="/authors" class="button button--color button--full-width">
Get Information
</a>
</div>
</div>
<a class="close-reveal-modal" aria-label="Close">
<i class="material-icons">clear</i>
</a>
</div>
</div>
<div class="middle-column__main ">
<div class="html-content__container content__container content__container__combined-for-large content__container__combined-for-large__first" style="overflow: auto;">
<article><div class='html-article-content'>
<div itemscope itemtype="http://schema.org/ScholarlyArticle" id="abstract" class="abstract_div">
<div class="js-check-update-container"></div>
<div>
<span itemprop="publisher" content="Multidisciplinary Digital Publishing Institute"></span><span itemprop="url" content="https://www.mdpi.com/2075-4418/9/1/29"></span>
<div class="article-icons"><span class="label openaccess" data-dropdown="drop-article-label-openaccess" aria-expanded="false">Open Access</span><span class="label articletype">Review</span></div>
<h1 class="title hypothesis_container" itemprop="name">
Automatic Pulmonary Nodule Detection Applying Deep Learning or Machine Learning Algorithms to the LIDC-IDRI Database: A Systematic Review </h1>
<div class="art-authors hypothesis_container">

by
<span class="inlineblock "><div class="sciprofiles-link" style="display: inline-block"><a class="sciprofiles-link__link" href="https://sciprofiles.com/profile/595564" target="_blank" rel="noopener noreferrer"><img class="sciprofiles-link__image" src="/bundles/mdpisciprofileslink/img/unknown-user.png" style="width: auto; height: 16px; border-radius: 50%;"><span class="sciprofiles-link__name">Lea Marie Pehrson</span></a></div><sup> 1,2,*</sup><span style="display: inline; margin-left: 5px;"></span><a class="toEncode emailCaptcha visibility-hidden" data-author-id="1691479" href="mailto:please_login"><sup><i class="fa fa-envelope-o"></i></sup></a>, </span><span class="inlineblock "><div class="sciprofiles-link" style="display: inline-block"><a class="sciprofiles-link__link" href="https://sciprofiles.com/profile/93192" target="_blank" rel="noopener noreferrer"><img class="sciprofiles-link__image" src="/bundles/mdpisciprofileslink/img/unknown-user.png" style="width: auto; height: 16px; border-radius: 50%;"><span class="sciprofiles-link__name">Michael Bachmann Nielsen</span></a></div><sup> 1</sup><a href="https://orcid.org/0000-0002-9380-1688" target="_blank" rel="noopener noreferrer"><img src="/img/design/orcid.png?1b5ed457ed71c59e" title="ORCID" style="position: relative; width: 13px; margin-left: 3px; max-width: 13px !important; height: auto; top: -5px;"></a> and </span><span class="inlineblock "><div class="sciprofiles-link" style="display: inline-block"><a class="sciprofiles-link__link" href="https://sciprofiles.com/profile/author/NXkyZ3BvcHhKaFR1aUxXd1NQa3hFUT09" target="_blank" rel="noopener noreferrer"><img class="sciprofiles-link__image" src="/bundles/mdpisciprofileslink/img/unknown-user.png" style="width: auto; height: 16px; border-radius: 50%;"><span class="sciprofiles-link__name">Carsten Ammitzbøl Lauridsen</span></a></div><sup> 1,2</sup></span> 
</div>
<div class="nrm"></div>
<span style="display:block; height:6px;"></span>
<div></div>
<div style="margin: 5px 0 15px 0;" class="hypothesis_container">
<div class="art-affiliations">
<div class="affiliation ">
<div class="affiliation-item"><sup>1</sup></div>
<div class="affiliation-name ">Department of Diagnostic Radiology, Copenhagen University Hospital, Rigshospitalet, 2100 Copenhagen, Denmark</div>
</div>
<div class="affiliation ">
<div class="affiliation-item"><sup>2</sup></div>
<div class="affiliation-name ">Department of Technology, Faculty of Health and Technology, University College Copenhagen, 2200 Copenhagen, Denmark</div>
</div>
<div class="affiliation">
<div class="affiliation-item"><sup>*</sup></div>
<div class="affiliation-name ">Author to whom correspondence should be addressed. </div>
</div>
</div>
</div>
<div class="bib-identity" style="margin-bottom: 10px;">
<em>Diagnostics</em> <b>2019</b>, <em>9</em>(1), 29; <a href="https://doi.org/10.3390/diagnostics9010029">https://doi.org/10.3390/diagnostics9010029</a>
</div>
<div class="pubhistory" style="font-weight: bold; padding-bottom: 10px;">
<span style="display: inline-block">Received: 20 December 2018</span>
/
<span style="display: inline-block">Revised: 29 January 2019</span>
/
<span style="display: inline-block">Accepted: 19 February 2019</span>
/
<span style="display: inline-block">Published: 7 March 2019</span>
</div>
<div class="belongsTo" style="margin-bottom: 10px;">
(This article belongs to the Section <a href="/journal/diagnostics/sections/medical_imaging">Medical Imaging and Theranostics</a>)<br />
</div>
<div class="highlight-box1">
<div class="download">
<a class="button button--color-inversed margin-bottom-10 UD_ArticlePDF" href="/2075-4418/9/1/29/pdf?version=1551940425" onclick="ga('send', 'pageview', '/2075-4418/9/1/29/pdf?version=1551940425');">Download PDF</a>
<div class="js-browse-figures" style="display: inline-block;">
 <a href="#" class="button button--color-inversed margin-bottom-10 openpopupgallery UI_BrowseArticleFigures" data-target='article-popup'>Browse Figure</a>
</div>
<div id="article-popup" class="popupgallery" style="display: inline; line-height: 200%">
<a href="/diagnostics/diagnostics-09-00029/article_deploy/html/images/diagnostics-09-00029-g001.png" title="
                        <strong>Figure 1</strong><br/>
                                                    &lt;p&gt;Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) flowchart of the literature search and study selection.&lt;/p&gt;
                                                ">
</a>
</div>
<a class="button button--color-inversed" data-dropdown="drop-supplementary-211748" aria-controls="drop-supplementary-211748" aria-expanded="false">
Citation Export
</a>
<div id="drop-supplementary-211748" class="f-dropdown label__btn__dropdown label__btn__dropdown--button" data-dropdown-content aria-hidden="true" tabindex="-1">

<form style="margin:0; padding:0; display:inline;" name="export-bibtex" method="POST" action="/export">
<input type="hidden" name="articles_ids[]" value="211748">
<input type="hidden" name="export_format_top" value="bibtex">
<input type="hidden" name="export_submit_top" value="">
</form>

<form style="margin:0; padding:0; display:inline;" name="export-endnote" method="POST" action="/export">
<input type="hidden" name="articles_ids[]" value="211748">
<input type="hidden" name="export_format_top" value="endnote_no_abstract">
<input type="hidden" name="export_submit_top" value="">
</form>

<form style="margin:0; padding:0; display:inline;" name="export-ris" method="POST" action="/export">
<input type="hidden" name="articles_ids[]" value="211748">
<input type="hidden" name="export_format_top" value="ris">
<input type="hidden" name="export_submit_top" value="">
</form>
<a href="javascript:window.document.forms['export-bibtex'].submit()">BibTeX</a>
<br />
<a href="javascript:window.document.forms['export-endnote'].submit()">EndNote</a>
<br />
<a href="javascript:window.document.forms['export-ris'].submit()">RIS</a>
<br />
<a href="/2075-4418/9/1/29#cite">Cite This Paper</a>
</div>
</div>
</div>
<div class="responsive-moving-container small hidden" data-id="article-counters" style="margin-top: 15px;"></div>
</div>
<div class='html-abstract-title'>
<a name="abstractc"></a>
<h2>Abstract</h2>
</div>
<div class="art-abstract in-tab hypothesis_container">
 The aim of this study was to provide an overview of the literature available on machine learning (ML) algorithms applied to the Lung Image Database Consortium Image Collection (LIDC-IDRI) database as a tool for the optimization of detecting lung nodules in thoracic CT scans. This systematic review was compiled according to Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Only original research articles concerning algorithms applied to the LIDC-IDRI database were included. The initial search yielded 1972 publications after removing duplicates, and 41 of these articles were included in this study. The articles were divided into two subcategories describing their overall architecture. The majority of feature-based algorithms achieved an accuracy &gt;90% compared to the deep learning (DL) algorithms that achieved an accuracy in the range of 82.2%&ndash;97.6%. In conclusion, ML and DL algorithms are able to detect lung nodules with a high level of accuracy, sensitivity, and specificity using ML, when applied to an annotated archive of CT scans of the lung. However, there is no consensus on the method applied to determine the efficiency of ML algorithms.
</div>
<div class="art-keywords in-tab hypothesis_container"><em>Keywords: </em>
<span itemprop="keywords" style="display:none">deep learning; machine learning; nodule detection</span>
<span> <a href="/search?q=deep%20learning">deep learning</a>; <a href="/search?q=machine%20learning">machine learning</a>; <a href="/search?q=nodule%20detection">nodule detection</a></span>
</div>
</div>
</div> <div class="hypothesis_container">
<ul class="menu html-nav" data-prev-node="#html-quick-links-title">
</ul>
<div class="html-body">
<section id='sec1-diagnostics-09-00029' type='intro'><h2 data-nested='1'> 1. Introduction</h2><div class='html-p'>Machine learning (ML) and deep learning (DL) are becoming established disciplines in the broad field of applying artificial intelligence in analyzing and utilizing patterns in datasets. As the complexity and shear amount of data increase, applying these patterns for the benefit of, e.g., clinical decision making, becomes increasingly nontrivial [<a href="#B1-diagnostics-09-00029" class="html-bibr">1</a>]. Extraordinary advancements in areas of technology such as high-performance computing have made it possible to attempt solving these problems algorithmically. The purpose of various ML and DL algorithms may be to improve quality, consistency, and/or capacity of data interpretation in diagnostics, thus improving diagnostics and treatment decisions to the benefit of clinical outcomes. Considering the implications this may have for the practice of medicine and healthcare, it is important to engage in this area of research from many perspectives. ML is already being applied to the practice of radiology, and the systems being developed today are showing to be robust in real-world conditions [<a href="#B2-diagnostics-09-00029" class="html-bibr">2</a>]. Several reviews have been published reviewing these techniques [<a href="#B3-diagnostics-09-00029" class="html-bibr">3</a>]. The Cancer Imaging Archive (TCIA) has the largest annotated public database, known as the Lung Image Database Consortium Image Collection (LIDC-IDRI), containing 1018 cases [<a href="#B4-diagnostics-09-00029" class="html-bibr">4</a>]. Since 2014, there have not been any systematic reviews published concerning the application of ML for the optimization of detecting pulmonary nodules in CT scans from the LIDC-IDRI database. The database is created with the intent to further the development of the training and evaluation of computer-assisted diagnostic (CAD) methods for lung cancer detection and diagnosis. The aim of this systematic review is, therefore, to provide an overview of the published literature, in order to evaluate the algorithm’s ability to detect lung nodules in CT scans released by the LIDC-IDRI database.</div></section><section id='sec2-diagnostics-09-00029' type=''><h2 data-nested='1'> 2. Materials and Methods</h2><div class='html-p'>The eligibility criteria and analysis in this review were performed according to the PRISMA guidelines 2009 (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) [<a href="#B5-diagnostics-09-00029" class="html-bibr">5</a>]. The literature search was completed on 22 November 2018. The literary search was performed in PubMed, Web of Science, Scopus, The Institute of Electrical and Electronics Engineers, Inc. (IEEE), and the association for computing machinery library database. This was done to identify publications that apply ML or DL algorithms to the LIDC-IDRI database for optimizing lung nodule detection. The selection criteria for the publications included are articles written in English and published since the 1 January 2014. To perform the search, the following expressions were used:</div><div class='html-p'>Search string number 1: (“3D” OR “3-dimensional” OR “three-dimensional”) AND (“detection” OR “segmentation” OR “cad” OR “cade”) AND (“lung” OR “lungs” OR “pulmonary” OR “chest”) AND (“nodule” OR “nodules” OR “cancer” OR “tumor” OR “tumors”).</div><div class='html-p'>Search string number 2: (“deep learning” OR “machine learning”) AND (“detection” OR “segmentation” OR “feature” OR “feature extraction” OR “features” OR “classification”) AND (“The lung image database consortium” OR “LIDC”) AND (“Lung nodule” OR “nodule detection”).</div><div class='html-p'>The first search expression is inspired by a previous review from 2014 [<a href="#B3-diagnostics-09-00029" class="html-bibr">3</a>]. The second search is presented by the author, and has been applied to the databases to identify publications that apply the latest technology related to lung nodule detection. By applying two search strings, we were able to include a larger number of articles. After removal of duplicates, all studies included in the search result were screened by title and abstract by two authors (L.M.P. and C.A.L.). Original research articles concerning algorithms applied to the LIDC-IDRI database were included. The LIDC-IDRI is the largest annotated database on thoracic CT scans [<a href="#B4-diagnostics-09-00029" class="html-bibr">4</a>]. The articles were subsequently retrieved and read by the same authors. Consensus was reached through discussion. All reference lists of the included articles were manually searched for further references. The articles were divided into two groups based on the type of algorithm presented in the articles. <a href="#diagnostics-09-00029-t001" class="html-table">Table 1</a> presents 19 articles that apply a feature-based learning algorithm. <a href="#diagnostics-09-00029-t002" class="html-table">Table 2</a> presents 22 articles that apply DL algorithms in order to detect lung nodules. The inclusion criteria for articles included all apply a type of ML algorithm to the LIDC-IDRI database and present results that showcase the algorithm’s accuracy, sensitivity, and specificity, and ability to obtain area under the curve (AUC) results; and were published from 1 January 2014. The articles that did not present at least one of these criteria and applied the LIDC-IDRI database were excluded. After removal of duplicates, the initial search yielded 1972 publications, 1792 of which were excluded. A total of 180 full-text articles were assessed for eligibility and 139 of these articles were excluded because of lacking data requirements, leaving 41 articles that were included in this systematic review. The study selection is summarized in <a href="#diagnostics-09-00029-f001" class="html-fig">Figure 1</a>.</div><div class='html-p'>The LIDC-IDRI is the largest publicly available annotated CT database. It consists of 7371 lesions marked as a nodule by at least one radiologist. Of these lesions, 2669 were at least 3 mm or larger, and annotated by, at minimum, one radiologist. Out of the 2669 lesions, 928 (34.7%) received the same mark by four radiologists. The 2669 lesions are outlined and subjective nodule characteristics are all annotated. The LIDC-IDRI required the four radiologists to independently review each scan and mark lesions identified with respect to specific criteria described in Armato et al. 2014 [<a href="#B4-diagnostics-09-00029" class="html-bibr">4</a>].</div><div class='html-p'>The following is an acknowledged definition of ML: The algorithm is applied to a dataset, in this case, the LIDC-IDRI database. The annotations of nodules and the estimated malignancy of the nodule in the training data are learned by the algorithm. The knowledge obtained from the training set allows the algorithm to learn to make predictions. The prediction, in this case, could be whether there is a nodule located on the slice or whether the nodule is benign or malignant. Altering the features that are given can lead to an improvement in diagnosis. If the algorithm is able to optimize the parameters, it is considered to be learning the task. There are several differences between DL algorithms and algorithms based on hand-engineered features: the structure of the algorithm differs—the DL algorithm usually consists of several hidden layers; the two approaches require different input information; the algorithms based on hand-engineered features require proper segmentation of the nodule from a radiologist, or a segmentation algorithm and further quantitative image feature extraction; and the DL approach does not need the same elaborative segmentation process as the algorithms are able to make predictions from one marked point per nodule [<a href="#B6-diagnostics-09-00029" class="html-bibr">6</a>]. The data extracted from the articles are the results presented by the authors. These results showcase the algorithm’s ability to achieve the highest accuracy, sensitivity, and specificity, and derive AUC values.</div></section><section id='sec3-diagnostics-09-00029' type='results'><h2 data-nested='1'> 3. Results</h2><section id='sec3dot1-diagnostics-09-00029' type=''><h4 class='html-italic' data-nested='2'> 3.1. Algorithms Applying a Feature-Based Framework</h4><div class='html-p'><a href="#diagnostics-09-00029-t001" class="html-table">Table 1</a> shows the 19 studies that have applied a feature-based framework. This table correspondingly showcases the best results the studies achieved using a specific algorithm. In the table, the studies marked with a star (“*”) presented several types of alterations to the algorithm, producing different results. These results are not presented in the table. Furthermore, if the data were unable to be obtained from the publication, this is stated as Not Available (NA).</div></section><section id='sec3dot2-diagnostics-09-00029' type=''><h4 class='html-italic' data-nested='2'> 3.2. Support Vector Machine (Six Studies)</h4><div class='html-p'>Eight out of 19 studies proposed an algorithm applying a type of Support-vector machine (SVM) classifier [<a href="#B7-diagnostics-09-00029" class="html-bibr">7</a>,<a href="#B8-diagnostics-09-00029" class="html-bibr">8</a>,<a href="#B10-diagnostics-09-00029" class="html-bibr">10</a>,<a href="#B12-diagnostics-09-00029" class="html-bibr">12</a>,<a href="#B13-diagnostics-09-00029" class="html-bibr">13</a>,<a href="#B20-diagnostics-09-00029" class="html-bibr">20</a>,<a href="#B21-diagnostics-09-00029" class="html-bibr">21</a>,<a href="#B24-diagnostics-09-00029" class="html-bibr">24</a>]. These studies achieved some of the best results with regards to accuracy, sensitivity, specificity, and AUC, and all applied an SVM classifier and a type of feature extraction with focus on shape, intensity, or texture. The algorithms that applied an SVM classifier reached a range of accuracy of 68.4%–99.0%, sensitivity of 55.0%–98.6%, specificity of 87.5%–98.2%, and an AUC of 0.905–0.998.</div><div class='html-p'>The table displays 12 studies marked with a star [<a href="#B7-diagnostics-09-00029" class="html-bibr">7</a>,<a href="#B8-diagnostics-09-00029" class="html-bibr">8</a>,<a href="#B10-diagnostics-09-00029" class="html-bibr">10</a>,<a href="#B12-diagnostics-09-00029" class="html-bibr">12</a>,<a href="#B13-diagnostics-09-00029" class="html-bibr">13</a>,<a href="#B14-diagnostics-09-00029" class="html-bibr">14</a>,<a href="#B16-diagnostics-09-00029" class="html-bibr">16</a>,<a href="#B20-diagnostics-09-00029" class="html-bibr">20</a>,<a href="#B21-diagnostics-09-00029" class="html-bibr">21</a>,<a href="#B22-diagnostics-09-00029" class="html-bibr">22</a>,<a href="#B23-diagnostics-09-00029" class="html-bibr">23</a>,<a href="#B24-diagnostics-09-00029" class="html-bibr">24</a>]. These studies applied several alternative combinations of features, classifiers, or validation methods. Eight of these algorithms achieved the best results while applying an SVM type of classifier, and the best of all the algorithms, except one, reached an accuracy range of 96.7%–99.0% [<a href="#B7-diagnostics-09-00029" class="html-bibr">7</a>,<a href="#B8-diagnostics-09-00029" class="html-bibr">8</a>,<a href="#B10-diagnostics-09-00029" class="html-bibr">10</a>,<a href="#B12-diagnostics-09-00029" class="html-bibr">12</a>,<a href="#B20-diagnostics-09-00029" class="html-bibr">20</a>,<a href="#B21-diagnostics-09-00029" class="html-bibr">21</a>,<a href="#B24-diagnostics-09-00029" class="html-bibr">24</a>].</div></section><section id='sec3dot3-diagnostics-09-00029' type=''><h4 class='html-italic' data-nested='2'> 3.3. Other Classifiers (Six Studies)</h4><div class='html-p'>Gong et al. [<a href="#B14-diagnostics-09-00029" class="html-bibr">14</a>] tested the algorithms on an Fisher linear discriminant analysis (FLDA) and naïve Bayes classifier. The FLDA classifier obtained the highest AUC and sensitivity compared to the naïve Bayes classifier. Gupta et al. [<a href="#B15-diagnostics-09-00029" class="html-bibr">15</a>] applied a stacked autoencoder to acquire an unsupervised neural network. A softmax layer was stacked with the autoencoder to perform the classification. The softmax classifier was used to solve binary classification problems. Hancock et al. [<a href="#B16-diagnostics-09-00029" class="html-bibr">16</a>] tested linear and nonlinear classifiers combined with either features included or excluded. The best performing algorithm was the nonlinear classifier, including the diameter and volume features. The nonlinear classifier with features excluded outperformed both the linear classifiers.</div><div class='html-p'>Lu et al. [<a href="#B19-diagnostics-09-00029" class="html-bibr">19</a>] presented an algorithm consisting of a hybrid method. The method integrated existing and often-applied algorithms. Taşcı et al. [<a href="#B22-diagnostics-09-00029" class="html-bibr">22</a>] presented an algorithm for detection of juxtrapleural nodules. The algorithm was initially tested on ten different classifiers. The best performing classifier out of the ten tested was the generalized linear model regression (GLMR) classifier, which utilized 22 out of 33 features and achieved an accuracy of 92.9%.</div><div class='html-p'>Liu et al. [<a href="#B18-diagnostics-09-00029" class="html-bibr">18</a>] presented a multilayer, fully connected network and consists of one input layer, one hidden layer, and one linear output layer. Wang et al. proposed a new classifier, utilizing semi-supervised extreme learning machine (SS-ELM). The proposed method achieved better results compared to applying an extreme learning machine (ELM), SVM, probabilistic neural network (PNN), and multilayer perceptron (MLP) classifier.</div><div class='html-p'>Bai et al. [<a href="#B9-diagnostics-09-00029" class="html-bibr">9</a>] combined a model-based local shape analysis and data-driven local contextual feature learning to improve detection in low dose CT. The algorithm applied a random forest trained to learn and combine a subset of these primitives into discriminative orientation invariant contextual features and classify nodule candidates. By applying this method, the algorithm reached a sensitivity of 80%. Liu et al. [<a href="#B18-diagnostics-09-00029" class="html-bibr">18</a>] proposed an ANN algorithm trained on the LIDC-IDRI database. The algorithm applied 3D geometric and statistical features to constitute a voting method. While applying this method the algorithm reached a sensitivity of 89.4%. El Regaily [<a href="#B11-diagnostics-09-00029" class="html-bibr">11</a>] applied a simple rule classifier and achieved a total accuracy of 70.53%. These results were satisfactory, taking into consideration the classifier applied on the initial first step of the classification. The author proposed to apply a SVM classifier in order to raise the accuracy and reduce the amounts of FP.</div><div class='html-p'>Jaffar et al. [<a href="#B17-diagnostics-09-00029" class="html-bibr">17</a>] achieved the highest sensitivity, specificity, and AUC. This was done while applying a random forest classifier. The study proposed a novel ensemble shape gradient features (NESGF) descriptor for pulmonary nodule classification using the histogram of oriented surface normal vectors and multi-coordinate histogram of gradient descriptor.</div></section><section id='sec3dot4-diagnostics-09-00029' type=''><h4 class='html-italic' data-nested='2'> 3.4. Algorithms Applying Deep Learning Architecture</h4><div class='html-p'>Data presented in <a href="#diagnostics-09-00029-t002" class="html-table">Table 2</a> showcase the 22 studies that applied DL algorithms [<a href="#B6-diagnostics-09-00029" class="html-bibr">6</a>,<a href="#B26-diagnostics-09-00029" class="html-bibr">26</a>,<a href="#B27-diagnostics-09-00029" class="html-bibr">27</a>,<a href="#B28-diagnostics-09-00029" class="html-bibr">28</a>,<a href="#B29-diagnostics-09-00029" class="html-bibr">29</a>,<a href="#B30-diagnostics-09-00029" class="html-bibr">30</a>,<a href="#B31-diagnostics-09-00029" class="html-bibr">31</a>,<a href="#B32-diagnostics-09-00029" class="html-bibr">32</a>,<a href="#B33-diagnostics-09-00029" class="html-bibr">33</a>,<a href="#B34-diagnostics-09-00029" class="html-bibr">34</a>,<a href="#B35-diagnostics-09-00029" class="html-bibr">35</a>,<a href="#B36-diagnostics-09-00029" class="html-bibr">36</a>,<a href="#B37-diagnostics-09-00029" class="html-bibr">37</a>,<a href="#B38-diagnostics-09-00029" class="html-bibr">38</a>,<a href="#B39-diagnostics-09-00029" class="html-bibr">39</a>,<a href="#B40-diagnostics-09-00029" class="html-bibr">40</a>,<a href="#B41-diagnostics-09-00029" class="html-bibr">41</a>,<a href="#B42-diagnostics-09-00029" class="html-bibr">42</a>,<a href="#B43-diagnostics-09-00029" class="html-bibr">43</a>,<a href="#B44-diagnostics-09-00029" class="html-bibr">44</a>,<a href="#B45-diagnostics-09-00029" class="html-bibr">45</a>,<a href="#B46-diagnostics-09-00029" class="html-bibr">46</a>,<a href="#B47-diagnostics-09-00029" class="html-bibr">47</a>]. Some of the authors tested different types of algorithms; the results shown in <a href="#diagnostics-09-00029-t002" class="html-table">Table 2</a> are the best performing algorithms presented in the literature. Furthermore, if the data were unable to be obtained from the publication, this is stated as Not Available (NA).</div></section><section id='sec3dot5-diagnostics-09-00029' type=''><h4 class='html-italic' data-nested='2'> 3.5. Convolutional Neural Network (Twelve Studies)</h4><div class='html-p'>The convolution neural network architecture is the most frequently applied architecture in <a href="#diagnostics-09-00029-t002" class="html-table">Table 2</a> [<a href="#B6-diagnostics-09-00029" class="html-bibr">6</a>,<a href="#B26-diagnostics-09-00029" class="html-bibr">26</a>,<a href="#B27-diagnostics-09-00029" class="html-bibr">27</a>,<a href="#B28-diagnostics-09-00029" class="html-bibr">28</a>,<a href="#B29-diagnostics-09-00029" class="html-bibr">29</a>,<a href="#B30-diagnostics-09-00029" class="html-bibr">30</a>,<a href="#B31-diagnostics-09-00029" class="html-bibr">31</a>,<a href="#B32-diagnostics-09-00029" class="html-bibr">32</a>,<a href="#B33-diagnostics-09-00029" class="html-bibr">33</a>,<a href="#B34-diagnostics-09-00029" class="html-bibr">34</a>,<a href="#B35-diagnostics-09-00029" class="html-bibr">35</a>,<a href="#B36-diagnostics-09-00029" class="html-bibr">36</a>]. The CNN architecture reached an accuracy of 82.2%–97.6%, sensitivity of 83.1%–96.6%, specificity of 71.4%–98.2%, and an AUC of 0.87%–0.98%. Da Silva et al. increased the number of nodules and achieved superlative results. The studies included in this review that applied the PSO algorithm are all included in the top three best-achieving algorithms.</div></section><section id='sec3dot6-diagnostics-09-00029' type=''><h4 class='html-italic' data-nested='2'> 3.6. Deep Believe Network</h4><div class='html-p'>Zhang et al. is the only study which applied a deep believe network [<a href="#B37-diagnostics-09-00029" class="html-bibr">37</a>]. The algorithm is trained to detect large nodules &gt;30 mm, and achieved results above 90% with regards to accuracy, sensitivity and specificity. Two out of 14 articles applied a deep convolutional neural network (DCNN). The articles reached an accuracy of 89.0%–89.5% and a sensitivity of 84.2%–87.1% [<a href="#B39-diagnostics-09-00029" class="html-bibr">39</a>,<a href="#B40-diagnostics-09-00029" class="html-bibr">40</a>].</div></section><section id='sec3dot7-diagnostics-09-00029' type=''><h4 class='html-italic' data-nested='2'> 3.7. Other</h4><div class='html-p'>Abbas et al. [<a href="#B44-diagnostics-09-00029" class="html-bibr">44</a>] chose deep neural network architecture and achieved results above 94% with regards to accuracy, sensitivity and specificity. Gruetzemacher et al. [<a href="#B43-diagnostics-09-00029" class="html-bibr">43</a>] also applied a DNN architecture and achieved above 94% in sensitivity. The study by Nibali et al. [<a href="#B46-diagnostics-09-00029" class="html-bibr">46</a>] is the only study that applied a deep residual neural network and achieved accuracy, sensitivity, and specificity above 88% [<a href="#B46-diagnostics-09-00029" class="html-bibr">46</a>]. Shaffie et al. [<a href="#B42-diagnostics-09-00029" class="html-bibr">42</a>] and Naqi et al. [<a href="#B47-diagnostics-09-00029" class="html-bibr">47</a>] both presented an architecture utilizing autoencoders. Naqi et al. [<a href="#B47-diagnostics-09-00029" class="html-bibr">47</a>] presented results above 95% in accuracy, sensitivity, and specificity. Shaffie et al. presented results above 85%. Xie et al. [<a href="#B38-diagnostics-09-00029" class="html-bibr">38</a>] proposed an algorithm utilizing the multiview knowledge-based collaborative (MV-KBC) deep model to separate malignant from benign nodules using limited chest CT data.</div></section></section><section id='sec4-diagnostics-09-00029' type='discussion'><h2 data-nested='1'> 4. Discussion</h2><div class='html-p'>The included studies all applied to the largest annotated image archive of CT scans of the lungs [<a href="#B4-diagnostics-09-00029" class="html-bibr">4</a>]. All included articles were able to detect lung nodules with a high accuracy, sensitivity, and specificity, using ML. The majority of the algorithms achieved results above 90% in one or more of the four diagnostic performing parameters. However, there is no consensus on the methods applied to determine the efficiency of ML algorithms, and the heterogeneity in the selection of included scans and the different parameters for the algorithms makes it challenging to compare them.</div><div class='html-p'>Applying ML algorithms to medical images comes with several limitations, one of the most profound being the lack of labeled training data. The lack of large training datasets is often mentioned as an obstacle, therefore, databases such as LIDC-IDRI are greatly appreciated and applied for training and validating algorithms. It should be noted that over the course of at least a decade, most Western hospitals have used picture archiving and communication system (PACS) systems in radiology. This magnitude of imaging data acquired for specific purposes in well-structured archives is uncommon. The main challenge is, thus, not the availability of image data itself, but the acquisition of relevant annotations/labeling for these images. Free-text reports on the radiologists’ findings are stored on the PACS system. Turning these reports into accurate labeling of structures and findings can be challenging and requires sophisticated text-mining methods, which is an important field of study in itself, where deep learning is also widely used nowadays. Introducing a structured reporting system would become very beneficial in an ML objective; this could potentially lead to improvement of radiologic findings and, eventually, patient care.</div><div class='html-p'>The general architecture of feature-based and DL algorithms differ. The specific architecture within the two groups also differs—the architectures and restrictions are set by the author. These are some of the contributing factors for the difference in performance when applying the same general architecture. This contributes to the difficulty in comparison. The algorithms applying feature-based architecture generated, overall, better results compared to the algorithms applying a DL approach [<a href="#B29-diagnostics-09-00029" class="html-bibr">29</a>,<a href="#B47-diagnostics-09-00029" class="html-bibr">47</a>]. The feature-based algorithms consist of different steps; the first step is usually computing the image features that will be of importance in the prediction process. The best combination of features is then selected, and the features can be applied to classify the image. The features are often based on texture, shape, or size of a nodule. The annotations given in the LIDC-IDRI dataset can be extracted, and the algorithm is able to learn to make a prediction. When the author is training the algorithm, it is possible to optimize the parameters when diagnosing correctly, thus improving the performance. The benefits of applying a DL algorithm is that the algorithm does not need feature identification as the first step. The algorithm identifies the features as a part of the learning process. The definition of DL is an algorithm which applies neural networks with multiple layers, usually more than 20. This has become possible because of the tools initially created for computer gaming and the massive parallel computing power of a graphics processing unit.</div><div class='html-p'>One of the most beneficial reasons for applying a DL algorithm is the learning curve. The DL algorithm is able to improve the performance over time, compared to a feature-based algorithm. The weight of the feature is set by the author and cannot be altered. The different types of DL algorithms have different abilities.</div><div class='html-p'>Several larger companies have evolved image recognition algorithms, and these algorithms are pre-trained on images that are not specific to the task. An example of this is Google’s GoogLeNet [<a href="#B48-diagnostics-09-00029" class="html-bibr">48</a>], which is trained on more than a million images from the ImageNet database. GoogLeNet has a rich feature representation and selection which can be incorporated into an algorithm made for nodule detection.</div><div class='html-p'>Ramachandran et al. [<a href="#B31-diagnostics-09-00029" class="html-bibr">31</a>] incorporated this technique into the algorithm they presented. The algorithm proposed a new object detection workflow, using a convolutional neural network to detect nodules in images and define the bounding boxes around them. The system presented an architecture based on DetectNet, which incorporates GoogLeNet inception layers without the fully connected layers.</div><div class='html-p'>Several of the proposed techniques have the potential for building medical diagnosis tools. Five of the feature-based and two of the DL algorithms presented an accuracy &gt;95% [<a href="#B7-diagnostics-09-00029" class="html-bibr">7</a>,<a href="#B10-diagnostics-09-00029" class="html-bibr">10</a>,<a href="#B20-diagnostics-09-00029" class="html-bibr">20</a>,<a href="#B21-diagnostics-09-00029" class="html-bibr">21</a>,<a href="#B29-diagnostics-09-00029" class="html-bibr">29</a>,<a href="#B47-diagnostics-09-00029" class="html-bibr">47</a>]. These contributions should move forward from the LIDC-IDRI database and be taken into consideration with regard to implementing this technique for clinical practice. This could lead to an increase in nodule detection. To our knowledge, there are no studies published concerning this topic.</div></section><section id='sec5-diagnostics-09-00029' type='conclusions'><h2 data-nested='1'> 5. Conclusions</h2><div class='html-p'>In conclusion, studies on ML and DL algorithms are able to detect lung nodules at a high level of accuracy, sensitivity, and specificity using ML when applied to an annotated archive of CT scans of the lung. However, there is no consensus on the method applied to determine the efficiency of ML algorithms. So far, there are no studies demonstrating in which clinical setting to ML could be used, and whether or not this would lead to detection of a higher number of lung nodules.</div></section>
</div>
<div class="html-back">
<section class='html-notes'><h2>Author Contributions</h2><div class='html-p'>Conceptualization, L.M.P., M.B.N. and C.A.L.; Methodology L.M.P., M.B.N. and C.A.L. Investigation, L.M.P.; Data Curation, L.M.P. and C.A.L.; Writing—Original Draft Preparation, L.M.P.; Writing—Review &amp; Editing, L.M.P., M.B.N. and C.A.L. Supervision, M.B.N. and C.A.L.</div></section><section class='html-notes'><h2>Funding</h2><div class='html-p'>This research received no external funding.</div></section><section class='html-notes'><h2>Conflicts of Interest</h2><div class='html-p'>The authors declare no conflict of interest.</div></section><section id='html-references_list'><h2>References</h2><ol class='html-xx'><li id='B1-diagnostics-09-00029' class='html-x' data-content='1.'>Doi, K. Diagnostic imaging over the last 50 years: Research and development in medical imaging science and technology. <span class='html-italic'>Phys. Med. Biol.</span> <b>2006</b>, <span class='html-italic'>51</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Diagnostic+imaging+over+the+last+50+years:+Research+and+development+in+medical+imaging+science+and+technology&author=Doi,+K.&publication_year=2006&journal=Phys.+Med.+Biol.&volume=51&doi=10.1088/0031-9155/51/13/R02&pmid=16790920" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1088/0031-9155/51/13/R02" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/16790920" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B2-diagnostics-09-00029' class='html-x' data-content='2.'>Erickson, B.J.; Korfiatis, P.; Akkus, Z.; Kline, T.L. Machine Learning for Medical Imaging. <span class='html-italic'>Radiographics</span> <b>2017</b>, <span class='html-italic'>37</span>, 505–515. [<a href="https://scholar.google.com/scholar_lookup?title=Machine+Learning+for+Medical+Imaging&author=Erickson,+B.J.&author=Korfiatis,+P.&author=Akkus,+Z.&author=Kline,+T.L.&publication_year=2017&journal=Radiographics&volume=37&pages=505%E2%80%93515&doi=10.1148/rg.2017160130&pmid=28212054" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1148/rg.2017160130" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/28212054" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>][<a href="https://europepmc.org/articles/pmc5375621?pdf=render" target='_blank' rel="noopener noreferrer">Green Version</a>]</li><li id='B3-diagnostics-09-00029' class='html-x' data-content='3.'>Valente, I.R.S.; Cortez, P.C.; Neto, E.C.; Soares, J.M.; de Albuquerque, V.H.C.; Tavares, J.M. Automatic 3D pulmonary nodule detection in CT images: A survey. <span class='html-italic'>Comput. Methods Programs Biomed.</span> <b>2016</b>, <span class='html-italic'>124</span>, 91–107. [<a href="https://scholar.google.com/scholar_lookup?title=Automatic+3D+pulmonary+nodule+detection+in+CT+images:+A+survey&author=Valente,+I.R.S.&author=Cortez,+P.C.&author=Neto,+E.C.&author=Soares,+J.M.&author=de+Albuquerque,+V.H.C.&author=Tavares,+J.M.&publication_year=2016&journal=Comput.+Methods+Programs+Biomed.&volume=124&pages=91%E2%80%93107&doi=10.1016/j.cmpb.2015.10.006&pmid=26652979" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.cmpb.2015.10.006" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/26652979" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>][<a href="http://repositorio-aberto.up.pt/bitstream/10216/82455/2/110858.pdf" target='_blank' rel="noopener noreferrer">Green Version</a>]</li><li id='B4-diagnostics-09-00029' class='html-x' data-content='4.'>Armato, S.G.; McLennan, G.; Bidaut, L.; McNitt-Gray, M.F.; Meyer, C.R.; Reeves, A.P.; Zhao, B.; Aberle, D.R.; Henschke, C.I.; Hoffman, E.A.; et al. The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): A Completed Reference Database of Lung Nodules on CT Scans. <span class='html-italic'>Med. Phys.</span> <b>2011</b>, <span class='html-italic'>38</span>, 915–931. [<a href="https://scholar.google.com/scholar_lookup?title=The+Lung+Image+Database+Consortium+(LIDC)+and+Image+Database+Resource+Initiative+(IDRI):+A+Completed+Reference+Database+of+Lung+Nodules+on+CT+Scans&author=Armato,+S.G.&author=McLennan,+G.&author=Bidaut,+L.&author=McNitt-Gray,+M.F.&author=Meyer,+C.R.&author=Reeves,+A.P.&author=Zhao,+B.&author=Aberle,+D.R.&author=Henschke,+C.I.&author=Hoffman,+E.A.&publication_year=2011&journal=Med.+Phys.&volume=38&pages=915%E2%80%93931&doi=10.1118/1.3528204&pmid=21452728" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1118/1.3528204" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/21452728" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>][<a href="https://europepmc.org/articles/pmc3041807?pdf=render" target='_blank' rel="noopener noreferrer">Green Version</a>]</li><li id='B5-diagnostics-09-00029' class='html-x' data-content='5.'>Moher, D.; Liberati, A.; Tetzlaff, J.; Altman, D.G.; PRISMA Group. Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement. <span class='html-italic'>Ann. Int. Med.</span> <b>2009</b>, <span class='html-italic'>151</span>, 264–269. [<a href="https://scholar.google.com/scholar_lookup?title=Preferred+reporting+items+for+systematic+reviews+and+meta-analyses:+The+PRISMA+statement&author=Moher,+D.&author=Liberati,+A.&author=Tetzlaff,+J.&author=Altman,+D.G.&author=PRISMA+Group&publication_year=2009&journal=Ann.+Int.+Med.&volume=151&pages=264%E2%80%93269&doi=10.7326/0003-4819-151-4-200908180-00135&pmid=19622511" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.7326/0003-4819-151-4-200908180-00135" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/19622511" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B6-diagnostics-09-00029' class='html-x' data-content='6.'>Causey, J.L.; Zhang, J.; Ma, S.; Jiang, B.; Qualls, J.A.; Politte, D.G.; Prior, F.; Zhang, S.; Huang, X. Highly accurate model for prediction of lung nodule malignancy with CT scans. <span class='html-italic'>Sci. Rep.</span> <b>2018</b>, <span class='html-italic'>8</span>, 9286. [<a href="https://scholar.google.com/scholar_lookup?title=Highly+accurate+model+for+prediction+of+lung+nodule+malignancy+with+CT+scans&author=Causey,+J.L.&author=Zhang,+J.&author=Ma,+S.&author=Jiang,+B.&author=Qualls,+J.A.&author=Politte,+D.G.&author=Prior,+F.&author=Zhang,+S.&author=Huang,+X.&publication_year=2018&journal=Sci.+Rep.&volume=8&pages=9286&doi=10.1038/s41598-018-27569-w&pmid=29915334" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1038/s41598-018-27569-w" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/29915334" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B7-diagnostics-09-00029' class='html-x' data-content='7.'>Akram, S.; Javed, M.Y.; Qamar, U.; Khanum, A.; Hassan, A. Artificial neural network based classification of lungs nodule using hybrid features from computerized tomographic images. <span class='html-italic'>Appl. Math. Inf. Sci.</span> <b>2015</b>, <span class='html-italic'>9</span>, 183–195. [<a href="https://scholar.google.com/scholar_lookup?title=Artificial+neural+network+based+classification+of+lungs+nodule+using+hybrid+features+from+computerized+tomographic+images&author=Akram,+S.&author=Javed,+M.Y.&author=Qamar,+U.&author=Khanum,+A.&author=Hassan,+A.&publication_year=2015&journal=Appl.+Math.+Inf.+Sci.&volume=9&pages=183%E2%80%93195&doi=10.12785/amis/090124" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.12785/amis/090124" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B8-diagnostics-09-00029' class='html-x' data-content='8.'>Alilou, M.; Kovalev, V.; Snezhko, E.; Taimouri, V. A comprehensive framework for automatic detection of pulmonary nodules in lung ct images. <span class='html-italic'>Image Anal. Stereol.</span> <b>2014</b>, <span class='html-italic'>33</span>, 13–27. [<a href="https://scholar.google.com/scholar_lookup?title=A+comprehensive+framework+for+automatic+detection+of+pulmonary+nodules+in+lung+ct+images&author=Alilou,+M.&author=Kovalev,+V.&author=Snezhko,+E.&author=Taimouri,+V.&publication_year=2014&journal=Image+Anal.+Stereol.&volume=33&pages=13%E2%80%9327&doi=10.5566/ias.v33.p13-27" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.5566/ias.v33.p13-27" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B9-diagnostics-09-00029' class='html-x' data-content='9.'>Bai, J.; Huang, X.; Liu, S.; Song, Q.; Bhagalia, R. Learning Orientation Invariant Contextual Features for Nodule Detection in Lung ct Scans. In Proceedings of the 2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI), New York, NY, USA, 16–19 April 2015. [<a href="https://scholar.google.com/scholar_lookup?title=Learning+Orientation+Invariant+Contextual+Features+for+Nodule+Detection+in+Lung+ct+Scans&conference=Proceedings+of+the+2015+IEEE+12th+International+Symposium+on+Biomedical+Imaging+(ISBI)&author=Bai,+J.&author=Huang,+X.&author=Liu,+S.&author=Song,+Q.&author=Bhagalia,+R.&publication_year=2015&doi=10.1109/ISBI.2015.7164072" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/ISBI.2015.7164072" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B10-diagnostics-09-00029' class='html-xx' data-content='10.'>Choi, W.-J.; Choi, T.-S. Automated pulmonary nodule detection based on three-dimensional shape-based feature descriptor. <span class='html-italic'>Comput. Methods Programs Biomed.</span> <b>2014</b>, <span class='html-italic'>113</span>, 37–54. [<a href="https://scholar.google.com/scholar_lookup?title=Automated+pulmonary+nodule+detection+based+on+three-dimensional+shape-based+feature+descriptor&author=Choi,+W.-J.&author=Choi,+T.-S.&publication_year=2014&journal=Comput.+Methods+Programs+Biomed.&volume=113&pages=37%E2%80%9354&doi=10.1016/j.cmpb.2013.08.015&pmid=24148147" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.cmpb.2013.08.015" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/24148147" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B11-diagnostics-09-00029' class='html-xx' data-content='11.'>El Regaily, S.; Salem, M.; Abdel Aziz, M.; Roushdy, M. Lung Nodule Segmentation and Detection in Computed Tomography. In Proceedings of the 8th Eighth International Conference on Intelligent Computing and Information Systems (ICICIS), Cairo, Egypt, 5–7 December 2017. [<a href="https://scholar.google.com/scholar_lookup?title=Lung+Nodule+Segmentation+and+Detection+in+Computed+Tomography&conference=Proceedings+of+the+8th+Eighth+International+Conference+on+Intelligent+Computing+and+Information+Systems+(ICICIS)&author=El+Regaily,+S.&author=Salem,+M.&author=Abdel+Aziz,+M.&author=Roushdy,+M.&publication_year=2017&doi=10.1109/INTELCIS.2017.8260029" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/INTELCIS.2017.8260029" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B12-diagnostics-09-00029' class='html-xx' data-content='12.'>Firmino, M.; Angelo, G.; Morais, H.; Dantas, M.R.; Valentim, R. Computer-aided detection (CADe) and diagnosis (CADx) system for lung cancer with likelihood of malignancy. <span class='html-italic'>Biomed. Eng. Online</span> <b>2016</b>, <span class='html-italic'>15</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Computer-aided+detection+(CADe)+and+diagnosis+(CADx)+system+for+lung+cancer+with+likelihood+of+malignancy&author=Firmino,+M.&author=Angelo,+G.&author=Morais,+H.&author=Dantas,+M.R.&author=Valentim,+R.&publication_year=2016&journal=Biomed.+Eng.+Online&volume=15&doi=10.1186/s12938-015-0120-7&pmid=26759159" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1186/s12938-015-0120-7" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/26759159" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B13-diagnostics-09-00029' class='html-xx' data-content='13.'>Gonçalves, L.; Novo, J.; Cunha, A.; Campilho, A. Learning Lung Nodule Malignancy Likelihood from Radiologist Annotations or Diagnosis Data. <span class='html-italic'>J. Med. Biol. Eng.</span> <b>2018</b>, <span class='html-italic'>38</span>, 424–442. [<a href="https://scholar.google.com/scholar_lookup?title=Learning+Lung+Nodule+Malignancy+Likelihood+from+Radiologist+Annotations+or+Diagnosis+Data&author=Gon%C3%A7alves,+L.&author=Novo,+J.&author=Cunha,+A.&author=Campilho,+A.&publication_year=2018&journal=J.+Med.+Biol.+Eng.&volume=38&pages=424%E2%80%93442&doi=10.1007/s40846-017-0317-2" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s40846-017-0317-2" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B14-diagnostics-09-00029' class='html-xx' data-content='14.'>Gong, J.; Liu, J.-Y.; Wang, L.-J.; Zheng, B.; Nie, S.-D. Computer-aided detection of pulmonary nodules using dynamic self-adaptive template matching and a FLDA classifier. <span class='html-italic'>Phys. Medica</span> <b>2016</b>, <span class='html-italic'>32</span>, 1502–1509. [<a href="https://scholar.google.com/scholar_lookup?title=Computer-aided+detection+of+pulmonary+nodules+using+dynamic+self-adaptive+template+matching+and+a+FLDA+classifier&author=Gong,+J.&author=Liu,+J.-Y.&author=Wang,+L.-J.&author=Zheng,+B.&author=Nie,+S.-D.&publication_year=2016&journal=Phys.+Medica&volume=32&pages=1502%E2%80%931509&doi=10.1016/j.ejmp.2016.11.001&pmid=27856118" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.ejmp.2016.11.001" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/27856118" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B15-diagnostics-09-00029' class='html-xx' data-content='15.'>Gupta, A.; Saar, T.; Martens, O.; Moullec, Y.L. Unsupervised feature mapping via stacked sparse autoencoder for automated detection of large pulmonary nodules in CT images. <span class='html-italic'>Elektron. Elektrotechnika</span> <b>2017</b>, <span class='html-italic'>23</span>, 59–63. [<a href="https://scholar.google.com/scholar_lookup?title=Unsupervised+feature+mapping+via+stacked+sparse+autoencoder+for+automated+detection+of+large+pulmonary+nodules+in+CT+images&author=Gupta,+A.&author=Saar,+T.&author=Martens,+O.&author=Moullec,+Y.L.&publication_year=2017&journal=Elektron.+Elektrotechnika&volume=23&pages=59%E2%80%9363&doi=10.5755/j01.eie.23.6.19695" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.5755/j01.eie.23.6.19695" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B16-diagnostics-09-00029' class='html-xx' data-content='16.'>Hancock, M.C.; Magnan, J.F. Predictive capabilities of statistical learning methods for lung nodule malignancy classification using diagnostic image features: An investigation using the Lung Image Database Consortium dataset. <span class='html-italic'>SPIE Med. Imaging</span> <b>2017</b>, <span class='html-italic'>1013425</span>, 1013425. [<a href="https://scholar.google.com/scholar_lookup?title=Predictive+capabilities+of+statistical+learning+methods+for+lung+nodule+malignancy+classification+using+diagnostic+image+features:+An+investigation+using+the+Lung+Image+Database+Consortium+dataset&author=Hancock,+M.C.&author=Magnan,+J.F.&publication_year=2017&journal=SPIE+Med.+Imaging&volume=1013425&pages=1013425&doi=10.1117/12.2254446" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1117/12.2254446" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B17-diagnostics-09-00029' class='html-xx' data-content='17.'>Jaffar, M.A.; Zia, M.S.; Hussain, M.; Siddiqui, A.B.; Akram, S.; Jamil, U. An ensemble shape gradient features descriptor based nodule detection paradigm: A novel model to augment complex diagnostic decisions assistance. <span class='html-italic'>Multimed. Tools Appl.</span> <b>2018</b>, 1–27. [<a href="https://scholar.google.com/scholar_lookup?title=An+ensemble+shape+gradient+features+descriptor+based+nodule+detection+paradigm:+A+novel+model+to+augment+complex+diagnostic+decisions+assistance&author=Jaffar,+M.A.&author=Zia,+M.S.&author=Hussain,+M.&author=Siddiqui,+A.B.&author=Akram,+S.&author=Jamil,+U.&publication_year=2018&journal=Multimed.+Tools+Appl.&pages=1%E2%80%9327&doi=10.1007/s11042-018-6092-4" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s11042-018-6092-4" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B18-diagnostics-09-00029' class='html-xx' data-content='18.'>Liu, X.; Hou, F.; Qin, H.; Hao, A. A CADe system for nodule detection in thoracic CT images based on artificial neural network. <span class='html-italic'>Sci. China Inf. Sci.</span> <b>2017</b>, <span class='html-italic'>60</span>. [<a href="https://scholar.google.com/scholar_lookup?title=A+CADe+system+for+nodule+detection+in+thoracic+CT+images+based+on+artificial+neural+network&author=Liu,+X.&author=Hou,+F.&author=Qin,+H.&author=Hao,+A.&publication_year=2017&journal=Sci.+China+Inf.+Sci.&volume=60&doi=10.1007/s11432-016-9008-0" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s11432-016-9008-0" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B19-diagnostics-09-00029' class='html-xx' data-content='19.'>Lu, L.; Tan, Y.; Schwartz, L.H.; Zhao, B. Hybrid detection of lung nodules on CT scan images. <span class='html-italic'>Med. Phys.</span> <b>2015</b>, <span class='html-italic'>42</span>, 5042–5054. [<a href="https://scholar.google.com/scholar_lookup?title=Hybrid+detection+of+lung+nodules+on+CT+scan+images&author=Lu,+L.&author=Tan,+Y.&author=Schwartz,+L.H.&author=Zhao,+B.&publication_year=2015&journal=Med.+Phys.&volume=42&pages=5042%E2%80%935054&doi=10.1118/1.4927573&pmid=26328955" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1118/1.4927573" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/26328955" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B20-diagnostics-09-00029' class='html-xx' data-content='20.'>Naqi, S.M.; Sharif, M.; Yasmin, M. Multistage segmentation model and SVM-ensemble for precise lung nodule detection. <span class='html-italic'>Int. J. Comput. Assist. Radiol. Surg.</span> <b>2018</b>, <span class='html-italic'>13</span>, 1083–1095. [<a href="https://scholar.google.com/scholar_lookup?title=Multistage+segmentation+model+and+SVM-ensemble+for+precise+lung+nodule+detection&author=Naqi,+S.M.&author=Sharif,+M.&author=Yasmin,+M.&publication_year=2018&journal=Int.+J.+Comput.+Assist.+Radiol.+Surg.&volume=13&pages=1083%E2%80%931095&doi=10.1007/s11548-018-1715-9&pmid=29492880" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s11548-018-1715-9" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/29492880" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B21-diagnostics-09-00029' class='html-xx' data-content='21.'>Shaukat, F.; Raja, G.; Gooya, A.; Frangi, A.F. Fully automatic detection of lung nodules in CT images using a hybrid feature set. <span class='html-italic'>Med. Phys.</span> <b>2017</b>, <span class='html-italic'>44</span>, 3615–3629. [<a href="https://scholar.google.com/scholar_lookup?title=Fully+automatic+detection+of+lung+nodules+in+CT+images+using+a+hybrid+feature+set&author=Shaukat,+F.&author=Raja,+G.&author=Gooya,+A.&author=Frangi,+A.F.&publication_year=2017&journal=Med.+Phys.&volume=44&pages=3615%E2%80%933629&doi=10.1002/mp.12273&pmid=28409834" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1002/mp.12273" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/28409834" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>][<a href="http://eprints.whiterose.ac.uk/115106/1/Research_Paper_Med_R.pdf" target='_blank' rel="noopener noreferrer">Green Version</a>]</li><li id='B22-diagnostics-09-00029' class='html-xx' data-content='22.'>Taşcı, E.; Uğur, A. Shape and Texture Based Novel Features for Automated Juxtapleural Nodule Detection in Lung CTs. <span class='html-italic'>J. Med. Syst.</span> <b>2015</b>, <span class='html-italic'>39</span>, 1–13. [<a href="https://scholar.google.com/scholar_lookup?title=Shape+and+Texture+Based+Novel+Features+for+Automated+Juxtapleural+Nodule+Detection+in+Lung+CTs&author=Ta%C5%9Fc%C4%B1,+E.&author=U%C4%9Fur,+A.&publication_year=2015&journal=J.+Med.+Syst.&volume=39&pages=1%E2%80%9313&doi=10.1007/s10916-015-0231-5&pmid=25732079" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s10916-015-0231-5" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/25732079" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B23-diagnostics-09-00029' class='html-xx' data-content='23.'>Wang, Z.; Xin, J.; Sun, P.; Lin, Z.; Yao, Y.; Gao, X. Improved lung nodule diagnosis accuracy using lung CT images with uncertain class. <span class='html-italic'>Comput. Methods Programs Biomed.</span> <b>2018</b>, <span class='html-italic'>162</span>, 197–209. [<a href="https://scholar.google.com/scholar_lookup?title=Improved+lung+nodule+diagnosis+accuracy+using+lung+CT+images+with+uncertain+class&author=Wang,+Z.&author=Xin,+J.&author=Sun,+P.&author=Lin,+Z.&author=Yao,+Y.&author=Gao,+X.&publication_year=2018&journal=Comput.+Methods+Programs+Biomed.&volume=162&pages=197%E2%80%93209&doi=10.1016/j.cmpb.2018.05.028&pmid=29903487" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.cmpb.2018.05.028" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/29903487" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B24-diagnostics-09-00029' class='html-xx' data-content='24.'>Zhang, W.; Wang, X.; Li, X.; Chen, J. 3D skeletonization feature-based computer-aided detection system for pulmonary nodules in CT datasets. <span class='html-italic'>Comput. Biol. Med.</span> <b>2018</b>, <span class='html-italic'>92</span>, 64–72. [<a href="https://scholar.google.com/scholar_lookup?title=3D+skeletonization+feature-based+computer-aided+detection+system+for+pulmonary+nodules+in+CT+datasets&author=Zhang,+W.&author=Wang,+X.&author=Li,+X.&author=Chen,+J.&publication_year=2018&journal=Comput.+Biol.+Med.&volume=92&pages=64%E2%80%9372&doi=10.1016/j.compbiomed.2017.11.008&pmid=29154123" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.compbiomed.2017.11.008" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/29154123" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B25-diagnostics-09-00029' class='html-xx' data-content='25.'>Zhao, T.; Wang, H.; Li, L.; Qi, Y.; Gao, H.; Han, F.F.; Liang, Z.; Qi, Y.; Cao, Y. <span class='html-italic'>A Hybrid CNN Feature Model for Pulmonary Nodule Differentiation Task</span>; Springer: Cham, Switzerland, 2017. [<a href="https://scholar.google.com/scholar_lookup?title=A+Hybrid+CNN+Feature+Model+for+Pulmonary+Nodule+Differentiation+Task&author=Zhao,+T.&author=Wang,+H.&author=Li,+L.&author=Qi,+Y.&author=Gao,+H.&author=Han,+F.F.&author=Liang,+Z.&author=Qi,+Y.&author=Cao,+Y.&publication_year=2017" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/978-3-319-67552-7_3" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B26-diagnostics-09-00029' class='html-xx' data-content='26.'>Chen, J. The Effect of Kernel Size of CNNs for Lung Nodule Classification. In Proceedings of the 2017 9th International Conference on Advanced Infocomm Technology (ICAIT), Chengdu, China, 22–24 November 2017; pp. 340–344. [<a href="https://scholar.google.com/scholar_lookup?title=The+Effect+of+Kernel+Size+of+CNNs+for+Lung+Nodule+Classification&conference=Proceedings+of+the+2017+9th+International+Conference+on+Advanced+Infocomm+Technology+(ICAIT)&author=Chen,+J.&publication_year=2017&pages=340%E2%80%93344" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>]</li><li id='B27-diagnostics-09-00029' class='html-xx' data-content='27.'>Da Nóbrega, R.V.M.; Peixoto, S.A.; Da Silva, S.P.P.; Filho, P.P.R. Lung Nodule Classification via Deep Transfer Learning in CT Lung Images. In Proceedings of the 2018 IEEE 31st International Symposium on Computer-Based Medical Systems (CBMS), Karlstad, Sweden, 18–21 June 2018; pp. 244–249. [<a href="https://scholar.google.com/scholar_lookup?title=Lung+Nodule+Classification+via+Deep+Transfer+Learning+in+CT+Lung+Images&conference=Proceedings+of+the+2018+IEEE+31st+International+Symposium+on+Computer-Based+Medical+Systems+(CBMS)&author=Da+N%C3%B3brega,+R.V.M.&author=Peixoto,+S.A.&author=Da+Silva,+S.P.P.&author=Filho,+P.P.R.&publication_year=2018&pages=244%E2%80%93249&doi=10.1109/CBMS.2018.00050" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/CBMS.2018.00050" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B28-diagnostics-09-00029' class='html-xx' data-content='28.'>Da Silva, G.L.F.; da Silva Neto, O.P.; Silva, A.C.; de Paiva, A.C.; Gattass, M. Lung nodules diagnosis based on evolutionary convolutional neural network. <span class='html-italic'>Multimed. Tools Appl.</span> <b>2017</b>, <span class='html-italic'>76</span>, 19039–19055. [<a href="https://scholar.google.com/scholar_lookup?title=Lung+nodules+diagnosis+based+on+evolutionary+convolutional+neural+network&author=Da+Silva,+G.L.F.&author=da+Silva+Neto,+O.P.&author=Silva,+A.C.&author=de+Paiva,+A.C.&author=Gattass,+M.&publication_year=2017&journal=Multimed.+Tools+Appl.&volume=76&pages=19039%E2%80%9319055&doi=10.1007/s11042-017-4480-9" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s11042-017-4480-9" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B29-diagnostics-09-00029' class='html-xx' data-content='29.'>Da Silva, G.L.F.; Valente, T.L.A.; Silva, A.C.; de Paiva, A.C.; Gattass, M. Convolutional neural network-based PSO for lung nodule false positive reduction on CT images. <span class='html-italic'>Comput. Methods Programs Biomed.</span> <b>2018</b>, <span class='html-italic'>162</span>, 109–118. [<a href="https://scholar.google.com/scholar_lookup?title=Convolutional+neural+network-based+PSO+for+lung+nodule+false+positive+reduction+on+CT+images&author=Da+Silva,+G.L.F.&author=Valente,+T.L.A.&author=Silva,+A.C.&author=de+Paiva,+A.C.&author=Gattass,+M.&publication_year=2018&journal=Comput.+Methods+Programs+Biomed.&volume=162&pages=109%E2%80%93118&doi=10.1016/j.cmpb.2018.05.006&pmid=29903476" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.cmpb.2018.05.006" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/29903476" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B30-diagnostics-09-00029' class='html-xx' data-content='30.'>Han, G.; Liu, X.; Zheng, G.; Wang, M.; Huang, S. Automatic recognition of 3D GGO CT imaging signs through the fusion of hybrid resampling and layer-wise fine-tuning CNNs. <span class='html-italic'>Med. Biol. Eng. Comput.</span> <b>2018</b>, 2201–2212. [<a href="https://scholar.google.com/scholar_lookup?title=Automatic+recognition+of+3D+GGO+CT+imaging+signs+through+the+fusion+of+hybrid+resampling+and+layer-wise+fine-tuning+CNNs&author=Han,+G.&author=Liu,+X.&author=Zheng,+G.&author=Wang,+M.&author=Huang,+S.&publication_year=2018&journal=Med.+Biol.+Eng.+Comput.&pages=2201%E2%80%932212&doi=10.1007/s11517-018-1850-z&pmid=29873026" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s11517-018-1850-z" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/29873026" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B31-diagnostics-09-00029' class='html-xx' data-content='31.'>Ramachandran, S.; George, J.; Skaria, S.; Varun, V.V. Using YOLO based deep learning network for real time detection and localization of lung nodules from low dose CT scans. In Proceedings of the Medical Imaging 2018: Computer-Aided Diagnosis, Houston, TX, USA, 12–15 February 2018; Volume 53. [<a href="https://scholar.google.com/scholar_lookup?title=Using+YOLO+based+deep+learning+network+for+real+time+detection+and+localization+of+lung+nodules+from+low+dose+CT+scans&conference=Proceedings+of+the+Medical+Imaging+2018:+Computer-Aided+Diagnosis&author=Ramachandran,+S.&author=George,+J.&author=Skaria,+S.&author=Varun,+V.V.&publication_year=2018&doi=10.1117/12.2293699" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1117/12.2293699" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B32-diagnostics-09-00029' class='html-xx' data-content='32.'>Song, Q.Z.; Zhao, L.; Luo, X.K.; Dou, X.C. Using Deep Learning for Classification of Lung Nodules on Computed Tomography Images. <span class='html-italic'>J. Healthc. Eng.</span> <b>2017</b>, <span class='html-italic'>2017</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Using+Deep+Learning+for+Classification+of+Lung+Nodules+on+Computed+Tomography+Images&author=Song,+Q.Z.&author=Zhao,+L.&author=Luo,+X.K.&author=Dou,+X.C.&publication_year=2017&journal=J.+Healthc.+Eng.&volume=2017&doi=10.1155/2017/8314740" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1155/2017/8314740" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B33-diagnostics-09-00029' class='html-xx' data-content='33.'>Sun, W.; Zheng, B.; Qian, W. Automatic Feature Learning Using Multichannel ROI Based on Deep Structured Algorithms for Computerized Lung Cancer Diagnosis. <span class='html-italic'>Comput. Biol. Med.</span> <b>2017</b>, <span class='html-italic'>89</span>, 530–539. [<a href="https://scholar.google.com/scholar_lookup?title=Automatic+Feature+Learning+Using+Multichannel+ROI+Based+on+Deep+Structured+Algorithms+for+Computerized+Lung+Cancer+Diagnosis&author=Sun,+W.&author=Zheng,+B.&author=Qian,+W.&publication_year=2017&journal=Comput.+Biol.+Med.&volume=89&pages=530%E2%80%93539&doi=10.1016/j.compbiomed.2017.04.006&pmid=28473055" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.compbiomed.2017.04.006" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/28473055" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B34-diagnostics-09-00029' class='html-xx' data-content='34.'>Wang, S.; Zhou, M.; Liu, Z.; Liu, Z.; Gu, D.; Zang, Y.; Dong, D.; Gevaert, O.; Tian, J. Central focused convolutional neural networks: Developing a data-driven model for lung nodule segmentation. <span class='html-italic'>Med. Image Anal.</span> <b>2017</b>, <span class='html-italic'>40</span>, 172–183. [<a href="https://scholar.google.com/scholar_lookup?title=Central+focused+convolutional+neural+networks:+Developing+a+data-driven+model+for+lung+nodule+segmentation&author=Wang,+S.&author=Zhou,+M.&author=Liu,+Z.&author=Liu,+Z.&author=Gu,+D.&author=Zang,+Y.&author=Dong,+D.&author=Gevaert,+O.&author=Tian,+J.&publication_year=2017&journal=Med.+Image+Anal.&volume=40&pages=172%E2%80%93183&doi=10.1016/j.media.2017.06.014&pmid=28688283" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.media.2017.06.014" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/28688283" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B35-diagnostics-09-00029' class='html-xx' data-content='35.'>Zhao, X.; Liu, L.; Qi, S.; Teng, Y.; Li, J.; Qian, W. Agile convolutional neural network for pulmonary nodule classification using CT images. <span class='html-italic'>Int. J. Comput. Assist. Radiol. Surg.</span> <b>2018</b>, <span class='html-italic'>13</span>, 585–595. [<a href="https://scholar.google.com/scholar_lookup?title=Agile+convolutional+neural+network+for+pulmonary+nodule+classification+using+CT+images&author=Zhao,+X.&author=Liu,+L.&author=Qi,+S.&author=Teng,+Y.&author=Li,+J.&author=Qian,+W.&publication_year=2018&journal=Int.+J.+Comput.+Assist.+Radiol.+Surg.&volume=13&pages=585%E2%80%93595&doi=10.1007/s11548-017-1696-0&pmid=29473129" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s11548-017-1696-0" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/29473129" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B36-diagnostics-09-00029' class='html-xx' data-content='36.'>Zhu, W.; Liu, C.; Fan, W.; Xie, X. DeepLung: Deep 3D dual path nets for automated pulmonary nodule detection and classification. In Proceedings of the 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), Lake Tahoe, NV, USA, 12–15 March 2018; pp. 673–681. [<a href="https://scholar.google.com/scholar_lookup?title=DeepLung:+Deep+3D+dual+path+nets+for+automated+pulmonary+nodule+detection+and+classification&conference=Proceedings+of+the+2018+IEEE+Winter+Conference+on+Applications+of+Computer+Vision+(WACV)&author=Zhu,+W.&author=Liu,+C.&author=Fan,+W.&author=Xie,+X.&publication_year=2018&pages=673%E2%80%93681&doi=10.1109/WACV.2018.00079" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/WACV.2018.00079" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B37-diagnostics-09-00029' class='html-xx' data-content='37.'>Zhang, T.; Zhao, J.; Luo, J.; Qiang, Y. Deep belief network for lung nodules diagnosed in CT imaging. <span class='html-italic'>Int. J. Perform. Eng.</span> <b>2017</b>, <span class='html-italic'>13</span>, 1358–1370. [<a href="https://scholar.google.com/scholar_lookup?title=Deep+belief+network+for+lung+nodules+diagnosed+in+CT+imaging&author=Zhang,+T.&author=Zhao,+J.&author=Luo,+J.&author=Qiang,+Y.&publication_year=2017&journal=Int.+J.+Perform.+Eng.&volume=13&pages=1358%E2%80%931370&doi=10.23940/ijpe.17.08.p17.13581370" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.23940/ijpe.17.08.p17.13581370" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B38-diagnostics-09-00029' class='html-xx' data-content='38.'>Xie, Y.; Xia, Y.; Zhang, J.; Song, Y.; Feng, D.; Fulham, M.; Cai, W. Knowledge-based Collaborative Deep Learning for Benign-Malignant Lung Nodule Classification on Chest CT. <span class='html-italic'>IEEE Trans. Med. Imaging</span> <b>2018</b>. [<a href="https://scholar.google.com/scholar_lookup?title=Knowledge-based+Collaborative+Deep+Learning+for+Benign-Malignant+Lung+Nodule+Classification+on+Chest+CT&author=Xie,+Y.&author=Xia,+Y.&author=Zhang,+J.&author=Song,+Y.&author=Feng,+D.&author=Fulham,+M.&author=Cai,+W.&publication_year=2018&journal=IEEE+Trans.+Med.+Imaging&doi=10.1109/TMI.2018.2876510&pmid=30334786" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/TMI.2018.2876510" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/30334786" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B39-diagnostics-09-00029' class='html-xx' data-content='39.'>Xie, Y.; Zhang, J.; Xia, Y.; Fulham, M.; Zhang, Y. Fusing texture, shape and deep model-learned information at decision level for automated classification of lung nodules on chest CT. <span class='html-italic'>Inf. Fusion</span> <b>2018</b>, <span class='html-italic'>42</span>, 102–110. [<a href="https://scholar.google.com/scholar_lookup?title=Fusing+texture,+shape+and+deep+model-learned+information+at+decision+level+for+automated+classification+of+lung+nodules+on+chest+CT&author=Xie,+Y.&author=Zhang,+J.&author=Xia,+Y.&author=Fulham,+M.&author=Zhang,+Y.&publication_year=2018&journal=Inf.+Fusion&volume=42&pages=102%E2%80%93110&doi=10.1016/j.inffus.2017.10.005" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1016/j.inffus.2017.10.005" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B40-diagnostics-09-00029' class='html-xx' data-content='40.'>Li, W.; Cao, P.; Zhao, D.; Wang, J. Pulmonary Nodule Classification with Deep Convolutional Neural Networks on Computed Tomography Images. <span class='html-italic'>Comput. Math. Methods Med.</span> <b>2016</b>, <span class='html-italic'>2016</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Pulmonary+Nodule+Classification+with+Deep+Convolutional+Neural+Networks+on+Computed+Tomography+Images&author=Li,+W.&author=Cao,+P.&author=Zhao,+D.&author=Wang,+J.&publication_year=2016&journal=Comput.+Math.+Methods+Med.&volume=2016&doi=10.1155/2016/6215085&pmid=28070212" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1155/2016/6215085" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/28070212" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B41-diagnostics-09-00029' class='html-xx' data-content='41.'>Dobrenkii, A.; Kuleev, R.; Khan, A.; Rivera, A.R.; Khattak, A.M. Large residual multiple view 3D CNN for false positive reduction in pulmonary nodule detection. In Proceedings of the 2017 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB), Manchester, UK, 23–25 August 2017. [<a href="https://scholar.google.com/scholar_lookup?title=Large+residual+multiple+view+3D+CNN+for+false+positive+reduction+in+pulmonary+nodule+detection&conference=Proceedings+of+the+2017+IEEE+Conference+on+Computational+Intelligence+in+Bioinformatics+and+Computational+Biology+(CIBCB)&author=Dobrenkii,+A.&author=Kuleev,+R.&author=Khan,+A.&author=Rivera,+A.R.&author=Khattak,+A.M.&publication_year=2017&doi=10.1109/CIBCB.2017.8058549" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/CIBCB.2017.8058549" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B42-diagnostics-09-00029' class='html-xx' data-content='42.'>Shaffie, A.; Soliman, A.; Fraiwan, L.; Ghazal, M.; Taher, F.; Dunlap, N.; Wang, B.; van Berkel, V.; Keynton, R.; Elmaghraby, A.; et al. A Generalized Deep Learning-Based Diagnostic System for Early Diagnosis of Various Types of Pulmonary Nodules. <span class='html-italic'>Technol. Cancer Res. Treat.</span> <b>2018</b>, <span class='html-italic'>17</span>. [<a href="https://scholar.google.com/scholar_lookup?title=A+Generalized+Deep+Learning-Based+Diagnostic+System+for+Early+Diagnosis+of+Various+Types+of+Pulmonary+Nodules&author=Shaffie,+A.&author=Soliman,+A.&author=Fraiwan,+L.&author=Ghazal,+M.&author=Taher,+F.&author=Dunlap,+N.&author=Wang,+B.&author=van+Berkel,+V.&author=Keynton,+R.&author=Elmaghraby,+A.&publication_year=2018&journal=Technol.+Cancer+Res.+Treat.&volume=17&doi=10.1177/1533033818798800&pmid=30244648" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1177/1533033818798800" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/30244648" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B43-diagnostics-09-00029' class='html-xx' data-content='43.'>Gruetzemacher, R.; Gupta, A.; Paradice, D. 3D deep learning for detecting pulmonary nodules in CT scans. <span class='html-italic'>J. Am. Med. Inform. Assoc.</span> <b>2018</b>, <span class='html-italic'>25</span>, 1301–1310. [<a href="https://scholar.google.com/scholar_lookup?title=3D+deep+learning+for+detecting+pulmonary+nodules+in+CT+scans&author=Gruetzemacher,+R.&author=Gupta,+A.&author=Paradice,+D.&publication_year=2018&journal=J.+Am.+Med.+Inform.+Assoc.&volume=25&pages=1301%E2%80%931310&doi=10.1093/jamia/ocy098&pmid=30137371" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1093/jamia/ocy098" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/30137371" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B44-diagnostics-09-00029' class='html-xx' data-content='44.'>Abbas, Q. Nodular-Deep: Classification of Pulmonary Nodules using Deep Neural Network. <span class='html-italic'>Int. J. Med. Res. Heal. Sci.</span> <b>2017</b>, <span class='html-italic'>6</span>, 111–118. [<a href="https://scholar.google.com/scholar_lookup?title=Nodular-Deep:+Classification+of+Pulmonary+Nodules+using+Deep+Neural+Network&author=Abbas,+Q.&publication_year=2017&journal=Int.+J.+Med.+Res.+Heal.+Sci.&volume=6&pages=111%E2%80%93118" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>]</li><li id='B45-diagnostics-09-00029' class='html-xx' data-content='45.'>Hamidian, S.; Sahiner, B.; Petrick, N.; Pezeshk, A. 3D convolutional neural network for automatic detection of lung nodules in chest CT. <span class='html-italic'>Proc SPIE Int Soc Opt Eng.</span> <b>2017</b>, <span class='html-italic'>10134</span>. [<a href="https://scholar.google.com/scholar_lookup?title=3D+convolutional+neural+network+for+automatic+detection+of+lung+nodules+in+chest+CT&author=Hamidian,+S.&author=Sahiner,+B.&author=Petrick,+N.&author=Pezeshk,+A.&publication_year=2017&journal=Proc+SPIE+Int+Soc+Opt+Eng.&volume=10134&doi=10.1117/12.2255795" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1117/12.2255795" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B46-diagnostics-09-00029' class='html-xx' data-content='46.'>Nibali, A.; He, Z.; Wollersheim, D. Pulmonary nodule classification with deep residual networks. <span class='html-italic'>Int. J. Comput. Assist. Radiol. Surg.</span> <b>2017</b>, <span class='html-italic'>12</span>, 1799–1808. [<a href="https://scholar.google.com/scholar_lookup?title=Pulmonary+nodule+classification+with+deep+residual+networks&author=Nibali,+A.&author=He,+Z.&author=Wollersheim,+D.&publication_year=2017&journal=Int.+J.+Comput.+Assist.+Radiol.+Surg.&volume=12&pages=1799%E2%80%931808&doi=10.1007/s11548-017-1605-6&pmid=28501942" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s11548-017-1605-6" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>] [<a href="https://www.ncbi.nlm.nih.gov/pubmed/28501942" class='cross-ref' data-typ='pmid' target='_blank' rel='noopener noreferrer'>PubMed</a>]</li><li id='B47-diagnostics-09-00029' class='html-xx' data-content='47.'>Naqi, S.M.; Sharif, M.; Jaffar, A. Lung nodule detection and classification based on geometric fit in parametric form and deep learning. <span class='html-italic'>Neural Comput. Appl.</span> <b>2018</b>, <span class='html-italic'>3456789</span>. [<a href="https://scholar.google.com/scholar_lookup?title=Lung+nodule+detection+and+classification+based+on+geometric+fit+in+parametric+form+and+deep+learning&author=Naqi,+S.M.&author=Sharif,+M.&author=Jaffar,+A.&publication_year=2018&journal=Neural+Comput.+Appl.&volume=3456789&doi=10.1007/s00521-018-3773-x" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1007/s00521-018-3773-x" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li><li id='B48-diagnostics-09-00029' class='html-xx' data-content='48.'>Christian, S.; Wei, L.; Yangqing, J.; Pierre, S.; Scott, R.; Dragomir, A.; Dumitru, E.; Vincent, V.; Andrew, R. Going Deeper with Convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Boston, MA, USA, 7–12 June 2015. [<a href="https://scholar.google.com/scholar_lookup?title=Going+Deeper+with+Convolutions&conference=Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition&author=Christian,+S.&author=Wei,+L.&author=Yangqing,+J.&author=Pierre,+S.&author=Scott,+R.&author=Dragomir,+A.&author=Dumitru,+E.&author=Vincent,+V.&author=Andrew,+R.&publication_year=2015&doi=10.1109/CVPR.2015.7298594" class='google-scholar' target='_blank' rel='noopener noreferrer'>Google Scholar</a>] [<a href="https://dx.doi.org/10.1109/CVPR.2015.7298594" class='cross-ref' target='_blank' rel='noopener noreferrer'>CrossRef</a>]</li></ol></section><section id='FigureandTables' type='display-objects'><div class="html-fig-wrap" id="diagnostics-09-00029-f001">
<div class='html-fig_img'>
<div class="html-figpopup html-figpopup-link" href="#fig_body_display_diagnostics-09-00029-f001">
<img alt="Diagnostics 09 00029 g001 550" data-large="/diagnostics/diagnostics-09-00029/article_deploy/html/images/diagnostics-09-00029-g001.png" data-original="/diagnostics/diagnostics-09-00029/article_deploy/html/images/diagnostics-09-00029-g001.png" onerror="/diagnostics/diagnostics-09-00029/article_deploy/html/images/diagnostics-09-00029-g001.png" src="/diagnostics/diagnostics-09-00029/article_deploy/html/images/diagnostics-09-00029-g001-550.jpg" />
<a class="html-expand html-figpopup" href="#fig_body_display_diagnostics-09-00029-f001"></a>
</div>
</div>
<div class="html-fig_description">
<b>Figure 1.</b>
Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) flowchart of the literature search and study selection.

</div>
</div>
<div class="html-fig_show  mfp-hide" id="fig_body_display_diagnostics-09-00029-f001">
<div class="html-caption"> <b>Figure 1.</b>
Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) flowchart of the literature search and study selection.</div>
<div class="html-img"><img alt="Diagnostics 09 00029 g001" data-large="/diagnostics/diagnostics-09-00029/article_deploy/html/images/diagnostics-09-00029-g001.png" data-original="/diagnostics/diagnostics-09-00029/article_deploy/html/images/diagnostics-09-00029-g001.png" onerror="/diagnostics/diagnostics-09-00029/article_deploy/html/images/diagnostics-09-00029-g001.png" src="/diagnostics/diagnostics-09-00029/article_deploy/html/images/diagnostics-09-00029-g001.png" /></div>
</div><div class="html-table-wrap" id="diagnostics-09-00029-t001">
<div class="html-table_wrap_td">
<div class="html-tablepopup html-tablepopup-link" href='#table_body_display_diagnostics-09-00029-t001'>
<img alt="Table" src="https://www.mdpi.com/img/table.png" />
<a class="html-expand html-tablepopup" href="#table_body_display_diagnostics-09-00029-t001"></a>
</div>
</div>
<div class="html-table_wrap_discription">
<b>Table 1.</b>
Feature-based algorithms applied to the Lung Image Database Consortium Image Collection (LIDC-IDRI) database.
</div>
</div>
<div class="html-table_show  mfp-hide " id="table_body_display_diagnostics-09-00029-t001">
<div class="html-caption"><b>Table 1.</b>
Feature-based algorithms applied to the Lung Image Database Consortium Image Collection (LIDC-IDRI) database.</div>
<table>
<thead><tr><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Author</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Year</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>CT Scans Incl.</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Accuracy (%)</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Sensitivity (%)</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Specificity (%)</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>AUC</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Classifier</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Nodule Type</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Selected Features</th></tr></thead><tbody><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Akram et al. * [<a href="#B7-diagnostics-09-00029" class="html-bibr">7</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2015</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>84</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>96.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>96.9</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>96.3</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.980</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>SVM</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2D and 3D geometric and intensity statistical features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Alilou et al. * [<a href="#B8-diagnostics-09-00029" class="html-bibr">8</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2014</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>60</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>80.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA </td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>SVM</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Solid</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2D and 3D subset of features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Bai et al. [<a href="#B9-diagnostics-09-00029" class="html-bibr">9</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2015</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>99</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>80.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Local shape analysis and data-driven local contextual feature learning</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Choi et al. * [<a href="#B10-diagnostics-09-00029" class="html-bibr">10</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2014</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>84</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>99.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>97.5</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>97.5</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.998</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>SVM-r</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CAD system for different dimensions of AHSN features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>El Regaily et al. [<a href="#B11-diagnostics-09-00029" class="html-bibr">11</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>400</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>70.5</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>77.7</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>69.5</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>The simple rule classifier</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Geometric and intensity statistical features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Firmino et al. * [<a href="#B12-diagnostics-09-00029" class="html-bibr">12</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2016</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>420</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>94.4</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>SVM</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>HOG; watershed; features of texture, shape, and appearance</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Gonçalves et al. * [<a href="#B13-diagnostics-09-00029" class="html-bibr">13</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>68.4</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>55.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>87.5</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.905</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>SVM</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Solid nodules</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Intensity-, texture-, and shape-based features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Gong et al. * [<a href="#B14-diagnostics-09-00029" class="html-bibr">14</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2016</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>100</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>91.5</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>90.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>91.5</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.960</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>FLDA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Not GGO</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>11 selected image features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Gupta et al. [<a href="#B15-diagnostics-09-00029" class="html-bibr">15</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>899</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>90.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.980</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>softmax</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Large nodules</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Feature mapping: stacked sparse autoencoder (SSAE)</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Hancock et al. * [<a href="#B16-diagnostics-09-00029" class="html-bibr">16</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>619</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>88.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>84.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.949</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Nonlinear</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Nonlinear classifier, diameter, and volume features included</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Jaffar et al. [<a href="#B17-diagnostics-09-00029" class="html-bibr">17</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>59</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>98.8</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>98.4</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>98.7</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.999</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Random forest</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Novel ensemble shape gradient features (NESGF)</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Liu et al. [<a href="#B18-diagnostics-09-00029" class="html-bibr">18</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>107</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>89.4</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Geometric and statistical features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Lu et al. [<a href="#B19-diagnostics-09-00029" class="html-bibr">19</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2015</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>98</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>85.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Regression tree</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Hybrid scheme based on 16 features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Naqi et al. * [<a href="#B20-diagnostics-09-00029" class="html-bibr">20</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>250</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>99.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>98.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>98.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.990</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>SVM </td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Geometric texture features descriptor (GTFD)</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Shaukat et al. * [<a href="#B21-diagnostics-09-00029" class="html-bibr">21</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>850</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>97.1</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>98.1</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>96.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.995</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>SVM-Gaussian</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Intensity, shape (2D and 3D), and texture features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Taşcı et al.* [<a href="#B22-diagnostics-09-00029" class="html-bibr">22</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2015</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>24</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>92.9</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.883</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>GLMR</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Juxtapleural</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Seven shape- and texture-based features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Wang et al. * [<a href="#B23-diagnostics-09-00029" class="html-bibr">23</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>95.9</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>95.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>95.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.961</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>SS-ELM</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Haralick features and morphological features</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Zhang et al. * [<a href="#B24-diagnostics-09-00029" class="html-bibr">24</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>71</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>89.3</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>SVM</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Juxtavascular nodules</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>3D skeletonization</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Zhao et al. [<a href="#B25-diagnostics-09-00029" class="html-bibr">25</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>91.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.970</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>softmax</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Global and local features</td></tr></tbody>
</table>
<div class='html-table_foot html-p'><div class='html-p' style='text-indent:0em;'><span class='html-fn-content'>CAD: Computer-aided detection, AHSN: angular histograms of surface normal, HOG: Histogram of oriented Gradients, NA: not available. The studies marked with a star (“*”) presented several types of alterations to the algorithm, producing different results. These results are not presented in the table.</span></div><div style='clear:both;'></div></div>
</div><div class="html-table-wrap" id="diagnostics-09-00029-t002">
<div class="html-table_wrap_td">
<div class="html-tablepopup html-tablepopup-link" href='#table_body_display_diagnostics-09-00029-t002'>
<img alt="Table" src="https://www.mdpi.com/img/table.png" />
<a class="html-expand html-tablepopup" href="#table_body_display_diagnostics-09-00029-t002"></a>
</div>
</div>
<div class="html-table_wrap_discription">
<b>Table 2.</b>
Deep learning algorithms applied to the LIDC-IDRI database.
</div>
</div>
<div class="html-table_show  mfp-hide " id="table_body_display_diagnostics-09-00029-t002">
<div class="html-caption"><b>Table 2.</b>
Deep learning algorithms applied to the LIDC-IDRI database.</div>
<table>
<thead><tr><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Author</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Year</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Malignant</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Benign</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Accuracy (%)</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Sensitivity (%)</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Specificity (%)</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>AUC</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Noduli Type</th><th align='center' valign='middle' style='border-top:solid thin;border-bottom:solid thin' class='html-align-center'>Architecture</th></tr></thead><tbody><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Chen et al. [<a href="#B26-diagnostics-09-00029" class="html-bibr">26</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>93.7</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Sun et al. [<a href="#B33-diagnostics-09-00029" class="html-bibr">33</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>47576</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>41372</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.890</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Wang et al. [<a href="#B34-diagnostics-09-00029" class="html-bibr">34</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>83.1</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Da Silva et al. [<a href="#B29-diagnostics-09-00029" class="html-bibr">29</a>] </td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>3415</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>8742</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>97.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>92.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>98.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.955</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Da silva et al. [<a href="#B28-diagnostics-09-00029" class="html-bibr">28</a>] </td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>1413</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>1830</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>94.75</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>94.7</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>95.1</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.940</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Causey et al. [<a href="#B6-diagnostics-09-00029" class="html-bibr">6</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>94.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>94.8</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>94.3</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.984</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Ramachandran et al. [<a href="#B31-diagnostics-09-00029" class="html-bibr">31</a>] </td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>3300</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>3300</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>93.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>89.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Zhu et al. [<a href="#B36-diagnostics-09-00029" class="html-bibr">36</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>450</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>554</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>90.4</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Da Nóbrega et al. [<a href="#B27-diagnostics-09-00029" class="html-bibr">27</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>88.4</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>85.3</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.931</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Song et al. [<a href="#B32-diagnostics-09-00029" class="html-bibr">32</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2311</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2265</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>84.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>84.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>84.3</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.910</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Han et al. [<a href="#B30-diagnostics-09-00029" class="html-bibr">30</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>538</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>622</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>82.5</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>96.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>71.4</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>GGO</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Zhao X. et al. [<a href="#B35-diagnostics-09-00029" class="html-bibr">35</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>375</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>368</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>82.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.877</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Zhang et al. [<a href="#B37-diagnostics-09-00029" class="html-bibr">37</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>40800</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>32000</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>95.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>93.5</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>90.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.930</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>&gt; 30 mm</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>DBN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Xie et al. [<a href="#B39-diagnostics-09-00029" class="html-bibr">39</a>] </td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>648</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>1324</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>89.53</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>84.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>92.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.960</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>DCNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Li et al. [<a href="#B40-diagnostics-09-00029" class="html-bibr">40</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2016</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>40772</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>21720</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>89.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>87.1</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>DCNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Shaffie et al. [<a href="#B42-diagnostics-09-00029" class="html-bibr">42</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>91.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>85.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>95.8</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.95 </td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Deep autoencoder</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Gruetzemacher et al. [<a href="#B43-diagnostics-09-00029" class="html-bibr">43</a>] </td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>94.2</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>DNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Abbas et al. [<a href="#B44-diagnostics-09-00029" class="html-bibr">44</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>1300</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>1300</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>95.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>94.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>96.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.950</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>DNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Hamidian et al. [<a href="#B45-diagnostics-09-00029" class="html-bibr">45</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>80.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>FCN + CNN</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Xie et al. [<a href="#B38-diagnostics-09-00029" class="html-bibr">38</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>644</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>1301</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>91.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>86.5</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>94.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>0.95 </td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>MV-KBC</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Nibali et al. [<a href="#B46-diagnostics-09-00029" class="html-bibr">46</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2017</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>420</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>411</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>89.9</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>91.1</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>88.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>ResNet</td></tr><tr><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>Naqi et al. [<a href="#B47-diagnostics-09-00029" class="html-bibr">47</a>]</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>2018</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>96.9</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>95.6</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>97.0</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>NA</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>All types</td><td align='center' valign='middle' style='border-bottom:solid thin' class='html-align-center'>SA + softmax</td></tr></tbody>
</table>
</div></section>
<section id="html-copyright"><br>© 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<a href="https://creativecommons.org/licenses/by/4.0/" target='_blank' rel="noopener noreferrer">http://creativecommons.org/licenses/by/4.0/</a>).</section>
</div>
</div>
</article>
</div>
</div>
</div>
</div>
</div>
</section>
<div id="footer">
<div class="journal-info">
<span>
<em><a class="Var_JournalInfo" href="/journal/diagnostics">Diagnostics</a></em>,
EISSN 2075-4418,
Published by MDPI
</span>
<span>
<a data-dropdown="drop-view-disclaimer-journal" aria-controls="drop-view-disclaimer-journal" aria-expanded="false" data-options="align:top; is_hover:true; hover_timeout:2000;">
Disclaimer
</a>
<div id="drop-view-disclaimer-journal" class="f-dropdown label__btn__dropdown label__btn__dropdown--wide text-left" data-dropdown-content aria-hidden="true" tabindex="-1">
The statements, opinions and data contained in the journal <em>Diagnostics</em> are solely
those of the individual authors and contributors and not of the publisher and the editor(s).
MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.
</div>
</span>
<div class="large-right">
<span>
<a href="/rss/journal/diagnostics" class="rss-link">RSS</a>
</span>
<span>
<a href="/journal/diagnostics/toc-alert">Content Alert</a>
</span>
</div>
</div>
<div class="row full-width footer-links" data-equalizer="footer" data-equalizer-mq="small">
<div class="large-2 large-push-4 medium-3 small-6 columns" data-equalizer-watch="footer">
<h3>
Further Information
</h3>
<a href="/apc">
Article Processing Charges
</a>
<a href="/about/payment">
Pay an Invoice
</a>
<a href="/openaccess">
Open Access Policy
</a>
<a href="/about/contact">
Contact MDPI
</a>
<a href="https://careers.mdpi.com" target="_blank" rel="noopener noreferrer">
Jobs at MDPI
</a>
</div>
<div class="large-2 large-push-4 medium-3 small-6 columns" data-equalizer-watch="footer">
<h3>
Guidelines
</h3>
<a href="/authors">
For Authors
</a>
<a href="/reviewers">
For Reviewers
</a>
<a href="/editors">
For Editors
</a>
<a href="/librarians">
For Librarians
</a>
<a href="/publishing_services">
For Publishers
</a>
<a href="/societies">
For Societies
</a>
<a href="/conference_organizers">
For Conference Organizers
</a>
</div>
<div class="large-2 large-push-4 medium-3 small-6 columns">
<h3>
MDPI Initiatives
</h3>
<a href="https://sciforum.net" target="_blank" rel="noopener noreferrer">
Sciforum
</a>
<a href="https://www.mdpi.com/books" target="_blank" rel="noopener noreferrer">
MDPI Books
</a>
<a href="https://www.preprints.org" target="_blank" rel="noopener noreferrer">
Preprints
</a>
<a href="https://www.scilit.net" target="_blank" rel="noopener noreferrer">
Scilit
</a>
<a href="https://sciprofiles.com" target="_blank" rel="noopener noreferrer">
SciProfiles
</a>
<a href="https://encyclopedia.pub" target="_blank" rel="noopener noreferrer">
Encyclopedia
</a>
<a href="https://jams.pub" target="_blank" rel="noopener noreferrer">
JAMS
</a>
<a href="/about/proceedings">
Proceedings Series
</a>
</div>
<div class="large-2 large-push-4 medium-3 small-6 right-border-large-without columns UA_FooterFollowMDPI">
<h3>
Follow MDPI
</h3>
<a href="https://www.linkedin.com/company/mdpi" target="_blank" rel="noopener noreferrer">
LinkedIn
</a>
<a href="https://www.facebook.com/MDPIOpenAccessPublishing" target="_blank" rel="noopener noreferrer">
Facebook
</a>
<a href="https://twitter.com/MDPIOpenAccess" target="_blank" rel="noopener noreferrer">
Twitter
</a>
</div>
<div id="footer-subscribe" class="large-4 large-pull-8 medium-12 small-12 left-border-large columns">
<div class="footer-subscribe__container">
<img class="show-for-large-up" src="/img/design/mdpi-pub-logo-white-small.png?71d18e5f805839ab" alt="MDPI" title="MDPI Open Access Journals" style="height: 50px; margin-bottom: 10px;">
<form id="newsletter" method="POST" action="/subscribe">
<p>
Subscribe to receive issue release notifications and newsletters from MDPI journals
</p>
<select multiple id="newsletter-journal" class="foundation-select" name="journals[]">
<option value="acoustics">Acoustics</option>
<option value="actuators">Actuators</option>
<option value="admsci">Administrative Sciences</option>
<option value="adolescents">Adolescents</option>
<option value="aerospace">Aerospace</option>
<option value="agriculture">Agriculture</option>
<option value="agriengineering">AgriEngineering</option>
<option value="agronomy">Agronomy</option>
<option value="ai">AI</option>
<option value="algorithms">Algorithms</option>
<option value="allergies">Allergies</option>
<option value="alloys">Alloys</option>
<option value="analytica">Analytica</option>
<option value="anatomia">Anatomia</option>
<option value="animals">Animals</option>
<option value="antibiotics">Antibiotics</option>
<option value="antibodies">Antibodies</option>
<option value="antioxidants">Antioxidants</option>
<option value="applbiosci">Applied Biosciences</option>
<option value="applmech">Applied Mechanics</option>
<option value="applmicrobiol">Applied Microbiology</option>
<option value="applnano">Applied Nano</option>
<option value="applsci">Applied Sciences</option>
<option value="asi">Applied System Innovation</option>
<option value="appliedchem">AppliedChem</option>
<option value="appliedmath">AppliedMath</option>
 <option value="aquacj">Aquaculture Journal</option>
<option value="architecture">Architecture</option>
<option value="arts">Arts</option>
<option value="astronomy">Astronomy</option>
<option value="atmosphere">Atmosphere</option>
<option value="atoms">Atoms</option>
<option value="audiolres">Audiology Research</option>
<option value="automation">Automation</option>
<option value="axioms">Axioms</option>
<option value="bacteria">Bacteria</option>
<option value="batteries">Batteries</option>
<option value="behavsci">Behavioral Sciences</option>
<option value="beverages">Beverages</option>
<option value="BDCC">Big Data and Cognitive Computing</option>
<option value="biochem">BioChem</option>
<option value="bioengineering">Bioengineering</option>
<option value="biologics">Biologics</option>
<option value="biology">Biology</option>
<option value="blsf">Biology and Life Sciences Forum</option>
<option value="biomass">Biomass</option>
<option value="biomechanics">Biomechanics</option>
<option value="biomed">BioMed</option>
<option value="biomedicines">Biomedicines</option>
<option value="biomedinformatics">BioMedInformatics</option>
<option value="biomimetics">Biomimetics</option>
<option value="biomolecules">Biomolecules</option>
<option value="biophysica">Biophysica</option>
<option value="biosensors">Biosensors</option>
<option value="biotech">BioTech</option>
<option value="birds">Birds</option>
<option value="brainsci">Brain Sciences</option>
<option value="buildings">Buildings</option>
<option value="businesses">Businesses</option>
<option value="carbon">C</option>
<option value="cancers">Cancers</option>
<option value="cardiogenetics">Cardiogenetics</option>
<option value="catalysts">Catalysts</option>
<option value="cells">Cells</option>
<option value="ceramics">Ceramics</option>
<option value="challenges">Challenges</option>
<option value="ChemEngineering">ChemEngineering</option>
<option value="chemistry">Chemistry</option>
<option value="chemproc">Chemistry Proceedings</option>
<option value="chemosensors">Chemosensors</option>
<option value="children">Children</option>
<option value="chips">Chips</option>
<option value="civileng">CivilEng</option>
<option value="cleantechnol">Clean Technologies</option>
<option value="climate">Climate</option>
<option value="ctn">Clinical and Translational Neuroscience</option>
<option value="clinpract">Clinics and Practice</option>
<option value="clockssleep">Clocks &amp; Sleep</option>
<option value="coasts">Coasts</option>
<option value="coatings">Coatings</option>
<option value="colloids">Colloids and Interfaces</option>
<option value="colorants">Colorants</option>
<option value="compounds">Compounds</option>
<option value="computation">Computation</option>
<option value="csmf">Computer Sciences &amp; Mathematics Forum</option>
<option value="computers">Computers</option>
<option value="condensedmatter">Condensed Matter</option>
<option value="conservation">Conservation</option>
<option value="constrmater">Construction Materials</option>
<option value="cmd">Corrosion and Materials Degradation</option>
<option value="cosmetics">Cosmetics</option>
<option value="covid">COVID</option>
<option value="crops">Crops</option>
<option value="cryptography">Cryptography</option>
<option value="crystals">Crystals</option>
<option value="cimb">Current Issues in Molecular Biology</option>
<option value="curroncol">Current Oncology</option>
<option value="dairy">Dairy</option>
<option value="data">Data</option>
<option value="dentistry">Dentistry Journal</option>
<option value="dermato">Dermato</option>
<option value="dermatopathology">Dermatopathology</option>
<option value="designs">Designs</option>
<option value="diabetology">Diabetology</option>
<option value="diagnostics">Diagnostics</option>
<option value="dietetics">Dietetics</option>
<option value="digital">Digital</option>
<option value="disabilities">Disabilities</option>
<option value="diseases">Diseases</option>
<option value="diversity">Diversity</option>
<option value="dna">DNA</option>
<option value="drones">Drones</option>
<option value="dynamics">Dynamics</option>
<option value="earth">Earth</option>
<option value="ecologies">Ecologies</option>
<option value="econometrics">Econometrics</option>
<option value="economies">Economies</option>
<option value="education">Education Sciences</option>
<option value="electricity">Electricity</option>
<option value="electrochem">Electrochem</option>
<option value="electronicmat">Electronic Materials</option>
<option value="electronics">Electronics</option>
<option value="encyclopedia">Encyclopedia</option>
<option value="endocrines">Endocrines</option>
<option value="energies">Energies</option>
<option value="eng">Eng</option>
<option value="engproc">Engineering Proceedings</option>
<option value="entomology">Entomology</option>
<option value="entropy">Entropy</option>
<option value="environsciproc">Environmental Sciences Proceedings</option>
<option value="environments">Environments</option>
<option value="epidemiologia">Epidemiologia</option>
<option value="epigenomes">Epigenomes</option>
<option value="ebj">European Burn Journal</option>
<option value="ejihpe">European Journal of Investigation in Health, Psychology and Education</option>
<option value="fermentation">Fermentation</option>
<option value="fibers">Fibers</option>
<option value="fintech">FinTech</option>
<option value="fire">Fire</option>
<option value="fishes">Fishes</option>
<option value="fluids">Fluids</option>
<option value="foods">Foods</option>
<option value="forecasting">Forecasting</option>
 <option value="forensicsci">Forensic Sciences</option>
<option value="forests">Forests</option>
<option value="foundations">Foundations</option>
<option value="fractalfract">Fractal and Fractional</option>
<option value="fuels">Fuels</option>
<option value="futureinternet">Future Internet</option>
<option value="futurepharmacol">Future Pharmacology</option>
<option value="futuretransp">Future Transportation</option>
<option value="galaxies">Galaxies</option>
<option value="games">Games</option>
<option value="gases">Gases</option>
<option value="gastroent">Gastroenterology Insights</option>
<option value="gastrointestdisord">Gastrointestinal Disorders</option>
<option value="gels">Gels</option>
<option value="genealogy">Genealogy</option>
<option value="genes">Genes</option>
<option value="geographies">Geographies</option>
<option value="geohazards">GeoHazards</option>
<option value="geomatics">Geomatics</option>
<option value="geosciences">Geosciences</option>
<option value="geotechnics">Geotechnics</option>
<option value="geriatrics">Geriatrics</option>
<option value="healthcare">Healthcare</option>
<option value="hearts">Hearts</option>
<option value="hemato">Hemato</option>
<option value="hematolrep">Hematology Reports</option>
 <option value="heritage">Heritage</option>
<option value="histories">Histories</option>
<option value="horticulturae">Horticulturae</option>
<option value="humanities">Humanities</option>
<option value="humans">Humans</option>
<option value="hydrobiology">Hydrobiology</option>
<option value="hydrogen">Hydrogen</option>
<option value="hydrology">Hydrology</option>
<option value="hygiene">Hygiene</option>
<option value="immuno">Immuno</option>
<option value="idr">Infectious Disease Reports</option>
<option value="informatics">Informatics</option>
<option value="information">Information</option>
<option value="infrastructures">Infrastructures</option>
<option value="inorganics">Inorganics</option>
<option value="insects">Insects</option>
<option value="instruments">Instruments</option>
<option value="ijerph">International Journal of Environmental Research and Public Health</option>
<option value="ijfs">International Journal of Financial Studies</option>
<option value="ijms">International Journal of Molecular Sciences</option>
<option value="IJNS">International Journal of Neonatal Screening</option>
<option value="ijpb">International Journal of Plant Biology</option>
<option value="ijtm">International Journal of Translational Medicine</option>
<option value="ijtpp">International Journal of Turbomachinery, Propulsion and Power</option>
<option value="inventions">Inventions</option>
<option value="IoT">IoT</option>
<option value="ijgi">ISPRS International Journal of Geo-Information</option>
<option value="J">J</option>
<option value="jal">Journal of Ageing and Longevity</option>
<option value="jcdd">Journal of Cardiovascular Development and Disease</option>
<option value="jcm">Journal of Clinical Medicine</option>
<option value="jcs">Journal of Composites Science</option>
<option value="jcp">Journal of Cybersecurity and Privacy</option>
<option value="jdb">Journal of Developmental Biology</option>
<option value="jfb">Journal of Functional Biomaterials</option>
<option value="jfmk">Journal of Functional Morphology and Kinesiology</option>
<option value="jof">Journal of Fungi</option>
<option value="jimaging">Journal of Imaging</option>
<option value="jintelligence">Journal of Intelligence</option>
<option value="jlpea">Journal of Low Power Electronics and Applications</option>
<option value="jmmp">Journal of Manufacturing and Materials Processing</option>
<option value="jmse">Journal of Marine Science and Engineering</option>
<option value="jmp">Journal of Molecular Pathology</option>
<option value="jnt">Journal of Nanotheranostics</option>
<option value="jne">Journal of Nuclear Engineering</option>
<option value="JOItmC">Journal of Open Innovation: Technology, Market, and Complexity</option>
<option value="ohbm">Journal of Otorhinolaryngology, Hearing and Balance Medicine</option>
<option value="jpm">Journal of Personalized Medicine</option>
<option value="jor">Journal of Respiration</option>
<option value="jrfm">Journal of Risk and Financial Management</option>
<option value="jsan">Journal of Sensor and Actuator Networks</option>
<option value="jtaer">Journal of Theoretical and Applied Electronic Commerce Research</option>
<option value="jox">Journal of Xenobiotics</option>
<option value="jzbg">Journal of Zoological and Botanical Gardens</option>
<option value="journalmedia">Journalism and Media</option>
<option value="kidneydial">Kidney and Dialysis</option>
<option value="knowledge">Knowledge</option>
<option value="land">Land</option>
<option value="languages">Languages</option>
<option value="laws">Laws</option>
<option value="life">Life</option>
<option value="liquids">Liquids</option>
<option value="literature">Literature</option>
<option value="livers">Livers</option>
<option value="logics">Logics</option>
<option value="logistics">Logistics</option>
<option value="lubricants">Lubricants</option>
<option value="make">Machine Learning and Knowledge Extraction</option>
<option value="machines">Machines</option>
<option value="macromol">Macromol</option>
<option value="magnetism">Magnetism</option>
<option value="magnetochemistry">Magnetochemistry</option>
<option value="marinedrugs">Marine Drugs</option>
<option value="materials">Materials</option>
<option value="materproc">Materials Proceedings</option>
<option value="mca">Mathematical and Computational Applications</option>
<option value="mathematics">Mathematics</option>
<option value="medsci">Medical Sciences</option>
<option value="msf">Medical Sciences Forum</option>
<option value="medicina">Medicina</option>
<option value="medicines">Medicines</option>
<option value="membranes">Membranes</option>
<option value="merits">Merits</option>
<option value="metabolites">Metabolites</option>
<option value="metals">Metals</option>
<option value="meteorology">Meteorology</option>
 <option value="methane">Methane</option>
<option value="mps">Methods and Protocols</option>
<option value="metrology">Metrology</option>
<option value="micro">Micro</option>
<option value="microbiolres">Microbiology Research</option>
<option value="micromachines">Micromachines</option>
<option value="microorganisms">Microorganisms</option>
<option value="microplastics">Microplastics</option>
<option value="minerals">Minerals</option>
<option value="mining">Mining</option>
<option value="modelling">Modelling</option>
<option value="molbank">Molbank</option>
<option value="molecules">Molecules</option>
<option value="mti">Multimodal Technologies and Interaction</option>
<option value="muscles">Muscles</option>
<option value="nanoenergyadv">Nanoenergy Advances</option>
<option value="nanomanufacturing">Nanomanufacturing</option>
<option value="nanomaterials">Nanomaterials</option>
<option value="network">Network</option>
<option value="neuroglia">Neuroglia</option>
<option value="neurolint">Neurology International</option>
<option value="neurosci">NeuroSci</option>
<option value="nitrogen">Nitrogen</option>
<option value="ncrna">Non-Coding RNA</option>
<option value="nursrep">Nursing Reports</option>
<option value="nutraceuticals">Nutraceuticals</option>
<option value="nutrients">Nutrients</option>
<option value="obesities">Obesities</option>
<option value="oceans">Oceans</option>
<option value="onco">Onco</option>
<option value="optics">Optics</option>
<option value="oral">Oral</option>
<option value="organics">Organics</option>
<option value="organoids">Organoids</option>
<option value="osteology">Osteology</option>
<option value="oxygen">Oxygen</option>
<option value="parasitologia">Parasitologia</option>
<option value="particles">Particles</option>
<option value="pathogens">Pathogens</option>
<option value="pathophysiology">Pathophysiology</option>
<option value="pediatrrep">Pediatric Reports</option>
<option value="pharmaceuticals">Pharmaceuticals</option>
<option value="pharmaceutics">Pharmaceutics</option>
<option value="pharmacoepidemiology">Pharmacoepidemiology</option>
<option value="pharmacy">Pharmacy</option>
<option value="philosophies">Philosophies</option>
<option value="photochem">Photochem</option>
<option value="photonics">Photonics</option>
<option value="phycology">Phycology</option>
<option value="physchem">Physchem</option>
<option value="psf">Physical Sciences Forum</option>
<option value="physics">Physics</option>
<option value="physiologia">Physiologia</option>
<option value="plants">Plants</option>
<option value="plasma">Plasma</option>
<option value="pollutants">Pollutants</option>
<option value="polymers">Polymers</option>
<option value="polysaccharides">Polysaccharides</option>
<option value="poultry">Poultry</option>
 <option value="powders">Powders</option>
<option value="proceedings">Proceedings</option>
<option value="processes">Processes</option>
<option value="prosthesis">Prosthesis</option>
<option value="proteomes">Proteomes</option>
<option value="psych">Psych</option>
<option value="psychiatryint">Psychiatry International</option>
<option value="publications">Publications</option>
<option value="qubs">Quantum Beam Science</option>
<option value="quantumrep">Quantum Reports</option>
<option value="quaternary">Quaternary</option>
<option value="radiation">Radiation</option>
<option value="reactions">Reactions</option>
<option value="recycling">Recycling</option>
<option value="religions">Religions</option>
<option value="remotesensing">Remote Sensing</option>
<option value="reports">Reports</option>
<option value="reprodmed">Reproductive Medicine</option>
<option value="resources">Resources</option>
<option value="rheumato">Rheumato</option>
<option value="risks">Risks</option>
<option value="robotics">Robotics</option>
<option value="ruminants">Ruminants</option>
<option value="safety">Safety</option>
<option value="sci">Sci</option>
<option value="scipharm">Scientia Pharmaceutica</option>
<option value="seeds">Seeds</option>
<option value="sensors">Sensors</option>
<option value="separations">Separations</option>
<option value="sexes">Sexes</option>
<option value="signals">Signals</option>
<option value="sinusitis">Sinusitis</option>
<option value="smartcities">Smart Cities</option>
<option value="socsci">Social Sciences</option>
<option value="societies">Societies</option>
<option value="software">Software</option>
<option value="soilsystems">Soil Systems</option>
<option value="solar">Solar</option>
<option value="solids">Solids</option>
<option value="sports">Sports</option>
<option value="standards">Standards</option>
<option value="stats">Stats</option>
<option value="stresses">Stresses</option>
<option value="surfaces">Surfaces</option>
<option value="surgeries">Surgeries</option>
<option value="std">Surgical Techniques Development</option>
<option value="sustainability">Sustainability</option>
<option value="suschem">Sustainable Chemistry</option>
<option value="symmetry">Symmetry</option>
<option value="synbio">SynBio</option>
<option value="systems">Systems</option>
<option value="taxonomy">Taxonomy</option>
<option value="technologies">Technologies</option>
<option value="telecom">Telecom</option>
<option value="textiles">Textiles</option>
<option value="thalassrep">Thalassemia Reports</option>
<option value="thermo">Thermo</option>
<option value="tomography">Tomography</option>
<option value="tourismhosp">Tourism and Hospitality</option>
 <option value="toxics">Toxics</option>
<option value="toxins">Toxins</option>
<option value="transplantology">Transplantology</option>
<option value="traumacare">Trauma Care</option>
<option value="tropicalmed">Tropical Medicine and Infectious Disease</option>
<option value="universe">Universe</option>
<option value="urbansci">Urban Science</option>
<option value="uro">Uro</option>
<option value="vaccines">Vaccines</option>
<option value="vehicles">Vehicles</option>
<option value="venereology">Venereology</option>
<option value="vetsci">Veterinary Sciences</option>
<option value="vibration">Vibration</option>
<option value="viruses">Viruses</option>
<option value="vision">Vision</option>
<option value="water">Water</option>
<option value="wind">Wind</option>
<option value="women">Women</option>
<option value="world">World</option>
<option value="wevj">World Electric Vehicle Journal</option>
<option value="youth">Youth</option>
<option value="zoonoticdis">Zoonotic Diseases</option>
</select>
<input name="email" type="email" placeholder="Enter your email address..." required="required" />
<button class="genericCaptcha button button--dark UA_FooterNewsletterSubscribeButton" type="submit">Subscribe</button>
</form>
</div>
</div>
</div>
<div id="footer-copyright">
<div class="row">
<div class="columns large-6 medium-6 small-12 text-left">
© 1996-2022 MDPI (Basel, Switzerland) unless otherwise stated
</div>
<div class="columns large-6 medium-6 small-12 small-text-left medium-text-right large-text-right">
<a data-dropdown="drop-view-disclaimer" aria-controls="drop-view-disclaimer" aria-expanded="false" data-options="align:top; is_hover:true; hover_timeout:2000;">
Disclaimer
</a>
<div id="drop-view-disclaimer" class="f-dropdown label__btn__dropdown label__btn__dropdown--wide text-left" data-dropdown-content aria-hidden="true" tabindex="-1">
The statements, opinions and data contained in the journals are solely
those of the individual authors and contributors and not of the publisher and the editor(s).
MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.
</div>
<a href="/about/terms-and-conditions">
Terms and Conditions
</a>
<a href="/about/privacy">
Privacy Policy
</a>
</div>
</div>
</div>
</div>
<div id="cookie-notification" class="js-allow-cookies" style="display: none;">
<div class="columns large-10 medium-10 small-12">
We use cookies on our website to ensure you get the best experience.<br class="show-for-medium-up" />
Read more about our cookies <a href="/about/privacy">here</a>.
</div>
<div class="columns large-2 medium-2 small-12 small-only-text-left text-right">
<a class="button button--default" href="/accept_cookies">Accept</a>
</div>
</div>
<div id="cookie-notification" class="js-survey" style="display: none;">
<div class="columns large-10 medium-10 small-12">
<strong>We have just recently launched a new version of our website.</strong><br class="show-for-meidum-up" />
<span style="font-weight: 400;">
Help us to further improve by taking part in this short 5 minute survey <span style="inline-block">
<span class="show-for-medium-up js-survey-link"><a href="https://www.surveymonkey.com/r/VWJZ6VW" target="_blank" rel="noopener noreferrer">here</a>.</span>
<span class="show-for-small-only js-survey-link"><a href="https://www.surveymonkey.com/r/VWMDSNQ" target="_blank" rel="noopener noreferrer">here</a>.</span>
</span>
</span>
</div>
<div class="columns large-2 medium-2 small-12 small-only-text-left text-right">
<a class="button button--default js-disable-survey-link" href="/disable_survey">Never show this again</a>
</div>
</div>
</div>
<div id="main-share-modal" class="reveal-modal reveal-modal-new reveal-modal-new--small" data-reveal aria-labelledby="modalTitle" aria-hidden="true" role="dialog">
<div class="row">
<div class="small-12 columns">
<h2 style="margin: 0;">Share Link</h2>
</div>
<div class="small-12 columns">
<div class="social-media-links UA_ShareModalLinks" style="text-align: left;">
<a href="/cdn-cgi/l/email-protection#ab948dcac6db90d8dec9c1cec8df96edd9c4c68e999be6effbe28e98ea8e999b8e9999eadedfc4c6cadfc2c88e999bfbdec7c6c4c5cad9d28e999be5c4cfdec7ce8e999befcedfcec8dfc2c4c58e999beadbdbc7d2c2c5cc8e999befcecedb8e999be7cecad9c5c2c5cc8e999bc4d98e999be6cac8c3c2c5ce8e999be7cecad9c5c2c5cc8e999beac7ccc4d9c2dfc3c6d88e999bdfc48e999bdfc3ce8e999be7e2efe886e2eff9e28e999befcadfcac9cad8ce8e98ea8e999bea8e999bf8d2d8dfcec6cadfc2c88e999bf9ceddc2cedc8ddadec4df908dcac6db90c9c4cfd296c3dfdfdbd8918484dcdcdc85c6cfdbc285c8c4c6849f99989f929d8e98ea8e9bea8e9beaeadedfc4c6cadfc2c88e999bfbdec7c6c4c5cad9d28e999be5c4cfdec7ce8e999befcedfcec8dfc2c4c58e999beadbdbc7d2c2c5cc8e999befcecedb8e999be7cecad9c5c2c5cc8e999bc4d98e999be6cac8c3c2c5ce8e999be7cecad9c5c2c5cc8e999beac7ccc4d9c2dfc3c6d88e999bdfc48e999bdfc3ce8e999be7e2efe886e2eff9e28e999befcadfcac9cad8ce8e98ea8e999bea8e999bf8d2d8dfcec6cadfc2c88e999bf9ceddc2cedca1a1ffc3ce8e999bcac2c68e999bc4cd8e999bdfc3c2d88e999bd8dfdecfd28e999bdccad88e999bdfc48e999bdbd9c4ddc2cfce8e999bcac58e999bc4ddced9ddc2cedc8e999bc4cd8e999bdfc3ce8e999bc7c2dfced9cadfded9ce8e999bcaddcac2c7cac9c7ce8e999bc4c58e999bc6cac8c3c2c5ce8e999bc7cecad9c5c2c5cc8e999b8e9993e6e78e99928e999bcac7ccc4d9c2dfc3c6d88e999bcadbdbc7c2cecf8e999bdfc48e999bdfc3ce8e999be7dec5cc8e999be2c6caccce8e999befcadfcac9cad8ce8e999be8c4c5d8c4d9dfc2dec68e999be2c6caccce8e999be8c4c7c7cec8dfc2c4c58e999b8e9993e7e2efe886e2eff9e28e99928e999bcfcadfcac9cad8ce8e999bcad88e999bca8e999bdfc4c4c78e999bcdc4d98e999bdfc3ce8e999bc4dbdfc2c6c2d1cadfc2c4c58e999bc4cd8e999bcfcedfcec8dfc2c5cc8e999bc7dec5cc8e999bc5c4cfdec7ced88e999bc2c58e999bdfc3c4d9cac8c2c88e999be8ff8e999bd8c8cac5d8858e999bffc3c2d88e999bd8d2d8dfcec6cadfc2c88e999bd9ceddc2cedc8e999bdccad88e999bc8c4c6dbc2c7cecf8e999bcac8c8c4d9cfc2c5cc8e999bdfc48e999bfbd9cecdced9d9cecf8e999bf9cedbc4d9dfc2c5cc8e999be2dfcec6d88e999bcdc4d98e999bf8d2d8dfcec6cadfc2c88e999bf9ceddc2cedcd88e999bcac5cf8e999be6cedfca86eac5cac7d2d8ced88e999b8e9993fbf9e2f8e6ea8e99928e999bccdec2cfcec7c2c5ced8858e999be4c5c7d28e999bc4d9c2ccc2c5cac78e999bd9ced8cecad9c8c38e999bcad9dfc2c8c7ced88e999bc8c4c5c8ced9c5c2c5cc8e999bcac7ccc4d9c2dfc3c6d88e999bcadbdbc7c2cecf8e999bdfc48e999bdfc3ce8e999be7e2efe886e2eff9e28e999bcfcadfcac9cad8ce8e999bdcced9ce8e999bc2c5c8c7decfcecf858e999bffc3ce8e999bc2c5c2dfc2cac78e999bd8cecad9c8c38e999bd2c2cec7cfcecf8e999b9a929c998e999bdbdec9c7c2c8cadfc2c4c5d88e999bcacddfced98e999bd9cec6c4ddc2c5cc8e999bcfdedbc7c2c8cadfced88e99e88e999bcac5cf8e999b9f9a8e999bc4cd8e999bdfc3ced8ce8e999bcad9dfc2c8c7ced88e999bdcced9ce8e999bc2c5c8c7decfcecf8e999bc2c58e999bdfc3c2d88e999bd8dfdecfd2858e999bffc3ce8e999bcad9dfc2c8c7ced88e999bdcced9ce8e999bcfc2ddc2cfcecf8e999bc2c5dfc48e999bdfdcc48e999bd8dec9c8cadfceccc4d9c2ced88e999bcfced8c8d9c2c9c2c5cc8e999bdfc3cec2d98e999bc4ddced9cac7c78e999bcad9c8c3c2dfcec8dfded9ce858e999bffc3ce8e999bc6cac1c4d9c2dfd28e999bc4cd8e999bcdcecadfded9ce86c9cad8cecf8e999bcac7ccc4d9c2dfc3c6d88e999bcac8c3c2ceddcecf8e999bcac58e999bcac8c8ded9cac8d28e999b8e98ee929b8e999e8e999bc8c4c6dbcad9cecf8e999bdfc48e999bdfc3ce8e999bcfcecedb8e999bc7cecad9c5c2c5cc8e999b8e9993efe78e99928e999bcac7ccc4d9c2dfc3c6d88e999bdfc3cadf8e999bcac8c3c2ceddcecf8e999bcac58e999bcac8c8ded9cac8d28e999bc2c58e999bdfc3ce8e999bd9cac5ccce8e999bc4cd8e999b939985998e999e8eee998e939b8e9298929c859d8e999e858e999be2c58e999bc8c4c5c8c7ded8c2c4c58e99e88e999be6e78e999bcac5cf8e999befe78e999bcac7ccc4d9c2dfc3c6d88e999bcad9ce8e999bcac9c7ce8e999bdfc48e999bcfcedfcec8df8e999bc7dec5cc8e999bc5c4cfdec7ced88e999bdcc2dfc38e999bca8e999bc3c2ccc38e999bc7ceddcec78e999bc4cd8e999bcac8c8ded9cac8d28e99e88e999bd8cec5d8c2dfc2ddc2dfd28e99e88e999bcac5cf8e999bd8dbcec8c2cdc2c8c2dfd28e999bded8c2c5cc8e999be6e78e99e88e999bdcc3cec58e999bcadbdbc7c2cecf8e999bdfc48e999bcac58e999bcac5c5c4dfcadfcecf8e999bcad9c8c3c2ddce8e999bc4cd8e999be8ff8e999bd8c8cac5d88e999bc4cd8e999bdfc3ce8e999bc7dec5cc858e999be3c4dcceddced98e99e88e999bdfc3ced9ce8e999bc2d88e999bc5c48e999bc8c4c5d8cec5d8ded88e999bc4c5f0858585f6" title="Email">
<i class="fa fa-envelope-square" style="font-size: 30px;"></i>
</a>
<a href="https://twitter.com/intent/tweet?text=Automatic+Pulmonary+Nodule+Detection+Applying+Deep+Learning+or+Machine+Learning+Algorithms+to+the+LIDC-IDRI+Database%3A+A+Systematic+Review&amp;hashtags=mdpidiagnostics&amp;url=https%3A%2F%2Fwww.mdpi.com%2F423496&amp;via=diagnostic_mdpi" onclick="windowOpen(this.href,600,800); return false" title="Twitter" target="_blank" rel="noopener noreferrer">
<i class="fa fa-twitter-square" style="font-size: 30px;"></i>
</a>
<a href="	                    http://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fwww.mdpi.com%2F423496&amp;title=Automatic%20Pulmonary%20Nodule%20Detection%20Applying%20Deep%20Learning%20or%20Machine%20Learning%20Algorithms%20to%20the%20LIDC-IDRI%20Database%3A%20A%20Systematic%20Review%26source%3Dhttps%3A%2F%2Fwww.mdpi.com%26summary%3DThe%20aim%20of%20this%20study%20was%20to%20provide%20an%20overview%20of%20the%20literature%20available%20on%20machine%20learning%20%28ML%29%20algorithms%20applied%20to%20the%20Lung%20Image%20Database%20Consortium%20Image%20Collection%20%28LIDC-IDRI%29%20database%20as%20a%20tool%20for%20the%20optimization%20of%20detecting%20lung%20%5B...%5D" onclick="windowOpen(this.href,600,800); return false" title="LinkedIn" target="_blank" rel="noopener noreferrer">
<i class="fa fa-linkedin-square" style="font-size: 30px;"></i>
</a>
<a href="https://www.facebook.com/sharer.php?u=https://www.mdpi.com/423496" title="facebook" target="_blank" rel="noopener noreferrer">
<i class="fa fa-facebook-square" style="font-size: 30px;"></i>
</a>
<a href="javascript:void(0);" title="Wechat" data-reveal-id="weixin-share-modal">
<i class="fa fa-weixin-square" style="font-size: 26px;"></i>
</a>
<a href="https://www.reddit.com/submit?url=https://www.mdpi.com/423496" title="Reddit" target="_blank" rel="noopener noreferrer">
<i class="fa fa-reddit-square" style="font-size: 30px;"></i>
</a>
<a href="https://www.mendeley.com/import/?url=https://www.mdpi.com/423496" title="Mendeley" target="_blank" rel="noopener noreferrer">
<i class="fa fa-mendeley-square" style="font-size: 30px;"></i>
</a>
<a href="http://www.citeulike.org/posturl?url=https://www.mdpi.com/423496" title="CiteULike" target="_blank" rel="noopener noreferrer">
<i class="fa fa-citeulike-square" style="font-size: 30px;"></i>
</a>
</div>
</div>
<div class="small-9 columns">
<input id="js-clipboard-text" type="text" readonly value="https://www.mdpi.com/423496" />
</div>
<div class="small-3 columns text-left">
<a class="button button--color js-clipboard-copy" data-clipboard-target="#js-clipboard-text">Copy</a>
</div>
</div>
<a class="close-reveal-modal" aria-label="Close">
<i class="material-icons">clear</i>
</a>
</div>
<div id="weixin-share-modal" class="reveal-modal reveal-modal-new" data-reveal aria-labelledby="weixin-share-modal-title" aria-hidden="true" role="dialog">
<div class="row">
<div class="small-12 columns">
<h2 id="weixin-share-modal-title" style="margin: 0;">Share</h2>
</div>
<div class="small-12 columns">
<div class="weixin-qr-code-section">

<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg width="300" height="300" version="1.1" xmlns="http://www.w3.org/2000/svg">
<desc>https://www.mdpi.com/423496</desc>
<g id="elements" fill="black" stroke="none">
<rect x="0" y="0" width="12" height="12" />
<rect x="12" y="0" width="12" height="12" />
<rect x="24" y="0" width="12" height="12" />
<rect x="36" y="0" width="12" height="12" />
<rect x="48" y="0" width="12" height="12" />
<rect x="60" y="0" width="12" height="12" />
<rect x="72" y="0" width="12" height="12" />
<rect x="108" y="0" width="12" height="12" />
<rect x="144" y="0" width="12" height="12" />
<rect x="168" y="0" width="12" height="12" />
<rect x="180" y="0" width="12" height="12" />
<rect x="216" y="0" width="12" height="12" />
<rect x="228" y="0" width="12" height="12" />
<rect x="240" y="0" width="12" height="12" />
<rect x="252" y="0" width="12" height="12" />
<rect x="264" y="0" width="12" height="12" />
<rect x="276" y="0" width="12" height="12" />
<rect x="288" y="0" width="12" height="12" />
<rect x="0" y="12" width="12" height="12" />
<rect x="72" y="12" width="12" height="12" />
<rect x="96" y="12" width="12" height="12" />
<rect x="132" y="12" width="12" height="12" />
<rect x="144" y="12" width="12" height="12" />
<rect x="156" y="12" width="12" height="12" />
<rect x="180" y="12" width="12" height="12" />
<rect x="192" y="12" width="12" height="12" />
<rect x="216" y="12" width="12" height="12" />
<rect x="288" y="12" width="12" height="12" />
<rect x="0" y="24" width="12" height="12" />
<rect x="24" y="24" width="12" height="12" />
<rect x="36" y="24" width="12" height="12" />
<rect x="48" y="24" width="12" height="12" />
<rect x="72" y="24" width="12" height="12" />
<rect x="96" y="24" width="12" height="12" />
<rect x="108" y="24" width="12" height="12" />
<rect x="120" y="24" width="12" height="12" />
<rect x="132" y="24" width="12" height="12" />
<rect x="144" y="24" width="12" height="12" />
<rect x="168" y="24" width="12" height="12" />
<rect x="180" y="24" width="12" height="12" />
<rect x="216" y="24" width="12" height="12" />
<rect x="240" y="24" width="12" height="12" />
<rect x="252" y="24" width="12" height="12" />
<rect x="264" y="24" width="12" height="12" />
<rect x="288" y="24" width="12" height="12" />
<rect x="0" y="36" width="12" height="12" />
<rect x="24" y="36" width="12" height="12" />
<rect x="36" y="36" width="12" height="12" />
<rect x="48" y="36" width="12" height="12" />
<rect x="72" y="36" width="12" height="12" />
<rect x="108" y="36" width="12" height="12" />
<rect x="120" y="36" width="12" height="12" />
<rect x="132" y="36" width="12" height="12" />
<rect x="168" y="36" width="12" height="12" />
<rect x="216" y="36" width="12" height="12" />
<rect x="240" y="36" width="12" height="12" />
<rect x="252" y="36" width="12" height="12" />
<rect x="264" y="36" width="12" height="12" />
<rect x="288" y="36" width="12" height="12" />
<rect x="0" y="48" width="12" height="12" />
<rect x="24" y="48" width="12" height="12" />
<rect x="36" y="48" width="12" height="12" />
<rect x="48" y="48" width="12" height="12" />
<rect x="72" y="48" width="12" height="12" />
<rect x="96" y="48" width="12" height="12" />
<rect x="168" y="48" width="12" height="12" />
<rect x="180" y="48" width="12" height="12" />
<rect x="216" y="48" width="12" height="12" />
<rect x="240" y="48" width="12" height="12" />
<rect x="252" y="48" width="12" height="12" />
<rect x="264" y="48" width="12" height="12" />
<rect x="288" y="48" width="12" height="12" />
<rect x="0" y="60" width="12" height="12" />
<rect x="72" y="60" width="12" height="12" />
<rect x="96" y="60" width="12" height="12" />
<rect x="108" y="60" width="12" height="12" />
<rect x="132" y="60" width="12" height="12" />
<rect x="180" y="60" width="12" height="12" />
<rect x="192" y="60" width="12" height="12" />
<rect x="216" y="60" width="12" height="12" />
<rect x="288" y="60" width="12" height="12" />
<rect x="0" y="72" width="12" height="12" />
<rect x="12" y="72" width="12" height="12" />
<rect x="24" y="72" width="12" height="12" />
<rect x="36" y="72" width="12" height="12" />
<rect x="48" y="72" width="12" height="12" />
<rect x="60" y="72" width="12" height="12" />
<rect x="72" y="72" width="12" height="12" />
<rect x="96" y="72" width="12" height="12" />
<rect x="120" y="72" width="12" height="12" />
<rect x="144" y="72" width="12" height="12" />
<rect x="168" y="72" width="12" height="12" />
<rect x="192" y="72" width="12" height="12" />
<rect x="216" y="72" width="12" height="12" />
<rect x="228" y="72" width="12" height="12" />
<rect x="240" y="72" width="12" height="12" />
<rect x="252" y="72" width="12" height="12" />
<rect x="264" y="72" width="12" height="12" />
<rect x="276" y="72" width="12" height="12" />
<rect x="288" y="72" width="12" height="12" />
<rect x="96" y="84" width="12" height="12" />
<rect x="108" y="84" width="12" height="12" />
<rect x="144" y="84" width="12" height="12" />
<rect x="168" y="84" width="12" height="12" />
<rect x="180" y="84" width="12" height="12" />
<rect x="192" y="84" width="12" height="12" />
<rect x="0" y="96" width="12" height="12" />
<rect x="12" y="96" width="12" height="12" />
<rect x="36" y="96" width="12" height="12" />
<rect x="72" y="96" width="12" height="12" />
<rect x="84" y="96" width="12" height="12" />
<rect x="120" y="96" width="12" height="12" />
<rect x="144" y="96" width="12" height="12" />
<rect x="156" y="96" width="12" height="12" />
<rect x="168" y="96" width="12" height="12" />
<rect x="180" y="96" width="12" height="12" />
<rect x="192" y="96" width="12" height="12" />
<rect x="216" y="96" width="12" height="12" />
<rect x="228" y="96" width="12" height="12" />
<rect x="240" y="96" width="12" height="12" />
<rect x="264" y="96" width="12" height="12" />
<rect x="276" y="96" width="12" height="12" />
<rect x="36" y="108" width="12" height="12" />
<rect x="120" y="108" width="12" height="12" />
<rect x="132" y="108" width="12" height="12" />
<rect x="192" y="108" width="12" height="12" />
<rect x="216" y="108" width="12" height="12" />
<rect x="288" y="108" width="12" height="12" />
<rect x="0" y="120" width="12" height="12" />
<rect x="12" y="120" width="12" height="12" />
<rect x="24" y="120" width="12" height="12" />
<rect x="36" y="120" width="12" height="12" />
<rect x="48" y="120" width="12" height="12" />
<rect x="60" y="120" width="12" height="12" />
<rect x="72" y="120" width="12" height="12" />
<rect x="84" y="120" width="12" height="12" />
<rect x="108" y="120" width="12" height="12" />
<rect x="120" y="120" width="12" height="12" />
<rect x="144" y="120" width="12" height="12" />
<rect x="156" y="120" width="12" height="12" />
<rect x="204" y="120" width="12" height="12" />
<rect x="216" y="120" width="12" height="12" />
<rect x="276" y="120" width="12" height="12" />
<rect x="288" y="120" width="12" height="12" />
<rect x="12" y="132" width="12" height="12" />
<rect x="36" y="132" width="12" height="12" />
<rect x="48" y="132" width="12" height="12" />
<rect x="132" y="132" width="12" height="12" />
<rect x="144" y="132" width="12" height="12" />
<rect x="156" y="132" width="12" height="12" />
<rect x="180" y="132" width="12" height="12" />
<rect x="204" y="132" width="12" height="12" />
<rect x="216" y="132" width="12" height="12" />
<rect x="240" y="132" width="12" height="12" />
<rect x="0" y="144" width="12" height="12" />
<rect x="12" y="144" width="12" height="12" />
<rect x="72" y="144" width="12" height="12" />
<rect x="84" y="144" width="12" height="12" />
<rect x="156" y="144" width="12" height="12" />
<rect x="168" y="144" width="12" height="12" />
<rect x="204" y="144" width="12" height="12" />
<rect x="216" y="144" width="12" height="12" />
<rect x="228" y="144" width="12" height="12" />
<rect x="252" y="144" width="12" height="12" />
<rect x="276" y="144" width="12" height="12" />
<rect x="288" y="144" width="12" height="12" />
<rect x="36" y="156" width="12" height="12" />
<rect x="60" y="156" width="12" height="12" />
<rect x="96" y="156" width="12" height="12" />
<rect x="108" y="156" width="12" height="12" />
<rect x="120" y="156" width="12" height="12" />
<rect x="156" y="156" width="12" height="12" />
<rect x="216" y="156" width="12" height="12" />
<rect x="228" y="156" width="12" height="12" />
<rect x="252" y="156" width="12" height="12" />
<rect x="264" y="156" width="12" height="12" />
<rect x="288" y="156" width="12" height="12" />
<rect x="0" y="168" width="12" height="12" />
<rect x="36" y="168" width="12" height="12" />
<rect x="60" y="168" width="12" height="12" />
<rect x="72" y="168" width="12" height="12" />
<rect x="84" y="168" width="12" height="12" />
<rect x="96" y="168" width="12" height="12" />
<rect x="108" y="168" width="12" height="12" />
<rect x="132" y="168" width="12" height="12" />
<rect x="156" y="168" width="12" height="12" />
<rect x="168" y="168" width="12" height="12" />
<rect x="192" y="168" width="12" height="12" />
<rect x="216" y="168" width="12" height="12" />
<rect x="228" y="168" width="12" height="12" />
<rect x="240" y="168" width="12" height="12" />
<rect x="264" y="168" width="12" height="12" />
<rect x="288" y="168" width="12" height="12" />
<rect x="12" y="180" width="12" height="12" />
<rect x="36" y="180" width="12" height="12" />
<rect x="84" y="180" width="12" height="12" />
<rect x="96" y="180" width="12" height="12" />
<rect x="132" y="180" width="12" height="12" />
<rect x="156" y="180" width="12" height="12" />
<rect x="168" y="180" width="12" height="12" />
<rect x="180" y="180" width="12" height="12" />
<rect x="192" y="180" width="12" height="12" />
<rect x="216" y="180" width="12" height="12" />
<rect x="240" y="180" width="12" height="12" />
<rect x="276" y="180" width="12" height="12" />
<rect x="0" y="192" width="12" height="12" />
<rect x="12" y="192" width="12" height="12" />
<rect x="48" y="192" width="12" height="12" />
<rect x="60" y="192" width="12" height="12" />
<rect x="72" y="192" width="12" height="12" />
<rect x="84" y="192" width="12" height="12" />
<rect x="108" y="192" width="12" height="12" />
<rect x="120" y="192" width="12" height="12" />
<rect x="132" y="192" width="12" height="12" />
<rect x="168" y="192" width="12" height="12" />
<rect x="192" y="192" width="12" height="12" />
<rect x="204" y="192" width="12" height="12" />
<rect x="216" y="192" width="12" height="12" />
<rect x="228" y="192" width="12" height="12" />
<rect x="240" y="192" width="12" height="12" />
<rect x="252" y="192" width="12" height="12" />
<rect x="264" y="192" width="12" height="12" />
<rect x="96" y="204" width="12" height="12" />
<rect x="108" y="204" width="12" height="12" />
<rect x="120" y="204" width="12" height="12" />
<rect x="132" y="204" width="12" height="12" />
<rect x="156" y="204" width="12" height="12" />
<rect x="180" y="204" width="12" height="12" />
<rect x="192" y="204" width="12" height="12" />
<rect x="240" y="204" width="12" height="12" />
<rect x="252" y="204" width="12" height="12" />
<rect x="288" y="204" width="12" height="12" />
<rect x="0" y="216" width="12" height="12" />
<rect x="12" y="216" width="12" height="12" />
<rect x="24" y="216" width="12" height="12" />
<rect x="36" y="216" width="12" height="12" />
<rect x="48" y="216" width="12" height="12" />
<rect x="60" y="216" width="12" height="12" />
<rect x="72" y="216" width="12" height="12" />
<rect x="96" y="216" width="12" height="12" />
<rect x="108" y="216" width="12" height="12" />
<rect x="120" y="216" width="12" height="12" />
<rect x="144" y="216" width="12" height="12" />
<rect x="180" y="216" width="12" height="12" />
<rect x="192" y="216" width="12" height="12" />
<rect x="216" y="216" width="12" height="12" />
<rect x="240" y="216" width="12" height="12" />
<rect x="252" y="216" width="12" height="12" />
<rect x="276" y="216" width="12" height="12" />
<rect x="288" y="216" width="12" height="12" />
<rect x="0" y="228" width="12" height="12" />
<rect x="72" y="228" width="12" height="12" />
<rect x="108" y="228" width="12" height="12" />
<rect x="120" y="228" width="12" height="12" />
<rect x="132" y="228" width="12" height="12" />
<rect x="144" y="228" width="12" height="12" />
<rect x="192" y="228" width="12" height="12" />
<rect x="240" y="228" width="12" height="12" />
<rect x="252" y="228" width="12" height="12" />
<rect x="264" y="228" width="12" height="12" />
<rect x="288" y="228" width="12" height="12" />
<rect x="0" y="240" width="12" height="12" />
<rect x="24" y="240" width="12" height="12" />
<rect x="36" y="240" width="12" height="12" />
<rect x="48" y="240" width="12" height="12" />
<rect x="72" y="240" width="12" height="12" />
<rect x="108" y="240" width="12" height="12" />
<rect x="132" y="240" width="12" height="12" />
<rect x="156" y="240" width="12" height="12" />
<rect x="192" y="240" width="12" height="12" />
<rect x="204" y="240" width="12" height="12" />
<rect x="216" y="240" width="12" height="12" />
<rect x="228" y="240" width="12" height="12" />
<rect x="240" y="240" width="12" height="12" />
<rect x="252" y="240" width="12" height="12" />
<rect x="276" y="240" width="12" height="12" />
<rect x="0" y="252" width="12" height="12" />
<rect x="24" y="252" width="12" height="12" />
<rect x="36" y="252" width="12" height="12" />
<rect x="48" y="252" width="12" height="12" />
<rect x="72" y="252" width="12" height="12" />
<rect x="96" y="252" width="12" height="12" />
<rect x="108" y="252" width="12" height="12" />
<rect x="120" y="252" width="12" height="12" />
<rect x="156" y="252" width="12" height="12" />
<rect x="168" y="252" width="12" height="12" />
<rect x="204" y="252" width="12" height="12" />
<rect x="228" y="252" width="12" height="12" />
<rect x="240" y="252" width="12" height="12" />
<rect x="252" y="252" width="12" height="12" />
<rect x="264" y="252" width="12" height="12" />
<rect x="0" y="264" width="12" height="12" />
<rect x="24" y="264" width="12" height="12" />
<rect x="36" y="264" width="12" height="12" />
<rect x="48" y="264" width="12" height="12" />
<rect x="72" y="264" width="12" height="12" />
<rect x="108" y="264" width="12" height="12" />
<rect x="120" y="264" width="12" height="12" />
<rect x="168" y="264" width="12" height="12" />
<rect x="180" y="264" width="12" height="12" />
<rect x="192" y="264" width="12" height="12" />
<rect x="228" y="264" width="12" height="12" />
<rect x="240" y="264" width="12" height="12" />
<rect x="264" y="264" width="12" height="12" />
<rect x="288" y="264" width="12" height="12" />
<rect x="0" y="276" width="12" height="12" />
<rect x="72" y="276" width="12" height="12" />
<rect x="96" y="276" width="12" height="12" />
<rect x="108" y="276" width="12" height="12" />
<rect x="132" y="276" width="12" height="12" />
<rect x="156" y="276" width="12" height="12" />
<rect x="168" y="276" width="12" height="12" />
<rect x="180" y="276" width="12" height="12" />
<rect x="192" y="276" width="12" height="12" />
<rect x="204" y="276" width="12" height="12" />
<rect x="216" y="276" width="12" height="12" />
<rect x="252" y="276" width="12" height="12" />
<rect x="0" y="288" width="12" height="12" />
<rect x="12" y="288" width="12" height="12" />
<rect x="24" y="288" width="12" height="12" />
<rect x="36" y="288" width="12" height="12" />
<rect x="48" y="288" width="12" height="12" />
<rect x="60" y="288" width="12" height="12" />
<rect x="72" y="288" width="12" height="12" />
<rect x="96" y="288" width="12" height="12" />
<rect x="156" y="288" width="12" height="12" />
<rect x="168" y="288" width="12" height="12" />
<rect x="180" y="288" width="12" height="12" />
<rect x="192" y="288" width="12" height="12" />
<rect x="228" y="288" width="12" height="12" />
<rect x="276" y="288" width="12" height="12" />
<rect x="288" y="288" width="12" height="12" />
</g>
</svg>
</div>
</div>
</div>
<a class="close-reveal-modal" aria-label="Close">
<i class="material-icons">clear</i>
</a>
</div>
<a href="#" class="back-to-top"><span class="show-for-medium-up">Back to Top</span><span class="show-for-small">Top</span></a>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script src="/assets/js/modernizr-2.8.3.min.js?5227e0738f7f421d"></script>
<script src="/assets/js/jquery-1.12.4.min.js?4f252523d4af0b47"></script>
<script src="/assets/js/foundation-5.5.3.min.js?6b2ec41c18b29054"></script>
<script src="/assets/js/foundation-5.5.3.equalizer.min.js?0f6c549b75ec554c"></script>
<script src="/assets/js/jquery.multiselect.js?0edd3998731d1091"></script>
<script src="/assets/js/jquery.cycle2.min.js?63413052928f97ee"></script>
<script>
            $('select.foundation-select').multiselect({
                search: true,
                minHeight: 130,
                maxHeight: 130,
            });

            $(document).foundation({
                orbit: {
                    timer_speed: 4000,
                },
                reveal: {
                    animation: 'fadeAndPop',
                    animation_speed: 100,
                }
            });

            // old browser fix - this way the console log rows won't throw (silent) errors in browsers not supporting console log
            if (!window.console) window.console = {};
            if (!window.console.log) window.console.log = function () { };

    var currentJournalNameSystem = "diagnostics";

            $(document).ready(function()
            {
                $(".chosen-select").each(function(element) {
                    var maxSelected = (undefined !== $(this).data('maxselectedoptions') ? $(this).data('maxselectedoptions') : 100);

                    $(this).on('chosen:ready', function(event, data) {
                        var select = $(data.chosen.form_field);
                        if (select.attr('id') === 'journal-browser-volume') {
                            $(data.chosen.dropdown).addClass('UI_JournalBrowser_Volume_Options');
                        }
                        if (select.attr('id') === 'journal-browser-issue') {
                            $(data.chosen.dropdown).addClass('UI_JournalBrowser_Issue_Options');
                        }
                    }).chosen({ disable_search_threshold: 7, max_selected_options: maxSelected, width: "100%" });
                });

                $(".toEncode").each(function(e) {
                    var oldHref = $(this).attr("href");
                    var newHref = oldHref.replace('.botdefense.please.enable.javascript.','@');
                    $(this).attr("href", newHref);

                    if (!$(this).hasClass("emailCaptcha"))
                    {
                        $(this).html(newHref.replace('mailto:', ''));
                    }
                    
                    
                    $(this).removeClass("visibility-hidden");
                });

                $(document).on('opened.fndtn.reveal', '[data-reveal]', function()
                {
                    $(document).foundation('equalizer', 'reflow');
                });

                // fix the images that have tag height / width defined
                // otherwise the default foundation styles overwrite the tag definitions
                $("img").each(function()
                {
                   if ($(this).attr('width') != undefined || $(this).attr('height') != undefined)
                   {
                       $(this).addClass("img-fixed");
                   }
                });

                $("#basic_search, #advanced_search").submit(function(e) {
                    var searchArguments = false;

                    $(this).find("input,select").not("#search,.search-button").each(function() {
                        if (undefined === $(this).val() || "" === $(this).val()) {
                            $(this).attr('name', null);
                        } else {
                            $(this).attr('name');
                            searchArguments = true;
                        }
                    });

                    if (!searchArguments) {
                        window.location = $(this).attr('action');
                        return false;
                    }
                });

                $(".hide-show-desktop-option").click(function(e) 
                {
                    e.preventDefault();
                    var parentDiv = $(this).closest("div");

                    $.ajax({
                        url: $(this).attr('href'),
                        success: function(msg)
                        {
                            parentDiv.removeClass().hide();
                        }
                    });
                });

                $(".generic-toggleable-header").click(function(e) {
                    $(this).toggleClass("active");
                    $(this).next(".generic-toggleable-content").toggleClass("active");
                });

                /*
                * handle whole row as a link if the row contains only one visible link
                */
                $("table.new tr").hover(function()
                {
                   if ($(this).find("td:visible a").length == 1)
                   {
                       $(this).addClass("single-link");
                   }
                },
                function()
                {
                   $(this).removeClass("single-link");
                });

                $("table.new:not(.table-of-tables)").on("click", "tr.single-link", function(e)
                {
                    var target = $(e.target);
                    if (!e.ctrlKey && !target.is("a")) {
                        $(this).find("td:visible a")[0].click();
                    }
                });

                $(document).on("click", ".custom-accordion-for-small-screen-link", function(e) {
                    if ($(this).closest("#basic_search").length > 0) {
                        if ($(".search-container__advanced").first().is(":visible")) {
                            openAdvanced()
                        }
                    }

                    if (Foundation.utils.is_small_only()) {
                        if ($(this).hasClass("active")) {
                            $(this).removeClass("active");
                            $(this).next(".custom-accordion-for-small-screen-content").addClass("show-for-medium-up");
                        }
                        else {
                            $(this).addClass("active");
                            $(this).next(".custom-accordion-for-small-screen-content").removeClass("show-for-medium-up");
                            $(document).foundation('orbit', 'reflow');
                        }
                    }

                    if (undefined !== $(this).data("callback")) {
                        var customCallback = $(this).data("callback");
                        func = window[customCallback];
                        func();
                    }
                });

                $(document).on("click", ".js-open-small-search", function(e) {
                    e.preventDefault();  
                    $(this).toggleClass("active").closest(".tab-bar").toggleClass("active");
                    $(".search-container").toggleClass("hide-for-small-down");
                });

                $(document).on("click", ".js-survey-link", function(e) {
                    localStorage.setItem("mdpi_disable_survey", true);
                    window.location.href = "/disable_survey";
                });

                $(document).on("click", ".js-disable-survey-link", function(e) {
                    localStorage.setItem("mdpi_disable_survey", true);
                });

                $(document).on("click", ".js-open-menu", function(e) {
                    $(".search-container").addClass("hide-for-small-down");

                });

                $(window).on('resize', function() {
                    recalculate_main_browser_position();
                    recalculate_responsive_moving_containers();
                });

                checkCookiesAllowed();
                updateSearchLabelVisibilities();
                recalculate_main_browser_position();
                recalculate_responsive_moving_containers();
                
                
                if (window.document.documentMode == 11) {
                    $("<link/>", { rel: "stylesheet", type: "text/css", href: "https://fonts.googleapis.com/icon?family=Material+Icons"}).appendTo("head");
                }
            });

            function recalculate_main_browser_position() {
                if (Foundation.utils.is_small_only()) {
                    if ($("#js-main-top-container").parent("#js-large-main-top-container").length > 0) {
                        $("#js-main-top-container").appendTo($("#js-small-main-top-container"));
                    }
                }
                else {
                    if ($("#js-main-top-container").parent("#js-small-main-top-container").length > 0) {
                        $("#js-main-top-container").appendTo($("#js-large-main-top-container"));
                    }
                }
            }

            function recalculate_responsive_moving_containers() {
                $(".responsive-moving-container.large").each(function() {
                    var previousParent = $(".responsive-moving-container.active[data-id='"+$(this).data("id")+"']");
                    var movingContent  = previousParent.html();

                    if (Foundation.utils.is_small_only()) {
                        var currentParent = $(".responsive-moving-container.small[data-id='"+$(this).data("id")+"']");
                    }
                    else if (Foundation.utils.is_medium_only()) {
                        var currentParent = $(".responsive-moving-container.medium[data-id='"+$(this).data("id")+"']");
                    }
                    else {
                        var currentParent = $(".responsive-moving-container.large[data-id='"+$(this).data("id")+"']");
                    }

                    if (previousParent.attr("class") !== currentParent.attr("class")) {
                        currentParent.html(movingContent);
                        previousParent.html();
                        currentParent.addClass("active");
                        previousParent.removeClass("active");
                    }
                });
            }

            // cookies allowed is checked from a) local storage and b) from server separately so that the footer bar doesn't
            // get included in the custom page caches
            function checkCookiesAllowed() {
                var cookiesEnabled = localStorage.getItem("mdpi_cookies_enabled"); 

                if (null === cookiesEnabled) {
                    $.ajax({
                        url: "/ajax_cookie_value/mdpi_cookies_accepted",
                        success: function(data)
                        {
                            if (data.value) {
                                localStorage.setItem("mdpi_cookies_enabled", true);
                                checkDisplaySurvey();
                            }
                            else {
                                $(".js-allow-cookies").show();
                            }
                        }
                    });
                }
                else {
                    checkDisplaySurvey();
                }
            }

            // cookies allowed is checked from a) local storage and b) from server separately so that the footer bar doesn't
            // get included in the custom page caches
            //
            // NOTE! survey has been closed. Not used anymore (this code can be moved to somewhere for storage in case we need similar logic with other iterations)
            // 
            function checkDisplaySurvey() {
                
                var surveyDisabled = localStorage.getItem("mdpi_disable_survey"); 
                var viewCount      = localStorage.getItem("mdpi_new_layout_views"); 
                var viewLimit      = localStorage.getItem("mdpi_new_layout_limit");

                if (null !== surveyDisabled) {
                    return;
                }

                
                return;
                // todo: the below part can be removed later on...

                if (null === viewLimit) {
                    localStorage.setItem("mdpi_new_layout_limit", Math.floor(Math.random() * 50));
                    localStorage.setItem("mdpi_new_layout_views", 0);
                }
                else {
                    viewCount++;
                    localStorage.setItem("mdpi_new_layout_views", viewCount);

                    if (viewCount >= viewLimit) {
                        $.ajax({
                            url: "/ajax_cookie_value/mdpi_disable_survey",
                            success: function(data)
                            {
                                if (data.value) {
                                    localStorage.setItem("mdpi_disable_survey", true);
                                }
                                else {
                                    $(".js-survey").show();
                                }
                            }
                        });
                    }
                }
            }
            
        </script>
<script src="/assets/js/lib.js?f6e377fcd57aadd4"></script>
<script src="/assets/js/mdpi.js?5eb1824a20c5547f"></script>
<script>var banners_url = 'https://serve.mdpi.com';</script>
<script type='text/javascript' src='/assets/js/ifvisible.min.js?c621d19ecb761212'></script>
<script src="/assets/js/xmltohtml/affix.js?ac4ea55275297c15"></script>
<script src="/assets/js/clipboard.min.js?3f3688138a1b9fc4"></script>
<script type="text/javascript">
        $(document).ready(function()
        {
            var helpFunctions = $(".middle-column__help__fixed");
            var middleColumn  = $("#middle-column");

            helpFunctions.affix({
                offset: {
                    top: function() {
                        return middleColumn.offset().top - 8 - (Foundation.utils.is_medium_only() ? 30 : 0);
                    },
                    bottom: function() {
                        return $("#footer").innerHeight() + 56 + (Foundation.utils.is_medium_only() ? 0 : 0);
                    }
                }
            });

            new ClipboardJS('.js-clipboard-copy');
        });
    </script>
<script src="/assets/js/jquery-ui-1.12.0.min.js?4c2c52cc11e5a28d"></script>
<script>
        $(document).ready(function()
        {
            
            $(".link-article-menu").click(function(e) {
                e.preventDefault();

                $(this).find('span').toggle();
                $(this).next("div").toggleClass("active");
            });

                    });
    </script>
<script src="/assets/js/xmltohtml/affix.js?ac4ea55275297c15"></script>
<script src="/assets/js/xmltohtml/storage.js?e9b262d3a3476d25"></script>
<script src="/assets/js/xmltohtml/jquery-scrollspy.js?09cbaec0dbb35a67"></script>
<script src="/assets/js/xmltohtml/magnific-popup.js?4a09c18460afb26c"></script>
<script src="/assets/js/xmltohtml/underscore.js?f893e294cde60c24"></script>
<script type="text/javascript">
    $('document').ready(function(){
    //   if(1 == 0){
    //     var doi = $('.html-art-header').find('a');
    //     var text = doi.text();
    //     doi.remove();
    //     $('.html-art-header p').append(text);
    //     $('.html-art-header').html($('.html-art-header')[0].innerHTML.replace(/doi:\s+/,'doi:&nbsp;'))
    //   }

      $("#left-column").addClass("show-for-large-up");
      $("#middle-column").removeClass("medium-9").removeClass("left-bordered").addClass("medium-12");
    });
	$(document).on('DOMNodeInserted', function(e) {

        var element = $(e.target);

        if (element.hasClass('menu') && element.hasClass('html-nav') )
        {
            element.addClass("side-menu-ul");
                                            }
    });
  </script>
<script src="/assets/js/jquery-ui-1.10.4.custom.min.js?9fb4d59ff745b497"></script>
<script src="/assets/js/xmltohtml/articles.js?a87788b81891bfc0"></script>
<script>
        repositionOpenSideBar = function() {
            $('#left-column').addClass("show-for-large-up show-for-medium-up").show();
            $('#middle-column').removeClass('large-12').removeClass('medium-12');
            $('#middle-column').addClass('large-9');
        }

        repositionCloseSideBar = function() {
            $('#left-column').removeClass("show-for-large-up show-for-medium-up").hide();
            $('#middle-column').removeClass('large-9');
            $('#middle-column').addClass('large-12').addClass('medium-12');
        }
    </script>
<script>
        $(document).ready(function() {

            $(document).on('keyup', function (e) {
                if (e.keyCode == 27) {

                    var hElem = $(this).find(".annotator-adder");

                    if (hElem.length){
                        hElem.css({'visibility':'hidden'});
                    } else {
                        document.querySelector("hypothesis-adder").shadowRoot.querySelector(".annotator-adder").style.visibility = "hidden";
                    }

                }
            });
        });
    </script>
<script>
            window.hypothesisConfig = function () {
                return {
                    sidebarAppUrl: 'https://commenting.mdpi.com/app.html',
                    showHighlights:   'whenSidebarOpen'  ,
                    openSidebar:  false  ,
                    assetRoot: 'https://commentingres.mdpi.com/hypothesis',
                    services: [{
                        apiUrl: 'https://commenting.mdpi.com/api/',
                        authority: 'mdpi',
                        grantToken: '',
                        doi: '10.3390/diagnostics9010029'
                    }],
                };
            };
            MathJax . Hub . Startup . signal . Interest ( function ( message ) {
                if ( message == 'End' ){
                var hypoLink = document . getElementById ( "hypothesis_frame" )
                hypoLink . setAttribute ( "src" , "https://commenting.mdpi.com/embed.js" )
                }
});
        </script>
<script async id="hypothesis_frame"></script>
<!--[if lt IE 9]>
                        <script src="/assets/js/ie8/ie8.js?6eef8fcbc831f5bd"></script>
            <script src="/assets/js/ie8/jquery.xdomainrequest.min.js?a945caca315782b0"></script>
        <![endif]-->

<script>
            !function(e,t,n,s,u,a){e.twq||(s=e.twq=function(){s.exe?s.exe.apply(s,arguments):s.queue.push(arguments);
            },s.version='1.1',s.queue=[],u=t.createElement(n),u.async=!0,u.src='//static.ads-twitter.com/uwt.js',
            a=t.getElementsByTagName(n)[0],a.parentNode.insertBefore(u,a))}(window,document,'script');
            // Insert Twitter Pixel ID and Standard Event data below
            twq('init','o2pip');
            twq('track','PageView');
        </script>

<script type="text/javascript">(function(){window['__CF$cv$params']={r:'7020f078cd917267',m:'DOk1yCFZerMK.q0wcgRpqgWrRy1Gn2S25EWH78BJJRQ-1650993105-0-Adb1APu90aw0oYzfvvP8FPNqNBxYli7DRBnHXn8Fx0quRLgNZlJkSk7xuLn59TnYcfGjzcf+g2RJiR+BmYLW+vW74F4I2PQwg4LZrFIGbK4kmcEvdZx3PtTBlSOLRfeQbBiOoSyRWXJ/ExDMwq4nP/w=',s:[0xebd3eccdc3,0xd861731f40],}})();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194" integrity="sha512-Gi7xpJR8tSkrpF7aordPZQlW2DLtzUlZcumS8dMQjwDHEnw9I7ZLyiOj/6tZStRBGtGgN6ceN6cMH8z7etPGlw==" data-cf-beacon='{"rayId":"7020f078cd917267","token":"28b078b091674c0f80b4eb2521a2d256","version":"2021.12.0","si":100}' crossorigin="anonymous"></script>
</body>
</html>
<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images | Scientific Reports</title>
    
        
    


<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"diagnosis;viral-infection","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Scientific Reports","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/s41598-020-76550-z"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":true,"legacy":{"webtrendsLicenceType":"http://creativecommons.org/licenses/by/4.0/"}}},"contentInfo":{"authors":["Linda Wang","Zhong Qiu Lin","Alexander Wong"],"publishedAt":1605052800,"publishedAtString":"2020-11-11","title":"COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"srep","title":"scientific reports","volume":"10","issue":"1"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"ab_test_highlight_supp_info","active":false},{"name":"nature-oa-paywall","active":true},{"name":"nature-onwards-journey","active":false}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"PL","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"]}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>


    <script>
        window.dataLayer.push({
            cmpAndNewGtmFeatureFlag: true
        });
    </script>



    <script>
        (function(w, d) {
            w.config = w.config || {};
            w.config.mustardcut = false;

            
            if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
                w.config.mustardcut = true;
                d.classList.add('js');
                d.classList.remove('grade-c');
            }
        })(window, document.documentElement);
    </script>


 



    
         
            
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) { html{text-size-adjust:100%;box-sizing:border-box;font-family:sans-serif;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;line-height:1.76;min-height:100%}article,aside,header,main,nav,section{display:block}h1{font-size:2em}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}svg:not(:root){overflow:hidden}button,input,select{font-family:sans-serif;font-size:100%;line-height:1.15}select{margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[hidden]{display:none}button{border-radius:0;cursor:pointer}.c-card--major .c-card__title,.u-h1,.u-h2,button,h1{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-card--major .c-card__title,.u-h1,.u-h2,h1{font-weight:700}h1{font-size:2rem;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2{font-size:1.5rem;letter-spacing:-.0117156rem;line-height:1.6rem;margin-bottom:8px}.u-h3,h2{letter-spacing:-.0117156rem}h2{font-size:1.5rem;line-height:1.6rem}.u-h3{font-size:1.25rem;margin-bottom:8px}.c-card__title,.u-h3,h2{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-weight:700}.c-card__title,.u-h3{line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title{font-size:1.25rem;margin-bottom:8px}.c-card__title,h3{font-size:1.25rem}.u-h4{margin-bottom:8px}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-reading-companion__figure-title,.u-h4,h3,h4,h5,h6{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4{font-size:1.125rem}body,button,div,form,h1,h2,h3,input{margin:0;padding:0}p{padding:0}nav ol,nav ul{list-style:none none}body{font-size:1.125rem}p{margin:0 0 28px}ol,ul{margin-bottom:28px;margin-top:0}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-identifiers__open{color:#b74616}.c-article-title{font-size:1.5rem;line-height:1.25;margin-bottom:16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{margin-left:0}.c-article-author-list li,.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list__show-more{margin-right:4px}@media only screen and (max-width:539px){html.js .js-small-screen-show-inline{display:inline!important;visibility:visible!important}.js .js-smaller-author-etal{display:none;visibility:hidden}}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-button-author-list svg{margin:1px 4px 0 0}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:0 0 16px}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;line-height:1.3;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-reading-companion__figure-full-link svg{margin-left:4px}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;display:inline-block;font-size:.875rem;font-weight:700;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px;text-decoration:none}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-editorial-summary__container .c-article-editorial-summary__button:focus{outline:3px solid #fece3e;will-change:transform}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title,.c-header__menu--global .c-header__item svg{display:none}.c-reading-companion{clear:both}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__figures-list,.c-reading-companion__references-list,.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.3;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{display:inline-block}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-reading-companion__panel--active{display:block}.page-temporary-flag .c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.page-temporary-flag .c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.page-temporary-flag .c-pdf-download{max-height:48px}}.page-temporary-flag .c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 16px}.page-temporary-flag .c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.page-temporary-flag .c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.page-temporary-flag .c-pdf-download__text{padding-right:8px}}.page-temporary-flag .c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.page-temporary-flag .c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a{color:inherit}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__list--inline>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}.c-breadcrumbs__chevron{fill:#888;margin:4px 4px 0}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:16px 0 0}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}.c-card--flush .c-card__body{padding:0}.c-card--dark .c-card__title{color:#fff}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:8px 0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__row--flush{padding:0}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin-right:24px}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px;padding:0 16px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;line-height:1.4;list-style:none;margin:0 -8px;padding:0}.c-header__menu--global{font-weight:400;justify-content:flex-end}@media only screen and (min-width:540px){.c-header__menu--global .c-header__item svg{display:block}}.c-header__menu--journal{font-size:.875rem}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}@media only screen and (max-width:1023px){.c-header__menu--tools{display:none}}.c-header__item{display:flex}@media only screen and (min-width:540px){.c-header__item:not(:first-child){margin-left:8px}}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}@media only screen and (max-width:767px){.c-header__item--nature-research{display:none}}.c-header__row--flush .c-header__item{padding-bottom:8px;padding-top:8px}.c-header__link{align-items:center;color:inherit;display:flex;padding:8px;white-space:nowrap}.c-header-expander a{color:inherit}.c-header__link>svg{margin-left:2px;transition-duration:.2s}@media only screen and (min-width:540px){.c-header__link>svg{margin-left:4px}}.c-header__show-text{display:none}@media only screen and (min-width:540px){.c-header__show-text{display:inline}.c-header__item--dropdown-menu{position:relative}.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header-expander.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header-expander.has-tethered{left:0;right:auto}}.c-header-expander{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}.c-header-expander button{background-color:transparent;border:1px solid #fff;color:#fff}.c-header-expander__container{margin:0 auto;max-width:1280px;padding:0 16px}.c-header-expander__keyline{border-bottom:1px solid #555;margin-bottom:0;padding-bottom:16px}.c-header-expander__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4}.c-header-expander__list{display:flex;flex-wrap:wrap;margin:0;padding:0}.c-header-expander__item{margin:0 16px 8px 0}.c-header-expander__link{align-items:center;color:inherit;display:flex;white-space:nowrap}.c-header-expander__link>svg{margin-left:8px}.c-header-expander.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header-expander.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header-expander.has-tethered{min-width:225px}}.c-header-expander.has-tethered .c-header-expander__list{display:block}.c-header-expander.has-tethered .c-header-expander__item{margin:0;padding:8px 0}.c-header-expander.has-tethered .c-header-expander__item--keyline{border-top:1px solid #fff;margin-top:8px;padding-top:16px}.c-header-expander.has-tethered .c-header-expander__item--keyline-first-item-only~.c-header-expander__item--keyline-first-item-only{border-top:none;padding-top:0}.c-header-expander--tray.has-tethered{padding:32px 0 24px;transform:none;width:100%}.c-search{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.3}.c-search--max-width{max-width:720px}.c-search__field{align-items:center;display:flex;flex-flow:row wrap}.c-search__input-container{flex:1 0 100%;margin-bottom:8px}@media only screen and (min-width:768px){.c-search__input-container--md{flex:999 1 auto;margin-bottom:0;margin-right:16px}}.c-search__select-container{flex:1 1 auto;margin-bottom:8px}@media only screen and (min-width:540px){.c-search__select-container{flex:999 1 auto;margin-bottom:0;margin-right:16px}}@media only screen and (min-width:768px){.c-search__select-container{flex:1 0 auto}}.c-search__button-container{flex:1 0 100%}@media only screen and (min-width:540px){.c-search__button-container{flex:1 0 auto}}.c-search__input,.c-search__select{background-color:#fff;border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:.6em 1em;width:100%}.c-search__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}.u-button svg,.u-button--primary svg{fill:currentcolor}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:768px){.u-show-at-md{display:block;visibility:visible}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-link-inherit{color:inherit}.u-list-reset{list-style:none;margin:0;padding:0}.u-overflow-hidden{overflow:hidden}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-text-bold{font-weight:700}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-display-inline-block{display:inline-block}.u-justify-content-space-between{justify-content:space-between}.u-ma-0{margin:0}.u-mt-32{margin-top:32px}.u-mr-2{margin-right:2px}.u-mr-24{margin-right:24px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}} }</style>

            
            
            
                <link data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-506fbf6a26.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
                <noscript>
                    <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-506fbf6a26.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
                </noscript>
            
            <link rel="stylesheet" type="text/css" href="/static/css/article-print-0626cb52eb.css" media="print">
        
    




<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                
                    j.src = 'https://collect.nature.com/gtm.js?id=' + i + dl;
                
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                e.src = 'https://push-content.springernature.io/pcf_sb_5_1617714720898560639/production_live/consent-bundle-8-8.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-2b0f06c1e4.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


    <script id="js-position0">
        (function(w, d) {
            w.idpVerifyPrefix = 'https://verify.nature.com';
            w.ra21Host = 'https://wayf.springernature.com';
            var moduleSupport = (function() {
                return 'noModule' in d.createElement('script');
            })();

            var polyfillsUrl = function() {
                var features = {
                    'IntersectionObserver': window.IntersectionObserver,
                    'Promise': window.Promise,
                    'URLSearchParams': window.URLSearchParams,
                    'Symbol.iterator': window.Symbol && Symbol.iterator,
                    'Array.from': Array.from,
                    'Array.prototype.includes': Array.prototype.includes,
                    'Array.prototype.find': Array.prototype.find,
                    'Array.prototype.forEach': Array.prototype.forEach,
                    'NodeList.prototype.forEach': NodeList.prototype.forEach,
                    'Element.prototype.closest': Element.prototype.closest,
                    'Element.prototype.prepend': Element.prototype.prepend,
                    'Element.prototype.remove': Element.prototype.remove,
                    'Object.assign': Object.assign
                };
                var req = [];
                for (var feature in features) {
                    if (Object.prototype.hasOwnProperty.call(features, feature) && !features[feature]) {
                        req.push(feature);
                    }
                }
                if (req.length) {
                    return 'https://polyfill.io/v3/polyfill.min.js?features=' + req.join('%2C') + '&flags=always';
                }
                return null;
            };

            if (w.config.mustardcut === true) {
                w.loader = {
                    index: 0,
                    registered: [],
                    scripts: [
                        {src: polyfillsUrl(), test: 'polyfills-js', noinit: true},
                        
                            {src: '/static/js/global-article-es6-bundle-47866a2d29.js', test: 'global-article-js', module: true},
                            {src: '/static/js/global-article-es5-bundle-cb492f1819.js', test: 'global-article-js', nomodule: true},
                            {src: '/static/js/shared-es6-bundle-9a5a2e755a.js', test: 'shared-js', module: true},
                            {src: '/static/js/shared-es5-bundle-9f73397950.js', test: 'shared-js', nomodule: true},
                            {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                            {src: '/static/js/header-150-es5-bundle-c634a291c7.js', test: 'header-150-js', nomodule: true}
                        
                    ].filter(function (s) {
                        if (s.src === null) return false;
                        if (moduleSupport && s.nomodule) return false;
                        return !(!moduleSupport && s.module);
                    }),

                    register: function (value) {
                        this.registered.push(value);
                    },

                    ready: function () {
                        if (this.registered.length === this.scripts.length) {
                            this.registered.forEach(function (fn) {
                                if (typeof fn === 'function') {
                                    setTimeout(fn, 0); 
                                }
                            });
                            this.ready = function () {};
                        }
                    },

                    insert: function (s) {
                        var t = d.getElementById('js-position' + this.index);
                        if (t && t.insertAdjacentElement) {
                            t.insertAdjacentElement('afterend', s);
                        } else {
                            d.head.appendChild(s);
                        }
                        ++this.index;
                    },

                    createScript: function (script, beforeLoad) {
                        var s = d.createElement('script');
                        s.id = 'js-position' + (this.index + 1);
                        s.setAttribute('data-test', script.test);
                        if (beforeLoad) {
                            s.defer = 'defer';
                            s.onload = function () {
                                if (script.noinit) {
                                    loader.register(true);
                                }
                                if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                    loader.ready();
                                }
                            };
                        } else {
                            s.async = 'async';
                        }
                        s.src = script.src;
                        return s;
                    },

                    init: function () {
                        this.scripts.forEach(function (s) {
                            loader.insert(loader.createScript(s, true));
                        });

                        d.addEventListener('DOMContentLoaded', function () {
                            loader.ready();
                            
                                var conditionalScripts = [
                                    {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-885b4d4cd7.js', test: 'pan-zoom-js',  module: true },
                                    {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-6a76e92cf3.js', test: 'pan-zoom-js',  nomodule: true },
                                    {match: 'math,span.mathjax-tex', src: '/static/js/math-21da043fb2.js', test: 'math-js'}
                                ];
                            

                            if (conditionalScripts) {
                                conditionalScripts.filter(function (script) {
                                    return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                                }).forEach(function (script) {
                                    loader.insert(loader.createScript(script));
                                });
                            }
                        }, false);
                    }
                };
                loader.init();
            }
        })(window, document);
    </script>




<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="http://www.nature.com/search">
<link rel="search" href="http://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="http://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">



    
    <script type="application/ld+json">{"mainEntity":{"headline":"COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images","description":"The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors’ knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release. We also introduce COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient patient cases, with the largest number of publicly available COVID-19 positive cases to the best of the authors’ knowledge. Furthermore, we investigate how COVID-Net makes predictions using an explainability method in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images. By no means a production-ready solution, the hope is that the open access COVID-Net, along with the description on constructing the open source COVIDx dataset, will be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases and accelerate treatment of those who need it the most.","datePublished":"2020-11-11","dateModified":"2020-11-11","pageStart":"1","pageEnd":"12","license":"http://creativecommons.org/licenses/by/4.0/","sameAs":"https://doi.org/10.1038/s41598-020-76550-z","keywords":"Diagnosis,Viral infection,Science,Humanities and Social Sciences,multidisciplinary","image":"https://static-content.springer.com/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig1_HTML.jpg","isPartOf":{"name":"Scientific Reports","issn":["2045-2322"],"volumeNumber":"10","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group UK","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Wang, Linda","affiliation":[{"name":"University of Waterloo","address":{"name":"Department of Systems Design Engineering, University of Waterloo, Waterloo, Canada","@type":"PostalAddress"},"@type":"Organization"},{"name":"Waterloo Artificial Intelligence Institute","address":{"name":"Waterloo Artificial Intelligence Institute, Waterloo, Canada","@type":"PostalAddress"},"@type":"Organization"},{"name":"DarwinAI Corp.","address":{"name":"DarwinAI Corp., Waterloo, Canada","@type":"PostalAddress"},"@type":"Organization"}],"email":"linda.wang@uwaterloo.ca","@type":"Person"},{"name":"Lin, Zhong Qiu","affiliation":[{"name":"University of Waterloo","address":{"name":"Department of Systems Design Engineering, University of Waterloo, Waterloo, Canada","@type":"PostalAddress"},"@type":"Organization"},{"name":"Waterloo Artificial Intelligence Institute","address":{"name":"Waterloo Artificial Intelligence Institute, Waterloo, Canada","@type":"PostalAddress"},"@type":"Organization"},{"name":"DarwinAI Corp.","address":{"name":"DarwinAI Corp., Waterloo, Canada","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Wong, Alexander","affiliation":[{"name":"University of Waterloo","address":{"name":"Department of Systems Design Engineering, University of Waterloo, Waterloo, Canada","@type":"PostalAddress"},"@type":"Organization"},{"name":"Waterloo Artificial Intelligence Institute","address":{"name":"Waterloo Artificial Intelligence Institute, Waterloo, Canada","@type":"PostalAddress"},"@type":"Organization"},{"name":"DarwinAI Corp.","address":{"name":"DarwinAI Corp., Waterloo, Canada","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":true,"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>



    
    <link rel="canonical" href="https://www.nature.com/articles/s41598-020-76550-z">
    
    
    
        <meta name="journal_id" content="41598"/>
    
        <meta name="dc.title" content="COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images"/>
    
        <meta name="dc.source" content="Scientific Reports 2020 10:1"/>
    
        <meta name="dc.format" content="text/html"/>
    
        <meta name="dc.publisher" content="Nature Publishing Group"/>
    
        <meta name="dc.date" content="2020-11-11"/>
    
        <meta name="dc.type" content="OriginalPaper"/>
    
        <meta name="dc.language" content="En"/>
    
        <meta name="dc.copyright" content="2020 The Author(s)"/>
    
        <meta name="dc.rights" content="2020 The Author(s)"/>
    
        <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    
        <meta name="dc.description" content="The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors&#8217; knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release. We also introduce COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient patient cases, with the largest number of publicly available COVID-19 positive cases to the best of the authors&#8217; knowledge. Furthermore, we investigate how COVID-Net makes predictions using an explainability method in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images. By no means a production-ready solution, the hope is that the open access COVID-Net, along with the description on constructing the open source COVIDx dataset, will be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases and accelerate treatment of those who need it the most."/>
    
        <meta name="prism.issn" content="2045-2322"/>
    
        <meta name="prism.publicationName" content="Scientific Reports"/>
    
        <meta name="prism.publicationDate" content="2020-11-11"/>
    
        <meta name="prism.volume" content="10"/>
    
        <meta name="prism.number" content="1"/>
    
        <meta name="prism.section" content="OriginalPaper"/>
    
        <meta name="prism.startingPage" content="1"/>
    
        <meta name="prism.endingPage" content="12"/>
    
        <meta name="prism.copyright" content="2020 The Author(s)"/>
    
        <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    
        <meta name="prism.url" content="https://www.nature.com/articles/s41598-020-76550-z"/>
    
        <meta name="prism.doi" content="doi:10.1038/s41598-020-76550-z"/>
    
        <meta name="citation_pdf_url" content="https://www.nature.com/articles/s41598-020-76550-z.pdf"/>
    
        <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/s41598-020-76550-z"/>
    
        <meta name="citation_journal_title" content="Scientific Reports"/>
    
        <meta name="citation_journal_abbrev" content="Sci Rep"/>
    
        <meta name="citation_publisher" content="Nature Publishing Group"/>
    
        <meta name="citation_issn" content="2045-2322"/>
    
        <meta name="citation_title" content="COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images"/>
    
        <meta name="citation_volume" content="10"/>
    
        <meta name="citation_issue" content="1"/>
    
        <meta name="citation_online_date" content="2020/11/11"/>
    
        <meta name="citation_firstpage" content="1"/>
    
        <meta name="citation_lastpage" content="12"/>
    
        <meta name="citation_article_type" content="Article"/>
    
        <meta name="citation_fulltext_world_readable" content=""/>
    
        <meta name="citation_language" content="en"/>
    
        <meta name="dc.identifier" content="doi:10.1038/s41598-020-76550-z"/>
    
        <meta name="DOI" content="10.1038/s41598-020-76550-z"/>
    
        <meta name="citation_doi" content="10.1038/s41598-020-76550-z"/>
    
        <meta name="description" content="The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors&#8217; knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release. We also introduce COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient patient cases, with the largest number of publicly available COVID-19 positive cases to the best of the authors&#8217; knowledge. Furthermore, we investigate how COVID-Net makes predictions using an explainability method in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images. By no means a production-ready solution, the hope is that the open access COVID-Net, along with the description on constructing the open source COVIDx dataset, will be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases and accelerate treatment of those who need it the most."/>
    
        <meta name="dc.creator" content="Wang, Linda"/>
    
        <meta name="dc.creator" content="Lin, Zhong Qiu"/>
    
        <meta name="dc.creator" content="Wong, Alexander"/>
    
        <meta name="dc.subject" content="Diagnosis"/>
    
        <meta name="dc.subject" content="Viral infection"/>
    
        <meta name="citation_reference" content="citation_journal_title=JAMA; citation_title=Detection of SARS-CoV-2 in different types of clinical specimens; citation_author=W Wang; citation_volume=323; citation_issue=18; citation_publication_date=2020; citation_pages=1843-1844; citation_id=CR1"/>
    
        <meta name="citation_reference" content="West, C. P., Montori, V. M., &amp; Sampathkumar, P. Covid-19 testing: the threat of false-negative results. In Mayo Clinic Proceeding (2020)."/>
    
        <meta name="citation_reference" content="Fang, Y. et al. Sensitivity of chest CT for covid-19: comparison to RT-PCR. Radiology. 
https://doi.org/10.1148/radiol.2020200432

 (2020)."/>
    
        <meta name="citation_reference" content="Yang, Y. et&#160;al. Evaluating the accuracy of different respiratory specimens in the laboratory diagnosis and monitoring the viral shedding of 2019-ncov infections. medRxiv:2020.02.11.20021493 (2020)."/>
    
        <meta name="citation_reference" content="Wikramaratna, P., Paton, R. S., Ghafari, M., &amp; Lourenco, J. Estimating false-negative detection rate of sars-cov-2 by rt-pcr. medRxiv:2020.04.05.20053355 (2020)."/>
    
        <meta name="citation_reference" content="citation_journal_title=Radiol. Cardiothorac. Imaging; citation_title=Imaging profile of the COVID-19 infection: radiologic findings and literature review; citation_author=M-Y Ng; citation_volume=2; citation_issue=1; citation_publication_date=2020; citation_pages=e200034; citation_doi=10.1148/ryct.2020200034; citation_id=CR6"/>
    
        <meta name="citation_reference" content="citation_journal_title=The Lancet; citation_title=Clinical features of patients infected with 2019 Novel Coronavirus in Wuhan China; citation_author=C Huang; citation_volume=395; citation_publication_date=2020; citation_pages=497-506; citation_doi=10.1016/S0140-6736(20)30183-5; citation_id=CR7"/>
    
        <meta name="citation_reference" content="Guan, W. J., Hu Y., &amp; Ni Z. Y. Clinical characteristics of Coronavirus disease 2019 in China. N. Engl. J. Med. 382(18), 1708&#8211;1720 (2020)."/>
    
        <meta name="citation_reference" content="citation_journal_title=Radiology; citation_title=Correlation of chest CT and RT-PCR testing in coronavirus disease 2019 (COVID-19) in china: a report of 1014 cases; citation_author=T Ai; citation_publication_date=2020; citation_doi=10.1148/radiol.2020200642; citation_id=CR9"/>
    
        <meta name="citation_reference" content="citation_journal_title=Radiology; citation_title=The role of chest imaging in patient management during the COVID-19 pandemic: a multinational consensus statement from the fleischner society; citation_author=GD Rubin; citation_publication_date=2020; citation_doi=10.1016/j.chest.2020.04.003; citation_id=CR10"/>
    
        <meta name="citation_reference" content="citation_journal_title=Clin. Radiol.; citation_title=A British Society of thoracic imaging statement: considerations in designing local imaging diagnostic algorithms for the COVID-19 pandemic; citation_author=A Nair; citation_volume=75; citation_issue=5; citation_publication_date=2020; citation_pages=329-334; citation_doi=10.1016/j.crad.2020.03.008; citation_id=CR11"/>
    
        <meta name="citation_reference" content="citation_journal_title=Can. Assoc. Radiol. J.; citation_title=The Canadian Society of Thoracic Radiology (CSTR) and Canadian Association of Radiologists (CAR) consensus statement regarding chest imaging in suspected and confirmed COVID-19; citation_author=C Dennie; citation_volume=71; citation_issue=4; citation_publication_date=2020; citation_pages=470-481; citation_doi=10.1177/0846537120924606; citation_id=CR12"/>
    
        <meta name="citation_reference" content="citation_journal_title=Clin. Imaging; citation_title=Portable chest x-ray in coronavirus disease-19 (covid-19): a pictorial review; citation_author=A Jacobi, M Chung, A Bernheim, C Eber; citation_publication_date=2020; citation_doi=10.1016/j.clinimag.2020.04.001; citation_id=CR13"/>
    
        <meta name="citation_reference" content="Wu, G., &amp; Li, X. Mobile x-rays are highly valuable for critically ill covid patients. Eur. Radiol.. 
https://doi.org/10.1007/s00330-020-06918-2

(2020)."/>
    
        <meta name="citation_reference" content="Mao, B. et al. Assessing risk factors for SARS-CoV-2 infection in patients presenting with symptoms in Shanghai, China: a multicentre observational cohort study. Lancet Dig. Health. 
https://doi.org/10.1016/S2589-7500(20)30109-6

(2020)."/>
    
        <meta name="citation_reference" content="Cohen, J. P., Morrison, P., &amp; Dao, L. COVID-19 image data collection. 
arXiv:2003.11597

 (2020)."/>
    
        <meta name="citation_reference" content="Chung, A. Figure 1 COVID-19 chest x-ray data initiative. 
https://github.com/agchung/Figure1-COVID-chestxray-dataset

 (2020)."/>
    
        <meta name="citation_reference" content="Chung, A. Actualmed COVID-19 chest x-ray data initiative. 
https://github.com/agchung/Actualmed-COVID-chestxray-dataset

 (2020)."/>
    
        <meta name="citation_reference" content="Radiological Society of North America. COVID-19 radiography database. 
https://www.kaggle.com/tawsifurrahman/covid19-radiography-database

 (2019)."/>
    
        <meta name="citation_reference" content="Radiological Society of North America. RSNA pneumonia detection challenge. https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data (2019)."/>
    
        <meta name="citation_reference" content="LeCun, Y., Bengio, Y., &amp; Hinton, G. Deep learning. Nature 521, 436&#8211;444 (2015)."/>
    
        <meta name="citation_reference" content="Gozes, O. et&#160;al. Rapid AI development cycle for the coronavirus (COVID-19) pandemic: initial results for automated detection and patient monitoring using deep learning ct image analysis. 
arXiv:2003.05037

 (2020)."/>
    
        <meta name="citation_reference" content="Xu, X. et&#160;al. Deep learning system to screen coronavirus disease 2019 pneumonia. 
arXiv:2002.09334

 (2020)."/>
    
        <meta name="citation_reference" content="Li, L. et al. Artificial intelligence distinguishes COVID-19 from community acquired pneumonia on chest CT. Radiology. 
https://doi.org/10.1148/radiol.2020200905

 (2020)."/>
    
        <meta name="citation_reference" content="Shi, F. et&#160;al. Large-scale screening of covid-19 from community acquired pneumonia using infection size-aware classification. 
arXiv:2003.09860

 (2020)."/>
    
        <meta name="citation_reference" content="Li, X., Li, C., &amp; Zhu, D. Covid-mobilexpert: On-device covid-19 screening using snapshots of chest x-ray. 
arXiv:2004.03042

 (2020)."/>
    
        <meta name="citation_reference" content="Minaee, S., Kafieh, R., Sonka, M., Yazdani, S., &amp; Soufi, G.&#160;J. Deep-covid: predicting covid-19 from chest x-ray images using deep transfer learning. 
arXiv:2004.09363

 (2020)."/>
    
        <meta name="citation_reference" content="Afshar, P. et&#160;al. Covid-caps: a capsule network-based framework for identification of covid-19 cases from x-ray images. 
arXiv:2004.02696

 (2020)."/>
    
        <meta name="citation_reference" content="Luz, E. et&#160;al. Towards an effective and efficient deep learning model for covid-19 patterns detection in x-ray images. 
arXiv:2004.05717

 (2020)."/>
    
        <meta name="citation_reference" content="Khobahi, S., Agarwal, C., &amp; Soltanalian, M. Coronet: a deep network architecture for semi-supervised task-based identification of covid-19 from chest x-ray images. medRxiv. 
https://doi.org/10.1101/2020.04.14.20065722

 (2020)."/>
    
        <meta name="citation_reference" content="Ucar, F., &amp; Korkmaz, D. COVIDiagnosis-net: deep bayes-squeezenet based diagnosis of the coronavirus disease 2019 (COVID-19) from x-ray images. Med. Hypotheses. 
https://doi.org/10.1016/j.mehy.2020.109761

 (2020)."/>
    
        <meta name="citation_reference" content="Tartaglione, E., Barbano, C. A., Berzovini, C., Calandri, M., &amp; Grangetto, M. Unveiling covid-19 from chest x-ray with deep learning: a hurdles race with small data. 
arXiv:2004.05405

 (2020)."/>
    
        <meta name="citation_reference" content="Yeh, C.-F. et&#160;al. A cascaded learning strategy for robust covid-19 pneumonia chest x-ray screening. 
arXiv:2004.12786

 (2020)."/>
    
        <meta name="citation_reference" content="Zhang, Y. et&#160;al. Covid-da: deep domain adaptation from typical pneumonia to covid-19. 
arXiv:2005.01577

 (2020)."/>
    
        <meta name="citation_reference" content="Karim, M. R. et&#160;al. Deepcovidexplainer: explainable covid-19 predictions based on chest x-ray images (2020)."/>
    
        <meta name="citation_reference" content="Apostolopoulos, I. D., &amp; Mpesiana, T. A. Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks. Phys. Eng. Sci. Med. 43, 635&#8211;640. 
https://doi.org/10.1007/s13246-020-00865-4

 (2020)."/>
    
        <meta name="citation_reference" content="Farooq, M., &amp; Hafeez, A. Covid-resnet: a deep learning framework for screening of covid19 from radiographs (2020)."/>
    
        <meta name="citation_reference" content="Majeed, T., Rashid, R., Ali, D., &amp; Asaad, A. Covid-19 detection using cnn transfer learning from x-ray images. medRxiv (2020)."/>
    
        <meta name="citation_reference" content="Wang, X. et&#160;al. Chestx-ray8: hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. In 2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR), 3462&#8211;3471 (2017)."/>
    
        <meta name="citation_reference" content="He, K., Zhang, X., Ren, S., &amp; Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 770&#8211;778 (2016)."/>
    
        <meta name="citation_reference" content="Wong, A., Shafiee, M. J., Chwyl, B., &amp; Li, F. Ferminets: learning generative machines to generate efficient neural networks via generative synthesis. arXiv preprint 
arXiv:1809.05989

 (2018)."/>
    
        <meta name="citation_reference" content="Huang, G., Liu, Z., &amp; Weinberger, K. Q. Densely connected convolutional networks. arXiv preprint 
arXiv:1608.06993

 (2016)."/>
    
        <meta name="citation_reference" content="Deng, J. et&#160;al. Imagenet: a large-scale hierarchical image database. In 2009 IEEE Conference on Computer Vision and Pattern Recognition 248&#8211;255 (IEEE, 2009)."/>
    
        <meta name="citation_reference" content="Lin, Z. Q. et&#160;al. Do explanations reflect decisions? A machine-centric strategy to quantify the performance of explainability algorithms. arXiv preprint 
arXiv:1910.07387

 (2019)."/>
    
        <meta name="citation_reference" content="Wong, A. Netscore: towards universal metrics for large-scale performance analysis of deep neural networks for practical usage. CoRR. arXiv preprint 
arXiv:abs/1806.05512

 (2018)."/>
    
        <meta name="citation_reference" content="Simonyan, K., &amp; Zisserman, A. Very deep convolutional networks for large-scale image recognition (2014)."/>
    
        <meta name="citation_author" content="Wang, Linda"/>
    
        <meta name="citation_author_institution" content="Department of Systems Design Engineering, University of Waterloo, Waterloo, Canada"/>
    
        <meta name="citation_author_institution" content="Waterloo Artificial Intelligence Institute, Waterloo, Canada"/>
    
        <meta name="citation_author_institution" content="DarwinAI Corp., Waterloo, Canada"/>
    
        <meta name="citation_author" content="Lin, Zhong Qiu"/>
    
        <meta name="citation_author_institution" content="Department of Systems Design Engineering, University of Waterloo, Waterloo, Canada"/>
    
        <meta name="citation_author_institution" content="Waterloo Artificial Intelligence Institute, Waterloo, Canada"/>
    
        <meta name="citation_author_institution" content="DarwinAI Corp., Waterloo, Canada"/>
    
        <meta name="citation_author" content="Wong, Alexander"/>
    
        <meta name="citation_author_institution" content="Department of Systems Design Engineering, University of Waterloo, Waterloo, Canada"/>
    
        <meta name="citation_author_institution" content="Waterloo Artificial Intelligence Institute, Waterloo, Canada"/>
    
        <meta name="citation_author_institution" content="DarwinAI Corp., Waterloo, Canada"/>
    
        <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    
        <meta name="twitter:site" content="@SciReports"/>
    
        <meta name="twitter:card" content="summary_large_image"/>
    
        <meta name="twitter:image:alt" content="Content cover image"/>
    
        <meta name="twitter:title" content="COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images"/>
    
        <meta name="twitter:description" content="Scientific Reports - COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images"/>
    
        <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig1_HTML.jpg"/>
    

    
        <meta property="og:url" content="https://www.nature.com/articles/s41598-020-76550-z">
        <meta property="og:type" content="article">
        <meta property="og:site_name" content="Nature">
        <meta property="og:title" content="COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images - Scientific Reports">
        
        <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig1_HTML.jpg">
    
    <script>
        window.eligibleForRa21 = 'false'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://collect.nature.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/scientific_reports/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=s41598-020-76550-z;doi=10.1038/s41598-020-76550-z;subjmeta=139,2514,255,692,699,700;kwrd=Diagnosis,Viral+infection">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/scientific_reports/article&amp;sz=728x90&amp;c=-1016626240&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41598-020-76550-z%26doi%3D10.1038/s41598-020-76550-z%26subjmeta%3D139,2514,255,692,699,700%26kwrd%3DDiagnosis,Viral+infection">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/scientific_reports/article&amp;sz=728x90&amp;c=-1016626240&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41598-020-76550-z%26doi%3D10.1038/s41598-020-76550-z%26subjmeta%3D139,2514,255,692,699,700%26kwrd%3DDiagnosis,Viral+infection"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#cedde4">
        <div class="c-header__row c-header__row--flush">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/srep"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="//media.springernature.com/full/nature-cms/uploads/product/srep/header-d3c533c187c710c1bedbd8e293815d5f.svg" media="(min-width: 875px)">
                                <img src="//media.springernature.com/full/nature-cms/uploads/product/srep/header-d3c533c187c710c1bedbd8e293815d5f.svg" alt="Scientific Reports">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--nature-research">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--pipe">
                            <a class="c-header__link"
                               href="#search-menu"
                               data-header-expander
                               data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <span>Search</span><svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg>
                            </a>
                        </li>
                        <li class="c-header__item">
                            <a href="/nams/svc/myaccount"
    id="my-account"
    class="c-header__link placeholder"
    data-test="login-link" data-track="click" data-track-action="my account" data-track-category="nature-150-split-header" data-track-label="link">
    <span>My Account</span><svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M10.238 16.905a7.96 7.96 0 003.53-1.48c-.874-2.514-2.065-3.936-3.768-4.319V9.83a3.001 3.001 0 10-2 0v1.277c-1.703.383-2.894 1.805-3.767 4.319A7.96 7.96 0 009 17c.419 0 .832-.032 1.238-.095zm4.342-2.172a8 8 0 10-11.16 0c.757-2.017 1.84-3.608 3.49-4.322a4 4 0 114.182 0c1.649.714 2.731 2.305 3.488 4.322zM9 18A9 9 0 119 0a9 9 0 010 18z" fill="#333" fill-rule="evenodd"/></svg>
</a>
<a href="https://idp.nature.com/authorize/natureuser?client_id&#x3D;grover&amp;redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-020-76550-z"
    id="login-button"
    style="display: none;"
    class="c-header__link placeholder"
    data-test="login-link" data-track="click" data-track-action="login" data-track-category="nature-150-split-header" data-track-label="link">
    <span>Login</span><svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M10.238 16.905a7.96 7.96 0 003.53-1.48c-.874-2.514-2.065-3.936-3.768-4.319V9.83a3.001 3.001 0 10-2 0v1.277c-1.703.383-2.894 1.805-3.767 4.319A7.96 7.96 0 009 17c.419 0 .832-.032 1.238-.095zm4.342-2.172a8 8 0 10-11.16 0c.757-2.017 1.84-3.608 3.49-4.322a4 4 0 114.182 0c1.649.714 2.731 2.305 3.488 4.322zM9 18A9 9 0 119 0a9 9 0 010 18z" fill="#333" fill-rule="evenodd"/></svg>
</a>

                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <div class="c-header__split">
                            <ul class="c-header__menu c-header__menu--journal">
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                        <a href="#explore"
                                           class="c-header__link c-header__link--chevron"
                                           data-header-expander
                                           data-test="menu-button--explore"
                                           data-track="click" data-track-action="open explore expander" data-track-label="button">
                                            <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                                
                                    <li class="c-header__item c-header__item--dropdown-menu">
                                        <a href="#about-the-journal"
                                           class="c-header__link c-header__link--chevron"
                                           data-header-expander
                                           data-test="menu-button--about-the-journal"
                                           data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                            <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                    
                                        <li class="c-header__item c-header__item--dropdown-menu u-mr-2" data-test="publish-with-us-button">
                                            <a href="#publish-with-us"
                                               class="c-header__link c-header__link--chevron c-header__link--dropdown-menu"
                                               data-header-expander
                                               data-test="menu-button--publish"
                                               data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                                <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                            </a>
                                        </li>
                                    
                                
                            </ul>

                            
                        </div>

                        <ul class="c-header__menu c-header__menu--tools">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;288"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="http://feeds.nature.com/srep/rss/current"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                        <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16 u-hide u-show-at-md" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/srep" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:scientific reports"><span itemprop="name">scientific reports</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/srep/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix page-temporary-flag" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41598-020-76550-z.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
                <div class="c-pdf-button__container u-hide-at-lg js-context-bar-sticky-point-mobile">
                    <div class="c-pdf-container">
                        
                            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41598-020-76550-z.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            </a>
        </div>
    

                        
                    </div>
                </div>
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
    
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    
        <li class="c-article-identifiers__item">
            <span class="c-article-identifiers__open" data-test="open-access">Open Access</span>
        </li>
    
    

                        <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2020-11-11">11 November 2020</time></a></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images</h1>
                    <ul class="c-article-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Linda-Wang" aria-label="Read more about Linda Wang" data-author-popup="auth-Linda-Wang" data-corresp-id="c1">Linda Wang<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a>,<a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Zhong_Qiu-Lin" aria-label="Read more about Zhong Qiu Lin" data-author-popup="auth-Zhong_Qiu-Lin">Zhong Qiu Lin</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a>,<a href="#Aff3">3</a></sup> &amp; </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Alexander-Wong" aria-label="Read more about Alexander Wong" data-author-popup="auth-Alexander-Wong">Alexander Wong</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a>,<a href="#Aff3">3</a></sup> </li></ul>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/srep"><i data-test="journal-title">Scientific Reports</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 10</b>, Article number: <span data-test="article-number">19549</span> (<span data-test="article-publication-year">2020</span>)
            <a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
    <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
            
                <li class=" c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">47k <span class="c-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">664 <span class="c-article-metrics-bar__label">Citations</span></p>
                </li>
            
            
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">23 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                    </li>
                
            
            <li class="c-article-metrics-bar__item">
                <p class="c-article-metrics-bar__details"><a href="/articles/s41598-020-76550-z/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
            </li>
        </ul>
    </div>

                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/diagnosis" data-track="click" data-track-action="view subject" data-track-label="link">Diagnosis</a></li><li class="c-article-subject-list__subject"><a href="/subjects/viral-infection" data-track="click" data-track-action="view subject" data-track-label="link">Viral infection</a></li>
        </ul>
    </div>

                
    

    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors’ knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release. We also introduce COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient patient cases, with the largest number of publicly available COVID-19 positive cases to the best of the authors’ knowledge. Furthermore, we investigate how COVID-Net makes predictions using an explainability method in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images. By no means a production-ready solution, the hope is that the open access COVID-Net, along with the description on constructing the open source COVIDx dataset, will be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases and accelerate treatment of those who need it the most.</p></div></div></section>
            <noscript>
                
            </noscript>

                
            
                <section data-title="Introduction"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population, caused by the infection of individuals by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). A critical step in the fight against COVID-19 is effective screening of infected patients, such that those infected can receive immediate treatment and care, as well as be isolated to mitigate the spread of the virus. The main screening method used for detecting COVID-19 cases is reverse transcriptase-polymerase chain reaction (RT-PCR)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Wang, W. et al. Detection of SARS-CoV-2 in different types of clinical specimens. JAMA 323(18), 1843–1844 (2020)." href="/articles/s41598-020-76550-z#ref-CR1" id="ref-link-section-d21123127e359">1</a></sup> testing, which can detect SARS-CoV-2 ribonucleic acid (RNA) from respiratory specimens (collected through a variety of means such as nasopharyngeal or oropharyngeal swabs). While RT-PCR testing is the gold standard as it is highly specific, it is a very time-consuming, laborious, and complicated manual process that is in short supply. Furthermore, the sensitivity of RT-PCR testing is highly variable and have not been reported in a clear and consistent manner to date<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="West, C. P., Montori, V. M., &amp; Sampathkumar, P. Covid-19 testing: the threat of false-negative results. In Mayo Clinic Proceeding (2020)." href="/articles/s41598-020-76550-z#ref-CR2" id="ref-link-section-d21123127e363">2</a></sup>, and initial findings in China showing relatively poor sensitivity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Fang, Y. et al. Sensitivity of chest CT for covid-19: comparison to RT-PCR. Radiology. &#xA;https://doi.org/10.1148/radiol.2020200432&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR3" id="ref-link-section-d21123127e367">3</a></sup>. Furthermore, subsequent findings showed highly variable positive rate depending on how the specimen was collected as well as decreasing positive rate with time after symptom onset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Yang, Y. et al. Evaluating the accuracy of different respiratory specimens in the laboratory diagnosis and monitoring the viral shedding of 2019-ncov infections. medRxiv:2020.02.11.20021493 (2020)." href="/articles/s41598-020-76550-z#ref-CR4" id="ref-link-section-d21123127e371">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Wikramaratna, P., Paton, R. S., Ghafari, M., &amp; Lourenco, J. Estimating false-negative detection rate of sars-cov-2 by rt-pcr. medRxiv:2020.04.05.20053355 (2020)." href="/articles/s41598-020-76550-z#ref-CR5" id="ref-link-section-d21123127e374">5</a></sup>.</p><p>An alternative screening method that has also been utilized for COVID-19 screening has been radiography examination, where chest radiography imaging (e.g., chest X-ray (CXR) or computed tomography (CT) imaging) is conducted and analyzed by radiologists to look for visual indicators associated with SARS-CoV-2 viral infection. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ng, M.-Y. et al. Imaging profile of the COVID-19 infection: radiologic findings and literature review. Radiol. Cardiothorac. Imaging 2(1), e200034 (2020)." href="#ref-CR6" id="ref-link-section-d21123127e381">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Huang, C. et al. Clinical features of patients infected with 2019 Novel Coronavirus in Wuhan China. The Lancet 395, 497–506 (2020)." href="#ref-CR7" id="ref-link-section-d21123127e381_1">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Guan, W. J., Hu Y., &amp; Ni Z. Y. Clinical characteristics of Coronavirus disease 2019 in China. N. Engl. J. Med. 382(18), 1708–1720 (2020)." href="/articles/s41598-020-76550-z#ref-CR8" id="ref-link-section-d21123127e384">8</a></sup>, with some suggesting that radiography examination could be used as a primary tool for COVID-19 screening in epidemic areas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Ai, T. et al. Correlation of chest CT and RT-PCR testing in coronavirus disease 2019 (COVID-19) in china: a report of 1014 cases. Radiology (2020). &#xA;https://doi.org/10.1148/radiol.2020200642&#xA;&#xA;." href="/articles/s41598-020-76550-z#ref-CR9" id="ref-link-section-d21123127e388">9</a></sup>. For example, Huang et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Huang, C. et al. Clinical features of patients infected with 2019 Novel Coronavirus in Wuhan China. The Lancet 395, 497–506 (2020)." href="/articles/s41598-020-76550-z#ref-CR7" id="ref-link-section-d21123127e392">7</a></sup> identified that the majority of the COVID-19 positive cases in their study presented bilateral radiographic abnormalities in CXR images, and Guan et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Guan, W. J., Hu Y., &amp; Ni Z. Y. Clinical characteristics of Coronavirus disease 2019 in China. N. Engl. J. Med. 382(18), 1708–1720 (2020)." href="/articles/s41598-020-76550-z#ref-CR8" id="ref-link-section-d21123127e396">8</a></sup> identified COVID-19 positive cases in their study presented radiographic abnormalities such as ground-glass opacity, bilateral abnormalities, and interstitial abnormalities in CXR and CT images. While much of the recent discussion has revolved around CT imaging due to greater image detail in the acquisitions, there are several advantages to leveraging CXR imaging for COVID-19 screening amid the global COVID-19 pandemic, particularly in resource-constrained areas and heavily-affected areas:</p><ul class="u-list-style-bullet">
<li>
<p><b>Rapid triaging</b> CXR imaging enables rapid triaging of patients suspected of COVID-19 and can be done in parallel of viral testing (which takes time) to help relief the high volumes of patients especially in areas most affected where they have ran out of capacity (e.g., New York, Spain, and Italy), or even as standalone when viral testing isn’t an option (low supplies). Furthermore, CXR imaging can be quite effective for triaging in geographic areas where patients are instructed to stay home until the onset of advanced symptoms (e.g., New York City), since abnormalities are often seen at time of presentation when patients suspected of COVID-19 arrive at clinical sites<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Rubin, G. D. et al. The role of chest imaging in patient management during the COVID-19 pandemic: a multinational consensus statement from the fleischner society. Radiology (2020). &#xA;https://doi.org/10.1016/j.chest.2020.04.003&#xA;&#xA;." href="/articles/s41598-020-76550-z#ref-CR10" id="ref-link-section-d21123127e408">10</a></sup>.</p>
</li>
<li>
<p><b>Availability and accessibility</b> CXR imaging is readily available and accessible in many clinical sites and imaging centers as it is considered standard equipment in most healthcare systems. In particular, CXR imaging is much more readily available than CT imaging, especially in developing countries where CT scanners are cost prohibitive due to high equipment and maintenance costs.</p>
</li>
<li>
<p><b>Portability</b> The existence of portable CXR systems means that imaging can be performed within an isolation room, thus significantly reducing the risk of COVID-19 transmission during transport to fixed systems such as CT scanners as well as within the rooms housing the fixed imaging systems<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Rubin, G. D. et al. The role of chest imaging in patient management during the COVID-19 pandemic: a multinational consensus statement from the fleischner society. Radiology (2020). &#xA;https://doi.org/10.1016/j.chest.2020.04.003&#xA;&#xA;." href="/articles/s41598-020-76550-z#ref-CR10" id="ref-link-section-d21123127e428">10</a></sup>.</p>
</li>
</ul><p>As such, radiography examination can be conducted faster and have greater availability given the prevalence of chest radiology imaging systems in modern healthcare systems and the availability of portable units, making them a good complement to RT-PCR testing particularly since CXR imaging is often performed as part of standard procedure for patients with a respiratory complaint<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Nair, A. et al. A British Society of thoracic imaging statement: considerations in designing local imaging diagnostic algorithms for the COVID-19 pandemic. Clin. Radiol. 75(5), 329–334 (2020)." href="/articles/s41598-020-76550-z#ref-CR11" id="ref-link-section-d21123127e436">11</a></sup>. It is also suggested that CXR imaging may have utility for situations where patients with initial negative RT-PCR testing outcomes return to the emergency department with worsening symptoms<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Dennie, C. et al. The Canadian Society of Thoracic Radiology (CSTR) and Canadian Association of Radiologists (CAR) consensus statement regarding chest imaging in suspected and confirmed COVID-19. Can. Assoc. Radiol. J. 71(4), 470–481 (2020)." href="/articles/s41598-020-76550-z#ref-CR12" id="ref-link-section-d21123127e440">12</a></sup>. Furthermore, some have suggested that as the COVID-19 pandemic progresses, there will be a greater reliance on portable CXR due to the aforementioned advantages<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Jacobi, A., Chung, M., Bernheim, A. &amp; Eber, C. Portable chest x-ray in coronavirus disease-19 (covid-19): a pictorial review. Clin. Imaging&#xA;https://doi.org/10.1016/j.clinimag.2020.04.001&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR13" id="ref-link-section-d21123127e444">13</a></sup>, and found portable CXR to be highly valuable for critically ill COVID-19 patients<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Wu, G., &amp; Li, X. Mobile x-rays are highly valuable for critically ill covid patients. Eur. Radiol.. &#xA;https://doi.org/10.1007/s00330-020-06918-2&#xA;&#xA;(2020)." href="/articles/s41598-020-76550-z#ref-CR14" id="ref-link-section-d21123127e448">14</a></sup>. Hence, CXR are an integral part of some screening strategies that have been proposed<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Mao, B. et al. Assessing risk factors for SARS-CoV-2 infection in patients presenting with symptoms in Shanghai, China: a multicentre observational cohort study. Lancet Dig. Health. &#xA;https://doi.org/10.1016/S2589-7500(20)30109-6&#xA;&#xA;(2020)." href="/articles/s41598-020-76550-z#ref-CR15" id="ref-link-section-d21123127e452">15</a></sup>. However, one of the biggest bottlenecks faced is the need for expert radiologists to interpret the radiography images, since the visual indicators can be subtle. As such, computer-aided diagnostic systems that can aid radiologists to more rapidly and accurately interpret radiography images to detect COVID-19 cases is highly desired.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Figure 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig1_HTML.jpg?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig1_HTML.jpg" alt="figure 1" loading="lazy" width="685" height="1264"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Example CXR images of: (<b>A</b>) non-COVID19 infection, and (<b>B</b>) COVID-19 viral infection in the COVIDx dataset.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Motivated by the urgent need to develop solutions to aid in the fight against the COVID-19 pandemic, inspired by the open source and open access efforts of the research community, and intrigued in exploring the efficacy of AI systems leveraging the more readily available and accessible CXR imaging modality, this study introduces COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from CXR images that is open source and available to the general public. The main contributions of this study are:</p><ul class="u-list-style-bullet">
<li>
<p>Introduction of a novel deep neural network architecture that is tailored for the detection of COVID-19 cases from CXR images using a human-machine collaborative design strategy. To the best of the authors’ knowledge, COVID-Net is the first neural network architecture designed for COVID-19 detection to introduce a lightweight projection-expansion-projection-extension (PEPX) design, which enables enhanced representational capacity while greatly reducing computational complexity. Furthermore, to the best of the authors’ knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release, which encourages reproducibility.</p>
</li>
<li>
<p>Introduction of COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient cases, created as a combination and modification of five open access data repositories containing chest radiography images (i.e.,<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Cohen, J. P., Morrison, P., &amp; Dao, L. COVID-19 image data collection. &#xA;arXiv:2003.11597&#xA;&#xA; (2020)." href="#ref-CR16" id="ref-link-section-d21123127e495">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Chung, A. Figure 1 COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Figure1-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="#ref-CR17" id="ref-link-section-d21123127e495_1">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Chung, A. Actualmed COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Actualmed-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="#ref-CR18" id="ref-link-section-d21123127e495_2">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Radiological Society of North America. COVID-19 radiography database. &#xA;https://www.kaggle.com/tawsifurrahman/covid19-radiography-database&#xA;&#xA; (2019)." href="#ref-CR19" id="ref-link-section-d21123127e495_3">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Radiological Society of North America. RSNA pneumonia detection challenge. https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data (2019)." href="/articles/s41598-020-76550-z#ref-CR20" id="ref-link-section-d21123127e498">20</a></sup>), two of which we introduced<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Chung, A. Figure 1 COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Figure1-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR17" id="ref-link-section-d21123127e502">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Chung, A. Actualmed COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Actualmed-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR18" id="ref-link-section-d21123127e505">18</a></sup>. To the best of the authors’ knowledge, COVIDx is the largest open access benchmark dataset available in terms of the number of publicly available COVID-19 positive cases.</p>
</li>
<li>
<p>Introduction of an explainability approach to investigating how COVID-Net makes predictions in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images.</p>
</li>
</ul><p>The paper is organized as follows. First, “<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41598-020-76550-z#Sec1">Introduction</a>” discusses the strategy used to create the COVIDx dataset, the strategy leveraged to create the proposed COVID-Net, the architecture design of COVID-Net, the implementation details of COVID-Net, and the strategy leveraged to audit COVID-Net via explainability. “<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41598-020-76550-z#Sec3">Methods</a>” presents and discusses the results of experiments conducted to evaluate the efficacy of the proposed COVID-Net in both a quantitative and qualitative manner. Finally, conclusions are drawn and future directions discussed in “<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41598-020-76550-z#Sec13">Experimental results</a>”.</p></div></div></section><section data-title="Related work"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Related work</h2><div class="c-article-section__content" id="Sec2-content"><p>Motivated by the need for faster interpretation of radiography images, a number of artificial intelligence (AI) systems based on deep learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="LeCun, Y., Bengio, Y., &amp; Hinton, G. Deep learning. Nature 521, 436–444 (2015)." href="/articles/s41598-020-76550-z#ref-CR21" id="ref-link-section-d21123127e535">21</a></sup> have been proposed and results have shown to be quite promising in terms of accuracy in detecting patients infected with COVID-19 via radiography imaging, with the focus primarily on CT imaging<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Gozes, O. et al. Rapid AI development cycle for the coronavirus (COVID-19) pandemic: initial results for automated detection and patient monitoring using deep learning ct image analysis. &#xA;arXiv:2003.05037&#xA;&#xA; (2020)." href="#ref-CR22" id="ref-link-section-d21123127e539">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Xu, X. et al. Deep learning system to screen coronavirus disease 2019 pneumonia. &#xA;arXiv:2002.09334&#xA;&#xA; (2020)." href="#ref-CR23" id="ref-link-section-d21123127e539_1">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Li, L. et al. Artificial intelligence distinguishes COVID-19 from community acquired pneumonia on chest CT. Radiology. &#xA;https://doi.org/10.1148/radiol.2020200905&#xA;&#xA; (2020)." href="#ref-CR24" id="ref-link-section-d21123127e539_2">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Shi, F. et al. Large-scale screening of covid-19 from community acquired pneumonia using infection size-aware classification. &#xA;arXiv:2003.09860&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR25" id="ref-link-section-d21123127e542">25</a></sup>. However, to the best of the authors’ knowledge at the time of the initial release of the proposed COVID-Net, most of the developed AI systems proposed in research literature have been closed source and unavailable to the research community to build upon for deeper understanding and extension of these systems. Furthermore, most of these systems are unavailable for public access and use. There has been significant recent efforts to push for open access and open source AI solutions for radiography-driven COVID-19 case detection<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Cohen, J. P., Morrison, P., &amp; Dao, L. COVID-19 image data collection. &#xA;arXiv:2003.11597&#xA;&#xA; (2020)." href="#ref-CR16" id="ref-link-section-d21123127e546">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Chung, A. Figure 1 COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Figure1-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="#ref-CR17" id="ref-link-section-d21123127e546_1">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Chung, A. Actualmed COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Actualmed-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR18" id="ref-link-section-d21123127e549">18</a></sup>, with an exemplary effort being the open source COVID-19 Image Data Collection, an effort by Cohen et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Cohen, J. P., Morrison, P., &amp; Dao, L. COVID-19 image data collection. &#xA;arXiv:2003.11597&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR16" id="ref-link-section-d21123127e553">16</a></sup> to build a dataset consisting of COVID-19 cases (as well as severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS) cases) with annotated CXR and CT images, so that the research community and citizen data scientists can leverage the dataset to explore and build AI systems for COVID-19 detection.Since the time of the initial public release of the proposed COVIDx dataset and the proposed COVID-Net, a number of studies have been conducted in the area of COVID-19 detection using CXR images<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Li, X., Li, C., &amp; Zhu, D. Covid-mobilexpert: On-device covid-19 screening using snapshots of chest x-ray. &#xA;arXiv:2004.03042&#xA;&#xA; (2020)." href="#ref-CR26" id="ref-link-section-d21123127e557">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Minaee, S., Kafieh, R., Sonka, M., Yazdani, S., &amp; Soufi, G. J. Deep-covid: predicting covid-19 from chest x-ray images using deep transfer learning. &#xA;arXiv:2004.09363&#xA;&#xA; (2020)." href="#ref-CR27" id="ref-link-section-d21123127e557_1">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Afshar, P. et al. Covid-caps: a capsule network-based framework for identification of covid-19 cases from x-ray images. &#xA;arXiv:2004.02696&#xA;&#xA; (2020)." href="#ref-CR28" id="ref-link-section-d21123127e557_2">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Luz, E. et al. Towards an effective and efficient deep learning model for covid-19 patterns detection in x-ray images. &#xA;arXiv:2004.05717&#xA;&#xA; (2020)." href="#ref-CR29" id="ref-link-section-d21123127e557_3">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Khobahi, S., Agarwal, C., &amp; Soltanalian, M. Coronet: a deep network architecture for semi-supervised task-based identification of covid-19 from chest x-ray images. medRxiv. &#xA;https://doi.org/10.1101/2020.04.14.20065722&#xA;&#xA; (2020)." href="#ref-CR30" id="ref-link-section-d21123127e557_4">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ucar, F., &amp; Korkmaz, D. COVIDiagnosis-net: deep bayes-squeezenet based diagnosis of the coronavirus disease 2019 (COVID-19) from x-ray images. Med. Hypotheses. &#xA;https://doi.org/10.1016/j.mehy.2020.109761&#xA;&#xA; (2020)." href="#ref-CR31" id="ref-link-section-d21123127e557_5">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Tartaglione, E., Barbano, C. A., Berzovini, C., Calandri, M., &amp; Grangetto, M. Unveiling covid-19 from chest x-ray with deep learning: a hurdles race with small data. &#xA;arXiv:2004.05405&#xA;&#xA; (2020)." href="#ref-CR32" id="ref-link-section-d21123127e557_6">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yeh, C.-F. et al. A cascaded learning strategy for robust covid-19 pneumonia chest x-ray screening. &#xA;arXiv:2004.12786&#xA;&#xA; (2020)." href="#ref-CR33" id="ref-link-section-d21123127e557_7">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Zhang, Y. et al. Covid-da: deep domain adaptation from typical pneumonia to covid-19. &#xA;arXiv:2005.01577&#xA;&#xA; (2020)." href="#ref-CR34" id="ref-link-section-d21123127e557_8">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Karim, M. R. et al. Deepcovidexplainer: explainable covid-19 predictions based on chest x-ray images (2020)." href="#ref-CR35" id="ref-link-section-d21123127e557_9">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Apostolopoulos, I. D., &amp; Mpesiana, T. A. Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks. Phys. Eng. Sci. Med. 43, 635–640. &#xA;https://doi.org/10.1007/s13246-020-00865-4&#xA;&#xA; (2020)." href="#ref-CR36" id="ref-link-section-d21123127e557_10">36</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Farooq, M., &amp; Hafeez, A. Covid-resnet: a deep learning framework for screening of covid19 from radiographs (2020)." href="#ref-CR37" id="ref-link-section-d21123127e557_11">37</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Majeed, T., Rashid, R., Ali, D., &amp; Asaad, A. Covid-19 detection using cnn transfer learning from x-ray images. medRxiv (2020)." href="/articles/s41598-020-76550-z#ref-CR38" id="ref-link-section-d21123127e560">38</a></sup>, several of which have leveraged variants of the COVIDx dataset or COVID-Net to conduct such studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Afshar, P. et al. Covid-caps: a capsule network-based framework for identification of covid-19 cases from x-ray images. &#xA;arXiv:2004.02696&#xA;&#xA; (2020)." href="#ref-CR28" id="ref-link-section-d21123127e565">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Luz, E. et al. Towards an effective and efficient deep learning model for covid-19 patterns detection in x-ray images. &#xA;arXiv:2004.05717&#xA;&#xA; (2020)." href="#ref-CR29" id="ref-link-section-d21123127e565_1">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Khobahi, S., Agarwal, C., &amp; Soltanalian, M. Coronet: a deep network architecture for semi-supervised task-based identification of covid-19 from chest x-ray images. medRxiv. &#xA;https://doi.org/10.1101/2020.04.14.20065722&#xA;&#xA; (2020)." href="#ref-CR30" id="ref-link-section-d21123127e565_2">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ucar, F., &amp; Korkmaz, D. COVIDiagnosis-net: deep bayes-squeezenet based diagnosis of the coronavirus disease 2019 (COVID-19) from x-ray images. Med. Hypotheses. &#xA;https://doi.org/10.1016/j.mehy.2020.109761&#xA;&#xA; (2020)." href="#ref-CR31" id="ref-link-section-d21123127e565_3">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Tartaglione, E., Barbano, C. A., Berzovini, C., Calandri, M., &amp; Grangetto, M. Unveiling covid-19 from chest x-ray with deep learning: a hurdles race with small data. &#xA;arXiv:2004.05405&#xA;&#xA; (2020)." href="#ref-CR32" id="ref-link-section-d21123127e565_4">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yeh, C.-F. et al. A cascaded learning strategy for robust covid-19 pneumonia chest x-ray screening. &#xA;arXiv:2004.12786&#xA;&#xA; (2020)." href="#ref-CR33" id="ref-link-section-d21123127e565_5">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Zhang, Y. et al. Covid-da: deep domain adaptation from typical pneumonia to covid-19. &#xA;arXiv:2005.01577&#xA;&#xA; (2020)." href="#ref-CR34" id="ref-link-section-d21123127e565_6">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Karim, M. R. et al. Deepcovidexplainer: explainable covid-19 predictions based on chest x-ray images (2020)." href="/articles/s41598-020-76550-z#ref-CR35" id="ref-link-section-d21123127e568">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Farooq, M., &amp; Hafeez, A. Covid-resnet: a deep learning framework for screening of covid19 from radiographs (2020)." href="/articles/s41598-020-76550-z#ref-CR37" id="ref-link-section-d21123127e571">37</a></sup>. Based on a comprehensive survey of the studies in research literature, they have focused primarily on the exploration of deep learning, in particular deep convolutional neural networks, given the significant successes and state-of-the-art achieved in a variety of computer vision tasks. It is important to note that the proposed COVID-Net and corresponding COVIDx dataset continues to evolve as new patient cases are continuously added and are made available publicly on a regular basis, and thus this study represents a snapshot of the current state of COVID-Net and COVIDx.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Methods</h2><div class="c-article-section__content" id="Sec3-content">
                <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Figure 2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig2_HTML.jpg?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig2_HTML.jpg" alt="figure 2" loading="lazy" width="685" height="1095"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Example CXR images from the COVIDx dataset, which comprises of 13,975 CXR images across 13,870 patient cases from five open access data repositories: (1) COVID-19 Image Data Collection<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Cohen, J. P., Morrison, P., &amp; Dao, L. COVID-19 image data collection. &#xA;arXiv:2003.11597&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR16" id="ref-link-section-d21123127e593">16</a></sup>, (2) Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig1">1</a> COVID-19 Chest X-Ray Dataset Initiative<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Chung, A. Figure 1 COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Figure1-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR17" id="ref-link-section-d21123127e600">17</a></sup> (established with Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig1">1</a>), (3) RSNA Pneumonia Detection challenge dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Radiological Society of North America. RSNA pneumonia detection challenge. https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data (2019)." href="/articles/s41598-020-76550-z#ref-CR20" id="ref-link-section-d21123127e607">20</a></sup>, (4) ActualMed COVID-19 Chest X-Ray Dataset Initiative<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Chung, A. Actualmed COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Actualmed-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR18" id="ref-link-section-d21123127e612">18</a></sup> (established with ActualMed), and (5) COVID-19 radiography database<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Radiological Society of North America. COVID-19 radiography database. &#xA;https://www.kaggle.com/tawsifurrahman/covid19-radiography-database&#xA;&#xA; (2019)." href="/articles/s41598-020-76550-z#ref-CR19" id="ref-link-section-d21123127e616">19</a></sup>.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <p>In this study, a human-machine collaborative design strategy is leveraged to create COVID-Net, where human-driven principled network design prototyping is combined with machine-driven design exploration to produce a network architecture tailored for the detection of COVID-19 cases from CXR images. An open access benchmark dataset called COVIDx is also created to facilitate for training and evaluating COVID-Net. Here, we will discuss in detail the process of creating the COVIDx dataset, the architecture design methodology behind the proposed COVID-Net, the resulting network architecture, the implementation details in creating COVID-Net, and the strategy for auditing COVID-Net via explainability.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Figure 3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="240"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>CXR images distribution for each infection type of the COVIDx dataset (normal means no infection). (Left bar) number of training images, (right bar) number of test images.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Figure 4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="240"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Number of patient cases for each infection type of the COVIDx dataset (normal means no infection). (Left bar) number of patient cases for training, (right bar) number of patient cases for testing.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec4">COVIDx dataset</h3><p>The dataset used to train and evaluate the proposed COVID-Net, which we will refer to as COVIDx, is comprised of a total of 13,975 CXR images across 13,870 patient cases. To the best of the authors’ knowledge, the proposed COVIDx dataset is the largest open access benchmark dataset in terms of the number of COVID-19 positive patient cases. To generate the COVIDx dataset, we combined and modified five different publicly available data repositories: (1) COVID-19 Image Data Collection<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Cohen, J. P., Morrison, P., &amp; Dao, L. COVID-19 image data collection. &#xA;arXiv:2003.11597&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR16" id="ref-link-section-d21123127e673">16</a></sup>, (2) Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig1">1</a> COVID-19 Chest X-ray Dataset Initiative<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Chung, A. Figure 1 COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Figure1-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR17" id="ref-link-section-d21123127e680">17</a></sup>, established in collaboration with Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig1">1</a>, (3) ActualMed COVID-19 Chest X-ray Dataset Initiative<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Chung, A. Actualmed COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Actualmed-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR18" id="ref-link-section-d21123127e687">18</a></sup>, established in collaboration with ActualMed, (4) RSNA Pneumonia Detection Challenge dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Radiological Society of North America. RSNA pneumonia detection challenge. https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data (2019)." href="/articles/s41598-020-76550-z#ref-CR20" id="ref-link-section-d21123127e692">20</a></sup>, which used publicly available CXR data from<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Wang, X. et al. Chestx-ray8: hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. In 2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR), 3462–3471 (2017)." href="/articles/s41598-020-76550-z#ref-CR39" id="ref-link-section-d21123127e696">39</a></sup>, and (5) COVID-19 radiography database<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Radiological Society of North America. COVID-19 radiography database. &#xA;https://www.kaggle.com/tawsifurrahman/covid19-radiography-database&#xA;&#xA; (2019)." href="/articles/s41598-020-76550-z#ref-CR19" id="ref-link-section-d21123127e700">19</a></sup>. Example CXR images from the COVIDx dataset are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig2">2</a> in illustrate the diversity of patient cases in the dataset. The choice of these five datasets from which to create COVIDx is guided by the fact that all five of the datasets are open source and fully accessible to the research community and the general public, and as datasets grow we will continue to grow COVIDx accordingly.</p><p>More specifically, we combined and modified the five data repositories to create the COVIDx dataset by leveraging the following types of patient cases from each of the data repositories:</p><ul class="u-list-style-bullet">
<li>
<p>Non-COVID19 pneumonia patient cases and COVID-19 patient cases from the COVID-19 Image Data Collection<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Cohen, J. P., Morrison, P., &amp; Dao, L. COVID-19 image data collection. &#xA;arXiv:2003.11597&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR16" id="ref-link-section-d21123127e716">16</a></sup></p>
</li>
<li>
<p>COVID-19 patient cases from the Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig1">1</a> COVID-19 Chest X-ray Dataset Initiative<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Chung, A. Figure 1 COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Figure1-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR17" id="ref-link-section-d21123127e728">17</a></sup>,</p>
</li>
<li>
<p>COVID-19 patient cases from the ActualMed COVID-19 Chest X-ray Dataset Initiative<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Chung, A. Actualmed COVID-19 chest x-ray data initiative. &#xA;https://github.com/agchung/Actualmed-COVID-chestxray-dataset&#xA;&#xA; (2020)." href="/articles/s41598-020-76550-z#ref-CR18" id="ref-link-section-d21123127e738">18</a></sup></p>
</li>
<li>
<p>Patient cases who have no pneumonia (i.e., normal) and non-COVID19 pneumonia patient cases from RSNA Pneumonia Detection Challenge dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Radiological Society of North America. RSNA pneumonia detection challenge. https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data (2019)." href="/articles/s41598-020-76550-z#ref-CR20" id="ref-link-section-d21123127e747">20</a></sup></p>
</li>
<li>
<p>COVID-19 patient cases from COVID-19 radiography database<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Radiological Society of North America. COVID-19 radiography database. &#xA;https://www.kaggle.com/tawsifurrahman/covid19-radiography-database&#xA;&#xA; (2019)." href="/articles/s41598-020-76550-z#ref-CR19" id="ref-link-section-d21123127e756">19</a></sup></p>
</li>
</ul><p>The distribution of images and patient cases amongst the different infection types shown in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig3">3</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig4">4</a>, respectively. The most noticeable trend is the limited amount of COVID-19 infection cases and associated CXR images, which reflects the scarcity of COVID-19 case data available in the public domain but also highlights the need to obtain more COVID-19 data as more case data becomes available to improve the dataset. More specifically, the COVIDx dataset contains 358 CXR images from 266 COVID-19 patient cases. For CXR images with no pneumonia and non-COVID19 pneumonia, there are significantly more patient cases and corresponding CXR images. More specifically, there are a total of 8,066 patient cases who have no pneumonia (i.e., normal) and 5,538 patient cases who have non-COVID19 pneumonia. Dataset generation scripts for constructing the COVIDx dataset is available publicly for open access at <a href="https://github.com/lindawangg/COVID-Net">https://github.com/lindawangg/COVID-Net</a>.</p><h3 class="c-article__sub-heading" id="Sec5">Principled network design prototyping</h3><p>The first stage of the human-machine collaborative design strategy employed to create the proposed COVID-Net is a principled network design prototyping stage, where an initial network design prototype is constructed based on human-driven design principles and best practices. More specifically in this study, we leveraged residual architecture design principles<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="He, K., Zhang, X., Ren, S., &amp; Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 770–778 (2016)." href="/articles/s41598-020-76550-z#ref-CR40" id="ref-link-section-d21123127e783">40</a></sup> as they have been shown time and again to enable reliable neural network architectures that are easier to train to high performance, and enables deeper architectures to be built successfully.</p><p>In this study, we construct the initial network design prototype to make one of the following three predictions: (a) no infection (normal), (b) non-COVID19 infection (e.g., viral, bacterial, etc.), and c) COVID-19 viral infection (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig1">1</a> for example CXR images of non-COVID19 and COVID-19 infections). The rationale for choosing these three possible predictions is that it can aid clinicians to better decide not only who should be prioritized for RT-PCR testing for COVID-19 case confirmation, but also which treatment strategy to employ depending on the cause of infection, since COVID-19 and non-COVID19 infections require different treatment plans.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Figure 5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="363"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>COVID-Net architecture. High architectural diversity and selective long-range connectivity can be observed as it is tailored for COVID-19 case detection from CXR images. The heavy use of a projection-expansion-projection design pattern in the COVID-Net architecture can also be observed, which provides enhanced representational capacity while maintaining computational efficiency.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec6">Machine-driven design exploration</h3><p>The second stage of the human-machine collaborative design strategy employed to create the proposed COVID-Net is a machine-driven design exploration stage. More specifically, at this stage, the initial network design prototype, data, along with human specific design requirements, act as a guide to a design exploration strategy to learn and identify the optimal macroarchitecture and microarchitecture designs with which to construct the final tailor-made deep neural network architecture. Such a machine-driven design exploration stage enables much greater granularity and much greater flexibility than is possible through manual human-driven architecture design, while still ensuring that the resulting deep neural network architecture satisfies domain-specific operational requirements. This is especially important for the design of COVID-Net, where sensitivity to COVID-19 cases is significant to limit the number of missed COVID-19 cases as much as possible.</p><p>In this study, we leverage generative synthesis<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Wong, A., Shafiee, M. J., Chwyl, B., &amp; Li, F. Ferminets: learning generative machines to generate efficient neural networks via generative synthesis. arXiv preprint &#xA;arXiv:1809.05989&#xA;&#xA; (2018)." href="/articles/s41598-020-76550-z#ref-CR41" id="ref-link-section-d21123127e822">41</a></sup> as the machine-driven design exploration strategy, which is based on an intricate interplay between a generator-inquisitor pair that work in tandem to garner insights and learn to generate deep neural network architectures that best satisfies human specified design requirements. More specifically, the following human specified design requirements were employed in this study to enable the generative synthesis process to learn and identify the optimal macroarchitecture and microarchitecture designs for the final COVID-Net network architecture: (1) COVID-19 sensitivity <span class="mathjax-tex">\(\ge \)</span> 80%, and (2) COVID-19 positive predictive value (PPV) <span class="mathjax-tex">\(\ge \)</span> 80%. By employing the aforementioned human specified design requirements, the machine-driven design exploration can be conducted in a way that ensures that the resulting COVID-Net is able to detect COVID-19 positive cases while limiting the number of false positive COVID-19 detections to avoid overwhelming clinical sites with unnecessary burden.</p><h3 class="c-article__sub-heading" id="Sec7">COVID-Net network architecture</h3><p>The proposed COVID-Net network architecture is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig5">5</a>, and available publicly for open access at <a href="https://github.com/lindawangg/COVID-Net">https://github.com/lindawangg/COVID-Net</a>. A number of interesting observations can be made with regards to the COVID-Net network arhchitecture design that was created via a human-machine collaborative design strategy.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec8">Lightweight design pattern</h4><p>It can be observed that the COVID-Net network architecture makes heavy use of a lightweight residual projection-expansion-projection-extension (PEPX) design pattern, which consists of:</p><ul class="u-list-style-bullet">
<li>
<p><b>First-stage projection</b> 1<span class="mathjax-tex">\(\times \)</span>1 convolutions for projecting input features to a lower dimension,</p>
</li>
<li>
<p><b>Expansion:</b> 1<span class="mathjax-tex">\(\times \)</span>1 convolutions for expanding features to a higher dimension that is different than that of the input features,</p>
</li>
<li>
<p><b>Depth-wise representation</b> efficient 3<span class="mathjax-tex">\(\times \)</span>3 depth-wise convolutions for learning spatial characteristics to minimize computational complexity while preserving representational capacity,</p>
</li>
<li>
<p><b>Second-stage projection</b> 1<span class="mathjax-tex">\(\times \)</span>1 convolutions for projecting features back to a lower dimension, and</p>
</li>
<li>
<p><b>Extension:</b> 1<span class="mathjax-tex">\(\times \)</span>1 convolutions that finally extend channel dimensionality to a higher dimension to produce the final features.</p>
</li>
</ul><p>Such a customized lightweight design pattern, which is discovered by the machine-driven design exploration strategy and not previously introduced in literature to the best of the authors’ knowledge, enables enhanced representational capacity while maintaining reduced computational complexity.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec9">Selective long-range connectivity</h4><p>It can also be observed that the COVID-Net architecture possesses selective long-range connectivity at various areas of the network architecture. The use of long-range connectivity has been found previously to enable improved representational capacity as well as make it easier to train, with an exemplary network architecture leveraging long-range connectivity being densely-connected deep neural network architectures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Huang, G., Liu, Z., &amp; Weinberger, K. Q. Densely connected convolutional networks. arXiv preprint &#xA;arXiv:1608.06993&#xA;&#xA; (2016)." href="/articles/s41598-020-76550-z#ref-CR42" id="ref-link-section-d21123127e1000">42</a></sup>. However, a disadvantage of leveraging a large number of long-range connections as done in densely-connected deep neural network architectures is a noticeable increase in computational complexity as well as memory overhead. To alleviate this, it can be observed that the COVID-Net network architecture only leverages long range connections in a sparing manner where necessary, as exhibited by the existence of four densely connected <span class="mathjax-tex">\(1\times 1\)</span> convolution layers that act as central hubs of long-range connectivity for earlier layers to connected to much later layers in the network architecture. As such, the COVID-Net network architecture is able to achieve high representational capacity and improve ease of training while still maintaining computational and memory efficiency. This also highlights the advantages of a machine-driven design strategy for identifying the optimal connectivity within a deep neural network architecture, tailored in this case specifically for the task of COVID-19 detection based on CXR images.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec10">Architectural diversity</h4><p>Finally, it can be observed that there is considerable architectural diversity in the COVID-Net architecture. In particular, the COVID-Net network architecture is comprised of a heterogeneous mix of convolution layers with a diversity of kernel sizes (ranging from <span class="mathjax-tex">\(7\times 7\)</span> to <span class="mathjax-tex">\(1\times 1\)</span>), and grouping configurations (ranging from ungrouped to depth-wise). The considerable architectural diversity exhibited by the COVID-Net architecture further reinforces the fact that the machine-driven design exploration strategy has tailored the network architecture at a very fine level of granularity for COVID-19 case detection from CXR images to achieve strong representational capacity for a specific task.</p><h3 class="c-article__sub-heading" id="Sec11">Implementation details</h3><p>The proposed COVID-Net was pretrained on the ImageNet<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Deng, J. et al. Imagenet: a large-scale hierarchical image database. In 2009 IEEE Conference on Computer Vision and Pattern Recognition 248–255 (IEEE, 2009)." href="/articles/s41598-020-76550-z#ref-CR43" id="ref-link-section-d21123127e1084">43</a></sup> dataset and then trained on the COVIDx dataset using the Adam optimizer using a learning rate policy where the learning rate decreases when learning stagnates for a period of time (i.e., ’patience’). The following hyperparameters were used for training: learning rate <span class="mathjax-tex">\(=\)</span> 2e−4, number of epochs <span class="mathjax-tex">\(=\)</span> 22, batch size <span class="mathjax-tex">\(=\)</span> 64, factor <span class="mathjax-tex">\(=\)</span> 0.7, patience <span class="mathjax-tex">\(=\)</span> 5. Finally, we introduce a batch re-balancing strategy to promote better distribution of each infection type at a batch level. The initial COVID-Net prototype was built and evaluated using the Keras deep learning library with a TensorFlow backend. The proposed COVID-Net architecture was built using generative synthesis<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Wong, A., Shafiee, M. J., Chwyl, B., &amp; Li, F. Ferminets: learning generative machines to generate efficient neural networks via generative synthesis. arXiv preprint &#xA;arXiv:1809.05989&#xA;&#xA; (2018)." href="/articles/s41598-020-76550-z#ref-CR41" id="ref-link-section-d21123127e1159">41</a></sup>, as described in “<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41598-020-76550-z#Sec6">Machine-driven design exploration</a>”.</p><h3 class="c-article__sub-heading" id="Sec12">COVID-Net auditing via explainability</h3><p>Due to the mission-critical nature of clinical applications such as COVID-19 detection that can affect the health and well-being of patients, it is important to design deep neural network architectures such as COVID-Net with responsibility and transparency in mind. Therefore, in this study, we perform an explainability-driven audit on COVID-Net to validate that it is making detection decisions based on relevant information rather than improper information (e.g., erroneous visual indicators outside of the body, embedded markup symbols, imaging artifacts, etc.). More specifically, we audit COVID-Net via an qualitative analysis to study the critical factors leveraged by COVID-Net in making detection decisions. Here, we leveraged GSInquire<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Lin, Z. Q. et al. Do explanations reflect decisions? A machine-centric strategy to quantify the performance of explainability algorithms. arXiv preprint &#xA;arXiv:1910.07387&#xA;&#xA; (2019)." href="/articles/s41598-020-76550-z#ref-CR44" id="ref-link-section-d21123127e1174">44</a></sup>, an explainability method that is a critical aspect of the generative synthesis strategy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Wong, A., Shafiee, M. J., Chwyl, B., &amp; Li, F. Ferminets: learning generative machines to generate efficient neural networks via generative synthesis. arXiv preprint &#xA;arXiv:1809.05989&#xA;&#xA; (2018)." href="/articles/s41598-020-76550-z#ref-CR41" id="ref-link-section-d21123127e1178">41</a></sup> leveraged in the machine-driven exploration strategy used to create the proposed COVID-Net network architecture. A brief summary of the GSInquire is provided as follows.</p><p>GSInquire revolves around the notion of an inquisitor <span class="mathjax-tex">\(\mathcal {I}\)</span> within a generator-inquisitor pair <span class="mathjax-tex">\(\left\{ \mathcal {G},\mathcal {I}\right\} \)</span>, with <span class="mathjax-tex">\(\mathcal {G}\)</span> denoting a generator, that work in tandem to obtain improved insights about deep neural networks as well as learn to generate networks. The insights gained by <span class="mathjax-tex">\(\mathcal {I}\)</span> can not only be used to improve <span class="mathjax-tex">\(\mathcal {G}\)</span> to generate better networks, but also be subsequently transformed into an interpretation of decisions made by a network. More specifically, a deep neural network is defined as a graph <span class="mathjax-tex">\(N=\left\{ V,E\right\} \)</span>, comprising a set <i>V</i> of vertices <span class="mathjax-tex">\(v \in V\)</span> and a set <i>E</i> of edges <span class="mathjax-tex">\(e \in E\)</span> that form the network. A generator function is defined as <span class="mathjax-tex">\(\mathcal {G}(s;\theta _\mathcal {G})\)</span> parameterized by <span class="mathjax-tex">\(\theta _\mathcal {G}\)</span> that, given a seed <span class="mathjax-tex">\(s \in S\)</span>, generates a deep neural network <span class="mathjax-tex">\(N_s=\left\{ V_s,E_s\right\} \)</span> (i.e., <span class="mathjax-tex">\(N_s = \mathcal {G}(s)\)</span>), where <i>S</i> is the set of possible seeds. Finally, an inquisitor function is defined as <span class="mathjax-tex">\(\mathcal {I}(\mathcal {G};\theta _\mathcal {I})\)</span> parameterized by <span class="mathjax-tex">\(\theta _\mathcal {I}\)</span> that, given a generator <span class="mathjax-tex">\(\mathcal {G}\)</span>, produces a set of parameter changes <span class="mathjax-tex">\(\Delta \theta _\mathcal {G}\)</span> (i.e., <span class="mathjax-tex">\(\Delta \theta _\mathcal {G} = \mathcal {I}(\mathcal {G})\)</span>).</p><p>In the scenario where the underlying goal is to obtain an interpretation <i>z</i> of a decision made by a reference network <span class="mathjax-tex">\(N_{ref}\)</span> (in this case, COVID-Net) for an input signal <i>x</i> (in this case, a CXR image), both <span class="mathjax-tex">\(\theta _{\mathcal {G}}\)</span> and <span class="mathjax-tex">\(\theta _{\mathcal {I}}\)</span> are initialized based on <span class="mathjax-tex">\(\left\{ V_{ref},E_{ref}\right\} \)</span>, a universal performance function <span class="mathjax-tex">\(\mathcal {U}\)</span> (e.g.,<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Wong, A. Netscore: towards universal metrics for large-scale performance analysis of deep neural networks for practical usage. CoRR. arXiv preprint &#xA;arXiv:abs/1806.05512&#xA;&#xA; (2018)." href="/articles/s41598-020-76550-z#ref-CR45" id="ref-link-section-d21123127e1778">45</a></sup>), and an indicator function <span class="mathjax-tex">\(1_r(\cdot )\)</span> s.t. <span class="mathjax-tex">\(\left\{ V_{s},E_{s}\right\} =\left\{ V_{ref},E_{ref}\right\} \)</span> to ensure interpretation consistency for <span class="mathjax-tex">\(N_{ref}\)</span>. Given the generated <span class="mathjax-tex">\(N_s = \mathcal {G}(s)\)</span>, the inquisitor <span class="mathjax-tex">\(\mathcal {I}\)</span> probes <span class="mathjax-tex">\(\left\{ \mathcal {V}_{s},\mathcal {E}_{s}\right\} \)</span>, where <span class="mathjax-tex">\(\mathcal {V}_{s} \subseteq V_{s}\)</span> and <span class="mathjax-tex">\(\mathcal {E}_{s} \subseteq E_{s}\)</span>, with the targeted stimulus signal as <i>x</i> and the corresponding set <span class="mathjax-tex">\(Y_{\mathcal {G}\left( s\right) }\)</span> of reactionary response signals <span class="mathjax-tex">\(y \in Y_{\mathcal {G}\left( s\right) }\)</span> are observed. The parameters <span class="mathjax-tex">\(\theta _{\mathcal {I}}\)</span> are updated based on <span class="mathjax-tex">\(Y_{\mathcal {G}\left( s\right) }\)</span>, <span class="mathjax-tex">\(\mathcal {U}(\mathcal {G}\left( s\right) )\)</span>, and <span class="mathjax-tex">\(1_r(\mathcal {G}\left( s\right) )\)</span>, leading to the inquisitor <span class="mathjax-tex">\(\mathcal {I}\)</span> learning from the insights that are derived from <span class="mathjax-tex">\(Y_{\mathcal {G}\left( s\right) }\)</span>. Following the update of <span class="mathjax-tex">\(\theta _{\mathcal {I}}\)</span>, set of parameters <span class="mathjax-tex">\(\Delta \theta _\mathcal {G} = \mathcal {I}(\mathcal {G})\)</span> is generated which can not only be leveraged to update <span class="mathjax-tex">\(\theta _{\mathcal {G}}\)</span> to improve <span class="mathjax-tex">\(\mathcal {G}\)</span>, but can also be transformed and projected into same subspace as <i>x</i> via a transformation <span class="mathjax-tex">\(\mathcal {T}(\Delta \theta _{\mathcal {G}\left( s\right) })\)</span> to produce an interpretation <span class="mathjax-tex">\(z(x;N_{ref})\)</span>. In this study, the produced interpretation indicates the critical factors leveraged by COVID-Net in making a detection decision based on a CXR image, and can be visualized spatially relative to the CXR image for greater insights into whether COVID-Net is making the right decisions for the right reasons and validate its performance.</p><h3 class="c-article__sub-heading" id="Sec20">Ethics approval</h3><p>The study has received ethics clearance from the University of Waterloo (42235).</p></div></div></section><section data-title="Experimental results"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Experimental results</h2><div class="c-article-section__content" id="Sec13-content"><p>To evaluate the efficacy of the proposed COVID-Net, we perform both quantitative and qualitative analysis to get a better understanding of its detection performance and decision-making behaviour.</p><h3 class="c-article__sub-heading" id="Sec14">Data pre-processing details</h3><p>The COVIDx dataset was used to train all tested deep neural network architectures. As a pre-processing step, the chest CXR images were cropped (top 8% of the image) prior to training in order to mitigate commonly-found embedded textual information in the CXR images. Furthermore, to train the tested deep neural network architectures, data augmentation was leveraged with the following augmentation types: translation (± 10% in <i>x</i> and <i>y</i> directions), rotation (± 10<span class="mathjax-tex">\(^{\circ }\)</span>), horizontal flip, zoom (± 15%), and intensity shift (± 10%). Data pre-processing scripts are available publicly for open access at <a href="https://github.com/lindawangg/COVID-Net">https://github.com/lindawangg/COVID-Net</a>.</p><h3 class="c-article__sub-heading" id="Sec15">Quantitative analysis</h3><p>To investigate the proposed COVID-Net in a quantitative manner, we computed the test accuracy, as well as sensitivity and positive predictive value (PPV) for each infection type, on the aforementioned COVIDx dataset. The test accuracy, along with the architectural complexity (in terms of number of parameters) and computational complexity (in terms of number of multiply-accumulation (MAC) operations) are shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-020-76550-z#Tab1">1</a>. It can be observed that COVID-Net achieves good accuracy by achieving 93.3% test accuracy, thus highlighting the efficacy of leveraging a human-machine collaborative design strategy for creating highly-customized deep neural network architectures in an accelerated manner, tailored around task, data, and operational requirements. This is especially important for scenarios such as disease detection, where new cases and new data are collected continuously and the ability to rapidly generate new deep neural network architectures tailored to the ever-evolving knowledge base over time is highly desired.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Performance of tested deep neural network architectures on COVIDx test dataset.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41598-020-76550-z/tables/1" aria-label="Full size table 1"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Sensitivity for each infection type.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41598-020-76550-z/tables/2" aria-label="Full size table 2"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Positive predictive value (PPV) for each infection type.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41598-020-76550-z/tables/3" aria-label="Full size table 3"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Figure 6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig6_HTML.png?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="688"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Confusion matrix for COVID-Net on the COVIDx test dataset.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                  <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7" data-title="Figure 7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig7_HTML.jpg?as=webp"><img aria-describedby="Fig7" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-020-76550-z/MediaObjects/41598_2020_76550_Fig7_HTML.jpg" alt="figure 7" loading="lazy" width="685" height="230"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Example CXR images of COVID-19 cases from several different patients and their associated critical factors (highlighted in red) as identified by GSInquire<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Lin, Z. Q. et al. Do explanations reflect decisions? A machine-centric strategy to quantify the performance of explainability algorithms. arXiv preprint &#xA;arXiv:1910.07387&#xA;&#xA; (2019)." href="/articles/s41598-020-76550-z#ref-CR44" id="ref-link-section-d21123127e2982">44</a></sup>.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41598-020-76550-z/figures/7" data-track-dest="link:Figure7 Full size image" aria-label="Full size image figure 7" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Next, we take a deeper exploration into the current limitations of the proposed COVID-Net by studying the sensitivity and PPV for each infection type, which is shown in Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-020-76550-z#Tab2">2</a> and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-020-76550-z#Tab3">3</a>, respectively, and the confusion matrix in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig6">6</a>. A number of interesting observations can be made about how COVID-Net performs under the different scenarios. First, it can be observed that COVID-Net can achieve good sensitivity for COVID-19 cases (91.0% sensitivity), which is important since we want to limit the number of missed COVID-19 cases as much as possible. Second, it can be observed that COVID-Net achieves high PPV for COVID-19 cases (98.9% PPV), which indicates very few false positive COVID-19 detections (for example, as seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig6">6</a>, one patient with non-COVID19 infection was misidentified as having COVID-19 viral infections). This high PPV is important given that too many false positives would increase the burden for the healthcare system due to the need for additional PCR testing and additional care. Therefore, based on these results, it can be seen that while COVID-Net performs well as a whole in detecting COVID-19 cases from CXR images, there are several areas of improvement that can benefit from collecting additional data, as well as improving the underlying training methodology to generalize better across such scenarios.</p><h3 class="c-article__sub-heading" id="Sec16">Architecture comparisons</h3><p>We now take a deep exploration into the impact of architectural design choices made by generative synthesis during the machine-driven design exploration process on the resulting COVID-Net network architecture being able to achieve in terms of balance between computational efficiency and performance. It is important to note that, based on a thorough survey of all machine learning methods for COVID-19 detection using chest x-rays in research literature<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Li, X., Li, C., &amp; Zhu, D. Covid-mobilexpert: On-device covid-19 screening using snapshots of chest x-ray. &#xA;arXiv:2004.03042&#xA;&#xA; (2020)." href="#ref-CR26" id="ref-link-section-d21123127e3018">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Minaee, S., Kafieh, R., Sonka, M., Yazdani, S., &amp; Soufi, G. J. Deep-covid: predicting covid-19 from chest x-ray images using deep transfer learning. &#xA;arXiv:2004.09363&#xA;&#xA; (2020)." href="#ref-CR27" id="ref-link-section-d21123127e3018_1">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Afshar, P. et al. Covid-caps: a capsule network-based framework for identification of covid-19 cases from x-ray images. &#xA;arXiv:2004.02696&#xA;&#xA; (2020)." href="#ref-CR28" id="ref-link-section-d21123127e3018_2">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Luz, E. et al. Towards an effective and efficient deep learning model for covid-19 patterns detection in x-ray images. &#xA;arXiv:2004.05717&#xA;&#xA; (2020)." href="#ref-CR29" id="ref-link-section-d21123127e3018_3">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Khobahi, S., Agarwal, C., &amp; Soltanalian, M. Coronet: a deep network architecture for semi-supervised task-based identification of covid-19 from chest x-ray images. medRxiv. &#xA;https://doi.org/10.1101/2020.04.14.20065722&#xA;&#xA; (2020)." href="#ref-CR30" id="ref-link-section-d21123127e3018_4">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ucar, F., &amp; Korkmaz, D. COVIDiagnosis-net: deep bayes-squeezenet based diagnosis of the coronavirus disease 2019 (COVID-19) from x-ray images. Med. Hypotheses. &#xA;https://doi.org/10.1016/j.mehy.2020.109761&#xA;&#xA; (2020)." href="#ref-CR31" id="ref-link-section-d21123127e3018_5">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Tartaglione, E., Barbano, C. A., Berzovini, C., Calandri, M., &amp; Grangetto, M. Unveiling covid-19 from chest x-ray with deep learning: a hurdles race with small data. &#xA;arXiv:2004.05405&#xA;&#xA; (2020)." href="#ref-CR32" id="ref-link-section-d21123127e3018_6">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yeh, C.-F. et al. A cascaded learning strategy for robust covid-19 pneumonia chest x-ray screening. &#xA;arXiv:2004.12786&#xA;&#xA; (2020)." href="#ref-CR33" id="ref-link-section-d21123127e3018_7">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Zhang, Y. et al. Covid-da: deep domain adaptation from typical pneumonia to covid-19. &#xA;arXiv:2005.01577&#xA;&#xA; (2020)." href="#ref-CR34" id="ref-link-section-d21123127e3018_8">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Karim, M. R. et al. Deepcovidexplainer: explainable covid-19 predictions based on chest x-ray images (2020)." href="#ref-CR35" id="ref-link-section-d21123127e3018_9">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Apostolopoulos, I. D., &amp; Mpesiana, T. A. Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks. Phys. Eng. Sci. Med. 43, 635–640. &#xA;https://doi.org/10.1007/s13246-020-00865-4&#xA;&#xA; (2020)." href="#ref-CR36" id="ref-link-section-d21123127e3018_10">36</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Farooq, M., &amp; Hafeez, A. Covid-resnet: a deep learning framework for screening of covid19 from radiographs (2020)." href="/articles/s41598-020-76550-z#ref-CR37" id="ref-link-section-d21123127e3021">37</a></sup>, the machine learning methods leveraged in these studies have been deep learning approaches. As such, we have focused this study to quantitatively compare between different deep neural network architectures to study the impact on computational efficiency and performance.</p><p>In order to perform this analysis, we evaluated the performances of the following deep neural network architectures for comparative purposes:</p><ul class="u-list-style-bullet">
<li>
<p><b>VGG-19</b><sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Simonyan, K., &amp; Zisserman, A. Very deep convolutional networks for large-scale image recognition (2014)." href="/articles/s41598-020-76550-z#ref-CR46" id="ref-link-section-d21123127e3035">46</a></sup> A deep neural network architecture that does not leverage residual design principles, lightweight design patterns, and have very low architectural diversity.</p>
</li>
<li>
<p><b>ResNet-50</b><sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="He, K., Zhang, X., Ren, S., &amp; Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 770–778 (2016)." href="/articles/s41598-020-76550-z#ref-CR40" id="ref-link-section-d21123127e3046">40</a></sup> A deep neural network architecture that leverages residual design principles and lightweight design patterns (e.g., bottleneck design patterns) and have moderate architectural diversity, but does not leverage lightweight PEPX design patterns and selective long-range connectivity. This architecture was leveraged in a study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Farooq, M., &amp; Hafeez, A. Covid-resnet: a deep learning framework for screening of covid19 from radiographs (2020)." href="/articles/s41598-020-76550-z#ref-CR37" id="ref-link-section-d21123127e3050">37</a></sup> on an early variant of COVIDx to good effect. As such, a quantitative performance evaluation of this architecture enables a more direct comparison with<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Farooq, M., &amp; Hafeez, A. Covid-resnet: a deep learning framework for screening of covid19 from radiographs (2020)." href="/articles/s41598-020-76550-z#ref-CR37" id="ref-link-section-d21123127e3054">37</a></sup> and highlight the benefits of the uniqueness of the COVID-Net architecture.</p>
</li>
</ul><p>The choice of these two deep neural network architectures is based on the fact that they do not possess the key defining traits of COVID-Net, which are lightweight PEPX design patterns, selective long-range connectivity, and high architectural diversity, thus allowing for a better understanding of the benefits of the unique traits of COVID-Net.</p><p>It can be observed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-020-76550-z#Tab1">1</a> that COVID-Net had noticeably lower architectural complexity and computational complexity than the VGG-19 and ResNet-50 architectures. For example, the proposed COVID-Net requires <span class="mathjax-tex">\(\sim \)</span>12<span class="mathjax-tex">\(\times \)</span> fewer MAC operations than the VGG-19 architecture and <span class="mathjax-tex">\(\sim \)</span>2.37<span class="mathjax-tex">\(\times \)</span> fewer MAC operations than the ReNset-50 architecture, respectively. This illustrates the benefits of the lightweight PEPX design patterns within the COVID-Net architecture compared to not using lightweight design patterns (e.g., VGG-19) and using other types of lightweight design patterns (e.g., bottleneck patterns as used in ResNet-50). It can also be observed in Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-020-76550-z#Tab1">1</a>, <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-020-76550-z#Tab2">2</a>, and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-020-76550-z#Tab3">3</a> that COVID-Net achieved noticeably higher test accuracy and COVID-19 sensitivity than the VGG-19 and ResNet-50 network architectures. For example, COVID-19 sensitivity of COVID-Net is &gt; 32% higher than VGG-19 and 8% higher than ResNet-50. These results illustrates the benefits of the selective long range connectivity and high architectural diversity found in COVID-Net, which enables strong representational capacity that is tailored for the task as well as making it easier to train. Therefore, these results demonstrate the benefits of the different design choices made during the machine-driven design exploration stage of the human-machine collaborative design strategy employed to create COVID-Net.</p><h3 class="c-article__sub-heading" id="Sec17">Qualitative analysis</h3><p>As mentioned earlier, we performed an audit on the proposed COVID-Net to gain better insights into how COVID-Net makes decisions, and validate whether it is making detection decisions based on relevant information rather than erroneous information that bias decisions based on irrelevant visual indicators. The critical factors identified by GSInquire<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Lin, Z. Q. et al. Do explanations reflect decisions? A machine-centric strategy to quantify the performance of explainability algorithms. arXiv preprint &#xA;arXiv:1910.07387&#xA;&#xA; (2019)." href="/articles/s41598-020-76550-z#ref-CR44" id="ref-link-section-d21123127e3142">44</a></sup> in several example CXR images of COVID-19 cases are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig7">7</a>. It can be observed that, based on the interpretation produced by GSInquire, the proposed COVID-Net primarily leverages areas in the lungs in the CXR images as the main critical factors in determining whether a CXR image is of a patient with a SARS-CoV-2 viral infection, as shown in red in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig7">7</a>. As such, we were able to validate that COVID-Net was not relying on improper information to make decisions (e.g., erroneous visual indicators outside the body, embedded markup symbols, imaging artifacts, etc.), which could lead to scenarios where the right decisions are made for the wrong reasons. Such ‘right decision, wrong reason’ scenarios are very difficult to track and identify without the use of such an explainability-driven auditing strategy, and thus highlight the value of explainability in improving the reliability of deep neural networks for clinical applications.</p><p>We further explored the relationship between the critical factors identified by GSInquire and the experimental results, particularly in relationship to clinical visual indicators leveraged for radiography examination of chest CXR images for COVID-19. In the cases in the experimental results where the proposed COVID-Net correctly detects COVID-19 infections (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-020-76550-z#Fig6">6</a>), the critical factors that are identified by GSInquire often corresponds to clinical visual factors such as ground-glass opacities, bilateral abnormalities, and interstitial abnormalities, which have been found to be useful for COVID-19 radiography examinations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ng, M.-Y. et al. Imaging profile of the COVID-19 infection: radiologic findings and literature review. Radiol. Cardiothorac. Imaging 2(1), e200034 (2020)." href="#ref-CR6" id="ref-link-section-d21123127e3158">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Huang, C. et al. Clinical features of patients infected with 2019 Novel Coronavirus in Wuhan China. The Lancet 395, 497–506 (2020)." href="#ref-CR7" id="ref-link-section-d21123127e3158_1">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Guan, W. J., Hu Y., &amp; Ni Z. Y. Clinical characteristics of Coronavirus disease 2019 in China. N. Engl. J. Med. 382(18), 1708–1720 (2020)." href="/articles/s41598-020-76550-z#ref-CR8" id="ref-link-section-d21123127e3161">8</a></sup>. What this illustrates is that the proposed COVID-Net can learn to leverage visual indicators in its decision-making process that relate to those leveraged by clinicians in their decision-making process. Therefore, these observations are insightful for establishing a deeper understanding into the overlaps between the decision-making process of deep neural networks for clinical applications and the decision-making process of clinicians during radiography examination.</p><p>In addition to performance validation for more responsible and transparent design, the ability to interpret and gain insights into how the proposed COVID-Net detects COVID-19 infections is also important for a number of other reasons:</p><ul class="u-list-style-bullet">
<li>
<p><b>Transparency</b> By understanding the critical factors being leveraged in COVID-19 case detection, the predictions made by the proposed COVID-Net become more transparent and trustworthy for clinicians to leverage during their screening process to aid them in making faster yet accurate assessments.</p>
</li>
<li>
<p><b>New insight discovery</b> The critical factors leveraged by the proposed COVID-Net could potentially help clinicians discover new insights into the key visual indicators associated with SARS-CoV-2 viral infection, which they can then leverage to improve screening accuracy.</p>
</li>
</ul></div></div></section><section data-title="Conclusion"><div class="c-article-section" id="Sec18-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec18">Conclusion</h2><div class="c-article-section__content" id="Sec18-content"><p>In this study, we introduced COVID-Net, a deep convolutional neural network design for the detection of COVID-19 cases from CXR images that is open source and available to the general public. We also introduce COVIDx, an open access benchmark dataset that is comprised of 13,975 CXR images across 13,870 patient cases from five open access data repositories. Moreover, we investigated how COVID-Net makes predictions using an explainability method in an attempt to gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening as well as improve trust and transparency when leveraging COVID-Net for accelerated computer-aided screening.</p><p>By no means a production-ready solution, the hope is that the promising results achieved by COVID-Net on the COVIDx test dataset, along with the fact that it is available in open source format alongside the description on constructing the open source dataset, will lead it to be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases from CXR images and accelerate treatment of those who need it the most. Future directions include continuing to improve sensitivity and PPV to COVID-19 infections as new data is collected, as well as extend the proposed COVID-Net to risk stratification for survival analysis, predicting risk status of patients, and predicting hospitalization duration which would be useful for triaging, patient population management, and individualized care planning.
</p></div></div></section>
            

            <section data-title="Data availability"><div class="c-article-section" id="data-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="data-availability">Data availability</h2><div class="c-article-section__content" id="data-availability-content">
              
              <p>The model, data and scripts are all available at <a href="https://github.com/lindawangg/COVID-Net">https://github.com/lindawangg/COVID-Net</a>.</p>
            </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Wang, W. <i>et al.</i> Detection of SARS-CoV-2 in different types of clinical specimens. <i>JAMA</i> <b>323</b>(18), 1843–1844 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXps1Srurs%3D" aria-label="CAS reference 1">CAS</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32159775" aria-label="PubMed reference 1" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7066521" aria-label="PubMed Central reference 1" rel="nofollow">PubMed Central</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Detection%20of%20SARS-CoV-2%20in%20different%20types%20of%20clinical%20specimens&amp;journal=JAMA&amp;volume=323&amp;issue=18&amp;pages=1843-1844&amp;publication_year=2020&amp;author=Wang%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">West, C. P., Montori, V. M., &amp; Sampathkumar, P. Covid-19 testing: the threat of false-negative results. In <i>Mayo Clinic Proceeding</i> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">Fang, Y. <i>et al.</i> Sensitivity of chest CT for covid-19: comparison to RT-PCR. <i>Radiology</i>. <a href="https://doi.org/10.1148/radiol.2020200432">https://doi.org/10.1148/radiol.2020200432</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Yang, Y. <i>et al.</i> Evaluating the accuracy of different respiratory specimens in the laboratory diagnosis and monitoring the viral shedding of 2019-ncov infections. <i>medRxiv:2020.02.11.20021493</i> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Wikramaratna, P., Paton, R. S., Ghafari, M., &amp; Lourenco, J. Estimating false-negative detection rate of sars-cov-2 by rt-pcr. <i>medRxiv:2020.04.05.20053355</i> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Ng, M.-Y. <i>et al.</i> Imaging profile of the COVID-19 infection: radiologic findings and literature review. <i>Radiol. Cardiothorac. Imaging</i> <b>2</b>(1), e200034 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1148%2Fryct.2020200034" aria-label="Article reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=Imaging%20profile%20of%20the%20COVID-19%20infection%3A%20radiologic%20findings%20and%20literature%20review&amp;journal=Radiol.%20Cardiothorac.%20Imaging&amp;volume=2&amp;issue=1&amp;publication_year=2020&amp;author=Ng%2CM-Y">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">Huang, C. <i>et al.</i> Clinical features of patients infected with 2019 Novel Coronavirus in Wuhan China. <i>The Lancet</i> <b>395</b>, 497–506 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXhs1Kqu7c%3D" aria-label="CAS reference 7">CAS</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2FS0140-6736%2820%2930183-5" aria-label="Article reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Clinical%20features%20of%20patients%20infected%20with%202019%20Novel%20Coronavirus%20in%20Wuhan%20China&amp;journal=The%20Lancet&amp;volume=395&amp;pages=497-506&amp;publication_year=2020&amp;author=Huang%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Guan, W. J., Hu Y., &amp; Ni Z. Y. Clinical characteristics of Coronavirus disease 2019 in China. <i>N. Engl. J. Med.</i> <b>382</b>(18), 1708–1720 (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">Ai, T. <i>et al.</i> Correlation of chest CT and RT-PCR testing in coronavirus disease 2019 (COVID-19) in china: a report of 1014 cases. <i>Radiology</i> (2020). <a href="https://doi.org/10.1148/radiol.2020200642">https://doi.org/10.1148/radiol.2020200642</a>.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1148%2Fradiol.2020200642" aria-label="Article reference 9">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32101510" aria-label="PubMed reference 9" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233399" aria-label="PubMed Central reference 9" rel="nofollow">PubMed Central</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Correlation%20of%20chest%20CT%20and%20RT-PCR%20testing%20in%20coronavirus%20disease%202019%20%28COVID-19%29%20in%20china%3A%20a%20report%20of%201014%20cases&amp;journal=Radiology&amp;doi=10.1148%2Fradiol.2020200642&amp;publication_year=2020&amp;author=Ai%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Rubin, G. D. <i>et al.</i> The role of chest imaging in patient management during the COVID-19 pandemic: a multinational consensus statement from the fleischner society. <i>Radiology</i> (2020). <a href="https://doi.org/10.1016/j.chest.2020.04.003">https://doi.org/10.1016/j.chest.2020.04.003</a>.</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.chest.2020.04.003" aria-label="Article reference 10">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32840468" aria-label="PubMed reference 10" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233395" aria-label="PubMed Central reference 10" rel="nofollow">PubMed Central</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20chest%20imaging%20in%20patient%20management%20during%20the%20COVID-19%20pandemic%3A%20a%20multinational%20consensus%20statement%20from%20the%20fleischner%20society&amp;journal=Radiology&amp;doi=10.1016%2Fj.chest.2020.04.003&amp;publication_year=2020&amp;author=Rubin%2CGD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Nair, A. <i>et al.</i> A British Society of thoracic imaging statement: considerations in designing local imaging diagnostic algorithms for the COVID-19 pandemic. <i>Clin. Radiol.</i> <b>75</b>(5), 329–334 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="/articles/cas-redirect/1:STN:280:DC%2BB38zislSmtQ%3D%3D" aria-label="CAS reference 11">CAS</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.crad.2020.03.008" aria-label="Article reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20British%20Society%20of%20thoracic%20imaging%20statement%3A%20considerations%20in%20designing%20local%20imaging%20diagnostic%20algorithms%20for%20the%20COVID-19%20pandemic&amp;journal=Clin.%20Radiol.&amp;volume=75&amp;issue=5&amp;pages=329-334&amp;publication_year=2020&amp;author=Nair%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Dennie, C. <i>et al.</i> The Canadian Society of Thoracic Radiology (CSTR) and Canadian Association of Radiologists (CAR) consensus statement regarding chest imaging in suspected and confirmed COVID-19. <i>Can. Assoc. Radiol. J.</i> <b>71</b>(4), 470–481 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1177%2F0846537120924606" aria-label="Article reference 12">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Canadian%20Society%20of%20Thoracic%20Radiology%20%28CSTR%29%20and%20Canadian%20Association%20of%20Radiologists%20%28CAR%29%20consensus%20statement%20regarding%20chest%20imaging%20in%20suspected%20and%20confirmed%20COVID-19&amp;journal=Can.%20Assoc.%20Radiol.%20J.&amp;volume=71&amp;issue=4&amp;pages=470-481&amp;publication_year=2020&amp;author=Dennie%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Jacobi, A., Chung, M., Bernheim, A. &amp; Eber, C. Portable chest x-ray in coronavirus disease-19 (covid-19): a pictorial review. <i>Clin. Imaging</i><a href="https://doi.org/10.1016/j.clinimag.2020.04.001">https://doi.org/10.1016/j.clinimag.2020.04.001</a> (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2Fj.clinimag.2020.04.001" aria-label="Article reference 13">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32871424" aria-label="PubMed reference 13" rel="nofollow">PubMed</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7141645" aria-label="PubMed Central reference 13" rel="nofollow">PubMed Central</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Portable%20chest%20x-ray%20in%20coronavirus%20disease-19%20%28covid-19%29%3A%20a%20pictorial%20review&amp;journal=Clin.%20Imaging&amp;doi=10.1016%2Fj.clinimag.2020.04.001&amp;publication_year=2020&amp;author=Jacobi%2CA&amp;author=Chung%2CM&amp;author=Bernheim%2CA&amp;author=Eber%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Wu, G., &amp; Li, X. Mobile x-rays are highly valuable for critically ill covid patients. <i>Eur. Radiol.</i>. <a href="https://doi.org/10.1007/s00330-020-06918-2">https://doi.org/10.1007/s00330-020-06918-2</a>(2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Mao, B. <i>et al.</i> Assessing risk factors for SARS-CoV-2 infection in patients presenting with symptoms in Shanghai, China: a multicentre observational cohort study. <i>Lancet Dig. Health</i>. <a href="https://doi.org/10.1016/S2589-7500(20)30109-6">https://doi.org/10.1016/S2589-7500(20)30109-6</a>(2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Cohen, J. P., Morrison, P., &amp; Dao, L. COVID-19 image data collection. <a href="http://arxiv.org/abs/2003.11597">arXiv:2003.11597</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">Chung, A. Figure 1 COVID-19 chest x-ray data initiative. <a href="https://github.com/agchung/Figure1-COVID-chestxray-dataset">https://github.com/agchung/Figure1-COVID-chestxray-dataset</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Chung, A. Actualmed COVID-19 chest x-ray data initiative. <a href="https://github.com/agchung/Actualmed-COVID-chestxray-dataset">https://github.com/agchung/Actualmed-COVID-chestxray-dataset</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Radiological Society of North America. COVID-19 radiography database. <a href="https://www.kaggle.com/tawsifurrahman/covid19-radiography-database">https://www.kaggle.com/tawsifurrahman/covid19-radiography-database</a> (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Radiological Society of North America. RSNA pneumonia detection challenge. <i>https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data</i> (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">LeCun, Y., Bengio, Y., &amp; Hinton, G. Deep learning. <i>Nature</i> <b>521</b>, 436–444 (2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Gozes, O. <i>et al.</i> Rapid AI development cycle for the coronavirus (COVID-19) pandemic: initial results for automated detection and patient monitoring using deep learning ct image analysis. <a href="http://arxiv.org/abs/2003.05037">arXiv:2003.05037</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">Xu, X. <i>et al.</i> Deep learning system to screen coronavirus disease 2019 pneumonia. <a href="http://arxiv.org/abs/2002.09334">arXiv:2002.09334</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24."><p class="c-article-references__text" id="ref-CR24">Li, L. <i>et al.</i> Artificial intelligence distinguishes COVID-19 from community acquired pneumonia on chest CT. <i>Radiology</i>. <a href="https://doi.org/10.1148/radiol.2020200905">https://doi.org/10.1148/radiol.2020200905</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25."><p class="c-article-references__text" id="ref-CR25">Shi, F. <i>et al.</i> Large-scale screening of covid-19 from community acquired pneumonia using infection size-aware classification. <a href="http://arxiv.org/abs/2003.09860">arXiv:2003.09860</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26."><p class="c-article-references__text" id="ref-CR26">Li, X., Li, C., &amp; Zhu, D. Covid-mobilexpert: On-device covid-19 screening using snapshots of chest x-ray. <a href="http://arxiv.org/abs/2004.03042">arXiv:2004.03042</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27."><p class="c-article-references__text" id="ref-CR27">Minaee, S., Kafieh, R., Sonka, M., Yazdani, S., &amp; Soufi, G. J. Deep-covid: predicting covid-19 from chest x-ray images using deep transfer learning. <a href="http://arxiv.org/abs/2004.09363">arXiv:2004.09363</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28."><p class="c-article-references__text" id="ref-CR28">Afshar, P. <i>et al.</i> Covid-caps: a capsule network-based framework for identification of covid-19 cases from x-ray images. <a href="http://arxiv.org/abs/2004.02696">arXiv:2004.02696</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29."><p class="c-article-references__text" id="ref-CR29">Luz, E. <i>et al.</i> Towards an effective and efficient deep learning model for covid-19 patterns detection in x-ray images. <a href="http://arxiv.org/abs/2004.05717">arXiv:2004.05717</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30."><p class="c-article-references__text" id="ref-CR30">Khobahi, S., Agarwal, C., &amp; Soltanalian, M. Coronet: a deep network architecture for semi-supervised task-based identification of covid-19 from chest x-ray images. <i>medRxiv</i>. <a href="https://doi.org/10.1101/2020.04.14.20065722">https://doi.org/10.1101/2020.04.14.20065722</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31."><p class="c-article-references__text" id="ref-CR31">Ucar, F., &amp; Korkmaz, D. COVIDiagnosis-net: deep bayes-squeezenet based diagnosis of the coronavirus disease 2019 (COVID-19) from x-ray images. <i>Med. Hypotheses</i>. <a href="https://doi.org/10.1016/j.mehy.2020.109761">https://doi.org/10.1016/j.mehy.2020.109761</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32."><p class="c-article-references__text" id="ref-CR32">Tartaglione, E., Barbano, C. A., Berzovini, C., Calandri, M., &amp; Grangetto, M. Unveiling covid-19 from chest x-ray with deep learning: a hurdles race with small data. <a href="http://arxiv.org/abs/2004.05405">arXiv:2004.05405</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33."><p class="c-article-references__text" id="ref-CR33">Yeh, C.-F. <i>et al.</i> A cascaded learning strategy for robust covid-19 pneumonia chest x-ray screening. <a href="http://arxiv.org/abs/2004.12786">arXiv:2004.12786</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34."><p class="c-article-references__text" id="ref-CR34">Zhang, Y. <i>et al.</i> Covid-da: deep domain adaptation from typical pneumonia to covid-19. <a href="http://arxiv.org/abs/2005.01577">arXiv:2005.01577</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35."><p class="c-article-references__text" id="ref-CR35">Karim, M. R. <i>et al.</i> Deepcovidexplainer: explainable covid-19 predictions based on chest x-ray images (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36."><p class="c-article-references__text" id="ref-CR36">Apostolopoulos, I. D., &amp; Mpesiana, T. A. Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks. <i>Phys. Eng. Sci. Med.</i> <b>43</b>, 635–640. <a href="https://doi.org/10.1007/s13246-020-00865-4">https://doi.org/10.1007/s13246-020-00865-4</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37."><p class="c-article-references__text" id="ref-CR37">Farooq, M., &amp; Hafeez, A. Covid-resnet: a deep learning framework for screening of covid19 from radiographs (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38."><p class="c-article-references__text" id="ref-CR38">Majeed, T., Rashid, R., Ali, D., &amp; Asaad, A. Covid-19 detection using cnn transfer learning from x-ray images. <i>medRxiv</i> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39."><p class="c-article-references__text" id="ref-CR39">Wang, X. <i>et al.</i> Chestx-ray8: hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. In <i>2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR)</i>, 3462–3471 (2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40."><p class="c-article-references__text" id="ref-CR40">He, K., Zhang, X., Ren, S., &amp; Sun, J. Deep residual learning for image recognition. In <i>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</i> 770–778 (2016).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41."><p class="c-article-references__text" id="ref-CR41">Wong, A., Shafiee, M. J., Chwyl, B., &amp; Li, F. Ferminets: learning generative machines to generate efficient neural networks via generative synthesis. arXiv preprint <a href="http://arxiv.org/abs/1809.05989">arXiv:1809.05989</a> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42."><p class="c-article-references__text" id="ref-CR42">Huang, G., Liu, Z., &amp; Weinberger, K. Q. Densely connected convolutional networks. arXiv preprint <a href="http://arxiv.org/abs/1608.06993">arXiv:1608.06993</a> (2016).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43."><p class="c-article-references__text" id="ref-CR43">Deng, J. <i>et al.</i> Imagenet: a large-scale hierarchical image database. In <i>2009 IEEE Conference on Computer Vision and Pattern Recognition</i> 248–255 (IEEE, 2009).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44."><p class="c-article-references__text" id="ref-CR44">Lin, Z. Q. <i>et al.</i> Do explanations reflect decisions? A machine-centric strategy to quantify the performance of explainability algorithms. arXiv preprint <a href="http://arxiv.org/abs/1910.07387">arXiv:1910.07387</a> (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45."><p class="c-article-references__text" id="ref-CR45">Wong, A. Netscore: towards universal metrics for large-scale performance analysis of deep neural networks for practical usage. <i>CoRR</i>. arXiv preprint <a href="http://arxiv.org/abs/1806.05512">arXiv:abs/1806.05512</a> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46."><p class="c-article-references__text" id="ref-CR46">Simonyan, K., &amp; Zisserman, A. Very deep convolutional networks for large-scale image recognition (2014).</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="https://citation-needed.springer.com/v2/references/10.1038/s41598-020-76550-z?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>We would like to thank Natural Sciences and Engineering Research Council of Canada (NSERC), the Canada Research Chairs program, DarwinAI Corp., and Audrey Chung.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Systems Design Engineering, University of Waterloo, Waterloo, Canada</p><p class="c-article-author-affiliation__authors-list">Linda Wang, Zhong Qiu Lin &amp; Alexander Wong</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Waterloo Artificial Intelligence Institute, Waterloo, Canada</p><p class="c-article-author-affiliation__authors-list">Linda Wang, Zhong Qiu Lin &amp; Alexander Wong</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">DarwinAI Corp., Waterloo, Canada</p><p class="c-article-author-affiliation__authors-list">Linda Wang, Zhong Qiu Lin &amp; Alexander Wong</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Linda-Wang"><span class="c-article-authors-search__title u-h3 js-search-name">Linda Wang</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=%22Linda%20Wang%22" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Linda%20Wang" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Linda%20Wang%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Zhong_Qiu-Lin"><span class="c-article-authors-search__title u-h3 js-search-name">Zhong Qiu Lin</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=%22Zhong%20Qiu%20Lin%22" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Zhong%20Qiu%20Lin" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Zhong%20Qiu%20Lin%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li><li id="auth-Alexander-Wong"><span class="c-article-authors-search__title u-h3 js-search-name">Alexander Wong</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=%22Alexander%20Wong%22" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Alexander%20Wong" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alexander%20Wong%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>L.W. and A.W. conceived the experiment, L.W., Z.L. and A.W. conducted the experiment, L.W. and A.W. analysed the results. All authors reviewed the manuscript.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:linda.wang@uwaterloo.ca">Linda Wang</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading" id="FPar2">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><h3 class="c-article__sub-heading">Publisher's note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content">
                <p><b>Open Access</b> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=COVID-Net%3A%20a%20tailored%20deep%20convolutional%20neural%20network%20design%20for%20detection%20of%20COVID-19%20cases%20from%20chest%20X-ray%20images&amp;author=Linda%20Wang%20et%20al&amp;contentID=10.1038%2Fs41598-020-76550-z&amp;copyright=The%20Author%28s%29&amp;publication=2045-2322&amp;publicationDate=2020-11-11&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/s41598-020-76550-z" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41598-020-76550-z" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Wang, L., Lin, Z.Q. &amp; Wong, A. COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images.
                    <i>Sci Rep</i> <b>10, </b>19549 (2020). https://doi.org/10.1038/s41598-020-76550-z</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" href="https://citation-needed.springer.com/v2/references/10.1038/s41598-020-76550-z?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2020-05-20">20 May 2020</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2020-10-26">26 October 2020</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2020-11-11">11 November 2020</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/s41598-020-76550-z</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">Further reading</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Proposing a novel deep network for detecting COVID-19 based on chest images" href="https://doi.org/10.1038/s41598-022-06802-7">
                                        Proposing a novel deep network for detecting COVID-19 based on chest images
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-mb-4 u-mt-auto">
                                        
                                            <li>Maryam Dialameh</li>
                                        
                                            <li>Ali Hamzeh</li>
                                        
                                            <li>Safoura Dialameh</li>
                                        
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2022)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Truncating fined-tuned vision-based models to lightweight deployable diagnostic tools for SARS-CoV-2 infected chest X-rays and CT-scans" href="https://doi.org/10.1007/s11042-022-12484-0">
                                        Truncating fined-tuned vision-based models to lightweight deployable diagnostic tools for SARS-CoV-2 infected chest X-rays and CT-scans
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact u-mb-4 u-mt-auto">
                                        
                                            <li>Francis Jesmar Montalbo</li>
                                        
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Multimedia Tools and Applications</i> (2022)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:A deep learning-based framework for detecting COVID-19 patients using chest X-rays" href="https://doi.org/10.1007/s00530-022-00917-7">
                                        A deep learning-based framework for detecting COVID-19 patients using chest X-rays
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-mb-4 u-mt-auto">
                                        
                                            <li>Sohaib Asif</li>
                                        
                                            <li>Ming Zhao</li>
                                        
                                            <li>Yusen Zhu</li>
                                        
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Multimedia Systems</i> (2022)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Experimental Technologies in the Diagnosis and Treatment of COVID-19 in Patients with Comorbidities" href="https://doi.org/10.1007/s41666-021-00106-7">
                                        Experimental Technologies in the Diagnosis and Treatment of COVID-19 in Patients with Comorbidities
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-mb-4 u-mt-auto">
                                        
                                            <li>Md Shahnoor Amin</li>
                                        
                                            <li>Marcin Wozniak</li>
                                        
                                            <li>Olivia C. Coiado</li>
                                        
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Journal of Healthcare Informatics Research</i> (2022)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:CCBlock: an effective use of deep learning for automatic diagnosis of COVID-19 using X-ray images" href="https://doi.org/10.1007/s42600-020-00110-7">
                                        CCBlock: an effective use of deep learning for automatic diagnosis of COVID-19 using X-ray images
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-mb-4 u-mt-auto">
                                        
                                            <li>Ali Al-Bawi</li>
                                        
                                            <li>Karrar Al-Kaabi</li>
                                        
                                            <li>Ahmad Al-Fatlawi</li>
                                        
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Research on Biomedical Engineering</i> (2022)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
                <section data-title="Comments"><div class="c-article-section" id="article-comments-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-comments">Comments</h2><div class="c-article-section__content" id="article-comments-content"><p>By submitting a comment you agree to abide by our <a href="/info/tandc.html">Terms</a> and <a href="/info/community-guidelines.html">Community Guidelines</a>. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.</p></div></div></section>
                <div id="inject-comments">
                    <div class="placeholder" data-replace="true"
                         data-disqus-placeholder="/platform/disqus?doi=10.1038/s41598-020-76550-z #article-comments-container">
                </div>
            </div>
            

            <span data-recommended="jobs"></span>
</div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            
                
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41598-020-76550-z.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            </a>
        </div>
    

            
        
    </div>
    

    
        
    

    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-mt-16" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/scientific_reports/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=s41598-020-76550-z;doi=10.1038/s41598-020-76550-z;subjmeta=139,2514,255,692,699,700;kwrd=Diagnosis,Viral+infection">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/scientific_reports/article&amp;sz=300x250&amp;c=404214274&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41598-020-76550-z%26doi%3D10.1038/s41598-020-76550-z%26subjmeta%3D139,2514,255,692,699,700%26kwrd%3DDiagnosis,Viral+infection">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/scientific_reports/article&amp;sz=300x250&amp;c=404214274&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41598-020-76550-z%26doi%3D10.1038/s41598-020-76550-z%26subjmeta%3D139,2514,255,692,699,700%26kwrd%3DDiagnosis,Viral+infection"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="u-hide-print c-header-expander" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header-expander__container">
                <h2 id="Explore-content" class="c-header-expander__heading u-js-hide">Explore content</h2>
                <ul class="c-header-expander__list">
                    
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/browse-subjects"
                                   data-track="click"
                                   data-track-action="subjects"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Subjects
                                </a>
                            </li>
                        
                    
                    
                        <li class="c-header-expander__item c-header-expander__item--keyline c-header-expander__item--keyline-first-item-only">
                            <a class="c-header-expander__link"
                               href="https://www.facebook.com/scientificreports"
                               data-track="click"
                               data-track-action="facebook"
                               data-track-label="link">Follow us on Facebook
                            </a>
                        </li>
                    
                    
                        <li class="c-header-expander__item c-header-expander__item--keyline c-header-expander__item--keyline-first-item-only">
                            <a class="c-header-expander__link"
                               href="https://twitter.com/SciReports"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header-expander__item c-header-expander__item--keyline c-header-expander__item--keyline-first-item-only u-hide-at-lg">
                            <a class="c-header-expander__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;288"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header-expander__item c-header-expander__item--keyline c-header-expander__item--keyline-first-item-only u-hide-at-lg">
                            <a class="c-header-expander__link"
                               href="http://feeds.nature.com/srep/rss/current"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="u-hide-print c-header-expander" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header-expander__container">
                    <h2 id="About-the-journal" class="c-header-expander__heading u-js-hide">About the journal</h2>
                    <ul class="c-header-expander__list">
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/about"
                                   data-track="click"
                                   data-track-action="about scientific reports"
                                   data-track-label="link">
                                    About Scientific Reports
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/journal-policies"
                                   data-track="click"
                                   data-track-action="journal policies"
                                   data-track-label="link">
                                    Journal policies
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/guide-to-referees"
                                   data-track="click"
                                   data-track-action="guide to referees"
                                   data-track-label="link">
                                    Guide to referees
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/guestedited"
                                   data-track="click"
                                   data-track-action="calls for papers"
                                   data-track-label="link">
                                    Calls for Papers
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/editorschoice"
                                   data-track="click"
                                   data-track-action="editor&#x27;s choice"
                                   data-track-label="link">
                                    Editor&#x27;s Choice
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/guestedited-collections"
                                   data-track="click"
                                   data-track-action="guest edited collections"
                                   data-track-label="link">
                                    Guest Edited Collections
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/top100-2019"
                                   data-track="click"
                                   data-track-action="scientific reports top 100 2019"
                                   data-track-label="link">
                                    Scientific Reports Top 100 2019
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/top100-2018"
                                   data-track="click"
                                   data-track-action="scientific reports top 100 2018"
                                   data-track-label="link">
                                    Scientific Reports Top 100 2018
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/top10"
                                   data-track="click"
                                   data-track-action="scientific reports top 10 2018"
                                   data-track-label="link">
                                    Scientific Reports Top 10 2018
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/top100"
                                   data-track="click"
                                   data-track-action="scientific reports top 100 2017"
                                   data-track-label="link">
                                    Scientific Reports Top 100 2017
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/ebm"
                                   data-track="click"
                                   data-track-action="editorial board highlights"
                                   data-track-label="link">
                                    Editorial Board Highlights
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/author-highlights"
                                   data-track="click"
                                   data-track-action="author highlights"
                                   data-track-label="link">
                                    Author Highlights
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/announcements"
                                   data-track="click"
                                   data-track-action="announcements"
                                   data-track-label="link">
                                    Announcements
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/anniversary-interviews"
                                   data-track="click"
                                   data-track-action="10th anniversary editorial board interviews"
                                   data-track-label="link">
                                    10th Anniversary Editorial Board Interviews
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/top100-2020"
                                   data-track="click"
                                   data-track-action="scientific reports top 100 2020"
                                   data-track-label="link">
                                    Scientific Reports Top 100 2020
                                </a>
                            </li>
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/top100-2021"
                                   data-track="click"
                                   data-track-action="scientific reports top 100 2021"
                                   data-track-label="link">
                                    Scientific Reports Top 100 2021
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="u-hide-print c-header-expander" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header-expander__container">
                    <h2 id="Publish-with-us-label" class="c-header-expander__heading u-js-hide">Publish with us</h2>
                    <ul class="c-header-expander__list">
                        
                            <li class="c-header-expander__item">
                                <a class="c-header-expander__link"
                                   href="/srep/author-instructions"
                                   data-track="click"
                                   data-track-action="for authors"
                                   data-track-label="link">
                                    For authors
                                </a>
                            </li>
                        
                        
                            <li class="c-header-expander__item c-header-expander__item--keyline">
                                <a class="c-header-expander__link"
                                   href="https://author-welcome.nature.com/41598"
                                   data-track="click"
                                   data-track-action="Submit manuscript"
                                   data-track-label="link"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header-expander c-header-expander--tray u-hide-print" data-track-component="nature-150-split-header">
    <div class="c-header-expander__container">
        <h2 class="u-visually-hidden">Search</h2>
        <div data-test="inline-search">
            <div class="c-search c-search--max-width u-mb-16">
                <form action="/search"
                      method="get"
                      role="search"
                      autocomplete="off"
                      data-dynamic-track-label
                      data-track="submit" data-track-action="search" data-track-label="form">
                    <label class="c-header-expander__heading u-mb-8" for="keywords">Search articles by subject, keyword or author</label>
                    <div class="c-search__field">
                        <div class="c-search__input-container c-search__input-container--md">
                            <input type="text"
                               required
                               class="c-search__input"
                               id="keywords"
                               name="q"
                               value=""
                               data-test="search-keywords">
                        </div>

                        <div class="c-search__select-container">
                            <label for="results-from" class="u-visually-hidden">Show results from</label>
                            <select id="results-from" name="journal" class="c-search__select">
                                
                                    
                                        <option value="" selected>All journals</option>
                                        <option value="srep">This journal</option>
                                    
                                
                            </select>
                        </div>
                        <div class="c-search__button-container">
                            <button type="submit" class="u-button u-button--primary u-button--full-width" data-test="search-submit">Search</button>
                        </div>
                    </div>
                </form>
            </div>
        </div>

        <div class="c-header-expander__keyline u-mb-16">
            <p class="u-ma-0">
                <a href="/search/advanced"
                   data-track="click" data-track-action="advanced search" data-track-label="link">
                    Advanced search
                </a>
            </p>
        </div>
        <h3 class="c-header-expander__heading">Quick links</h3>
        <ul class="u-list-reset">
            <li class="u-display-inline-block u-mr-24 u-mb-16"><a href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li class="u-display-inline-block u-mr-24 u-mb-16"><a href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li class="u-display-inline-block u-mr-24 u-mb-16"><a href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li class="u-display-inline-block u-mr-24 u-mb-16"><a href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
    <meta itemprop="publisher" content="Springer Nature">
    
    <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Scientific Reports (<i>Sci Rep</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">2045-2322</span> (online)
    </span>
    


                
    

            </p>
        </div>
    </div>
</div>


    <div>
        <div class="c-footer">
            <div class="u-container">
                <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__header">
        <div class="c-footer__logo">
            <img alt="Nature portfolio" src="/static/images/logos/nature-portfolio-white.svg" loading="lazy" width="200" height="31">
        </div>
        <ul class="c-menu c-menu--inherit u-mr-32">
            <li class="c-menu__item"><a class="c-menu__link" href="https://www.nature.com/npg_/company_info/index.html" data-track="click" data-track-action="about us" data-track-label="link">About us</a></li>
            <li class="c-menu__item"><a class="c-menu__link" href="https://www.nature.com/npg_/press_room/press_releases.html" data-track="click" data-track-action="press releases" data-track-label="link">Press releases</a></li>
            <li class="c-menu__item"><a class="c-menu__link" href="https://press.nature.com/" data-track="click" data-track-action="press office" data-track-label="link">Press office</a></li>
            <li class="c-menu__item"><a class="c-menu__link" href="https://support.nature.com/support/home" data-track="click" data-track-action="contact us" data-track-label="link">Contact us</a></li>
        </ul>
        <ul class="c-menu c-menu--inherit">
            <li class="c-menu__item">
                <a class="c-menu__link" href="https://www.facebook.com/NaturePortfolioJournals/" aria-label="Facebook" data-track="click" data-track-action="facebook" data-track-label="link">
                    <svg class="u-icon" role="img" aria-hidden="true" focusable="false" xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 20 20"><path d="M2.5 20C1.1 20 0 18.9 0 17.5v-15C0 1.1 1.1 0 2.5 0h15C18.9 0 20 1.1 20 2.5v15c0 1.4-1.1 2.5-2.5 2.5h-3.7v-7.7h2.6l.4-3h-3v-2c0-.9.2-1.5 1.5-1.5h1.6V3.1c-.3 0-1.2-.1-2.3-.1-2.3 0-3.9 1.4-3.9 4v2.2H8.1v3h2.6V20H2.5z"/></svg>
                </a>
            </li>
            <li class="c-menu__item">
                <a class="c-menu__link" href="https://twitter.com/NaturePortfolio?lang=en" aria-label="Twitter" data-track="click" data-track-action="twitter" data-track-label="link">
                    <svg class="u-icon" role="img" aria-hidden="true" focusable="false" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 20"><path d="M17.6 4.1c.8-.5 1.5-1.4 1.8-2.4-.8.5-1.7.9-2.6 1-.7-.8-1.8-1.4-3-1.4-2.3 0-4.1 1.9-4.1 4.3 0 .3 0 .7.1 1-3.4 0-6.4-1.8-8.4-4.4C1 2.9.8 3.6.8 4.4c0 1.5.7 2.8 1.8 3.6C2 8 1.4 7.8.8 7.5v.1c0 2.1 1.4 3.8 3.3 4.2-.3.1-.7.2-1.1.2-.3 0-.5 0-.8-.1.5 1.7 2 3 3.8 3-1.3 1.1-3.1 1.8-5 1.8-.3 0-.7 0-1-.1 1.8 1.2 4 1.9 6.3 1.9C13.8 18.6 18 12 18 6.3v-.6c.8-.6 1.5-1.4 2-2.2-.7.3-1.5.5-2.4.6z"/></svg>
                </a>
            </li>
            <li class="c-menu__item">
                <a class="c-menu__link" href="https://www.youtube.com/channel/UCvCLdSgYdSTpWcOgEJgi-ng" aria-label="YouTube" data-track="click" data-track-action="youtube" data-track-label="link">
                    <svg class="u-icon" role="img" aria-hidden="true" focusable="false" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 20"><path d="M7.9 12.6V6.9l5.4 2.8c0 .1-5.4 2.9-5.4 2.9zM19.8 6s-.2-1.4-.8-2c-.8-.8-1.6-.8-2-.9-2.8-.2-7-.2-7-.2s-4.2 0-7 .2c-.4 0-1.2 0-2 .9-.6.6-.8 2-.8 2S0 7.6 0 9.2v1.5c0 1.7.2 3.3.2 3.3s.2 1.4.8 2c.8.8 1.8.8 2.2.9 1.6.1 6.8.2 6.8.2s4.2 0 7-.2c.4 0 1.2-.1 2-.9.6-.6.8-2 .8-2s.2-1.6.2-3.3V9.2c0-1.6-.2-3.2-.2-3.2z"/></svg>
                </a>
            </li>
        </ul>
    </div>

    <div class="c-footer__grid">
        <div class="c-footer__group">
            <h3 class="c-footer__heading">Discover content</h3>
            <ul class="c-footer__list">
                <li class="c-footer__item"><a href="https://www.nature.com/siteindex" data-track="click" data-track-action="journals a-z" data-track-label="link">Journals A-Z</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/subjects/" data-track="click" data-track-action="article by subject" data-track-label="link">Articles by subject</a></li>
                <li class="c-footer__item"><a href="https://nano.nature.com/" data-track="click" data-track-action="nano" data-track-label="link">Nano</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/protocolexchange/" data-track="click" data-track-action="protocol exchange" data-track-label="link">Protocol Exchange</a></li>
                <li class="c-footer__item"><a href="https://www.natureindex.com/" data-track="click" data-track-action="nature index" data-track-label="link">Nature Index</a></li>
            </ul>
        </div>

        <div class="c-footer__group">
            <h3 class="c-footer__heading">Publishing policies</h3>
            <ul class="c-footer__list">
                <li class="c-footer__item"><a href="https://www.nature.com/authors/editorial_policies/" data-track="click" data-track-action="Nature portfolio policies" data-track-label="link">Nature portfolio policies</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/nature-research/open-access" data-track="click" data-track-action="open access" data-track-label="link">Open access</a></li>
            </ul>
        </div>

        <div class="c-footer__group">
            <h3 class="c-footer__heading">Author &amp; Researcher services</h3>
            <ul class="c-footer__list">
                <li class="c-footer__item"><a href="https://www.nature.com/reprints/" data-track="click" data-track-action="reprints and permissions" data-track-label="link">Reprints &amp; permissions</a></li>
                <li class="c-footer__item"><a href="https://www.springernature.com/gp/authors/research-data" data-track="click" data-track-action="data research service" data-track-label="link">Research data</a></li>
                <li class="c-footer__item"><a href="https://authorservices.springernature.com/go/nr" data-track="click" data-track-action="language editing" data-track-label="link">Language editing</a></li>
                <li class="c-footer__item"><a href="https://authorservices.springernature.com/scientific-editing/" data-track="click" data-track-action="scientific editing" data-track-label="link">Scientific editing</a></li>
                <li class="c-footer__item"><a href="https://masterclasses.nature.com/" data-track="click" data-track-action="nature masterclasses" data-track-label="link">Nature Masterclasses</a></li>
                <li class="c-footer__item"><a href="https://partnerships.nature.com/product/researcher-training/" data-track="click" data-track-action="nature research academies" data-track-label="link">Nature Research Academies</a></li>
                <li class="c-footer__item"><a href="https://solutions.springernature.com/" data-track="click" data-track-action="research solutions" data-track-label="link">Research Solutions</a></li>
            </ul>
        </div>

        <div class="c-footer__group">
            <h3 class="c-footer__heading">Libraries &amp; institutions</h3>
            <ul class="c-footer__list">
                <li class="c-footer__item"><a href="https://www.springernature.com/gp/librarians/tools-services" data-track="click" data-track-action="librarian service and tools" data-track-label="link">Librarian service &amp; tools</a></li>
                <li class="c-footer__item"><a href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal" data-track="click" data-track-action="librarian portal" data-track-label="link">Librarian portal</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/openresearch/about-open-access/information-for-institutions/" data-track="click" data-track-action="open research" data-track-label="link">Open research</a></li>
                <li class="c-footer__item"><a href="https://www.springernature.com/gp/librarians/recommend-to-your-library" data-track="click" data-track-action="Recommend to library" data-track-label="link">Recommend to library</a></li>
            </ul>
        </div>

        <div class="c-footer__group">
            <h3 class="c-footer__heading">Advertising &amp; partnerships</h3>
            <ul class="c-footer__list">
                <li class="c-footer__item"><a href="https://partnerships.nature.com/product/digital-advertising/" data-track="click" data-track-action="advertising" data-track-label="link">Advertising</a></li>
                <li class="c-footer__item"><a href="https://partnerships.nature.com/" data-track="click" data-track-action="partnerships and services" data-track-label="link">Partnerships &amp; Services</a></li>
                <li class="c-footer__item"><a href="https://partnerships.nature.com/media-kits/" data-track="click" data-track-action="media kits" data-track-label="link">Media kits</a></li>
                <li class="c-footer__item"><a href="https://partnerships.nature.com/product/branded-content-native-advertising/" data-track-action="branded content" data-track-label="link">Branded content</a></li>
            </ul>
        </div>

        <div class="c-footer__group">
            <h3 class="c-footer__heading">Career development</h3>
            <ul class="c-footer__list">
                <li class="c-footer__item"><a href="https://www.nature.com/naturecareers" data-track="click" data-track-action="nature careers" data-track-label="link">Nature Careers</a></li>
                <li class="c-footer__item"><a href="https://conferences.nature.com" data-track="click" data-track-action="nature conferences" data-track-label="link">Nature<span class="u-visually-hidden"> </span> Conferences</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/natureevents/" data-track="click" data-track-action="nature events" data-track-label="link">Nature<span class="u-visually-hidden"> </span> events</a></li>
            </ul>
        </div>

        <div class="c-footer__group">
            <h3 class="c-footer__heading">Regional websites</h3>
            <ul class="c-footer__list">
                <li class="c-footer__item"><a href="https://www.nature.com/natafrica" data-track="click" data-track-action="nature africa" data-track-label="link">Nature Africa</a></li>
                <li class="c-footer__item"><a href="http://www.naturechina.com" data-track="click" data-track-action="nature china" data-track-label="link">Nature China</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/nindia" data-track="click" data-track-action="nature india" data-track-label="link">Nature India</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/natitaly" data-track="click" data-track-action="nature Italy" data-track-label="link">Nature Italy</a></li>
                <li class="c-footer__item"><a href="https://www.natureasia.com/ja-jp/" data-track="click" data-track-action="nature japan" data-track-label="link">Nature Japan</a></li>
                <li class="c-footer__item"><a href="https://www.natureasia.com/ko-kr/" data-track="click" data-track-action="nature korea" data-track-label="link">Nature Korea</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/nmiddleeast/" data-track="click" data-track-action="nature middle east" data-track-label="link">Nature Middle East</a></li>
            </ul>
        </div>

        <div class="c-footer__group">
            <h3 class="c-footer__heading">Legal &amp; Privacy</h3>
            <ul class="c-footer__list">
                <li class="c-footer__item"><a href="https://www.nature.com/info/privacy" data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy Policy</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/info/cookies" data-track="click" data-track-action="use of cookies" data-track-label="link">Use of cookies</a></li>
                <li class="c-footer__item"><a class="optanon-toggle-display" href="javascript:;" data-cc-action="preferences" data-track="click" data-track-action="manage cookies" data-track-label="link">Manage cookies/Do not sell my data</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/info/legal-notice" data-track="click" data-track-action="legal notice" data-track-label="link">Legal notice</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/info/accessibility-statement" data-track="click" data-track-action="accessibility statement" data-track-label="link">Accessibility statement</a></li>
                <li class="c-footer__item"><a href="https://www.nature.com/info/terms-and-conditions" data-track="click" data-track-action="terms and conditions" data-track-label="link">Terms &amp; Conditions</a></li>
                <li class="c-footer__item"><a href="https://www.springernature.com/ccpa" data-track="click" data-track-action="california privacy statement" data-track-label="link">California Privacy Statement</a></li>
                
            </ul>
        </div>
    </div>
</div>


            </div>
        </div>
    </div>

    <div class="c-corporate-footer">
    <div class="u-container">
        <img src="/static/images/logos/sn-logo-white.svg" alt="Springer Nature" loading="lazy" width="140" height="14"/>
        <p class="c-corporate-footer__legal" data-test="copyright">&copy; 2022 Springer Nature Limited</p>
    </div>
</div>

    
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
        <symbol id="icon-info" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-success" viewBox="0 0 18 18">
            <path d="M9 0a9 9 0 110 18A9 9 0 019 0zm3.486 4.982l-4.718 5.506L5.14 8.465a.991.991 0 00-1.423.133 1.06 1.06 0 00.13 1.463l3.407 2.733a1 1 0 001.387-.133l5.385-6.334a1.06 1.06 0 00-.116-1.464.991.991 0 00-1.424.119z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-down" viewBox="0 0 16 16">
            <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/>
        </symbol>
        <symbol id="icon-warning" viewBox="0 0 18 18">
            <path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-plus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-minus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-error" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-springer-arrow-left">
            <path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/>
        </symbol>
        <symbol id="icon-springer-arrow-right">
            <path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/>
        </symbol>
        <symbol id="icon-arrow-up" viewBox="0 0 16 16">
            <path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-tick" viewBox="0 0 24 24">
            <path d="M12,24 C5.372583,24 0,18.627417 0,12 C0,5.372583 5.372583,0 12,0 C18.627417,0 24,5.372583 24,12 C24,18.627417 18.627417,24 12,24 Z M7.657,10.79 C7.45285634,10.6137568 7.18569967,10.5283283 6.91717333,10.5534259 C6.648647,10.5785236 6.40194824,10.7119794 6.234,10.923 C5.87705269,11.3666969 5.93445559,12.0131419 6.364,12.387 L10.261,15.754 C10.6765468,16.112859 11.3037113,16.0695601 11.666,15.657 L17.759,8.713 C18.120307,8.27302248 18.0695334,7.62621189 17.644,7.248 C17.4414817,7.06995024 17.1751516,6.9821166 16.9064461,7.00476032 C16.6377406,7.02740404 16.3898655,7.15856958 16.22,7.368 L10.768,13.489 L7.657,10.79 Z"/>
        </symbol>
    </svg>

</footer>




    
        

<div class="c-site-messages message hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif"
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="redesign banner visible">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="redesign banner dismiss">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter — what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="/briefing/signup/formfeedback" method="post" data-location="banner" data-track="submit" data-track-action="transmit-form">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="DirectEmailBannerRedesign2020">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">
                        <label class="nature-briefing-banner__email-label" for="banner-EmailAddressInput">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="banner-EmailAddressInput" name="email" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="1" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="redesign banner dismiss">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="redesign banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="/briefing/signup/?origin=Nature&amp;originReferralPoint=EmailBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>
    



    

    <noscript>
        <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
    </noscript>

    



<script src="//content.readcube.com/ping?doi=10.1038/s41598-020-76550-z&amp;format=js&amp;last_modified=2020-11-11" async></script>
<img src="/platform/track/article/s41598-020-76550-z" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>

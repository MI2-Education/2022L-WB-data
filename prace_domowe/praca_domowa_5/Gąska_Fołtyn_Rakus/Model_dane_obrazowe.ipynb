{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14b6b6e",
   "metadata": {},
   "source": [
    "# Modelowanie na danych obrazowych\n",
    "Przechodzimy do części zajmującej się przygotowaniem kilku modeli oraz wybraniem zeń najlepszego kandydata do naszych finalnych rozważań dotyczących związanych z naszymi bazami danych. Rozważanymi przez nas architekturami będą autorsko tworzone architektury w framework'u keras. Oczywiście nie jest to koniecznie finalna architektura w przypadku całego projektu i w przypadku znalezienia lepszego rozwiązania dla naszego rozwiązania, zastosujemy je."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb1ee8",
   "metadata": {},
   "source": [
    "Przygotowywanie bibliotek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47fd27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37418c5",
   "metadata": {},
   "source": [
    "## Dane oraz cel modelu\n",
    "Za pomocą naszych wcześniej wytworzonych narzędzi przygotowaliśmy jeden zbiór danych złożonych z danych pochodzących z następujących zbiorów danych:\n",
    "- covidx-cxr2\n",
    "- qatacov19-dataset\n",
    "- siim-acr-pneumothorax-segmentation\n",
    "- Shenzhen \n",
    "- rsna-pneumonia-detection-challenge \n",
    "Dane zostały podzielone na zbiory testowy, treningowy oraz walidacyjny (walidacyjny nie został ujęty w części treningowej).  \n",
    "Dane we wszystkich zbiorach zostały jednakowo przetworzone i ustandaryzowane wedle narzędzi zaopatrzonych w pracy domowej 4.  \n",
    "Celem naszego utworzonego zadania będzie klasyfikacja wielo-klasowa polegająca na predykcji choroby na podstawie skanu roentgena klatki piersiowej.  \n",
    "W naszej bazie zostały zawarte następujące klasy z następująco przypisanymi im encodingami:  \n",
    "- 0 - zdrowy\n",
    "- 1 - covid \n",
    "- 2 - tuberculosis \n",
    "- 3 - pneumonia\n",
    "Naszym zadaniem będzie poprawnie sklasyfikować daną etykiete.  \n",
    "W zbiorze danych nie zawarliśmy wszystkich używanych przez nas baz danych ze względu na zbyt duże różnice między nimi by móc jakkolwiek logicznie dokonać ich konkatenacji i uczenia (np. jeden zbiór z danymi był tomografią komputerową podczas gdy reszta danych była skanami roentgena więc ich łączenie nie miałoby sensu).  \n",
    " **Uwaga** Dane były zrównoważone, tudzież jest tyle samo danych z każdej klasy, zatem użycie miary accuracy w dalszych rozważaniach będzie adekwatne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23fb5274",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(r'C:\\Users\\aaf6\\Desktop\\WB-2\\Data_full\\etykiety.csv')\n",
    "labels = labels['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dfe1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wgranie i przygotowanie danych\n",
    "data = []\n",
    "names = []\n",
    "PATH = r'C:\\Users\\aaf6\\Desktop\\WB-2\\Data_full\\dataformodel'\n",
    "files = Path(PATH).glob('*')\n",
    "for file in files:\n",
    "    names.append(str(file).split('\\\\')[-1])\n",
    "    image = Image.open(file)\n",
    "    data.append(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c70ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce61dc7e",
   "metadata": {},
   "source": [
    "Poniżej zamieszczono pobranie danych za pomocą wbudowanego modułu kerasowego, wymagało to przydzielenie instancji klas do osobnych folderów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f55a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1344 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train = ImageDataGenerator()\n",
    "train_dataset = train.flow_from_directory(r\"C:\\\\Users\\\\aaf6\\\\Desktop\\\\WB-2\\\\Data_full_train\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14ce2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test = ImageDataGenerator()\n",
    "test_dataset = train.flow_from_directory(r\"C:\\\\Users\\\\aaf6\\\\Desktop\\\\WB-2\\\\Data_full_test\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d3ca7",
   "metadata": {},
   "source": [
    "### Tworzenie modeli\n",
    "Poniżej dokonaliśmy utworzenia 5 testowych modeli za pomocą framework'u keras. Każdy zeń różni się nieznacznie jeżeli chodzi o złożoność oraz ilość warstw, jednakże każdy opiera się na podobnej architekturze naprzemiennych warstw konwolucyjnych oraz Pooling. W celu zabezpieczenia przed przeuczeniem zawarliśmy również warstwy *Dropout* w niektórych modelach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df4fce",
   "metadata": {},
   "source": [
    "Pierwszy model był naszym testowym, \"domyślnym\" o \"sensownej\" wielkości. Architektura zawarta została poniżej.  \n",
    "W kerasie możliwym jest stworzenie modelu poprzez podawanie naprzemiennie warstw jakie chcemy ująć w naszsej architekturze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "212f74f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(16, (3,3), strides=2, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Dense(4, activation=\"softmax\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc09107a",
   "metadata": {},
   "source": [
    "Nasz drugi model został powiększony o dodatkowe dwa zestawy warstw konwolucyjnych oraz pooling. Ponieważ zdjęcia w naszej bazie są dość dużej rozdzielczości, użycie głębszej sieci może okazać się bardziej optymalne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b788ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(16, (3,3), strides=2, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Dense(4, activation=\"softmax\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1801851e",
   "metadata": {},
   "source": [
    "Niewielkie różnice względem pierwszego modelu, zmienione zostały wartości okna w poolingu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4060f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(16, (3,3), strides=2, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(4, 4)),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Conv2D(32, (4,4), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(4, 4)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Dense(4, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a4c1a",
   "metadata": {},
   "source": [
    "Poniższy cechuje się różnymi wartościami okien w warstwach konwolucyjnych oraz ilości neuronów w warstwie gęstej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "21bb1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(16, (3,3), strides=2, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(4, 4)),\n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512,activation = 'relu'),\n",
    "        layers.Dense(4, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405c407",
   "metadata": {},
   "source": [
    "I ostatnia nasza architektura, cechująca się ponownie większą głębokością, lecz o innej wielkości okna w warstwie poolingu (2x2) oraz większej głębokości niż \"domyślna\" architektura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4db9c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(16, (3,3), strides=2, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512,activation = 'relu'),\n",
    "        layers.Dense(4, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacfa61c",
   "metadata": {},
   "source": [
    "## Etap uczenia\n",
    "Poniżej przechodzimy do etapu uczenia naszych modeli na treningowej bazie danych. Treningu dokonaliśmy dla każdego z modeli na podobnej konfiguracji (optimizer RMSPROP oraz funkcja starty categorical_crossentropy przy batch size wynoszącym 32).  W ogólności przez charakter funkcjonowania warstw konwolucyjnych, rozdzielczość i sama ilość zdjęć, czas uczenia jest dość długi, chociaż nie przekracza 1 godziny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79c02dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42/42 [==============================] - 27s 630ms/step - loss: 47.5339 - accuracy: 0.5246\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 26s 625ms/step - loss: 1.8403 - accuracy: 0.6897\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 27s 646ms/step - loss: 1.5047 - accuracy: 0.8021\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 28s 661ms/step - loss: 1.1573 - accuracy: 0.8408\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 27s 651ms/step - loss: 0.7600 - accuracy: 0.8713\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 29s 691ms/step - loss: 0.4510 - accuracy: 0.8951\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 28s 673ms/step - loss: 0.6834 - accuracy: 0.8810\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 28s 669ms/step - loss: 0.2176 - accuracy: 0.9211\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 29s 682ms/step - loss: 0.4008 - accuracy: 0.9003\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 27s 630ms/step - loss: 0.4126 - accuracy: 0.9263\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 28s 657ms/step - loss: 0.3930 - accuracy: 0.9323\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 28s 675ms/step - loss: 0.4292 - accuracy: 0.9591\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 28s 663ms/step - loss: 0.1792 - accuracy: 0.9524\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 28s 667ms/step - loss: 0.3048 - accuracy: 0.9472\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 28s 672ms/step - loss: 0.1050 - accuracy: 0.9747\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 28s 672ms/step - loss: 0.1692 - accuracy: 0.9702\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 28s 668ms/step - loss: 0.1039 - accuracy: 0.9740\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 29s 689ms/step - loss: 0.1564 - accuracy: 0.9702\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 29s 693ms/step - loss: 0.2086 - accuracy: 0.9635\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 26s 625ms/step - loss: 0.0450 - accuracy: 0.9896\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 26s 623ms/step - loss: 0.2704 - accuracy: 0.9635\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 25s 593ms/step - loss: 0.0992 - accuracy: 0.9799\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 26s 622ms/step - loss: 0.1040 - accuracy: 0.9814\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 28s 652ms/step - loss: 0.1874 - accuracy: 0.9740\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 29s 683ms/step - loss: 0.1577 - accuracy: 0.9799\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 27s 631ms/step - loss: 0.0350 - accuracy: 0.9926\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 28s 674ms/step - loss: 0.4830 - accuracy: 0.9814\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 28s 652ms/step - loss: 0.0859 - accuracy: 0.9851\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 26s 607ms/step - loss: 0.1347 - accuracy: 0.9807\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 29s 675ms/step - loss: 0.0442 - accuracy: 0.9888\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 29s 693ms/step - loss: 0.7068 - accuracy: 0.9814\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 27s 642ms/step - loss: 3.2640 - accuracy: 0.9658\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 27s 637ms/step - loss: 0.0551 - accuracy: 0.9874\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 27s 644ms/step - loss: 0.1810 - accuracy: 0.9851\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 27s 634ms/step - loss: 0.0356 - accuracy: 0.9911\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 28s 657ms/step - loss: 0.1549 - accuracy: 0.9792\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 27s 645ms/step - loss: 0.3086 - accuracy: 0.9754\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 26s 628ms/step - loss: 0.8571 - accuracy: 0.9814\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 27s 649ms/step - loss: 0.0910 - accuracy: 0.9896\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 28s 655ms/step - loss: 2.5348 - accuracy: 0.9740\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 27s 640ms/step - loss: 0.0753 - accuracy: 0.9896\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 27s 642ms/step - loss: 1.5766 - accuracy: 0.9725\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 27s 650ms/step - loss: 0.2794 - accuracy: 0.9866\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 26s 610ms/step - loss: 0.0704 - accuracy: 0.9903\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 27s 644ms/step - loss: 0.1880 - accuracy: 0.9799\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 27s 642ms/step - loss: 0.0803 - accuracy: 0.9955\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 27s 636ms/step - loss: 0.0982 - accuracy: 0.9896\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 27s 632ms/step - loss: 0.0566 - accuracy: 0.9888\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 27s 649ms/step - loss: 0.0549 - accuracy: 0.9896\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 26s 623ms/step - loss: 0.2253 - accuracy: 0.9896\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'precict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19608\\2177563535.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rmsprop\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'precict'"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",metrics=['accuracy'],loss='categorical_crossentropy')\n",
    "model.fit(x=train_dataset, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b98ac7",
   "metadata": {},
   "source": [
    "Powyższy błąd wynikał z lietrówki, nie należy się nim przejmować, został naprawiony i nie wpływa na sieć, ani jej uczenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f7d27a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 29s 646ms/step - loss: 11.9510 - accuracy: 0.3065\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 29s 700ms/step - loss: 1.5016 - accuracy: 0.3661\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 29s 686ms/step - loss: 1.2450 - accuracy: 0.4970\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 36s 870ms/step - loss: 0.9306 - accuracy: 0.6295\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.7584 - accuracy: 0.7195\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.6617 - accuracy: 0.7634\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 48s 1s/step - loss: 0.5751 - accuracy: 0.7894\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4729 - accuracy: 0.8371\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4254 - accuracy: 0.8579\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.3795 - accuracy: 0.8594\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 48s 1s/step - loss: 0.3113 - accuracy: 0.8862\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4746 - accuracy: 0.8668\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.2435 - accuracy: 0.9211\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.3259 - accuracy: 0.8891\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.2480 - accuracy: 0.9219\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.1932 - accuracy: 0.9323\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.2032 - accuracy: 0.9345\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2416 - accuracy: 0.9159\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2387 - accuracy: 0.9263\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.1959 - accuracy: 0.9435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd45e79c40>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.compile(optimizer=\"rmsprop\",metrics=['accuracy'],loss='categorical_crossentropy')\n",
    "model_2.fit(x=train_dataset, batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98fadc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 43s 934ms/step - loss: 29.0291 - accuracy: 0.4196\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 38s 904ms/step - loss: 1.4224 - accuracy: 0.5439\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 44s 1s/step - loss: 0.9090 - accuracy: 0.6994\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 42s 1s/step - loss: 0.7423 - accuracy: 0.7634\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 42s 1s/step - loss: 0.5227 - accuracy: 0.8147\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 42s 1s/step - loss: 0.4485 - accuracy: 0.8534\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 42s 993ms/step - loss: 0.3551 - accuracy: 0.8884\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 42s 1s/step - loss: 0.3665 - accuracy: 0.8839\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 43s 1s/step - loss: 0.2924 - accuracy: 0.9085\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.2793 - accuracy: 0.9189\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 42s 985ms/step - loss: 0.2528 - accuracy: 0.9010\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 41s 968ms/step - loss: 0.2574 - accuracy: 0.9115\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 44s 1s/step - loss: 0.2508 - accuracy: 0.9286\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 43s 1s/step - loss: 0.1733 - accuracy: 0.9509\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 44s 1s/step - loss: 0.1694 - accuracy: 0.9375\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 42s 991ms/step - loss: 0.2250 - accuracy: 0.9435\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 41s 978ms/step - loss: 0.1614 - accuracy: 0.9457\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 41s 973ms/step - loss: 0.3896 - accuracy: 0.9360\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 40s 955ms/step - loss: 0.1633 - accuracy: 0.9621\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 40s 952ms/step - loss: 0.1811 - accuracy: 0.9449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd45ed02e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.compile(optimizer=\"rmsprop\",metrics=['accuracy'],loss='categorical_crossentropy')\n",
    "model_3.fit(x=train_dataset, batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4eba3529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 20.4066 - accuracy: 0.5893\n",
      "Epoch 2/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 1.4358 - accuracy: 0.6815\n",
      "Epoch 3/40\n",
      "42/42 [==============================] - 42s 999ms/step - loss: 1.2692 - accuracy: 0.7463\n",
      "Epoch 4/40\n",
      "42/42 [==============================] - 42s 998ms/step - loss: 1.6438 - accuracy: 0.7902\n",
      "Epoch 5/40\n",
      "42/42 [==============================] - 42s 998ms/step - loss: 0.2696 - accuracy: 0.9115\n",
      "Epoch 6/40\n",
      "42/42 [==============================] - 40s 951ms/step - loss: 0.8702 - accuracy: 0.8757\n",
      "Epoch 7/40\n",
      "42/42 [==============================] - 42s 997ms/step - loss: 1.4060 - accuracy: 0.8750\n",
      "Epoch 8/40\n",
      "42/42 [==============================] - 42s 995ms/step - loss: 0.3786 - accuracy: 0.9115\n",
      "Epoch 9/40\n",
      "42/42 [==============================] - 41s 975ms/step - loss: 0.2147 - accuracy: 0.9360\n",
      "Epoch 10/40\n",
      "42/42 [==============================] - 44s 1s/step - loss: 0.5015 - accuracy: 0.8958\n",
      "Epoch 11/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.1751 - accuracy: 0.9546\n",
      "Epoch 12/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.1473 - accuracy: 0.9591\n",
      "Epoch 13/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.1609 - accuracy: 0.9479\n",
      "Epoch 14/40\n",
      "42/42 [==============================] - 44s 1s/step - loss: 0.1790 - accuracy: 0.9516\n",
      "Epoch 15/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.1111 - accuracy: 0.9688\n",
      "Epoch 16/40\n",
      "42/42 [==============================] - 44s 1s/step - loss: 0.1252 - accuracy: 0.9665\n",
      "Epoch 17/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.1975 - accuracy: 0.9658\n",
      "Epoch 18/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.1862 - accuracy: 0.9725\n",
      "Epoch 19/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.0407 - accuracy: 0.9911\n",
      "Epoch 20/40\n",
      "42/42 [==============================] - 44s 1s/step - loss: 0.2637 - accuracy: 0.9665\n",
      "Epoch 21/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.0429 - accuracy: 0.9888\n",
      "Epoch 22/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.2306 - accuracy: 0.9762\n",
      "Epoch 23/40\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.3208 - accuracy: 0.9702\n",
      "Epoch 24/40\n",
      "42/42 [==============================] - 44s 1s/step - loss: 0.0162 - accuracy: 0.9955\n",
      "Epoch 25/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.0993 - accuracy: 0.9792\n",
      "Epoch 26/40\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.3891 - accuracy: 0.9710\n",
      "Epoch 27/40\n",
      "42/42 [==============================] - 43s 1s/step - loss: 0.1500 - accuracy: 0.9777\n",
      "Epoch 28/40\n",
      "42/42 [==============================] - 42s 1s/step - loss: 0.0239 - accuracy: 0.9918\n",
      "Epoch 29/40\n",
      "42/42 [==============================] - 44s 1s/step - loss: 1.5142 - accuracy: 0.9717\n",
      "Epoch 30/40\n",
      "42/42 [==============================] - 44s 1s/step - loss: 0.0770 - accuracy: 0.9851\n",
      "Epoch 31/40\n",
      "42/42 [==============================] - 43s 1s/step - loss: 0.1400 - accuracy: 0.9829\n",
      "Epoch 32/40\n",
      "42/42 [==============================] - 42s 997ms/step - loss: 0.1048 - accuracy: 0.9866\n",
      "Epoch 33/40\n",
      "42/42 [==============================] - 43s 1s/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 34/40\n",
      "42/42 [==============================] - 42s 999ms/step - loss: 0.8524 - accuracy: 0.9851\n",
      "Epoch 35/40\n",
      "42/42 [==============================] - 43s 1s/step - loss: 8.7361e-04 - accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "42/42 [==============================] - 41s 982ms/step - loss: 5.2013e-05 - accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "42/42 [==============================] - 42s 993ms/step - loss: 1.6445 - accuracy: 0.9717\n",
      "Epoch 38/40\n",
      "42/42 [==============================] - 41s 969ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 39/40\n",
      "42/42 [==============================] - 42s 993ms/step - loss: 5.4501e-05 - accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "42/42 [==============================] - 42s 999ms/step - loss: 0.9073 - accuracy: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd459b6910>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.compile(optimizer=\"rmsprop\",metrics=['accuracy'],loss='categorical_crossentropy')\n",
    "model_4.fit(x=train_dataset, batch_size=32, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eee6f15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "42/42 [==============================] - 44s 1s/step - loss: 1.3631 - accuracy: 0.5074\n",
      "Epoch 2/40\n",
      "42/42 [==============================] - 43s 1s/step - loss: 0.7478 - accuracy: 0.7507\n",
      "Epoch 3/40\n",
      "42/42 [==============================] - 43s 1s/step - loss: 0.5256 - accuracy: 0.8214\n",
      "Epoch 4/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.4060 - accuracy: 0.8430\n",
      "Epoch 5/40\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.2940 - accuracy: 0.9025\n",
      "Epoch 6/40\n",
      "42/42 [==============================] - 48s 1s/step - loss: 0.2511 - accuracy: 0.9085\n",
      "Epoch 7/40\n",
      "42/42 [==============================] - 48s 1s/step - loss: 0.2413 - accuracy: 0.9293\n",
      "Epoch 8/40\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.1917 - accuracy: 0.9397\n",
      "Epoch 9/40\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.1237 - accuracy: 0.9568\n",
      "Epoch 10/40\n",
      "42/42 [==============================] - 48s 1s/step - loss: 0.1370 - accuracy: 0.9509\n",
      "Epoch 11/40\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.1692 - accuracy: 0.9501\n",
      "Epoch 12/40\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.1383 - accuracy: 0.9673\n",
      "Epoch 13/40\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.1037 - accuracy: 0.9732\n",
      "Epoch 14/40\n",
      "42/42 [==============================] - 43s 1s/step - loss: 0.1060 - accuracy: 0.9695\n",
      "Epoch 15/40\n",
      "42/42 [==============================] - 45s 1s/step - loss: 0.1859 - accuracy: 0.9717\n",
      "Epoch 16/40\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0960 - accuracy: 0.9740\n",
      "Epoch 17/40\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.0556 - accuracy: 0.9814\n",
      "Epoch 18/40\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0701 - accuracy: 0.9836\n",
      "Epoch 19/40\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.0717 - accuracy: 0.9821\n",
      "Epoch 20/40\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.0773 - accuracy: 0.9777\n",
      "Epoch 21/40\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0906 - accuracy: 0.9866\n",
      "Epoch 22/40\n",
      "42/42 [==============================] - 39s 918ms/step - loss: 0.0986 - accuracy: 0.9829\n",
      "Epoch 23/40\n",
      "42/42 [==============================] - 37s 869ms/step - loss: 0.0614 - accuracy: 0.9829\n",
      "Epoch 24/40\n",
      "42/42 [==============================] - 38s 892ms/step - loss: 0.0565 - accuracy: 0.9851\n",
      "Epoch 25/40\n",
      "42/42 [==============================] - 39s 910ms/step - loss: 0.0507 - accuracy: 0.9866\n",
      "Epoch 26/40\n",
      "42/42 [==============================] - 40s 953ms/step - loss: 0.1265 - accuracy: 0.9799\n",
      "Epoch 27/40\n",
      "42/42 [==============================] - 38s 903ms/step - loss: 0.0383 - accuracy: 0.9896\n",
      "Epoch 28/40\n",
      "42/42 [==============================] - 39s 918ms/step - loss: 0.0873 - accuracy: 0.9814\n",
      "Epoch 29/40\n",
      "42/42 [==============================] - 39s 924ms/step - loss: 0.0307 - accuracy: 0.9933\n",
      "Epoch 30/40\n",
      "42/42 [==============================] - 39s 926ms/step - loss: 0.0998 - accuracy: 0.9821\n",
      "Epoch 31/40\n",
      "42/42 [==============================] - 38s 903ms/step - loss: 0.0456 - accuracy: 0.9874\n",
      "Epoch 32/40\n",
      "42/42 [==============================] - 39s 935ms/step - loss: 0.0588 - accuracy: 0.9859\n",
      "Epoch 33/40\n",
      "42/42 [==============================] - 39s 932ms/step - loss: 0.0611 - accuracy: 0.9814\n",
      "Epoch 34/40\n",
      "42/42 [==============================] - 38s 914ms/step - loss: 0.0393 - accuracy: 0.9903\n",
      "Epoch 35/40\n",
      "42/42 [==============================] - 39s 925ms/step - loss: 0.0861 - accuracy: 0.9911\n",
      "Epoch 36/40\n",
      "42/42 [==============================] - 38s 893ms/step - loss: 0.0171 - accuracy: 0.9940\n",
      "Epoch 37/40\n",
      "42/42 [==============================] - 39s 924ms/step - loss: 0.1032 - accuracy: 0.9859\n",
      "Epoch 38/40\n",
      "42/42 [==============================] - 38s 897ms/step - loss: 0.0574 - accuracy: 0.9866\n",
      "Epoch 39/40\n",
      "42/42 [==============================] - 38s 912ms/step - loss: 0.0370 - accuracy: 0.9903\n",
      "Epoch 40/40\n",
      "42/42 [==============================] - 38s 910ms/step - loss: 0.0015 - accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd459b6700>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.compile(optimizer=\"rmsprop\",metrics=['accuracy'],loss='categorical_crossentropy')\n",
    "model_5.fit(x=train_dataset, batch_size=32, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7894b8b",
   "metadata": {},
   "source": [
    "Jak można było zauważyć, dla każdej z architektury osiągana wartość accuracy była niezwykle wysoka, wręcz przyrównywała się do jedynki. Podejrzanym faktorem jest potencjalne przeuczenie sieci bądź zbyt wielkie różnice w zdjęciach pomiędzy różnymi bazami danych, z których pochodziły dane. Zastosowanie zbioru walidacyjnego będzie konieczne przy zastosowaniu i konfiguracji naszego ostatecznego modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe66cc",
   "metadata": {},
   "source": [
    "## Dokonywanie predykcji oraz analizowanie poprawności modeli na danych testowych\n",
    "Na koniec dokonamy sprawdzenia miary accuracy (dane były zrównoważone) na danych testowych (również zbiór zrównoważony) dla poszczególnych modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2394d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcja pomocnicza do dokonywania predykcji\n",
    "def prepare_labels_test(model):\n",
    "    labels_pred = model.predict(test_dataset)\n",
    "    labels_predicted = []\n",
    "    for i in range(labels_pred.shape[0]):\n",
    "        labels_predicted.append(list(labels_pred[i]).index(max(labels_pred[i])))\n",
    "    return labels_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06ed14e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1\n",
    "labels = prepare_labels_test(model)\n",
    "accuracy_score(test_dataset.classes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e7592e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2325"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 2\n",
    "labels = prepare_labels_test(model_2)\n",
    "accuracy_score(test_dataset.classes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "76cb35c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2475"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 3\n",
    "labels = prepare_labels_test(model_3)\n",
    "accuracy_score(test_dataset.classes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0dc5a7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 4\n",
    "labels = prepare_labels_test(model_4)\n",
    "accuracy_score(test_dataset.classes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b06652e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 5\n",
    "labels = prepare_labels_test(model_5)\n",
    "accuracy_score(test_dataset.classes, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaef0d4",
   "metadata": {},
   "source": [
    "## Wnioski\n",
    "Poniżej zamieszczam streszczone wnioski oraz uwagi dla naszych modeli, które będziemy musieli wziąć pod uwagę przy wyborze naszego ostatecznego modelu (i jego modyfikacji).  \n",
    "- Niestety ale modele wykazywały się dość niską miarą accuracy na danych testowych (blisko zgadywania) oraz bardzo dużymi na zbiorze treningowym, co jest dość nadzwyczajne gdyż dane pochodziły z jednej próbki co oznacza, iż powiniśmy jeszcze raz sprawdzić (i być może wyeksplorować dane testowe i treningowe) dane\n",
    "- W zbiorze treningowym dysponowaliśmy 1344 zdjęciami, co może być niewystarczającą ilością i doszło do zwyczajnego przeuczenia się, będziemy musieli zwiększyć ilość danych .\n",
    "- należy wziąć pod uwagę skorzystanie z głębszej sieci, która lepiej wyekstraktuje cechy naszych danych, gdyż istnieje podejrzenie zbyt płytkiej architektury\n",
    "- przydałoby się dokonać przetasowania danych (shuffle) by zoptymalizować uczenie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
